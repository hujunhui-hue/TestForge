{"file": "black\\action\\main.py", "class_name": null, "function_name": "determine_version_specifier", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["print", "read_version_specifier_from_pyproject", "sys.exit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Determine the version of Black to install. The version can be specified either via the `with.version` input or via the pyproject.toml file if `with.use_pyproject` is set to `true`.", "source_code": "def determine_version_specifier() -> str:\n    \"\"\"Determine the version of Black to install.\n\n    The version can be specified either via the `with.version` input or via the\n    pyproject.toml file if `with.use_pyproject` is set to `true`.\n    \"\"\"\n    if USE_PYPROJECT and VERSION:\n        print(\n            \"::error::'with.version' and 'with.use_pyproject' inputs are \"\n            \"mutually exclusive.\",\n            file=sys.stderr,\n            flush=True,\n        )\n        sys.exit(1)\n    if USE_PYPROJECT:\n        return read_version_specifier_from_pyproject()\n    elif VERSION and VERSION[0] in \"0123456789\":\n        return f\"=={VERSION}\"\n    else:\n        return VERSION", "loc": 20}
{"file": "black\\action\\main.py", "class_name": null, "function_name": "find_black_version_in_array", "parameters": ["array"], "param_types": {"array": "object"}, "return_type": "Union[str, None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BLACK_VERSION_RE.match", "EXTRAS_RE.sub", "EXTRAS_RE.sub('', item).strip", "isinstance", "item.split", "m.group", "m.group(1).strip", "print", "sys.exit"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_black_version_in_array(array: object) -> Union[str, None]:\n    if not isinstance(array, list):\n        return None\n    try:\n        for item in array:\n            # Rudimentary PEP 508 parsing.\n            item = item.split(\";\")[0]\n            item = EXTRAS_RE.sub(\"\", item).strip()\n            if item == \"black\":\n                print(\n                    \"::error::Version specifier missing for 'black' dependency in \"\n                    \"pyproject.toml.\",\n                    file=sys.stderr,\n                    flush=True,\n                )\n                sys.exit(1)\n            elif m := BLACK_VERSION_RE.match(item):\n                return m.group(1).strip()\n    except TypeError:\n        pass\n\n    return None", "loc": 22}
{"file": "black\\docs\\conf.py", "class_name": null, "function_name": "handle_include_read", "parameters": ["app", "relative_path", "parent_docname", "content"], "param_types": {"app": "Sphinx", "relative_path": "Path", "parent_docname": "str", "content": "list[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["replace_pr_numbers_with_links"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Handler for the include-read sphinx event.", "source_code": "def handle_include_read(\n    app: Sphinx,\n    relative_path: Path,\n    parent_docname: str,\n    content: list[str],\n) -> None:\n    \"\"\"Handler for the include-read sphinx event.\"\"\"\n    if parent_docname == \"change_log\":\n        content[0] = replace_pr_numbers_with_links(content[0])", "loc": 9}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "get_pypi_download_url", "parameters": ["package", "version"], "param_types": {"package": "str", "version": "Optional[str]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "cast", "json.load", "metadata['releases'].keys", "urlopen"], "control_structures": ["For", "If"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def get_pypi_download_url(package: str, version: Optional[str]) -> str:\n    with urlopen(PYPI_INSTANCE + f\"/{package}/json\") as page:\n        metadata = json.load(page)\n\n    if version is None:\n        sources = metadata[\"urls\"]\n    else:\n        if version in metadata[\"releases\"]:\n            sources = metadata[\"releases\"][version]\n        else:\n            raise ValueError(\n                f\"No releases found with version ('{version}') tag. \"\n                f\"Found releases: {metadata['releases'].keys()}\"\n            )\n\n    for source in sources:\n        if source[\"python_version\"] == \"source\":\n            break\n    else:\n        raise ValueError(f\"Couldn't find any sources for {package}\")\n\n    return cast(str, source[\"url\"])", "loc": 22}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "get_top_packages", "parameters": [], "param_types": {}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["json.load", "urlopen"], "control_structures": [], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def get_top_packages() -> list[str]:\n    with urlopen(PYPI_TOP_PACKAGES) as page:\n        result = json.load(page)\n\n    return [package[\"project\"] for package in result[\"rows\"]]", "loc": 5}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "get_package_source", "parameters": ["package", "version"], "param_types": {"package": "str", "version": "Optional[str]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_pypi_download_url"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_package_source(package: str, version: Optional[str]) -> str:\n    if package == \"cpython\":\n        if version is None:\n            version = \"main\"\n        return f\"https://github.com/python/cpython/archive/{version}.zip\"\n    elif package == \"pypy\":\n        if version is None:\n            version = \"branch/default\"\n        return (\n            f\"https://foss.heptapod.net/pypy/pypy/repository/{version}/archive.tar.bz2\"\n        )\n    else:\n        return get_pypi_download_url(package, version)", "loc": 13}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "get_first_archive_member", "parameters": ["archive"], "param_types": {"archive": "ArchiveKind"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["archive.getnames", "archive.namelist", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_first_archive_member(archive: ArchiveKind) -> str:\n    if isinstance(archive, tarfile.TarFile):\n        return archive.getnames()[0]\n    elif isinstance(archive, zipfile.ZipFile):\n        return archive.namelist()[0]", "loc": 5}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "download_and_extract", "parameters": ["package", "version", "directory"], "param_types": {"package": "str", "version": "Optional[str]", "directory": "Path"}, "return_type": "Path", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["archive.extractall", "get_archive_manager", "get_first_archive_member", "get_package_source", "urlretrieve"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def download_and_extract(package: str, version: Optional[str], directory: Path) -> Path:\n    source = get_package_source(package, version)\n\n    local_file, _ = urlretrieve(source, directory / f\"{package}-src\")\n    with get_archive_manager(local_file) as archive:\n        archive.extractall(path=directory)\n        result_dir = get_first_archive_member(archive)\n    return directory / result_dir", "loc": 8}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "get_package", "parameters": ["package", "version", "directory"], "param_types": {"package": "str", "version": "Optional[str]", "directory": "Path"}, "return_type": "Optional[Path]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["download_and_extract", "print", "traceback.print_exc"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_package(\n    package: str, version: Optional[str], directory: Path\n) -> Optional[Path]:\n    try:\n        return download_and_extract(package, version, directory)\n    except Exception:\n        print(f\"Caught an exception while downloading {package}.\")\n        traceback.print_exc()\n        return None", "loc": 9}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "download_and_extract_top_packages", "parameters": ["directory", "workers", "limit"], "param_types": {"directory": "Path", "workers": "int", "limit": "slice"}, "return_type": "Generator[Path, None, None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ThreadPoolExecutor", "executor.map", "get_top_packages", "partial"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def download_and_extract_top_packages(\n    directory: Path,\n    workers: int = 8,\n    limit: slice = DEFAULT_SLICE,\n) -> Generator[Path, None, None]:\n    with ThreadPoolExecutor(max_workers=workers) as executor:\n        bound_downloader = partial(get_package, version=None, directory=directory)\n        for package in executor.map(bound_downloader, get_top_packages()[limit]):\n            if package is not None:\n                yield package", "loc": 10}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "git_switch_branch", "parameters": ["branch", "repo", "new", "from_branch"], "param_types": {"branch": "str", "repo": "Path", "new": "bool", "from_branch": "Optional[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["args.append", "subprocess.run"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def git_switch_branch(\n    branch: str, repo: Path, new: bool = False, from_branch: Optional[str] = None\n) -> None:\n    args = [\"git\", \"checkout\"]\n    if new:\n        args.append(\"-b\")\n    args.append(branch)\n    if from_branch:\n        args.append(from_branch)\n    subprocess.run(args, cwd=repo)", "loc": 10}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "init_repos", "parameters": ["options"], "param_types": {"options": "Namespace"}, "return_type": "tuple[Path, ...]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["download_and_extract", "download_and_extract_top_packages", "git_create_repository", "options.output.mkdir", "slice", "subprocess.run", "tuple"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def init_repos(options: Namespace) -> tuple[Path, ...]:\n    options.output.mkdir(exist_ok=True)\n\n    if options.top_packages:\n        source_directories = tuple(\n            download_and_extract_top_packages(\n                directory=options.output,\n                workers=options.workers,\n                limit=slice(None, options.top_packages),\n            )\n        )\n    else:\n        source_directories = (\n            download_and_extract(\n                package=options.pypi_package,\n                version=options.version,\n                directory=options.output,\n            ),\n        )\n\n    for source_directory in source_directories:\n        git_create_repository(source_directory)\n\n    if options.black_repo is None:\n        subprocess.run(\n            [\"git\", \"clone\", \"https://github.com/psf/black.git\", INTERNAL_BLACK_REPO],\n            cwd=options.output,\n        )\n        options.black_repo = options.output / INTERNAL_BLACK_REPO\n\n    return source_directories", "loc": 31}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "black_runner", "parameters": ["version", "black_repo"], "param_types": {"version": "str", "black_repo": "Path"}, "return_type": "Path", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "atexit.register", "lru_cache", "subprocess.run", "tempfile.TemporaryDirectory", "venv.create"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def black_runner(version: str, black_repo: Path) -> Path:\n    directory = tempfile.TemporaryDirectory()\n    venv.create(directory.name, with_pip=True)\n\n    python = Path(directory.name) / \"bin\" / \"python\"\n    subprocess.run([python, \"-m\", \"pip\", \"install\", \"-e\", black_repo])\n\n    atexit.register(directory.cleanup)\n    return python", "loc": 9}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "format_repo_with_version", "parameters": ["repo", "from_branch", "black_repo", "black_version", "input_directory"], "param_types": {"repo": "Path", "from_branch": "Optional[str]", "black_repo": "Path", "black_version": "BlackVersion", "input_directory": "Path"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["black_repo / 'black.py'.resolve", "black_runner", "format_cmd.extend", "git_add_and_commit", "git_switch_branch", "subprocess.run"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_repo_with_version(\n    repo: Path,\n    from_branch: Optional[str],\n    black_repo: Path,\n    black_version: BlackVersion,\n    input_directory: Path,\n) -> str:\n    current_branch = f\"black-{black_version.version}\"\n    git_switch_branch(black_version.version, repo=black_repo)\n    git_switch_branch(current_branch, repo=repo, new=True, from_branch=from_branch)\n\n    format_cmd: list[Union[Path, str]] = [\n        black_runner(black_version.version, black_repo),\n        (black_repo / \"black.py\").resolve(),\n        \".\",\n    ]\n    if black_version.config:\n        format_cmd.extend([\"--config\", input_directory / black_version.config])\n\n    subprocess.run(format_cmd, cwd=repo, check=False)  # ensure the process\n    # continuess to run even it can't format some files. Reporting those\n    # should be enough\n    git_add_and_commit(f\"Format with black:{black_version.version}\", repo=repo)\n\n    return current_branch", "loc": 25}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "format_repos", "parameters": ["repos", "options"], "param_types": {"repos": "tuple[Path, ...]", "options": "Namespace"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BlackVersion", "format_repo_with_version", "git_switch_branch", "tuple", "version.split"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_repos(repos: tuple[Path, ...], options: Namespace) -> None:\n    black_versions = tuple(\n        BlackVersion(*version.split(\":\")) for version in options.versions\n    )\n\n    for repo in repos:\n        from_branch = None\n        for black_version in black_versions:\n            from_branch = format_repo_with_version(\n                repo=repo,\n                from_branch=from_branch,\n                black_repo=options.black_repo,\n                black_version=black_version,\n                input_directory=options.input,\n            )\n        git_switch_branch(\"main\", repo=repo)\n\n    git_switch_branch(\"main\", repo=options.black_repo)", "loc": 18}
{"file": "black\\gallery\\gallery.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ArgumentParser", "Path", "format_repos", "group.add_argument", "init_repos", "parser.add_argument", "parser.add_mutually_exclusive_group", "parser.parse_args"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main() -> None:\n    parser = ArgumentParser(description=\"\"\"Black Gallery is a script that\n    automates the process of applying different Black versions to a selected\n    PyPI package and seeing the results between versions.\"\"\")\n\n    group = parser.add_mutually_exclusive_group(required=True)\n    group.add_argument(\"-p\", \"--pypi-package\", help=\"PyPI package to download.\")\n    group.add_argument(\n        \"-t\", \"--top-packages\", help=\"Top n PyPI packages to download.\", type=int\n    )\n\n    parser.add_argument(\"-b\", \"--black-repo\", help=\"Black's Git repository.\", type=Path)\n    parser.add_argument(\n        \"-v\",\n        \"--version\",\n        help=(\n            \"Version for given PyPI package. Will be discarded if used with -t option.\"\n        ),\n    )\n    parser.add_argument(\n        \"-w\",\n        \"--workers\",\n        help=(\n            \"Maximum number of threads to download with at the same time. \"\n            \"Will be discarded if used with -p option.\"\n        ),\n    )\n    parser.add_argument(\n        \"-i\",\n        \"--input\",\n        default=Path(\"/input\"),\n        type=Path,\n        help=\"Input directory to read configuration.\",\n    )\n    parser.add_argument(\n        \"-o\",\n        \"--output\",\n        default=Path(\"/output\"),\n        type=Path,\n        help=\"Output directory to download and put result artifacts.\",\n    )\n    parser.add_argument(\"versions\", nargs=\"*\", default=(\"main\",), help=\"\")\n\n    options = parser.parse_args()\n    repos = init_repos(options)\n    format_repos(repos, options)", "loc": 46}
{"file": "black\\scripts\\check_pre_commit_rev_in_example.py", "class_name": null, "function_name": "main", "parameters": ["changes", "source_version_control"], "param_types": {"changes": "str", "source_version_control": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BeautifulSoup", "changes_soup.find_all", "commonmark.commonmark", "print", "source_version_control_soup.find", "sys.exit", "yaml.safe_load"], "control_structures": ["For", "If"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def main(changes: str, source_version_control: str) -> None:\n    changes_html = commonmark.commonmark(changes)\n    changes_soup = BeautifulSoup(changes_html, \"html.parser\")\n    headers = changes_soup.find_all(\"h2\")\n    latest_tag, *_ = [\n        header.string for header in headers if header.string != \"Unreleased\"\n    ]\n\n    source_version_control_html = commonmark.commonmark(source_version_control)\n    source_version_control_soup = BeautifulSoup(\n        source_version_control_html, \"html.parser\"\n    )\n    pre_commit_repos = yaml.safe_load(\n        source_version_control_soup.find(class_=\"language-yaml\").string\n    )[\"repos\"]\n\n    for repo in pre_commit_repos:\n        pre_commit_rev = repo[\"rev\"]\n        if not pre_commit_rev == latest_tag:\n            print(\n                \"Please set the rev in ``source_version_control.md`` to be the latest \"\n                f\"one.\\nExpected {latest_tag}, got {pre_commit_rev}.\\n\"\n            )\n            sys.exit(1)", "loc": 24}
{"file": "black\\scripts\\check_version_in_basics_example.py", "class_name": null, "function_name": "main", "parameters": ["changes", "the_basics"], "param_types": {"changes": "str", "the_basics": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BeautifulSoup", "changes_soup.find_all", "commonmark.commonmark", "print", "sys.exit", "the_basics_soup.find_all"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main(changes: str, the_basics: str) -> None:\n    changes_html = commonmark.commonmark(changes)\n    changes_soup = BeautifulSoup(changes_html, \"html.parser\")\n    headers = changes_soup.find_all(\"h2\")\n    tags = [header.string for header in headers if header.string != \"Unreleased\"]\n    latest_tag = tags[0]\n\n    the_basics_html = commonmark.commonmark(the_basics)\n    the_basics_soup = BeautifulSoup(the_basics_html, \"html.parser\")\n    version_examples = [\n        code_block.string\n        for code_block in the_basics_soup.find_all(class_=\"language-console\")\n        if \"$ black --version\" in code_block.string\n    ]\n\n    for tag in tags:\n        for version_example in version_examples:\n            if tag in version_example and tag != latest_tag:\n                print(\n                    \"Please set the version in the ``black --version`` \"\n                    \"examples from ``the_basics.md`` to be the latest one.\\n\"\n                    f\"Expected {latest_tag}, got {tag}.\\n\"\n                )\n                sys.exit(1)", "loc": 24}
{"file": "black\\scripts\\diff_shades_gha_helper.py", "class_name": null, "function_name": "http_get", "parameters": ["url"], "param_types": {"url": "str"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "dict", "http.request", "json.loads", "kwargs.get", "pprint.pprint", "print", "r.data.decode", "r.geturl", "r.info"], "control_structures": ["If"], "behavior_type": ["network_io", "serialization"], "doc_summary": "", "source_code": "def http_get(url: str, *, is_json: bool = True, **kwargs: Any) -> Any:\n    headers = kwargs.get(\"headers\") or {}\n    headers[\"User-Agent\"] = USER_AGENT\n    if \"github\" in url:\n        if GH_API_TOKEN:\n            headers[\"Authorization\"] = f\"token {GH_API_TOKEN}\"\n        headers[\"Accept\"] = \"application/vnd.github.v3+json\"\n    kwargs[\"headers\"] = headers\n\n    r = http.request(\"GET\", url, **kwargs)\n    if is_json:\n        data = json.loads(r.data.decode(\"utf-8\"))\n    else:\n        data = r.data\n    print(f\"[INFO]: issued GET request for {r.geturl()}\")\n    if not (200 <= r.status < 300):\n        pprint.pprint(dict(r.info()))\n        pprint.pprint(data)\n        raise RuntimeError(f\"unexpected status code: {r.status}\")\n\n    return data", "loc": 21}
{"file": "black\\scripts\\diff_shades_gha_helper.py", "class_name": null, "function_name": "config", "parameters": ["event"], "param_types": {"event": "Literal['push', 'pull_request']"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["click.Choice", "click.argument", "get_main_revision", "get_pr_revision", "get_pypi_version", "int", "json.dumps", "main.command", "os.getenv", "platform.python_version", "platform.system", "pprint.pprint", "set_output", "str"], "control_structures": ["For", "If"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def config(event: Literal[\"push\", \"pull_request\"]) -> None:\n    import diff_shades  # type: ignore[import-not-found]\n\n    if event == \"push\":\n        jobs = [{\"mode\": \"preview-new-changes\", \"force-flag\": \"--force-unstable-style\"}]\n        # Push on main, let's use PyPI Black as the baseline.\n        baseline_name = str(get_pypi_version())\n        baseline_cmd = f\"git checkout {baseline_name}\"\n        target_rev = os.getenv(\"GITHUB_SHA\")\n        assert target_rev is not None\n        target_name = \"main-\" + target_rev[:SHA_LENGTH]\n        target_cmd = f\"git checkout {target_rev}\"\n\n    elif event == \"pull_request\":\n        jobs = [\n            {\"mode\": \"preview-new-changes\", \"force-flag\": \"--force-unstable-style\"},\n            {\"mode\": \"assert-no-changes\", \"force-flag\": \"--force-stable-style\"},\n        ]\n        # PR, let's use main as the baseline.\n        baseline_rev = get_main_revision()\n        baseline_name = \"main-\" + baseline_rev[:SHA_LENGTH]\n        baseline_cmd = f\"git checkout {baseline_rev}\"\n        pr_ref = os.getenv(\"GITHUB_REF\")\n        assert pr_ref is not None\n        pr_num = int(pr_ref[10:-6])\n        pr_rev = get_pr_revision(pr_num)\n        target_name = f\"pr-{pr_num}-{pr_rev[:SHA_LENGTH]}\"\n        target_cmd = f\"gh pr checkout {pr_num} && git merge origin/main\"\n\n    env = f\"{platform.system()}-{platform.python_version()}-{diff_shades.__version__}\"\n    for entry in jobs:\n        entry[\"baseline-analysis\"] = f\"{entry['mode']}-{baseline_name}.json\"\n        entry[\"baseline-setup-cmd\"] = baseline_cmd\n        entry[\"target-analysis\"] = f\"{entry['mode']}-{target_name}.json\"\n        entry[\"target-setup-cmd\"] = target_cmd\n        entry[\"baseline-cache-key\"] = f\"{env}-{baseline_name}-{entry['mode']}\"\n        if event == \"pull_request\":\n            # These are only needed for the PR comment.\n            entry[\"baseline-sha\"] = baseline_rev\n            entry[\"target-sha\"] = pr_rev\n\n    set_output(\"matrix\", json.dumps(jobs, indent=None))\n    pprint.pprint(jobs)", "loc": 43}
{"file": "black\\scripts\\diff_shades_gha_helper.py", "class_name": null, "function_name": "comment_body", "parameters": ["baseline", "target", "baseline_sha", "target_sha", "pr_num"], "param_types": {"baseline": "Path", "target": "Path", "baseline_sha": "str", "target_sha": "str", "pr_num": "int"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["click.Path", "click.argument", "json.dump", "main.command", "open", "print", "proc.stdout.strip", "str", "subprocess.run"], "control_structures": ["If"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def comment_body(\n    baseline: Path, target: Path, baseline_sha: str, target_sha: str, pr_num: int\n) -> None:\n    # fmt: off\n    cmd = [\n        sys.executable, \"-m\", \"diff_shades\", \"--no-color\",\n        \"compare\", str(baseline), str(target), \"--quiet\", \"--check\"\n    ]\n    # fmt: on\n    proc = subprocess.run(cmd, stdout=subprocess.PIPE, encoding=\"utf-8\")\n    if not proc.returncode:\n        body = (\n            f\"**diff-shades** reports zero changes comparing this PR ({target_sha}) to\"\n            f\" main ({baseline_sha}).\\n\\n---\\n\\n\"\n        )\n    else:\n        body = (\n            f\"**diff-shades** results comparing this PR ({target_sha}) to main\"\n            f\" ({baseline_sha}). The full diff is [available in the logs]\"\n            f'($job-diff-url) under the \"{DIFF_STEP_NAME}\" step.'\n        )\n        body += \"\\n```text\\n\" + proc.stdout.strip() + \"\\n```\\n\"\n    body += (\n        f\"[**What is this?**]({DOCS_URL}) | [Workflow run]($workflow-run-url) |\"\n        \" [diff-shades documentation](https://github.com/ichard26/diff-shades#readme)\"\n    )\n    print(f\"[INFO]: writing comment details to {COMMENT_FILE}\")\n    with open(COMMENT_FILE, \"w\", encoding=\"utf-8\") as f:\n        json.dump({\"body\": body, \"pr-number\": pr_num}, f)", "loc": 29}
{"file": "black\\scripts\\diff_shades_gha_helper.py", "class_name": null, "function_name": "comment_details", "parameters": ["run_id"], "param_types": {"run_id": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BytesIO", "body.replace", "click.argument", "http_get", "json.loads", "main.command", "next", "rf.read", "rf.read().decode", "set_output", "str", "zfile.open", "zipfile.ZipFile"], "control_structures": ["If"], "behavior_type": ["file_io", "network_io", "serialization"], "doc_summary": "", "source_code": "def comment_details(run_id: str) -> None:\n    data = http_get(f\"https://api.github.com/repos/{REPO}/actions/runs/{run_id}\")\n    if data[\"event\"] != \"pull_request\" or data[\"conclusion\"] == \"cancelled\":\n        set_output(\"needs-comment\", \"false\")\n        return\n\n    set_output(\"needs-comment\", \"true\")\n    jobs = http_get(data[\"jobs_url\"])[\"jobs\"]\n    job = next(j for j in jobs if j[\"name\"] == \"analysis / preview-new-changes\")\n    diff_step = next(s for s in job[\"steps\"] if s[\"name\"] == DIFF_STEP_NAME)\n    diff_url = job[\"html_url\"] + f\"#step:{diff_step['number']}:1\"\n\n    artifacts = http_get(data[\"artifacts_url\"])[\"artifacts\"]\n    comment_artifact = next(a for a in artifacts if a[\"name\"] == COMMENT_FILE)\n    comment_url = comment_artifact[\"archive_download_url\"]\n    comment_zip = BytesIO(http_get(comment_url, is_json=False))\n    with zipfile.ZipFile(comment_zip) as zfile:\n        with zfile.open(COMMENT_FILE) as rf:\n            comment_data = json.loads(rf.read().decode(\"utf-8\"))\n\n    set_output(\"pr-number\", str(comment_data[\"pr-number\"]))\n    body = comment_data[\"body\"]\n    # It's more convenient to fill in these fields after the first workflow is done\n    # since this command can access the workflows API (doing it in the main workflow\n    # while it's still in progress seems impossible).\n    body = body.replace(\"$workflow-run-url\", data[\"html_url\"])\n    body = body.replace(\"$job-diff-url\", diff_url)\n    set_output(\"comment-body\", body)", "loc": 28}
{"file": "black\\scripts\\fuzz.py", "class_name": null, "function_name": "test_idempotent_any_syntatically_valid_python", "parameters": ["src_contents", "mode"], "param_types": {"src_contents": "str", "mode": "black.FileMode"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["black.assert_equivalent", "black.assert_stable", "black.format_str", "compile", "given", "hypothesmith.from_grammar", "hypothesmith.from_node", "list", "settings", "st.booleans", "st.builds", "st.integers", "st.just"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def test_idempotent_any_syntatically_valid_python(\n    src_contents: str, mode: black.FileMode\n) -> None:\n    if (\n        \"#\\r\" in src_contents or \"\\\\\\n\" in src_contents\n    ) and black.Preview.normalize_cr_newlines not in mode:\n        return\n\n    # Before starting, let's confirm that the input string is valid Python:\n    compile(src_contents, \"<string>\", \"exec\")  # else the bug is in hypothesmith\n\n    # Then format the code...\n    dst_contents = black.format_str(src_contents, mode=mode)\n\n    # And check that we got equivalent and stable output.\n    black.assert_equivalent(src_contents, dst_contents)\n    black.assert_stable(src_contents, dst_contents, mode=mode)", "loc": 17}
{"file": "black\\scripts\\generate_schema.py", "class_name": null, "function_name": "generate_schema_from_click", "parameters": ["cmd"], "param_types": {"cmd": "click.Command"}, "return_type": "dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TypeError", "isinstance", "param.name.replace", "param.to_info_dict"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def generate_schema_from_click(\n    cmd: click.Command,\n) -> dict[str, Any]:\n    result: dict[str, dict[str, Any]] = {}\n    for param in cmd.params:\n        if not isinstance(param, click.Option) or param.is_eager:\n            continue\n\n        assert param.name\n        name = param.name.replace(\"_\", \"-\")\n\n        result[name] = {}\n\n        match param.type:\n            case click.types.IntParamType():\n                result[name][\"type\"] = \"integer\"\n            case click.types.StringParamType() | click.types.Path():\n                result[name][\"type\"] = \"string\"\n            case click.types.Choice(choices=choices):\n                result[name][\"enum\"] = choices\n            case click.types.BoolParamType():\n                result[name][\"type\"] = \"boolean\"\n            case _:\n                msg = f\"{param.type!r} not a known type for {param}\"\n                raise TypeError(msg)\n\n        if param.multiple:\n            result[name] = {\"type\": \"array\", \"items\": result[name]}\n\n        result[name][\"description\"] = param.help\n\n        default = param.to_info_dict()[\"default\"]\n        if default is not None and not param.multiple:\n            result[name][\"default\"] = default\n\n    return result", "loc": 36}
{"file": "black\\scripts\\generate_schema.py", "class_name": null, "function_name": "main", "parameters": ["schemastore", "outfile"], "param_types": {"schemastore": "bool", "outfile": "IO[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["click.File", "click.command", "click.option", "generate_schema_from_click", "json.dumps", "print"], "control_structures": ["If"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def main(schemastore: bool, outfile: IO[str]) -> None:\n    properties = generate_schema_from_click(black.main)\n    del properties[\"line-ranges\"]\n\n    schema: dict[str, Any] = {\n        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n        \"$id\": (\n            \"https://github.com/psf/black/blob/main/src/black/resources/black.schema.json\"\n        ),\n        \"$comment\": \"tool.black table in pyproject.toml\",\n        \"type\": \"object\",\n        \"additionalProperties\": False,\n        \"properties\": properties,\n    }\n\n    if schemastore:\n        schema[\"$id\"] = \"https://json.schemastore.org/partial-black.json\"\n        # The precise list of unstable features may change frequently, so don't\n        # bother putting it in SchemaStore\n        schema[\"properties\"][\"enable-unstable-feature\"][\"items\"] = {\"type\": \"string\"}\n\n    print(json.dumps(schema, indent=2), file=outfile)", "loc": 22}
{"file": "black\\scripts\\make_width_table.py", "class_name": null, "function_name": "make_width_table", "parameters": [], "param_types": {}, "return_type": "Iterable[tuple[int, int, int]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["chr", "range", "wcwidth.wcwidth"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_width_table() -> Iterable[tuple[int, int, int]]:\n    start_codepoint = -1\n    end_codepoint = -1\n    range_width = -2\n    for codepoint in range(0, sys.maxunicode + 1):\n        width = wcwidth.wcwidth(chr(codepoint))\n        if width <= 1:\n            # Ignore narrow characters along with zero-width characters so that\n            # they are treated as single-width.  Note that treating zero-width\n            # characters as single-width is consistent with the heuristics built\n            # on top of str.isascii() in the str_width() function in strings.py.\n            continue\n        if start_codepoint < 0:\n            start_codepoint = codepoint\n            range_width = width\n        elif width != range_width or codepoint != end_codepoint + 1:\n            yield (start_codepoint, end_codepoint, range_width)\n            start_codepoint = codepoint\n            range_width = width\n        end_codepoint = codepoint\n    if start_codepoint >= 0:\n        yield (start_codepoint, end_codepoint, range_width)", "loc": 22}
{"file": "black\\scripts\\release.py", "class_name": null, "function_name": "get_git_tags", "parameters": ["versions_only"], "param_types": {"versions_only": "bool"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["LOG.error", "cp.stdout.splitlines", "run", "t[0].isdigit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Pull out all tags or calvers only", "source_code": "def get_git_tags(versions_only: bool = True) -> list[str]:\n    \"\"\"Pull out all tags or calvers only\"\"\"\n    cp = run([\"git\", \"tag\"], capture_output=True, check=True, encoding=\"utf8\")\n    if not cp.stdout:\n        LOG.error(f\"Returned no git tags stdout: {cp.stderr}\")\n        raise NoGitTagsError\n    git_tags = cp.stdout.splitlines()\n    if versions_only:\n        return [t for t in git_tags if t[0].isdigit()]\n    return git_tags", "loc": 10}
{"file": "black\\scripts\\release.py", "class_name": null, "function_name": "tuple_calver", "parameters": ["calver"], "param_types": {"calver": "str"}, "return_type": "tuple[int, ...]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["calver.split", "map", "tuple"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Convert a calver string into a tuple of ints for sorting", "source_code": "def tuple_calver(calver: str) -> tuple[int, ...]:  # mypy can't notice maxsplit below\n    \"\"\"Convert a calver string into a tuple of ints for sorting\"\"\"\n    try:\n        return tuple(map(int, calver.split(\".\", maxsplit=2)))\n    except ValueError:\n        return (0, 0, 0)", "loc": 6}
{"file": "black\\scripts\\release.py", "class_name": null, "function_name": "parse_args", "parameters": [], "param_types": {}, "return_type": "argparse.Namespace", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_handle_debug", "argparse.ArgumentParser", "parser.add_argument", "parser.parse_args"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"-a\",\n        \"--add-changes-template\",\n        action=\"store_true\",\n        help=\"Add the Unreleased template to CHANGES.md\",\n    )\n    parser.add_argument(\n        \"-d\", \"--debug\", action=\"store_true\", help=\"Verbose debug output\"\n    )\n    args = parser.parse_args()\n    _handle_debug(args.debug)\n    return args", "loc": 14}
{"file": "black\\scripts\\release.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["LOG.info", "Path", "SourceFiles", "parse_args", "sf.add_template_to_changes", "sf.update_repo_for_release"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main() -> int:\n    args = parse_args()\n\n    # Need parent.parent cause script is in scripts/ directory\n    sf = SourceFiles(Path(__file__).parent.parent)\n\n    if args.add_changes_template:\n        return sf.add_template_to_changes()\n\n    LOG.info(f\"Current version detected to be {sf.current_version}\")\n    LOG.info(f\"Next version will be {sf.next_version}\")\n    return sf.update_repo_for_release()", "loc": 12}
{"file": "black\\scripts\\release.py", "class_name": "SourceFiles", "function_name": "get_next_version", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["base_calver.split", "datetime.today", "datetime.today().strftime", "get_git_tags", "int", "len", "same_month_releases[-1].split", "t.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Workout the year and month + version number we need to move to", "source_code": "def get_next_version(self) -> str:\n    \"\"\"Workout the year and month + version number we need to move to\"\"\"\n    base_calver = datetime.today().strftime(\"%y.%m\")\n    calver_parts = base_calver.split(\".\")\n    base_calver = f\"{calver_parts[0]}.{int(calver_parts[1])}\"  # Remove leading 0\n    git_tags = get_git_tags()\n    same_month_releases = [\n        t for t in git_tags if t.startswith(base_calver) and \"a\" not in t\n    ]\n    if len(same_month_releases) < 1:\n        return f\"{base_calver}.0\"\n    same_month_version = same_month_releases[-1].split(\".\", 2)[-1]\n    return f\"{base_calver}.{int(same_month_version) + 1}\"", "loc": 13}
{"file": "black\\scripts\\release.py", "class_name": "SourceFiles", "function_name": "update_repo_for_release", "parameters": ["self"], "param_types": {}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.cleanup_changes_template_for_release", "self.update_version_in_docs"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Update CHANGES.md + doc files ready for release", "source_code": "def update_repo_for_release(self) -> int:\n    \"\"\"Update CHANGES.md + doc files ready for release\"\"\"\n    self.cleanup_changes_template_for_release()\n    self.update_version_in_docs()\n    return 0  # return 0 if no exceptions hit", "loc": 5}
{"file": "black\\src\\black\\brackets.py", "class_name": null, "function_name": "is_split_after_delimiter", "parameters": ["leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "Priority", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the priority of the `leaf` delimiter, given a line break after it. The delimiter priorities returned here are from those delimiters that would cause a line break after themselves.", "source_code": "def is_split_after_delimiter(leaf: Leaf) -> Priority:\n    \"\"\"Return the priority of the `leaf` delimiter, given a line break after it.\n\n    The delimiter priorities returned here are from those delimiters that would\n    cause a line break after themselves.\n\n    Higher numbers are higher priority.\n    \"\"\"\n    if leaf.type == token.COMMA:\n        return COMMA_PRIORITY\n\n    return 0", "loc": 12}
{"file": "black\\src\\black\\brackets.py", "class_name": null, "function_name": "is_split_before_delimiter", "parameters": ["leaf", "previous"], "param_types": {"leaf": "Leaf", "previous": "Optional[Leaf]"}, "return_type": "Priority", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_vararg", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the priority of the `leaf` delimiter, given a line break before it. The delimiter priorities returned here are from those delimiters that would cause a line break before themselves.", "source_code": "def is_split_before_delimiter(leaf: Leaf, previous: Optional[Leaf] = None) -> Priority:\n    \"\"\"Return the priority of the `leaf` delimiter, given a line break before it.\n\n    The delimiter priorities returned here are from those delimiters that would\n    cause a line break before themselves.\n\n    Higher numbers are higher priority.\n    \"\"\"\n    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):\n        # * and ** might also be MATH_OPERATORS but in this case they are not.\n        # Don't treat them as a delimiter.\n        return 0\n\n    if (\n        leaf.type == token.DOT\n        and leaf.parent\n        and leaf.parent.type not in {syms.import_from, syms.dotted_name}\n        and (previous is None or previous.type in CLOSING_BRACKETS)\n    ):\n        return DOT_PRIORITY\n\n    if (\n        leaf.type in MATH_OPERATORS\n        and leaf.parent\n        and leaf.parent.type not in {syms.factor, syms.star_expr}\n    ):\n        return MATH_PRIORITIES[leaf.type]\n\n    if leaf.type in COMPARATORS:\n        return COMPARATOR_PRIORITY\n\n    if (\n        leaf.type == token.STRING\n        and previous is not None\n        and previous.type == token.STRING\n    ):\n        return STRING_PRIORITY\n\n    if leaf.type not in {token.NAME, token.ASYNC}:\n        return 0\n\n    if (\n        leaf.value == \"for\"\n        and leaf.parent\n        and leaf.parent.type in {syms.comp_for, syms.old_comp_for}\n        or leaf.type == token.ASYNC\n    ):\n        if (\n            not isinstance(leaf.prev_sibling, Leaf)\n            or leaf.prev_sibling.value != \"async\"\n        ):\n            return COMPREHENSION_PRIORITY\n\n    if (\n        leaf.value == \"if\"\n        and leaf.parent\n        and leaf.parent.type in {syms.comp_if, syms.old_comp_if}\n    ):\n        return COMPREHENSION_PRIORITY\n\n    if leaf.value in {\"if\", \"else\"} and leaf.parent and leaf.parent.type == syms.test:\n        return TERNARY_PRIORITY\n\n    if leaf.value == \"is\":\n        return COMPARATOR_PRIORITY\n\n    if (\n        leaf.value == \"in\"\n        and leaf.parent\n        and leaf.parent.type in {syms.comp_op, syms.comparison}\n        and not (\n            previous is not None\n            and previous.type == token.NAME\n            and previous.value == \"not\"\n        )\n    ):\n        return COMPARATOR_PRIORITY\n\n    if (\n        leaf.value == \"not\"\n        and leaf.parent\n        and leaf.parent.type == syms.comp_op\n        and not (\n            previous is not None\n            and previous.type == token.NAME\n            and previous.value == \"is\"\n        )\n    ):\n        return COMPARATOR_PRIORITY\n\n    if leaf.value in LOGIC_OPERATORS and leaf.parent:\n        return LOGIC_PRIORITY\n\n    return 0", "loc": 94}
{"file": "black\\src\\black\\brackets.py", "class_name": null, "function_name": "max_delimiter_priority_in_atom", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "Priority", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BracketTracker", "bt.mark", "bt.max_delimiter_priority", "c.leaves", "isinstance"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Return maximum delimiter priority inside `node`. This is specific to atoms with contents contained in a pair of parentheses. If `node` isn't an atom or there are no enclosing parentheses, returns 0.", "source_code": "def max_delimiter_priority_in_atom(node: LN) -> Priority:\n    \"\"\"Return maximum delimiter priority inside `node`.\n\n    This is specific to atoms with contents contained in a pair of parentheses.\n    If `node` isn't an atom or there are no enclosing parentheses, returns 0.\n    \"\"\"\n    if node.type != syms.atom:\n        return 0\n\n    first = node.children[0]\n    last = node.children[-1]\n    if not (first.type == token.LPAR and last.type == token.RPAR):\n        return 0\n\n    bt = BracketTracker()\n    for c in node.children[1:-1]:\n        if isinstance(c, Leaf):\n            bt.mark(c)\n        else:\n            for leaf in c.leaves():\n                bt.mark(leaf)\n    try:\n        return bt.max_delimiter_priority()\n\n    except ValueError:\n        return 0", "loc": 26}
{"file": "black\\src\\black\\brackets.py", "class_name": null, "function_name": "get_leaves_inside_matching_brackets", "parameters": ["leaves"], "param_types": {"leaves": "Sequence[Leaf]"}, "return_type": "set[LeafID]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bracket_stack.append", "bracket_stack.pop", "enumerate", "id", "ids.add", "len", "next", "range", "set"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Return leaves that are inside matching brackets. The input `leaves` can have non-matching brackets at the head or tail parts. Matching brackets are included.", "source_code": "def get_leaves_inside_matching_brackets(leaves: Sequence[Leaf]) -> set[LeafID]:\n    \"\"\"Return leaves that are inside matching brackets.\n\n    The input `leaves` can have non-matching brackets at the head or tail parts.\n    Matching brackets are included.\n    \"\"\"\n    try:\n        # Start with the first opening bracket and ignore closing brackets before.\n        start_index = next(\n            i for i, l in enumerate(leaves) if l.type in OPENING_BRACKETS\n        )\n    except StopIteration:\n        return set()\n    bracket_stack = []\n    ids = set()\n    for i in range(start_index, len(leaves)):\n        leaf = leaves[i]\n        if leaf.type in OPENING_BRACKETS:\n            bracket_stack.append((BRACKET[leaf.type], i))\n        if leaf.type in CLOSING_BRACKETS:\n            if bracket_stack and leaf.type == bracket_stack[-1][0]:\n                _, start = bracket_stack.pop()\n                for j in range(start, i + 1):\n                    ids.add(id(leaves[j]))\n            else:\n                break\n    return ids", "loc": 27}
{"file": "black\\src\\black\\brackets.py", "class_name": "BracketTracker", "function_name": "mark", "parameters": ["self", "leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BracketMatchError", "id", "is_split_after_delimiter", "is_split_before_delimiter", "self.bracket_match.pop", "self.invisible.append", "self.maybe_decrement_after_for_loop_variable", "self.maybe_decrement_after_lambda_arguments", "self.maybe_increment_for_loop_variable", "self.maybe_increment_lambda_arguments"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Mark `leaf` with bracket-related metadata. Keep track of delimiters. All leaves receive an int `bracket_depth` field that stores how deep within brackets a given leaf is. 0 means there are no enclosing brackets", "source_code": "def mark(self, leaf: Leaf) -> None:\n    \"\"\"Mark `leaf` with bracket-related metadata. Keep track of delimiters.\n\n    All leaves receive an int `bracket_depth` field that stores how deep\n    within brackets a given leaf is. 0 means there are no enclosing brackets\n    that started on this line.\n\n    If a leaf is itself a closing bracket and there is a matching opening\n    bracket earlier, it receives an `opening_bracket` field with which it forms a\n    pair. This is a one-directional link to avoid reference cycles. Closing\n    bracket without opening happens on lines continued from previous\n    breaks, e.g. `) -> \"ReturnType\":` as part of a funcdef where we place\n    the return type annotation on its own line of the previous closing RPAR.\n\n    If a leaf is a delimiter (a token on which Black can split the line if\n    needed) and it's on depth 0, its `id()` is stored in the tracker's\n    `delimiters` field.\n    \"\"\"\n    if leaf.type == token.COMMENT:\n        return\n\n    if (\n        self.depth == 0\n        and leaf.type in CLOSING_BRACKETS\n        and (self.depth, leaf.type) not in self.bracket_match\n    ):\n        return\n\n    self.maybe_decrement_after_for_loop_variable(leaf)\n    self.maybe_decrement_after_lambda_arguments(leaf)\n    if leaf.type in CLOSING_BRACKETS:\n        self.depth -= 1\n        try:\n            opening_bracket = self.bracket_match.pop((self.depth, leaf.type))\n        except KeyError as e:\n            raise BracketMatchError(\n                \"Unable to match a closing bracket to the following opening\"\n                f\" bracket: {leaf}\"\n            ) from e\n        leaf.opening_bracket = opening_bracket\n        if not leaf.value:\n            self.invisible.append(leaf)\n    leaf.bracket_depth = self.depth\n    if self.depth == 0:\n        delim = is_split_before_delimiter(leaf, self.previous)\n        if delim and self.previous is not None:\n            self.delimiters[id(self.previous)] = delim\n        else:\n            delim = is_split_after_delimiter(leaf)\n            if delim:\n                self.delimiters[id(leaf)] = delim\n    if leaf.type in OPENING_BRACKETS:\n        self.bracket_match[self.depth, BRACKET[leaf.type]] = leaf\n        self.depth += 1\n        if not leaf.value:\n            self.invisible.append(leaf)\n    self.previous = leaf\n    self.maybe_increment_lambda_arguments(leaf)\n    self.maybe_increment_for_loop_variable(leaf)", "loc": 59}
{"file": "black\\src\\black\\brackets.py", "class_name": "BracketTracker", "function_name": "max_delimiter_priority", "parameters": ["self", "exclude"], "param_types": {"exclude": "Iterable[LeafID]"}, "return_type": "Priority", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["max", "self.delimiters.items"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Return the highest priority of a delimiter found on the line. Values are consistent with what `is_split_*_delimiter()` return.", "source_code": "def max_delimiter_priority(self, exclude: Iterable[LeafID] = ()) -> Priority:\n    \"\"\"Return the highest priority of a delimiter found on the line.\n\n    Values are consistent with what `is_split_*_delimiter()` return.\n    Raises ValueError on no delimiters.\n    \"\"\"\n    return max(v for k, v in self.delimiters.items() if k not in exclude)", "loc": 7}
{"file": "black\\src\\black\\brackets.py", "class_name": "BracketTracker", "function_name": "delimiter_count_with_priority", "parameters": ["self", "priority"], "param_types": {"priority": "Priority"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.delimiters.values", "self.max_delimiter_priority", "sum"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the number of delimiters with the given `priority`. If no `priority` is passed, defaults to max priority on the line.", "source_code": "def delimiter_count_with_priority(self, priority: Priority = 0) -> int:\n    \"\"\"Return the number of delimiters with the given `priority`.\n\n    If no `priority` is passed, defaults to max priority on the line.\n    \"\"\"\n    if not self.delimiters:\n        return 0\n\n    priority = priority or self.max_delimiter_priority()\n    return sum(1 for p in self.delimiters.values() if p == priority)", "loc": 10}
{"file": "black\\src\\black\\brackets.py", "class_name": "BracketTracker", "function_name": "maybe_increment_for_loop_variable", "parameters": ["self", "leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._for_loop_depths.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "In a for loop, or comprehension, the variables are often unpacks. To avoid splitting on the comma in this situation, increase the depth of tokens between `for` and `in`.", "source_code": "def maybe_increment_for_loop_variable(self, leaf: Leaf) -> bool:\n    \"\"\"In a for loop, or comprehension, the variables are often unpacks.\n\n    To avoid splitting on the comma in this situation, increase the depth of\n    tokens between `for` and `in`.\n    \"\"\"\n    if leaf.type == token.NAME and leaf.value == \"for\":\n        self.depth += 1\n        self._for_loop_depths.append(self.depth)\n        return True\n\n    return False", "loc": 12}
{"file": "black\\src\\black\\brackets.py", "class_name": "BracketTracker", "function_name": "maybe_decrement_after_for_loop_variable", "parameters": ["self", "leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._for_loop_depths.pop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "See `maybe_increment_for_loop_variable` above for explanation.", "source_code": "def maybe_decrement_after_for_loop_variable(self, leaf: Leaf) -> bool:\n    \"\"\"See `maybe_increment_for_loop_variable` above for explanation.\"\"\"\n    if (\n        self._for_loop_depths\n        and self._for_loop_depths[-1] == self.depth\n        and leaf.type == token.NAME\n        and leaf.value == \"in\"\n    ):\n        self.depth -= 1\n        self._for_loop_depths.pop()\n        return True\n\n    return False", "loc": 13}
{"file": "black\\src\\black\\brackets.py", "class_name": "BracketTracker", "function_name": "maybe_increment_lambda_arguments", "parameters": ["self", "leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._lambda_argument_depths.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "In a lambda expression, there might be more than one argument. To avoid splitting on the comma in this situation, increase the depth of tokens between `lambda` and `:`.", "source_code": "def maybe_increment_lambda_arguments(self, leaf: Leaf) -> bool:\n    \"\"\"In a lambda expression, there might be more than one argument.\n\n    To avoid splitting on the comma in this situation, increase the depth of\n    tokens between `lambda` and `:`.\n    \"\"\"\n    if leaf.type == token.NAME and leaf.value == \"lambda\":\n        self.depth += 1\n        self._lambda_argument_depths.append(self.depth)\n        return True\n\n    return False", "loc": 12}
{"file": "black\\src\\black\\brackets.py", "class_name": "BracketTracker", "function_name": "maybe_decrement_after_lambda_arguments", "parameters": ["self", "leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._lambda_argument_depths.pop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "See `maybe_increment_lambda_arguments` above for explanation.", "source_code": "def maybe_decrement_after_lambda_arguments(self, leaf: Leaf) -> bool:\n    \"\"\"See `maybe_increment_lambda_arguments` above for explanation.\"\"\"\n    if (\n        self._lambda_argument_depths\n        and self._lambda_argument_depths[-1] == self.depth\n        and leaf.type == token.COLON\n    ):\n        self.depth -= 1\n        self._lambda_argument_depths.pop()\n        return True\n\n    return False", "loc": 12}
{"file": "black\\src\\black\\cache.py", "class_name": null, "function_name": "get_cache_dir", "parameters": [], "param_types": {}, "return_type": "Path", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "os.environ.get", "user_cache_dir"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Get the cache directory used by black. Users can customize this directory on all systems using `BLACK_CACHE_DIR` environment variable. By default, the cache directory is the user cache directory", "source_code": "def get_cache_dir() -> Path:\n    \"\"\"Get the cache directory used by black.\n\n    Users can customize this directory on all systems using `BLACK_CACHE_DIR`\n    environment variable. By default, the cache directory is the user cache directory\n    under the black application.\n\n    This result is immediately set to a constant `black.cache.CACHE_DIR` as to avoid\n    repeated calls.\n    \"\"\"\n    # NOTE: Function mostly exists as a clean way to test getting the cache directory.\n    default_cache_dir = user_cache_dir(\"black\")\n    cache_dir = Path(os.environ.get(\"BLACK_CACHE_DIR\", default_cache_dir))\n    cache_dir = cache_dir / __version__\n    return cache_dir", "loc": 15}
{"file": "black\\src\\black\\cache.py", "class_name": "Cache", "function_name": "read", "parameters": ["cls", "mode"], "param_types": {"mode": "Mode"}, "return_type": "Self", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FileData", "cache_file.exists", "cache_file.open", "cls", "data.items", "err", "get_cache_file", "pickle.load"], "control_structures": ["If", "Try"], "behavior_type": ["file_io", "serialization"], "doc_summary": "Read the cache if it exists and is well-formed. If it is not well-formed, the call to write later should resolve the issue.", "source_code": "def read(cls, mode: Mode) -> Self:\n    \"\"\"Read the cache if it exists and is well-formed.\n\n    If it is not well-formed, the call to write later should\n    resolve the issue.\n    \"\"\"\n    cache_file = get_cache_file(mode)\n    try:\n        exists = cache_file.exists()\n    except OSError as e:\n        # Likely file too long; see #4172 and #4174\n        err(f\"Unable to read cache file {cache_file} due to {e}\")\n        return cls(mode, cache_file)\n    if not exists:\n        return cls(mode, cache_file)\n\n    with cache_file.open(\"rb\") as fobj:\n        try:\n            data: dict[str, tuple[float, int, str]] = pickle.load(fobj)\n            file_data = {k: FileData(*v) for k, v in data.items()}\n        except (pickle.UnpicklingError, ValueError, IndexError):\n            return cls(mode, cache_file)\n\n    return cls(mode, cache_file, file_data)", "loc": 24}
{"file": "black\\src\\black\\cache.py", "class_name": "Cache", "function_name": "hash_digest", "parameters": ["path"], "param_types": {"path": "Path"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hashlib.sha256", "hashlib.sha256(data).hexdigest", "path.read_bytes"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Return hash digest for path.", "source_code": "def hash_digest(path: Path) -> str:\n    \"\"\"Return hash digest for path.\"\"\"\n\n    data = path.read_bytes()\n    return hashlib.sha256(data).hexdigest()", "loc": 5}
{"file": "black\\src\\black\\cache.py", "class_name": "Cache", "function_name": "get_file_data", "parameters": ["path"], "param_types": {"path": "Path"}, "return_type": "FileData", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Cache.hash_digest", "FileData", "path.stat"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Return file data for path.", "source_code": "def get_file_data(path: Path) -> FileData:\n    \"\"\"Return file data for path.\"\"\"\n\n    stat = path.stat()\n    hash = Cache.hash_digest(path)\n    return FileData(stat.st_mtime, stat.st_size, hash)", "loc": 6}
{"file": "black\\src\\black\\cache.py", "class_name": "Cache", "function_name": "is_changed", "parameters": ["self", "source"], "param_types": {"source": "Path"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Cache.hash_digest", "res_src.stat", "self.file_data.get", "source.resolve", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Check if source has changed compared to cached version.", "source_code": "def is_changed(self, source: Path) -> bool:\n    \"\"\"Check if source has changed compared to cached version.\"\"\"\n    res_src = source.resolve()\n    old = self.file_data.get(str(res_src))\n    if old is None:\n        return True\n\n    st = res_src.stat()\n    if st.st_size != old.st_size:\n        return True\n    if st.st_mtime != old.st_mtime:\n        new_hash = Cache.hash_digest(res_src)\n        if new_hash != old.hash:\n            return True\n    return False", "loc": 15}
{"file": "black\\src\\black\\cache.py", "class_name": "Cache", "function_name": "filtered_cached", "parameters": ["self", "sources"], "param_types": {"sources": "Iterable[Path]"}, "return_type": "tuple[set[Path], set[Path]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["changed.add", "done.add", "self.is_changed", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Split an iterable of paths in `sources` into two sets. The first contains paths of files that modified on disk or are not in the cache. The other contains paths to non-modified files.", "source_code": "def filtered_cached(self, sources: Iterable[Path]) -> tuple[set[Path], set[Path]]:\n    \"\"\"Split an iterable of paths in `sources` into two sets.\n\n    The first contains paths of files that modified on disk or are not in the\n    cache. The other contains paths to non-modified files.\n    \"\"\"\n    changed: set[Path] = set()\n    done: set[Path] = set()\n    for src in sources:\n        if self.is_changed(src):\n            changed.add(src)\n        else:\n            done.add(src)\n    return changed, done", "loc": 14}
{"file": "black\\src\\black\\cache.py", "class_name": "Cache", "function_name": "write", "parameters": ["self", "sources"], "param_types": {"sources": "Iterable[Path]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CACHE_DIR.mkdir", "Cache.get_file_data", "os.replace", "pickle.dump", "self.file_data.items", "self.file_data.update", "src.resolve", "str", "tempfile.NamedTemporaryFile"], "control_structures": ["Try"], "behavior_type": ["serialization"], "doc_summary": "Update the cache file data and write a new cache file.", "source_code": "def write(self, sources: Iterable[Path]) -> None:\n    \"\"\"Update the cache file data and write a new cache file.\"\"\"\n    self.file_data.update(\n        **{str(src.resolve()): Cache.get_file_data(src) for src in sources}\n    )\n    try:\n        CACHE_DIR.mkdir(parents=True, exist_ok=True)\n        with tempfile.NamedTemporaryFile(\n            dir=str(self.cache_file.parent), delete=False\n        ) as f:\n            # We store raw tuples in the cache because it's faster.\n            data: dict[str, tuple[float, int, str]] = {\n                k: (*v,) for k, v in self.file_data.items()\n            }\n            pickle.dump(data, f, protocol=4)\n        os.replace(f.name, self.cache_file)\n    except OSError:\n        pass", "loc": 18}
{"file": "black\\src\\black\\comments.py", "class_name": null, "function_name": "generate_comments", "parameters": ["leaf"], "param_types": {"leaf": "LN"}, "return_type": "Iterator[Leaf]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "list_comments", "make_simple_prefix", "normalize_trailing_prefix"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Clean the prefix of the `leaf` and generate comments from it, if any. Comments in lib2to3 are shoved into the whitespace prefix.  This happens in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation", "source_code": "def generate_comments(leaf: LN) -> Iterator[Leaf]:\n    \"\"\"Clean the prefix of the `leaf` and generate comments from it, if any.\n\n    Comments in lib2to3 are shoved into the whitespace prefix.  This happens\n    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation\n    move because it does away with modifying the grammar to include all the\n    possible places in which comments can be placed.\n\n    The sad consequence for us though is that comments don't \"belong\" anywhere.\n    This is why this function generates simple parentless Leaf objects for\n    comments.  We simply don't know what the correct parent should be.\n\n    No matter though, we can live without this.  We really only need to\n    differentiate between inline and standalone comments.  The latter don't\n    share the line with any code.\n\n    Inline comments are emitted as regular token.COMMENT leaves.  Standalone\n    are emitted with a fake STANDALONE_COMMENT token identifier.\n    \"\"\"\n    total_consumed = 0\n    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):\n        total_consumed = pc.consumed\n        prefix = make_simple_prefix(pc.newlines, pc.form_feed)\n        yield Leaf(pc.type, pc.value, prefix=prefix)\n    normalize_trailing_prefix(leaf, total_consumed)", "loc": 25}
{"file": "black\\src\\black\\comments.py", "class_name": null, "function_name": "list_comments", "parameters": ["prefix"], "param_types": {"prefix": "str"}, "return_type": "list[ProtoComment]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ProtoComment", "enumerate", "len", "line.endswith", "line.startswith", "lru_cache", "make_comment", "match.groups", "re.match", "re.split", "result.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return a list of :class:`ProtoComment` objects parsed from the given `prefix`.", "source_code": "def list_comments(prefix: str, *, is_endmarker: bool) -> list[ProtoComment]:\n    \"\"\"Return a list of :class:`ProtoComment` objects parsed from the given `prefix`.\"\"\"\n    result: list[ProtoComment] = []\n    if not prefix or \"#\" not in prefix:\n        return result\n\n    consumed = 0\n    nlines = 0\n    ignored_lines = 0\n    form_feed = False\n    for index, full_line in enumerate(re.split(\"\\r?\\n|\\r\", prefix)):\n        consumed += len(full_line) + 1  # adding the length of the split '\\n'\n        match = re.match(r\"^(\\s*)(\\S.*|)$\", full_line)\n        assert match\n        whitespace, line = match.groups()\n        if not line:\n            nlines += 1\n            if \"\\f\" in full_line:\n                form_feed = True\n        if not line.startswith(\"#\"):\n            # Escaped newlines outside of a comment are not really newlines at\n            # all. We treat a single-line comment following an escaped newline\n            # as a simple trailing comment.\n            if line.endswith(\"\\\\\"):\n                ignored_lines += 1\n            continue\n\n        if index == ignored_lines and not is_endmarker:\n            comment_type = token.COMMENT  # simple trailing comment\n        else:\n            comment_type = STANDALONE_COMMENT\n        comment = make_comment(line)\n        result.append(\n            ProtoComment(\n                type=comment_type,\n                value=comment,\n                newlines=nlines,\n                consumed=consumed,\n                form_feed=form_feed,\n                leading_whitespace=whitespace,\n            )\n        )\n        form_feed = False\n        nlines = 0\n    return result", "loc": 45}
{"file": "black\\src\\black\\comments.py", "class_name": null, "function_name": "normalize_trailing_prefix", "parameters": ["leaf", "total_consumed"], "param_types": {"leaf": "LN", "total_consumed": "int"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["make_simple_prefix", "remainder.count", "remainder.endswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Normalize the prefix that's left over after generating comments. Note: don't use backslashes for formatting or you'll lose your voting rights.", "source_code": "def normalize_trailing_prefix(leaf: LN, total_consumed: int) -> None:\n    \"\"\"Normalize the prefix that's left over after generating comments.\n\n    Note: don't use backslashes for formatting or you'll lose your voting rights.\n    \"\"\"\n    remainder = leaf.prefix[total_consumed:]\n    if \"\\\\\" not in remainder:\n        nl_count = remainder.count(\"\\n\")\n        form_feed = \"\\f\" in remainder and remainder.endswith(\"\\n\")\n        leaf.prefix = make_simple_prefix(nl_count, form_feed)\n        return\n\n    leaf.prefix = \"\"", "loc": 13}
{"file": "black\\src\\black\\comments.py", "class_name": null, "function_name": "make_comment", "parameters": ["content"], "param_types": {"content": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["content.lstrip", "content.lstrip().startswith", "content.rstrip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return a consistently formatted comment from the given `content` string. All comments (except for \"##\", \"#!\", \"#:\", '#'\") should have a single space between the hash sign and the content.", "source_code": "def make_comment(content: str) -> str:\n    \"\"\"Return a consistently formatted comment from the given `content` string.\n\n    All comments (except for \"##\", \"#!\", \"#:\", '#'\") should have a single\n    space between the hash sign and the content.\n\n    If `content` didn't start with a hash sign, one is provided.\n    \"\"\"\n    content = content.rstrip()\n    if not content:\n        return \"#\"\n\n    if content[0] == \"#\":\n        content = content[1:]\n    if (\n        content\n        and content[0] == \"\\N{NO-BREAK SPACE}\"\n        and not content.lstrip().startswith(\"type:\")\n    ):\n        content = \" \" + content[1:]  # Replace NBSP by a simple space\n    if content and content[0] not in COMMENT_EXCEPTIONS:\n        content = \" \" + content\n    return \"#\" + content", "loc": 23}
{"file": "black\\src\\black\\comments.py", "class_name": null, "function_name": "normalize_fmt_off", "parameters": ["node", "mode", "lines"], "param_types": {"node": "Node", "mode": "Mode", "lines": "Collection[tuple[int, int]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["convert_one_fmt_off_pair"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "Convert content between `# fmt: off`/`# fmt: on` into standalone comments.", "source_code": "def normalize_fmt_off(\n    node: Node, mode: Mode, lines: Collection[tuple[int, int]]\n) -> None:\n    \"\"\"Convert content between `# fmt: off`/`# fmt: on` into standalone comments.\"\"\"\n    try_again = True\n    while try_again:\n        try_again = convert_one_fmt_off_pair(node, mode, lines)", "loc": 7}
{"file": "black\\src\\black\\comments.py", "class_name": null, "function_name": "convert_one_fmt_off_pair", "parameters": ["node", "mode", "lines"], "param_types": {"node": "Node", "mode": "Mode", "lines": "Collection[tuple[int, int]]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "Leaf", "_contains_fmt_skip_comment", "any", "first_leaf_of", "fmt_off_prefix.split", "generate_ignored_nodes", "hidden_value.endswith", "ignored.remove", "len", "list", "list_comments", "node.leaves", "parent.insert_child", "preceding_leaf", "prefix.split", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.", "source_code": "def convert_one_fmt_off_pair(\n    node: Node, mode: Mode, lines: Collection[tuple[int, int]]\n) -> bool:\n    \"\"\"Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.\n\n    Returns True if a pair was converted.\n    \"\"\"\n    for leaf in node.leaves():\n        previous_consumed = 0\n        for comment in list_comments(leaf.prefix, is_endmarker=False):\n            is_fmt_off = comment.value in FMT_OFF\n            is_fmt_skip = _contains_fmt_skip_comment(comment.value, mode)\n            if (not is_fmt_off and not is_fmt_skip) or (\n                # Invalid use when `# fmt: off` is applied before a closing bracket.\n                is_fmt_off\n                and leaf.type in CLOSING_BRACKETS\n            ):\n                previous_consumed = comment.consumed\n                continue\n            # We only want standalone comments. If there's no previous leaf or\n            # the previous leaf is indentation, it's a standalone comment in\n            # disguise.\n            if comment.type != STANDALONE_COMMENT:\n                prev = preceding_leaf(leaf)\n                if prev:\n                    if is_fmt_off and prev.type not in WHITESPACE:\n                        continue\n                    if is_fmt_skip and prev.type in WHITESPACE:\n                        continue\n\n            ignored_nodes = list(generate_ignored_nodes(leaf, comment, mode))\n            if not ignored_nodes:\n                continue\n\n            first = ignored_nodes[0]  # Can be a container node with the `leaf`.\n            parent = first.parent\n            prefix = first.prefix\n            if comment.value in FMT_OFF:\n                first.prefix = prefix[comment.consumed :]\n            if is_fmt_skip:\n                first.prefix = \"\"\n                standalone_comment_prefix = prefix\n            else:\n                standalone_comment_prefix = (\n                    prefix[:previous_consumed] + \"\\n\" * comment.newlines\n                )\n            hidden_value = \"\".join(str(n) for n in ignored_nodes)\n            comment_lineno = leaf.lineno - comment.newlines\n            if comment.value in FMT_OFF:\n                fmt_off_prefix = \"\"\n                if len(lines) > 0 and not any(\n                    line[0] <= comment_lineno <= line[1] for line in lines\n                ):\n                    # keeping indentation of comment by preserving original whitespaces.\n                    fmt_off_prefix = prefix.split(comment.value)[0]\n                    if \"\\n\" in fmt_off_prefix:\n                        fmt_off_prefix = fmt_off_prefix.split(\"\\n\")[-1]\n                standalone_comment_prefix += fmt_off_prefix\n                hidden_value = comment.value + \"\\n\" + hidden_value\n            if is_fmt_skip:\n                hidden_value += comment.leading_whitespace + comment.value\n            if hidden_value.endswith(\"\\n\"):\n                # That happens when one of the `ignored_nodes` ended with a NEWLINE\n                # leaf (possibly followed by a DEDENT).\n                hidden_value = hidden_value[:-1]\n            first_idx: Optional[int] = None\n            for ignored in ignored_nodes:\n                index = ignored.remove()\n                if first_idx is None:\n                    first_idx = index\n            assert parent is not None, \"INTERNAL ERROR: fmt: on/off handling (1)\"\n            assert first_idx is not None, \"INTERNAL ERROR: fmt: on/off handling (2)\"\n            parent.insert_child(\n                first_idx,\n                Leaf(\n                    STANDALONE_COMMENT,\n                    hidden_value,\n                    prefix=standalone_comment_prefix,\n                    fmt_pass_converted_first_leaf=first_leaf_of(first),\n                ),\n            )\n            return True\n\n    return False", "loc": 84}
{"file": "black\\src\\black\\comments.py", "class_name": null, "function_name": "generate_ignored_nodes", "parameters": ["leaf", "comment", "mode"], "param_types": {"leaf": "Leaf", "comment": "ProtoComment", "mode": "Mode"}, "return_type": "Iterator[LN]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_contains_fmt_skip_comment", "_generate_ignored_nodes_from_fmt_skip", "children_contains_fmt_on", "container_of", "enumerate", "is_fmt_on", "isinstance", "len"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "Starting from the container of `leaf`, generate all leaves until `# fmt: on`. If comment is skip, returns leaf only. Stops at the end of the block.", "source_code": "def generate_ignored_nodes(\n    leaf: Leaf, comment: ProtoComment, mode: Mode\n) -> Iterator[LN]:\n    \"\"\"Starting from the container of `leaf`, generate all leaves until `# fmt: on`.\n\n    If comment is skip, returns leaf only.\n    Stops at the end of the block.\n    \"\"\"\n    if _contains_fmt_skip_comment(comment.value, mode):\n        yield from _generate_ignored_nodes_from_fmt_skip(leaf, comment, mode)\n        return\n    container: Optional[LN] = container_of(leaf)\n    while container is not None and container.type != token.ENDMARKER:\n        if is_fmt_on(container):\n            return\n\n        # fix for fmt: on in children\n        if children_contains_fmt_on(container):\n            for index, child in enumerate(container.children):\n                if isinstance(child, Leaf) and is_fmt_on(child):\n                    if child.type in CLOSING_BRACKETS:\n                        # This means `# fmt: on` is placed at a different bracket level\n                        # than `# fmt: off`. This is an invalid use, but as a courtesy,\n                        # we include this closing bracket in the ignored nodes.\n                        # The alternative is to fail the formatting.\n                        yield child\n                    return\n                if (\n                    child.type == token.INDENT\n                    and index < len(container.children) - 1\n                    and children_contains_fmt_on(container.children[index + 1])\n                ):\n                    # This means `# fmt: on` is placed right after an indentation\n                    # level, and we shouldn't swallow the previous INDENT token.\n                    return\n                if children_contains_fmt_on(child):\n                    return\n                yield child\n        else:\n            if container.type == token.DEDENT and container.next_sibling is None:\n                # This can happen when there is no matching `# fmt: on` comment at the\n                # same level as `# fmt: on`. We need to keep this DEDENT.\n                return\n            yield container\n            container = container.next_sibling", "loc": 45}
{"file": "black\\src\\black\\comments.py", "class_name": null, "function_name": "is_fmt_on", "parameters": ["container"], "param_types": {"container": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["list_comments"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Determine whether formatting is switched on within a container. Determined by whether the last `# fmt:` comment is `on` or `off`.", "source_code": "def is_fmt_on(container: LN) -> bool:\n    \"\"\"Determine whether formatting is switched on within a container.\n    Determined by whether the last `# fmt:` comment is `on` or `off`.\n    \"\"\"\n    fmt_on = False\n    for comment in list_comments(container.prefix, is_endmarker=False):\n        if comment.value in FMT_ON:\n            fmt_on = True\n        elif comment.value in FMT_OFF:\n            fmt_on = False\n    return fmt_on", "loc": 11}
{"file": "black\\src\\black\\comments.py", "class_name": null, "function_name": "children_contains_fmt_on", "parameters": ["container"], "param_types": {"container": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["first_leaf_of", "is_fmt_on"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Determine if children have formatting switched on.", "source_code": "def children_contains_fmt_on(container: LN) -> bool:\n    \"\"\"Determine if children have formatting switched on.\"\"\"\n    for child in container.children:\n        leaf = first_leaf_of(child)\n        if leaf is not None and is_fmt_on(leaf):\n            return True\n\n    return False", "loc": 8}
{"file": "black\\src\\black\\comments.py", "class_name": null, "function_name": "contains_pragma_comment", "parameters": ["comment_list"], "param_types": {"comment_list": "list[Leaf]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["comment.value.startswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def contains_pragma_comment(comment_list: list[Leaf]) -> bool:\n    \"\"\"\n    Returns:\n        True iff one of the comments in @comment_list is a pragma used by one\n        of the more common static analysis tools for python (e.g. mypy, flake8,\n        pylint).\n    \"\"\"\n    for comment in comment_list:\n        if comment.value.startswith((\"# type:\", \"# noqa\", \"# pylint:\")):\n            return True\n\n    return False", "loc": 12}
{"file": "black\\src\\black\\concurrency.py", "class_name": null, "function_name": "maybe_install_uvloop", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["uvloop.install"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "If our environment has uvloop installed we use it. This is called only from command-line entry points to avoid interfering with the parent process if Black is used as a library.", "source_code": "def maybe_install_uvloop() -> None:\n    \"\"\"If our environment has uvloop installed we use it.\n\n    This is called only from command-line entry points to avoid\n    interfering with the parent process if Black is used as a library.\n    \"\"\"\n    try:\n        import uvloop\n\n        uvloop.install()\n    except ImportError:\n        pass", "loc": 12}
{"file": "black\\src\\black\\concurrency.py", "class_name": null, "function_name": "cancel", "parameters": ["tasks"], "param_types": {"tasks": "Iterable['asyncio.Future[Any]']"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["err", "task.cancel"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "asyncio signal handler that cancels all `tasks` and reports to stderr.", "source_code": "def cancel(tasks: Iterable[\"asyncio.Future[Any]\"]) -> None:\n    \"\"\"asyncio signal handler that cancels all `tasks` and reports to stderr.\"\"\"\n    err(\"Aborted!\")\n    for task in tasks:\n        task.cancel()", "loc": 5}
{"file": "black\\src\\black\\concurrency.py", "class_name": null, "function_name": "shutdown", "parameters": ["loop"], "param_types": {"loop": "asyncio.AbstractEventLoop"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["asyncio.all_tasks", "asyncio.gather", "cf_logger.setLevel", "logging.getLogger", "loop.close", "loop.run_until_complete", "task.cancel", "task.done"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Cancel all pending tasks on `loop`, wait for them, and close the loop.", "source_code": "def shutdown(loop: asyncio.AbstractEventLoop) -> None:\n    \"\"\"Cancel all pending tasks on `loop`, wait for them, and close the loop.\"\"\"\n    try:\n        # This part is borrowed from asyncio/runners.py in Python 3.7b2.\n        to_cancel = [task for task in asyncio.all_tasks(loop) if not task.done()]\n        if not to_cancel:\n            return\n\n        for task in to_cancel:\n            task.cancel()\n        loop.run_until_complete(asyncio.gather(*to_cancel, return_exceptions=True))\n    finally:\n        # `concurrent.futures.Future` objects cannot be cancelled once they\n        # are already running. There might be some when the `shutdown()` happened.\n        # Silence their logger's spew about the event loop being closed.\n        cf_logger = logging.getLogger(\"concurrent.futures\")\n        cf_logger.setLevel(logging.CRITICAL)\n        loop.close()", "loc": 18}
{"file": "black\\src\\black\\concurrency.py", "class_name": null, "function_name": "reformat_many", "parameters": ["sources", "fast", "write_back", "mode", "report", "workers"], "param_types": {"sources": "set[Path]", "fast": "bool", "write_back": "WriteBack", "mode": "Mode", "report": "Report", "workers": "Optional[int]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ProcessPoolExecutor", "ThreadPoolExecutor", "asyncio.new_event_loop", "asyncio.set_event_loop", "executor.shutdown", "int", "loop.run_until_complete", "maybe_install_uvloop", "min", "mypyc_attr", "os.cpu_count", "os.environ.get", "schedule_formatting", "shutdown"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Reformat multiple files using a ProcessPoolExecutor.", "source_code": "def reformat_many(\n    sources: set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: Mode,\n    report: Report,\n    workers: Optional[int],\n) -> None:\n    \"\"\"Reformat multiple files using a ProcessPoolExecutor.\"\"\"\n    maybe_install_uvloop()\n\n    if workers is None:\n        workers = int(os.environ.get(\"BLACK_NUM_WORKERS\", 0))\n        workers = workers or os.cpu_count() or 1\n    if sys.platform == \"win32\":\n        # Work around https://bugs.python.org/issue26903\n        workers = min(workers, 60)\n\n    executor: Executor | None = None\n    if workers > 1:\n        try:\n            executor = ProcessPoolExecutor(max_workers=workers)\n        except (ImportError, NotImplementedError, OSError):\n            # we arrive here if the underlying system does not support multi-processing\n            # like in AWS Lambda or Termux, in which case we gracefully fallback to\n            # a ThreadPoolExecutor with just a single worker (more workers would not do\n            # us any good due to the Global Interpreter Lock)\n            pass\n\n    if executor is None:\n        executor = ThreadPoolExecutor(max_workers=1)\n\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(loop)\n    try:\n        loop.run_until_complete(\n            schedule_formatting(\n                sources=sources,\n                fast=fast,\n                write_back=write_back,\n                mode=mode,\n                report=report,\n                loop=loop,\n                executor=executor,\n            )\n        )\n    finally:\n        try:\n            shutdown(loop)\n        finally:\n            asyncio.set_event_loop(None)\n        if executor is not None:\n            executor.shutdown()", "loc": 53}
{"file": "black\\src\\black\\debug.py", "class_name": "DebugVisitor", "function_name": "visit_default", "parameters": ["self", "node"], "param_types": {"node": "LN"}, "return_type": "Iterator[T]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self.out", "self.visit", "str", "token.tok_name.get", "type_repr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_default(self, node: LN) -> Iterator[T]:\n    indent = \" \" * (2 * self.tree_depth)\n    if isinstance(node, Node):\n        _type = type_repr(node.type)\n        self.out(f\"{indent}{_type}\", fg=\"yellow\")\n        self.tree_depth += 1\n        for child in node.children:\n            yield from self.visit(child)\n\n        self.tree_depth -= 1\n        self.out(f\"{indent}/{_type}\", fg=\"yellow\", bold=False)\n    else:\n        _type = token.tok_name.get(node.type, str(node.type))\n        self.out(f\"{indent}{_type}\", fg=\"blue\", nl=False)\n        if node.prefix:\n            # We don't have to handle prefixes for `Node` objects since\n            # that delegates to the first child anyway.\n            self.out(f\" {node.prefix!r}\", fg=\"green\", bold=False, nl=False)\n        self.out(f\" {node.value!r}\", fg=\"blue\", bold=False)", "loc": 19}
{"file": "black\\src\\black\\debug.py", "class_name": "DebugVisitor", "function_name": "show", "parameters": ["cls", "code"], "param_types": {"code": "Union[str, Leaf, Node]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DebugVisitor", "isinstance", "lib2to3_parse", "list", "v.visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Pretty-print the lib2to3 AST of a given string of `code`. Convenience method for debugging.", "source_code": "def show(cls, code: Union[str, Leaf, Node]) -> None:\n    \"\"\"Pretty-print the lib2to3 AST of a given string of `code`.\n\n    Convenience method for debugging.\n    \"\"\"\n    v: DebugVisitor[None] = DebugVisitor()\n    if isinstance(code, str):\n        code = lib2to3_parse(code)\n    list(v.visit(code))", "loc": 9}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "find_project_root", "parameters": ["srcs", "stdin_filename"], "param_types": {"srcs": "Sequence[str]", "stdin_filename": "Optional[str]"}, "return_type": "tuple[Path, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "Path.cwd", "_cached_resolve", "_load_toml", "directory / '.git'.exists", "directory / '.hg'.is_dir", "directory / 'pyproject.toml'.is_file", "list", "max", "path.is_dir", "pyproject_toml.get", "set", "set.intersection", "str", "tuple"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return a directory containing .git, .hg, or pyproject.toml. pyproject.toml files are only considered if they contain a [tool.black] section and are ignored otherwise. That directory will be a common parent of all files and directories passed in `srcs`. If no directory in the tree contains a marker that would specify it's the project root, the root of the file system is returned.", "source_code": "def find_project_root(\n    srcs: Sequence[str], stdin_filename: Optional[str] = None\n) -> tuple[Path, str]:\n    \"\"\"Return a directory containing .git, .hg, or pyproject.toml.\n\n    pyproject.toml files are only considered if they contain a [tool.black]\n    section and are ignored otherwise.\n\n    That directory will be a common parent of all files and directories\n    passed in `srcs`.\n\n    If no directory in the tree contains a marker that would specify it's the\n    project root, the root of the file system is returned.\n\n    Returns a two-tuple with the first element as the project root path and\n    the second element as a string describing the method by which the\n    project root was discovered.\n    \"\"\"\n    if stdin_filename is not None:\n        srcs = tuple(stdin_filename if s == \"-\" else s for s in srcs)\n    if not srcs:\n        srcs = [str(_cached_resolve(Path.cwd()))]\n\n    path_srcs = [_cached_resolve(Path(Path.cwd(), src)) for src in srcs]\n\n    # A list of lists of parents for each 'src'. 'src' is included as a\n    # \"parent\" of itself if it is a directory\n    src_parents = [\n        list(path.parents) + ([path] if path.is_dir() else []) for path in path_srcs\n    ]\n\n    common_base = max(\n        set.intersection(*(set(parents) for parents in src_parents)),\n        key=lambda path: path.parts,\n    )\n\n    for directory in (common_base, *common_base.parents):\n        if (directory / \".git\").exists():\n            return directory, \".git directory\"\n\n        if (directory / \".hg\").is_dir():\n            return directory, \".hg directory\"\n\n        if (directory / \"pyproject.toml\").is_file():\n            pyproject_toml = _load_toml(directory / \"pyproject.toml\")\n            if \"black\" in pyproject_toml.get(\"tool\", {}):\n                return directory, \"pyproject.toml\"\n\n    return directory, \"file system root\"", "loc": 49}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "find_pyproject_toml", "parameters": ["path_search_start", "stdin_filename"], "param_types": {"path_search_start": "tuple[str, ...]", "stdin_filename": "Optional[str]"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["err", "find_project_root", "find_user_pyproject_toml", "path_pyproject_toml.is_file", "path_user_pyproject_toml.is_file", "str"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Find the absolute filepath to a pyproject.toml if it exists", "source_code": "def find_pyproject_toml(\n    path_search_start: tuple[str, ...], stdin_filename: Optional[str] = None\n) -> Optional[str]:\n    \"\"\"Find the absolute filepath to a pyproject.toml if it exists\"\"\"\n    path_project_root, _ = find_project_root(path_search_start, stdin_filename)\n    path_pyproject_toml = path_project_root / \"pyproject.toml\"\n    if path_pyproject_toml.is_file():\n        return str(path_pyproject_toml)\n\n    try:\n        path_user_pyproject_toml = find_user_pyproject_toml()\n        return (\n            str(path_user_pyproject_toml)\n            if path_user_pyproject_toml.is_file()\n            else None\n        )\n    except (PermissionError, RuntimeError) as e:\n        # We do not have access to the user-level config directory, so ignore it.\n        err(f\"Ignoring user configuration directory due to {e!r}\")\n        return None", "loc": 20}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "parse_pyproject_toml", "parameters": ["path_config"], "param_types": {"path_config": "str"}, "return_type": "dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_load_toml", "config.items", "infer_target_version", "k.replace", "k.replace('--', '').replace", "mypyc_attr", "pyproject_toml.get", "pyproject_toml.get('tool', {}).get", "v.name.lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse a pyproject toml file, pulling out relevant parts for Black. If parsing fails, will raise a tomllib.TOMLDecodeError.", "source_code": "def parse_pyproject_toml(path_config: str) -> dict[str, Any]:\n    \"\"\"Parse a pyproject toml file, pulling out relevant parts for Black.\n\n    If parsing fails, will raise a tomllib.TOMLDecodeError.\n    \"\"\"\n    pyproject_toml = _load_toml(path_config)\n    config: dict[str, Any] = pyproject_toml.get(\"tool\", {}).get(\"black\", {})\n    config = {k.replace(\"--\", \"\").replace(\"-\", \"_\"): v for k, v in config.items()}\n\n    if \"target_version\" not in config:\n        inferred_target_version = infer_target_version(pyproject_toml)\n        if inferred_target_version is not None:\n            config[\"target_version\"] = [v.name.lower() for v in inferred_target_version]\n\n    return config", "loc": 15}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "infer_target_version", "parameters": ["pyproject_toml"], "param_types": {"pyproject_toml": "dict[str, Any]"}, "return_type": "Optional[list[TargetVersion]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_req_python_specifier", "parse_req_python_version", "project_metadata.get", "pyproject_toml.get"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Infer Black's target version from the project metadata in pyproject.toml. Supports the PyPA standard format (PEP 621): https://packaging.python.org/en/latest/specifications/declaring-project-metadata/#requires-python", "source_code": "def infer_target_version(\n    pyproject_toml: dict[str, Any],\n) -> Optional[list[TargetVersion]]:\n    \"\"\"Infer Black's target version from the project metadata in pyproject.toml.\n\n    Supports the PyPA standard format (PEP 621):\n    https://packaging.python.org/en/latest/specifications/declaring-project-metadata/#requires-python\n\n    If the target version cannot be inferred, returns None.\n    \"\"\"\n    project_metadata = pyproject_toml.get(\"project\", {})\n    requires_python = project_metadata.get(\"requires-python\", None)\n    if requires_python is not None:\n        try:\n            return parse_req_python_version(requires_python)\n        except InvalidVersion:\n            pass\n        try:\n            return parse_req_python_specifier(requires_python)\n        except (InvalidSpecifier, InvalidVersion):\n            pass\n\n    return None", "loc": 23}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "parse_req_python_version", "parameters": ["requires_python"], "param_types": {"requires_python": "str"}, "return_type": "Optional[list[TargetVersion]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TargetVersion", "Version"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Parse a version string (i.e. ``\"3.7\"``) to a list of TargetVersion. If parsing fails, will raise a packaging.version.InvalidVersion error. If the parsed version cannot be mapped to a valid TargetVersion, returns None.", "source_code": "def parse_req_python_version(requires_python: str) -> Optional[list[TargetVersion]]:\n    \"\"\"Parse a version string (i.e. ``\"3.7\"``) to a list of TargetVersion.\n\n    If parsing fails, will raise a packaging.version.InvalidVersion error.\n    If the parsed version cannot be mapped to a valid TargetVersion, returns None.\n    \"\"\"\n    version = Version(requires_python)\n    if version.release[0] != 3:\n        return None\n    try:\n        return [TargetVersion(version.release[1])]\n    except (IndexError, ValueError):\n        return None", "loc": 13}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "parse_req_python_specifier", "parameters": ["requires_python"], "param_types": {"requires_python": "str"}, "return_type": "Optional[list[TargetVersion]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SpecifierSet", "list", "specifier_set.filter", "strip_specifier_set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse a specifier string (i.e. ``\">=3.7,<3.10\"``) to a list of TargetVersion. If parsing fails, will raise a packaging.specifiers.InvalidSpecifier error. If the parsed specifier cannot be mapped to a valid TargetVersion, returns None.", "source_code": "def parse_req_python_specifier(requires_python: str) -> Optional[list[TargetVersion]]:\n    \"\"\"Parse a specifier string (i.e. ``\">=3.7,<3.10\"``) to a list of TargetVersion.\n\n    If parsing fails, will raise a packaging.specifiers.InvalidSpecifier error.\n    If the parsed specifier cannot be mapped to a valid TargetVersion, returns None.\n    \"\"\"\n    specifier_set = strip_specifier_set(SpecifierSet(requires_python))\n    if not specifier_set:\n        return None\n\n    target_version_map = {f\"3.{v.value}\": v for v in TargetVersion}\n    compatible_versions: list[str] = list(specifier_set.filter(target_version_map))\n    if compatible_versions:\n        return [target_version_map[v] for v in compatible_versions]\n    return None", "loc": 15}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "strip_specifier_set", "parameters": ["specifier_set"], "param_types": {"specifier_set": "SpecifierSet"}, "return_type": "SpecifierSet", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["','.join", "Specifier", "SpecifierSet", "Version", "len", "specifiers.append", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Strip minor versions for some specifiers in the specifier set. For background on version specifiers, see PEP 440: https://peps.python.org/pep-0440/#version-specifiers", "source_code": "def strip_specifier_set(specifier_set: SpecifierSet) -> SpecifierSet:\n    \"\"\"Strip minor versions for some specifiers in the specifier set.\n\n    For background on version specifiers, see PEP 440:\n    https://peps.python.org/pep-0440/#version-specifiers\n    \"\"\"\n    specifiers = []\n    for s in specifier_set:\n        if \"*\" in str(s):\n            specifiers.append(s)\n        elif s.operator in [\"~=\", \"==\", \">=\", \"===\"]:\n            version = Version(s.version)\n            stripped = Specifier(f\"{s.operator}{version.major}.{version.minor}\")\n            specifiers.append(stripped)\n        elif s.operator == \">\":\n            version = Version(s.version)\n            if len(version.release) > 2:\n                s = Specifier(f\">={version.major}.{version.minor}\")\n            specifiers.append(s)\n        else:\n            specifiers.append(s)\n\n    return SpecifierSet(\",\".join(str(s) for s in specifiers))", "loc": 23}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "find_user_pyproject_toml", "parameters": [], "param_types": {}, "return_type": "Path", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "Path(config_root).expanduser", "Path.home", "_cached_resolve", "os.environ.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the path to the top-level user configuration for black. This looks for ~\\.black on Windows and ~/.config/black on Linux and other Unix systems.", "source_code": "def find_user_pyproject_toml() -> Path:\n    r\"\"\"Return the path to the top-level user configuration for black.\n\n    This looks for ~\\.black on Windows and ~/.config/black on Linux and other\n    Unix systems.\n\n    May raise:\n    - RuntimeError: if the current user has no homedir\n    - PermissionError: if the current process cannot access the user's homedir\n    \"\"\"\n    if sys.platform == \"win32\":\n        # Windows\n        user_config_path = Path.home() / \".black\"\n    else:\n        config_root = os.environ.get(\"XDG_CONFIG_HOME\", \"~/.config\")\n        user_config_path = Path(config_root).expanduser() / \"black\"\n    return _cached_resolve(user_config_path)", "loc": 17}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "resolves_outside_root_or_cannot_stat", "parameters": ["path", "root", "report"], "param_types": {"path": "Path", "root": "Path", "report": "Optional[Report]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_cached_resolve", "report.path_ignored", "resolved_path.relative_to"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def resolves_outside_root_or_cannot_stat(\n    path: Path,\n    root: Path,\n    report: Optional[Report] = None,\n) -> bool:\n    \"\"\"\n    Returns whether the path is a symbolic link that points outside the\n    root directory. Also returns True if we failed to resolve the path.\n    \"\"\"\n    try:\n        resolved_path = _cached_resolve(path)\n    except OSError as e:\n        if report:\n            report.path_ignored(path, f\"cannot be read because {e}\")\n        return True\n    try:\n        resolved_path.relative_to(root)\n    except ValueError:\n        if report:\n            report.path_ignored(path, f\"is a symbolic link that points outside {root}\")\n        return True\n    return False", "loc": 22}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "best_effort_relative_path", "parameters": ["path", "root"], "param_types": {"path": "Path", "root": "Path"}, "return_type": "Path", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_cached_resolve", "_cached_resolve(path).relative_to", "next", "path.absolute", "path.absolute().relative_to", "path.relative_to"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def best_effort_relative_path(path: Path, root: Path) -> Path:\n    # Precondition: resolves_outside_root_or_cannot_stat(path, root) is False\n    try:\n        return path.absolute().relative_to(root)\n    except ValueError:\n        pass\n    root_parent = next((p for p in path.parents if _cached_resolve(p) == root), None)\n    if root_parent is not None:\n        return path.relative_to(root_parent)\n    # something adversarial, fallback to path guaranteed by precondition\n    return _cached_resolve(path).relative_to(root)", "loc": 11}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "path_is_excluded", "parameters": ["normalized_path", "pattern"], "param_types": {"normalized_path": "str", "pattern": "Optional[Pattern[str]]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bool", "match.group", "pattern.search"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def path_is_excluded(\n    normalized_path: str,\n    pattern: Optional[Pattern[str]],\n) -> bool:\n    match = pattern.search(normalized_path) if pattern else None\n    return bool(match and match.group(0))", "loc": 6}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "gen_python_files", "parameters": ["paths", "root", "include", "exclude", "extend_exclude", "force_exclude", "report", "gitignore_dict"], "param_types": {"paths": "Iterable[Path]", "root": "Path", "include": "Pattern[str]", "exclude": "Pattern[str]", "extend_exclude": "Optional[Pattern[str]]", "force_exclude": "Optional[Pattern[str]]", "report": "Report", "gitignore_dict": "Optional[dict[Path, PathSpec]]"}, "return_type": "Iterator[Path]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_path_is_ignored", "child.is_absolute", "child.is_dir", "child.is_file", "child.iterdir", "child.relative_to", "child.relative_to(root).as_posix", "gen_python_files", "get_gitignore", "include.search", "jupyter_dependencies_are_installed", "path_is_excluded", "report.path_ignored", "resolves_outside_root_or_cannot_stat", "root.is_absolute"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Generate all files under `path` whose paths are not excluded by the `exclude_regex`, `extend_exclude`, or `force_exclude` regexes, but are included by the `include` regex.", "source_code": "def gen_python_files(\n    paths: Iterable[Path],\n    root: Path,\n    include: Pattern[str],\n    exclude: Pattern[str],\n    extend_exclude: Optional[Pattern[str]],\n    force_exclude: Optional[Pattern[str]],\n    report: Report,\n    gitignore_dict: Optional[dict[Path, PathSpec]],\n    *,\n    verbose: bool,\n    quiet: bool,\n) -> Iterator[Path]:\n    \"\"\"Generate all files under `path` whose paths are not excluded by the\n    `exclude_regex`, `extend_exclude`, or `force_exclude` regexes,\n    but are included by the `include` regex.\n\n    Symbolic links pointing outside of the `root` directory are ignored.\n\n    `report` is where output about exclusions goes.\n    \"\"\"\n\n    assert root.is_absolute(), f\"INTERNAL ERROR: `root` must be absolute but is {root}\"\n    for child in paths:\n        assert child.is_absolute()\n        root_relative_path = child.relative_to(root).as_posix()\n\n        # First ignore files matching .gitignore, if passed\n        if gitignore_dict and _path_is_ignored(\n            root_relative_path, root, gitignore_dict\n        ):\n            report.path_ignored(child, \"matches a .gitignore file content\")\n            continue\n\n        # Then ignore with `--exclude` `--extend-exclude` and `--force-exclude` options.\n        root_relative_path = \"/\" + root_relative_path\n        if child.is_dir():\n            root_relative_path += \"/\"\n\n        if path_is_excluded(root_relative_path, exclude):\n            report.path_ignored(child, \"matches the --exclude regular expression\")\n            continue\n\n        if path_is_excluded(root_relative_path, extend_exclude):\n            report.path_ignored(\n                child, \"matches the --extend-exclude regular expression\"\n            )\n            continue\n\n        if path_is_excluded(root_relative_path, force_exclude):\n            report.path_ignored(child, \"matches the --force-exclude regular expression\")\n            continue\n\n        if resolves_outside_root_or_cannot_stat(child, root, report):\n            continue\n\n        if child.is_dir():\n            # If gitignore is None, gitignore usage is disabled, while a Falsey\n            # gitignore is when the directory doesn't have a .gitignore file.\n            if gitignore_dict is not None:\n                new_gitignore_dict = {\n                    **gitignore_dict,\n                    root / child: get_gitignore(child),\n                }\n            else:\n                new_gitignore_dict = None\n            yield from gen_python_files(\n                child.iterdir(),\n                root,\n                include,\n                exclude,\n                extend_exclude,\n                force_exclude,\n                report,\n                new_gitignore_dict,\n                verbose=verbose,\n                quiet=quiet,\n            )\n\n        elif child.is_file():\n            if child.suffix == \".ipynb\" and not jupyter_dependencies_are_installed(\n                warn=verbose or not quiet\n            ):\n                continue\n            include_match = include.search(root_relative_path) if include else True\n            if include_match:\n                yield child", "loc": 87}
{"file": "black\\src\\black\\files.py", "class_name": null, "function_name": "wrap_stream_for_windows", "parameters": ["f"], "param_types": {"f": "io.TextIOWrapper"}, "return_type": "Union[io.TextIOWrapper, 'colorama.AnsiToWin32']", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["wrap_stream"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Wrap stream with colorama's wrap_stream so colors are shown on Windows. If `colorama` is unavailable, the original stream is returned unmodified. Otherwise, the `wrap_stream()` function determines whether the stream needs", "source_code": "def wrap_stream_for_windows(\n    f: io.TextIOWrapper,\n) -> Union[io.TextIOWrapper, \"colorama.AnsiToWin32\"]:\n    \"\"\"\n    Wrap stream with colorama's wrap_stream so colors are shown on Windows.\n\n    If `colorama` is unavailable, the original stream is returned unmodified.\n    Otherwise, the `wrap_stream()` function determines whether the stream needs\n    to be wrapped for a Windows environment and will accordingly either return\n    an `AnsiToWin32` wrapper or the original stream.\n    \"\"\"\n    try:\n        from colorama.initialise import wrap_stream\n    except ImportError:\n        return f\n    else:\n        # Set `strip=False` to avoid needing to modify test_express_diff_with_color.\n        return wrap_stream(f, convert=None, strip=False, autoreset=False, wrap=True)", "loc": 18}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": null, "function_name": "jupyter_dependencies_are_installed", "parameters": [], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["find_spec", "out"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def jupyter_dependencies_are_installed(*, warn: bool) -> bool:\n    installed = (\n        find_spec(\"tokenize_rt\") is not None and find_spec(\"IPython\") is not None\n    )\n    if not installed and warn:\n        msg = (\n            \"Skipping .ipynb files as Jupyter dependencies are not installed.\\n\"\n            'You can fix this by running ``pip install \"black[jupyter]\"``'\n        )\n        out(msg)\n    return installed", "loc": 11}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": null, "function_name": "validate_cell", "parameters": ["src", "mode"], "param_types": {"src": "str", "mode": "Mode"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_get_code_start", "any", "line.split", "line.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Check that cell does not already contain TransformerManager transformations, or non-Python cell magics, which might cause tokenizer_rt to break because of indentations.", "source_code": "def validate_cell(src: str, mode: Mode) -> None:\n    r\"\"\"Check that cell does not already contain TransformerManager transformations,\n    or non-Python cell magics, which might cause tokenizer_rt to break because of\n    indentations.\n\n    If a cell contains ``!ls``, then it'll be transformed to\n    ``get_ipython().system('ls')``. However, if the cell originally contained\n    ``get_ipython().system('ls')``, then it would get transformed in the same way:\n\n        >>> TransformerManager().transform_cell(\"get_ipython().system('ls')\")\n        \"get_ipython().system('ls')\\n\"\n        >>> TransformerManager().transform_cell(\"!ls\")\n        \"get_ipython().system('ls')\\n\"\n\n    Due to the impossibility of safely roundtripping in such situations, cells\n    containing transformed magics will be ignored.\n    \"\"\"\n    if any(transformed_magic in src for transformed_magic in TRANSFORMED_MAGICS):\n        raise NothingChanged\n\n    line = _get_code_start(src)\n    if line.startswith(\"%%\") and (\n        line.split(maxsplit=1)[0][2:]\n        not in PYTHON_CELL_MAGICS | mode.python_cell_magics\n    ):\n        raise NothingChanged", "loc": 26}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": null, "function_name": "remove_trailing_semicolon", "parameters": ["src"], "param_types": {"src": "str"}, "return_type": "tuple[str, bool]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["reversed_enumerate", "src_to_tokens", "tokens_to_src"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Remove trailing semicolon from Jupyter notebook cell. For example, fig, ax = plt.subplots()", "source_code": "def remove_trailing_semicolon(src: str) -> tuple[str, bool]:\n    \"\"\"Remove trailing semicolon from Jupyter notebook cell.\n\n    For example,\n\n        fig, ax = plt.subplots()\n        ax.plot(x_data, y_data);  # plot data\n\n    would become\n\n        fig, ax = plt.subplots()\n        ax.plot(x_data, y_data)  # plot data\n\n    Mirrors the logic in `quiet` from `IPython.core.displayhook`, but uses\n    ``tokenize_rt`` so that round-tripping works fine.\n    \"\"\"\n    from tokenize_rt import reversed_enumerate, src_to_tokens, tokens_to_src\n\n    tokens = src_to_tokens(src)\n    trailing_semicolon = False\n    for idx, token in reversed_enumerate(tokens):\n        if token.name in TOKENS_TO_IGNORE:\n            continue\n        if token.name == \"OP\" and token.src == \";\":\n            del tokens[idx]\n            trailing_semicolon = True\n        break\n    if not trailing_semicolon:\n        return src, False\n    return tokens_to_src(tokens), True", "loc": 30}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": null, "function_name": "put_trailing_semicolon_back", "parameters": ["src", "has_trailing_semicolon"], "param_types": {"src": "str", "has_trailing_semicolon": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AssertionError", "reversed_enumerate", "src_to_tokens", "str", "token._replace", "tokens_to_src"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Put trailing semicolon back if cell originally had it. Mirrors the logic in `quiet` from `IPython.core.displayhook`, but uses ``tokenize_rt`` so that round-tripping works fine.", "source_code": "def put_trailing_semicolon_back(src: str, has_trailing_semicolon: bool) -> str:\n    \"\"\"Put trailing semicolon back if cell originally had it.\n\n    Mirrors the logic in `quiet` from `IPython.core.displayhook`, but uses\n    ``tokenize_rt`` so that round-tripping works fine.\n    \"\"\"\n    if not has_trailing_semicolon:\n        return src\n    from tokenize_rt import reversed_enumerate, src_to_tokens, tokens_to_src\n\n    tokens = src_to_tokens(src)\n    for idx, token in reversed_enumerate(tokens):\n        if token.name in TOKENS_TO_IGNORE:\n            continue\n        tokens[idx] = token._replace(src=token.src + \";\")\n        break\n    else:  # pragma: nocover\n        raise AssertionError(\n            \"INTERNAL ERROR: Was not able to reinstate trailing semicolon. \"\n            \"Please report a bug on https://github.com/psf/black/issues.  \"\n        ) from None\n    return str(tokens_to_src(tokens))", "loc": 22}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": null, "function_name": "mask_cell", "parameters": ["src"], "param_types": {"src": "str"}, "return_type": "tuple[str, list[Replacement]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TransformerManager", "ast.parse", "len", "replace_cell_magics", "replace_magics", "src.strip", "src.strip().splitlines", "transformed.strip", "transformed.strip().splitlines", "transformer_manager.transform_cell"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Mask IPython magics so content becomes parseable Python code. For example, %matplotlib inline", "source_code": "def mask_cell(src: str) -> tuple[str, list[Replacement]]:\n    \"\"\"Mask IPython magics so content becomes parseable Python code.\n\n    For example,\n\n        %matplotlib inline\n        'foo'\n\n    becomes\n\n        b\"25716f358c32750\"\n        'foo'\n\n    The replacements are returned, along with the transformed code.\n    \"\"\"\n    replacements: list[Replacement] = []\n    try:\n        ast.parse(src)\n    except SyntaxError:\n        # Might have IPython magics, will process below.\n        pass\n    else:\n        # Syntax is fine, nothing to mask, early return.\n        return src, replacements\n\n    from IPython.core.inputtransformer2 import TransformerManager\n\n    transformer_manager = TransformerManager()\n    # A side effect of the following transformation is that it also removes any\n    # empty lines at the beginning of the cell.\n    transformed = transformer_manager.transform_cell(src)\n    transformed, cell_magic_replacements = replace_cell_magics(transformed)\n    replacements += cell_magic_replacements\n    transformed = transformer_manager.transform_cell(transformed)\n    transformed, magic_replacements = replace_magics(transformed)\n    if len(transformed.strip().splitlines()) != len(src.strip().splitlines()):\n        # Multi-line magic, not supported.\n        raise NothingChanged\n    replacements += magic_replacements\n    return transformed, replacements", "loc": 40}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": null, "function_name": "create_token", "parameters": ["n_chars"], "param_types": {"n_chars": "int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "max", "secrets.token_hex"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Create a randomly generated token that is n_chars characters long.", "source_code": "def create_token(n_chars: int) -> str:\n    \"\"\"Create a randomly generated token that is n_chars characters long.\"\"\"\n    assert n_chars > 0\n    n_bytes = max(n_chars // 2 - 1, 1)\n    token = secrets.token_hex(n_bytes)\n    if len(token) + 3 > n_chars:\n        token = token[:-1]\n    # We use a bytestring so that the string does not get interpreted\n    # as a docstring.\n    return f'b\"{token}\"'", "loc": 10}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": null, "function_name": "get_token", "parameters": ["src", "magic"], "param_types": {"src": "str", "magic": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AssertionError", "create_token", "len"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Return randomly generated token to mask IPython magic with. For example, if 'magic' was `%matplotlib inline`, then a possible token to mask it with would be `\"43fdd17f7e5ddc83\"`. The token", "source_code": "def get_token(src: str, magic: str) -> str:\n    \"\"\"Return randomly generated token to mask IPython magic with.\n\n    For example, if 'magic' was `%matplotlib inline`, then a possible\n    token to mask it with would be `\"43fdd17f7e5ddc83\"`. The token\n    will be the same length as the magic, and we make sure that it was\n    not already present anywhere else in the cell.\n    \"\"\"\n    assert magic\n    n_chars = len(magic)\n    token = create_token(n_chars)\n    counter = 0\n    while token in src:\n        token = create_token(n_chars)\n        counter += 1\n        if counter > 100:\n            raise AssertionError(\n                \"INTERNAL ERROR: Black was not able to replace IPython magic. \"\n                \"Please report a bug on https://github.com/psf/black/issues.  \"\n                f\"The magic might be helpful: {magic}\"\n            ) from None\n    return token", "loc": 22}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": null, "function_name": "replace_cell_magics", "parameters": ["src"], "param_types": {"src": "str"}, "return_type": "tuple[str, list[Replacement]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CellMagicFinder", "Replacement", "ast.parse", "cell_magic_finder.visit", "get_token", "replacements.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Replace cell magic with token. Note that 'src' will already have been processed by IPython's TransformerManager().transform_cell.", "source_code": "def replace_cell_magics(src: str) -> tuple[str, list[Replacement]]:\n    r\"\"\"Replace cell magic with token.\n\n    Note that 'src' will already have been processed by IPython's\n    TransformerManager().transform_cell.\n\n    Example,\n\n        get_ipython().run_cell_magic('t', '-n1', 'ls =!ls\\n')\n\n    becomes\n\n        \"a794.\"\n        ls =!ls\n\n    The replacement, along with the transformed code, is returned.\n    \"\"\"\n    replacements: list[Replacement] = []\n\n    tree = ast.parse(src)\n\n    cell_magic_finder = CellMagicFinder()\n    cell_magic_finder.visit(tree)\n    if cell_magic_finder.cell_magic is None:\n        return src, replacements\n    header = cell_magic_finder.cell_magic.header\n    mask = get_token(src, header)\n    replacements.append(Replacement(mask=mask, src=header))\n    return f\"{mask}\\n{cell_magic_finder.cell_magic.body}\", replacements", "loc": 29}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": null, "function_name": "replace_magics", "parameters": ["src"], "param_types": {"src": "str"}, "return_type": "tuple[str, list[Replacement]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "AssertionError", "MagicFinder", "Replacement", "ast.parse", "enumerate", "get_token", "len", "magic_finder.visit", "new_srcs.append", "replacements.append", "src.split"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Replace magics within body of cell. Note that 'src' will already have been processed by IPython's TransformerManager().transform_cell.", "source_code": "def replace_magics(src: str) -> tuple[str, list[Replacement]]:\n    \"\"\"Replace magics within body of cell.\n\n    Note that 'src' will already have been processed by IPython's\n    TransformerManager().transform_cell.\n\n    Example, this\n\n        get_ipython().run_line_magic('matplotlib', 'inline')\n        'foo'\n\n    becomes\n\n        \"5e67db56d490fd39\"\n        'foo'\n\n    The replacement, along with the transformed code, are returned.\n    \"\"\"\n    replacements = []\n    magic_finder = MagicFinder()\n    magic_finder.visit(ast.parse(src))\n    new_srcs = []\n    for i, line in enumerate(src.split(\"\\n\"), start=1):\n        if i in magic_finder.magics:\n            offsets_and_magics = magic_finder.magics[i]\n            if len(offsets_and_magics) != 1:  # pragma: nocover\n                raise AssertionError(\n                    f\"Expecting one magic per line, got: {offsets_and_magics}\\n\"\n                    \"Please report a bug on https://github.com/psf/black/issues.\"\n                )\n            col_offset, magic = (\n                offsets_and_magics[0].col_offset,\n                offsets_and_magics[0].magic,\n            )\n            mask = get_token(src, magic)\n            replacements.append(Replacement(mask=mask, src=magic))\n            line = line[:col_offset] + mask\n        new_srcs.append(line)\n    return \"\\n\".join(new_srcs), replacements", "loc": 39}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": null, "function_name": "unmask_cell", "parameters": ["src", "replacements"], "param_types": {"src": "str", "replacements": "list[Replacement]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["src.replace"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Remove replacements from cell. For example \"9b20\"", "source_code": "def unmask_cell(src: str, replacements: list[Replacement]) -> str:\n    \"\"\"Remove replacements from cell.\n\n    For example\n\n        \"9b20\"\n        foo = bar\n\n    becomes\n\n        %%time\n        foo = bar\n    \"\"\"\n    for replacement in replacements:\n        src = src.replace(replacement.mask, replacement.src)\n    return src", "loc": 16}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": "CellMagicFinder", "function_name": "visit_Expr", "parameters": ["self", "node"], "param_types": {"node": "ast.Expr"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CellMagic", "_get_str_args", "_is_ipython_magic", "isinstance", "self.generic_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Find cell magic, extract header and body.", "source_code": "def visit_Expr(self, node: ast.Expr) -> None:\n    \"\"\"Find cell magic, extract header and body.\"\"\"\n    if (\n        isinstance(node.value, ast.Call)\n        and _is_ipython_magic(node.value.func)\n        and node.value.func.attr == \"run_cell_magic\"\n    ):\n        args = _get_str_args(node.value.args)\n        self.cell_magic = CellMagic(name=args[0], params=args[1], body=args[2])\n    self.generic_visit(node)", "loc": 10}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": "MagicFinder", "function_name": "visit_Assign", "parameters": ["self", "node"], "param_types": {"node": "ast.Assign"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AssertionError", "OffsetAndMagic", "_get_str_args", "_is_ipython_magic", "isinstance", "self.generic_visit", "self.magics[node.value.lineno].append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Look for system assign magics. For example, black_version = !black --version", "source_code": "def visit_Assign(self, node: ast.Assign) -> None:\n    \"\"\"Look for system assign magics.\n\n    For example,\n\n        black_version = !black --version\n        env = %env var\n\n    would have been (respectively) transformed to\n\n        black_version = get_ipython().getoutput('black --version')\n        env = get_ipython().run_line_magic('env', 'var')\n\n    and we look for instances of any of the latter.\n    \"\"\"\n    if isinstance(node.value, ast.Call) and _is_ipython_magic(node.value.func):\n        args = _get_str_args(node.value.args)\n        if node.value.func.attr == \"getoutput\":\n            src = f\"!{args[0]}\"\n        elif node.value.func.attr == \"run_line_magic\":\n            src = f\"%{args[0]}\"\n            if args[1]:\n                src += f\" {args[1]}\"\n        else:\n            raise AssertionError(\n                f\"Unexpected IPython magic {node.value.func.attr!r} found. \"\n                \"Please report a bug on https://github.com/psf/black/issues.\"\n            ) from None\n        self.magics[node.value.lineno].append(\n            OffsetAndMagic(node.value.col_offset, src)\n        )\n    self.generic_visit(node)", "loc": 32}
{"file": "black\\src\\black\\handle_ipynb_magics.py", "class_name": "MagicFinder", "function_name": "visit_Expr", "parameters": ["self", "node"], "param_types": {"node": "ast.Expr"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["OffsetAndMagic", "_get_str_args", "_is_ipython_magic", "isinstance", "self.generic_visit", "self.magics[node.value.lineno].append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Look for magics in body of cell. For examples, !ls", "source_code": "def visit_Expr(self, node: ast.Expr) -> None:\n    \"\"\"Look for magics in body of cell.\n\n    For examples,\n\n        !ls\n        !!ls\n        ?ls\n        ??ls\n\n    would (respectively) get transformed to\n\n        get_ipython().system('ls')\n        get_ipython().getoutput('ls')\n        get_ipython().run_line_magic('pinfo', 'ls')\n        get_ipython().run_line_magic('pinfo2', 'ls')\n\n    and we look for instances of any of the latter.\n    \"\"\"\n    if isinstance(node.value, ast.Call) and _is_ipython_magic(node.value.func):\n        args = _get_str_args(node.value.args)\n        if node.value.func.attr == \"run_line_magic\":\n            if args[0] == \"pinfo\":\n                src = f\"?{args[1]}\"\n            elif args[0] == \"pinfo2\":\n                src = f\"??{args[1]}\"\n            else:\n                src = f\"%{args[0]}\"\n                if args[1]:\n                    src += f\" {args[1]}\"\n        elif node.value.func.attr == \"system\":\n            src = f\"!{args[0]}\"\n        elif node.value.func.attr == \"getoutput\":\n            src = f\"!!{args[0]}\"\n        else:\n            raise NothingChanged  # unsupported magic.\n        self.magics[node.value.lineno].append(\n            OffsetAndMagic(node.value.col_offset, src)\n        )\n    self.generic_visit(node)", "loc": 40}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "should_split_funcdef_with_rhs", "parameters": ["line", "mode"], "param_types": {"line": "Line", "mode": "Mode"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Line", "get_leaves_inside_matching_brackets", "id", "result.append", "return_type_leaves.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "If a funcdef has a magic trailing comma in the return type, then we should first split the line with rhs to respect the comma.", "source_code": "def should_split_funcdef_with_rhs(line: Line, mode: Mode) -> bool:\n    \"\"\"If a funcdef has a magic trailing comma in the return type, then we should first\n    split the line with rhs to respect the comma.\n    \"\"\"\n    return_type_leaves: list[Leaf] = []\n    in_return_type = False\n\n    for leaf in line.leaves:\n        if leaf.type == token.COLON:\n            in_return_type = False\n        if in_return_type:\n            return_type_leaves.append(leaf)\n        if leaf.type == token.RARROW:\n            in_return_type = True\n\n    # using `bracket_split_build_line` will mess with whitespace, so we duplicate a\n    # couple lines from it.\n    result = Line(mode=line.mode, depth=line.depth)\n    leaves_to_track = get_leaves_inside_matching_brackets(return_type_leaves)\n    for leaf in return_type_leaves:\n        result.append(\n            leaf,\n            preformatted=True,\n            track_bracket=id(leaf) in leaves_to_track,\n        )\n\n    # we could also return true if the line is too long, and the return type is longer\n    # than the param list. Or if `should_split_rhs` returns True.\n    return result.magic_trailing_comma is not None", "loc": 29}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "left_hand_split", "parameters": ["line", "_features", "mode"], "param_types": {"line": "Line", "_features": "Collection[Feature]", "mode": "Mode"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CannotSplit", "bracket_split_build_line", "bracket_split_succeeded_or_raise", "current_leaves.append", "ensure_visible", "enumerate", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Split line into many lines, starting with the first matching bracket pair. Note: this usually looks weird, only use this for function definitions. Prefer RHS otherwise.  This is why this function is not symmetrical with", "source_code": "def left_hand_split(\n    line: Line, _features: Collection[Feature], mode: Mode\n) -> Iterator[Line]:\n    \"\"\"Split line into many lines, starting with the first matching bracket pair.\n\n    Note: this usually looks weird, only use this for function definitions.\n    Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses.\n    \"\"\"\n    for leaf_type in [token.LPAR, token.LSQB]:\n        tail_leaves: list[Leaf] = []\n        body_leaves: list[Leaf] = []\n        head_leaves: list[Leaf] = []\n        current_leaves = head_leaves\n        matching_bracket: Optional[Leaf] = None\n        depth = 0\n        for index, leaf in enumerate(line.leaves):\n            if index == 2 and leaf.type == token.LSQB:\n                # A [ at index 2 means this is a type param, so start\n                # tracking the depth\n                depth += 1\n            elif depth > 0:\n                if leaf.type == token.LSQB:\n                    depth += 1\n                elif leaf.type == token.RSQB:\n                    depth -= 1\n            if (\n                current_leaves is body_leaves\n                and leaf.type in CLOSING_BRACKETS\n                and leaf.opening_bracket is matching_bracket\n                and isinstance(matching_bracket, Leaf)\n                # If the code is still on LPAR and we are inside a type\n                # param, ignore the match since this is searching\n                # for the function arguments\n                and not (leaf_type == token.LPAR and depth > 0)\n            ):\n                ensure_visible(leaf)\n                ensure_visible(matching_bracket)\n                current_leaves = tail_leaves if body_leaves else head_leaves\n            current_leaves.append(leaf)\n            if current_leaves is head_leaves:\n                if leaf.type == leaf_type and (\n                    Preview.fix_type_expansion_split not in mode\n                    or not (leaf_type == token.LPAR and depth > 0)\n                ):\n                    matching_bracket = leaf\n                    current_leaves = body_leaves\n        if matching_bracket and tail_leaves:\n            break\n    if not matching_bracket or not tail_leaves:\n        raise CannotSplit(\"No brackets found\")\n\n    head = bracket_split_build_line(\n        head_leaves, line, matching_bracket, component=_BracketSplitComponent.head\n    )\n    body = bracket_split_build_line(\n        body_leaves, line, matching_bracket, component=_BracketSplitComponent.body\n    )\n    tail = bracket_split_build_line(\n        tail_leaves, line, matching_bracket, component=_BracketSplitComponent.tail\n    )\n    bracket_split_succeeded_or_raise(head, body, tail)\n    for result in (head, body, tail):\n        if result:\n            yield result", "loc": 65}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "right_hand_split", "parameters": ["line", "mode", "features", "omit"], "param_types": {"line": "Line", "mode": "Mode", "features": "Collection[Feature]", "omit": "Collection[LeafID]"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_first_right_hand_split", "_maybe_split_omitting_optional_parens"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Split line into many lines, starting with the last matching bracket pair. If the split was by optional parentheses, attempt splitting without them, too. `omit` is a collection of closing bracket IDs that shouldn't be considered for", "source_code": "def right_hand_split(\n    line: Line,\n    mode: Mode,\n    features: Collection[Feature] = (),\n    omit: Collection[LeafID] = (),\n) -> Iterator[Line]:\n    \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    `omit` is a collection of closing bracket IDs that shouldn't be considered for\n    this split.\n\n    Note: running this function modifies `bracket_depth` on the leaves of `line`.\n    \"\"\"\n    rhs_result = _first_right_hand_split(line, omit=omit)\n    yield from _maybe_split_omitting_optional_parens(\n        rhs_result, line, mode, features=features, omit=omit\n    )", "loc": 18}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "bracket_split_succeeded_or_raise", "parameters": ["head", "body", "tail"], "param_types": {"head": "Line", "body": "Line", "tail": "Line"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CannotSplit", "len", "str", "str(tail).strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Raise :exc:`CannotSplit` if the last left- or right-hand split failed. Do nothing otherwise. A left- or right-hand split is based on a pair of brackets. Content before", "source_code": "def bracket_split_succeeded_or_raise(head: Line, body: Line, tail: Line) -> None:\n    \"\"\"Raise :exc:`CannotSplit` if the last left- or right-hand split failed.\n\n    Do nothing otherwise.\n\n    A left- or right-hand split is based on a pair of brackets. Content before\n    (and including) the opening bracket is left on one line, content inside the\n    brackets is put on a separate line, and finally content starting with and\n    following the closing bracket is put on a separate line.\n\n    Those are called `head`, `body`, and `tail`, respectively. If the split\n    produced the same line (all content in `head`) or ended up with an empty `body`\n    and the `tail` is just the closing bracket, then it's considered failed.\n    \"\"\"\n    tail_len = len(str(tail).strip())\n    if not body:\n        if tail_len == 0:\n            raise CannotSplit(\"Splitting brackets produced the same line\")\n\n        elif tail_len < 3:\n            raise CannotSplit(\n                f\"Splitting brackets on an empty body to save {tail_len} characters is\"\n                \" not worth it\"\n            )", "loc": 24}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "bracket_split_build_line", "parameters": ["leaves", "original", "opening_bracket"], "param_types": {"leaves": "list[Leaf]", "original": "Line", "opening_bracket": "Leaf"}, "return_type": "Line", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "Line", "_ensure_trailing_comma", "get_leaves_inside_matching_brackets", "id", "leaves.insert", "len", "original.comments_after", "range", "result.append", "set", "should_split_line"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return a new line with given `leaves` and respective comments from `original`. If it's the head component, brackets will be tracked so trailing commas are respected.", "source_code": "def bracket_split_build_line(\n    leaves: list[Leaf],\n    original: Line,\n    opening_bracket: Leaf,\n    *,\n    component: _BracketSplitComponent,\n) -> Line:\n    \"\"\"Return a new line with given `leaves` and respective comments from `original`.\n\n    If it's the head component, brackets will be tracked so trailing commas are\n    respected.\n\n    If it's the body component, the result line is one-indented inside brackets and as\n    such has its first leaf's prefix normalized and a trailing comma added when\n    expected.\n    \"\"\"\n    result = Line(mode=original.mode, depth=original.depth)\n    if component is _BracketSplitComponent.body:\n        result.inside_brackets = True\n        result.depth += 1\n        if _ensure_trailing_comma(leaves, original, opening_bracket):\n            for i in range(len(leaves) - 1, -1, -1):\n                if leaves[i].type == STANDALONE_COMMENT:\n                    continue\n\n                if leaves[i].type != token.COMMA:\n                    new_comma = Leaf(token.COMMA, \",\")\n                    leaves.insert(i + 1, new_comma)\n                break\n\n    leaves_to_track: set[LeafID] = set()\n    if component is _BracketSplitComponent.head:\n        leaves_to_track = get_leaves_inside_matching_brackets(leaves)\n    # Populate the line\n    for leaf in leaves:\n        result.append(\n            leaf,\n            preformatted=True,\n            track_bracket=id(leaf) in leaves_to_track,\n        )\n        for comment_after in original.comments_after(leaf):\n            result.append(comment_after, preformatted=True)\n    if component is _BracketSplitComponent.body and should_split_line(\n        result, opening_bracket\n    ):\n        result.should_split_rhs = True\n    return result", "loc": 47}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "dont_increase_indentation", "parameters": ["split_func"], "param_types": {"split_func": "Transformer"}, "return_type": "Transformer", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["split_func", "wraps"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Normalize prefix of the first leaf in every line returned by `split_func`. This is a decorator over relevant split functions.", "source_code": "def dont_increase_indentation(split_func: Transformer) -> Transformer:\n    \"\"\"Normalize prefix of the first leaf in every line returned by `split_func`.\n\n    This is a decorator over relevant split functions.\n    \"\"\"\n\n    @wraps(split_func)\n    def split_wrapper(\n        line: Line, features: Collection[Feature], mode: Mode\n    ) -> Iterator[Line]:\n        for split_line in split_func(line, features, mode):\n            split_line.leaves[0].prefix = \"\"\n            yield split_line\n\n    return split_wrapper", "loc": 15}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "delimiter_split", "parameters": ["line", "features", "mode"], "param_types": {"line": "Line", "features": "Collection[Feature]", "mode": "Mode"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CannotSplit", "Line", "_can_add_trailing_comma", "_get_last_non_comment_leaf", "_safe_add_trailing_comma", "append_comments", "append_to_line", "bt.delimiter_count_with_priority", "bt.delimiters.get", "bt.max_delimiter_priority", "current_line.append", "current_line.append_safe", "enumerate", "id", "len", "line.comments_after", "min"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Split according to delimiters of the highest priority. If the appropriate Features are given, the split will add trailing commas also in function signatures and calls that contain `*` and `**`.", "source_code": "def delimiter_split(\n    line: Line, features: Collection[Feature], mode: Mode\n) -> Iterator[Line]:\n    \"\"\"Split according to delimiters of the highest priority.\n\n    If the appropriate Features are given, the split will add trailing commas\n    also in function signatures and calls that contain `*` and `**`.\n    \"\"\"\n    if len(line.leaves) == 0:\n        raise CannotSplit(\"Line empty\") from None\n    last_leaf = line.leaves[-1]\n\n    bt = line.bracket_tracker\n    try:\n        delimiter_priority = bt.max_delimiter_priority(exclude={id(last_leaf)})\n    except ValueError:\n        raise CannotSplit(\"No delimiters found\") from None\n\n    if (\n        delimiter_priority == DOT_PRIORITY\n        and bt.delimiter_count_with_priority(delimiter_priority) == 1\n    ):\n        raise CannotSplit(\"Splitting a single attribute from its owner looks wrong\")\n\n    current_line = Line(\n        mode=line.mode, depth=line.depth, inside_brackets=line.inside_brackets\n    )\n    lowest_depth = sys.maxsize\n    trailing_comma_safe = True\n\n    def append_to_line(leaf: Leaf) -> Iterator[Line]:\n        \"\"\"Append `leaf` to current line or to new line if appending impossible.\"\"\"\n        nonlocal current_line\n        try:\n            current_line.append_safe(leaf, preformatted=True)\n        except ValueError:\n            yield current_line\n\n            current_line = Line(\n                mode=line.mode, depth=line.depth, inside_brackets=line.inside_brackets\n            )\n            current_line.append(leaf)\n\n    def append_comments(leaf: Leaf) -> Iterator[Line]:\n        for comment_after in line.comments_after(leaf):\n            yield from append_to_line(comment_after)\n\n    last_non_comment_leaf = _get_last_non_comment_leaf(line)\n    for leaf_idx, leaf in enumerate(line.leaves):\n        yield from append_to_line(leaf)\n\n        previous_priority = leaf_idx > 0 and bt.delimiters.get(\n            id(line.leaves[leaf_idx - 1])\n        )\n        if (\n            previous_priority != delimiter_priority\n            or delimiter_priority in MIGRATE_COMMENT_DELIMITERS\n        ):\n            yield from append_comments(leaf)\n\n        lowest_depth = min(lowest_depth, leaf.bracket_depth)\n        if trailing_comma_safe and leaf.bracket_depth == lowest_depth:\n            trailing_comma_safe = _can_add_trailing_comma(leaf, features)\n\n        if last_leaf.type == STANDALONE_COMMENT and leaf_idx == last_non_comment_leaf:\n            current_line = _safe_add_trailing_comma(\n                trailing_comma_safe, delimiter_priority, current_line\n            )\n\n        leaf_priority = bt.delimiters.get(id(leaf))\n        if leaf_priority == delimiter_priority:\n            if (\n                leaf_idx + 1 < len(line.leaves)\n                and delimiter_priority not in MIGRATE_COMMENT_DELIMITERS\n            ):\n                yield from append_comments(line.leaves[leaf_idx + 1])\n\n            yield current_line\n            current_line = Line(\n                mode=line.mode, depth=line.depth, inside_brackets=line.inside_brackets\n            )\n\n    if current_line:\n        current_line = _safe_add_trailing_comma(\n            trailing_comma_safe, delimiter_priority, current_line\n        )\n        yield current_line", "loc": 87}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "standalone_comment_split", "parameters": ["line", "features", "mode"], "param_types": {"line": "Line", "features": "Collection[Feature]", "mode": "Mode"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CannotSplit", "Line", "append_to_line", "current_line.append", "current_line.append_safe", "line.comments_after", "line.contains_standalone_comments"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Split standalone comments from the rest of the line.", "source_code": "def standalone_comment_split(\n    line: Line, features: Collection[Feature], mode: Mode\n) -> Iterator[Line]:\n    \"\"\"Split standalone comments from the rest of the line.\"\"\"\n    if not line.contains_standalone_comments():\n        raise CannotSplit(\"Line does not have any standalone comments\")\n\n    current_line = Line(\n        mode=line.mode, depth=line.depth, inside_brackets=line.inside_brackets\n    )\n\n    def append_to_line(leaf: Leaf) -> Iterator[Line]:\n        \"\"\"Append `leaf` to current line or to new line if appending impossible.\"\"\"\n        nonlocal current_line\n        try:\n            current_line.append_safe(leaf, preformatted=True)\n        except ValueError:\n            yield current_line\n\n            current_line = Line(\n                line.mode, depth=line.depth, inside_brackets=line.inside_brackets\n            )\n            current_line.append(leaf)\n\n    for leaf in line.leaves:\n        yield from append_to_line(leaf)\n\n        for comment_after in line.comments_after(leaf):\n            yield from append_to_line(comment_after)\n\n    if current_line:\n        yield current_line", "loc": 32}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "remove_await_parens", "parameters": ["node", "mode", "features"], "param_types": {"node": "Node", "mode": "Mode", "features": "Collection[Feature]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "cast", "ensure_visible", "isinstance", "len", "maybe_make_parens_invisible_in_atom", "wrap_in_parentheses"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_await_parens(node: Node, mode: Mode, features: Collection[Feature]) -> None:\n    if node.children[0].type == token.AWAIT and len(node.children) > 1:\n        if (\n            node.children[1].type == syms.atom\n            and node.children[1].children[0].type == token.LPAR\n        ):\n            if maybe_make_parens_invisible_in_atom(\n                node.children[1],\n                parent=node,\n                mode=mode,\n                features=features,\n                remove_brackets_around_comma=True,\n            ):\n                wrap_in_parentheses(node, node.children[1], visible=False)\n\n            # Since await is an expression we shouldn't remove\n            # brackets in cases where this would change\n            # the AST due to operator precedence.\n            # Therefore we only aim to remove brackets around\n            # power nodes that aren't also await expressions themselves.\n            # https://peps.python.org/pep-0492/#updated-operator-precedence-table\n            # N.B. We've still removed any redundant nested brackets though :)\n            opening_bracket = cast(Leaf, node.children[1].children[0])\n            closing_bracket = cast(Leaf, node.children[1].children[-1])\n            bracket_contents = node.children[1].children[1]\n            if isinstance(bracket_contents, Node) and (\n                bracket_contents.type != syms.power\n                or bracket_contents.children[0].type == token.AWAIT\n                or any(\n                    isinstance(child, Leaf) and child.type == token.DOUBLESTAR\n                    for child in bracket_contents.children\n                )\n            ):\n                ensure_visible(opening_bracket)\n                ensure_visible(closing_bracket)", "loc": 35}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "remove_with_parens", "parameters": ["node", "parent", "mode", "features"], "param_types": {"node": "Node", "parent": "Node", "mode": "Mode", "features": "Collection[Feature]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "isinstance", "maybe_make_parens_invisible_in_atom", "node.leaves", "remove_with_parens", "wrap_in_parentheses"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Recursively hide optional parens in `with` statements.", "source_code": "def remove_with_parens(\n    node: Node, parent: Node, mode: Mode, features: Collection[Feature]\n) -> None:\n    \"\"\"Recursively hide optional parens in `with` statements.\"\"\"\n    # Removing all unnecessary parentheses in with statements in one pass is a tad\n    # complex as different variations of bracketed statements result in pretty\n    # different parse trees:\n    #\n    # with (open(\"file\")) as f:                       # this is an asexpr_test\n    #     ...\n    #\n    # with (open(\"file\") as f):                       # this is an atom containing an\n    #     ...                                         # asexpr_test\n    #\n    # with (open(\"file\")) as f, (open(\"file\")) as f:  # this is asexpr_test, COMMA,\n    #     ...                                         # asexpr_test\n    #\n    # with (open(\"file\") as f, open(\"file\") as f):    # an atom containing a\n    #     ...                                         # testlist_gexp which then\n    #                                                 # contains multiple asexpr_test(s)\n    if node.type == syms.atom:\n        if maybe_make_parens_invisible_in_atom(\n            node,\n            parent=parent,\n            mode=mode,\n            features=features,\n            remove_brackets_around_comma=True,\n        ):\n            wrap_in_parentheses(parent, node, visible=False)\n        if isinstance(node.children[1], Node):\n            remove_with_parens(node.children[1], node, mode=mode, features=features)\n    elif node.type == syms.testlist_gexp:\n        for child in node.children:\n            if isinstance(child, Node):\n                remove_with_parens(child, node, mode=mode, features=features)\n    elif node.type == syms.asexpr_test and not any(\n        leaf.type == token.COLONEQUAL for leaf in node.leaves()\n    ):\n        if maybe_make_parens_invisible_in_atom(\n            node.children[0],\n            parent=node,\n            mode=mode,\n            features=features,\n            remove_brackets_around_comma=True,\n        ):\n            wrap_in_parentheses(node, node.children[0], visible=False)", "loc": 46}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "should_split_line", "parameters": ["line", "opening_bracket"], "param_types": {"line": "Line", "opening_bracket": "Leaf"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["exclude.add", "id", "line.bracket_tracker.max_delimiter_priority", "set"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Should `line` be immediately split with `delimiter_split()` after RHS?", "source_code": "def should_split_line(line: Line, opening_bracket: Leaf) -> bool:\n    \"\"\"Should `line` be immediately split with `delimiter_split()` after RHS?\"\"\"\n\n    if not (opening_bracket.parent and opening_bracket.value in \"[{(\"):\n        return False\n\n    # We're essentially checking if the body is delimited by commas and there's more\n    # than one of them (we're excluding the trailing comma and if the delimiter priority\n    # is still commas, that means there's more).\n    exclude = set()\n    trailing_comma = False\n    try:\n        last_leaf = line.leaves[-1]\n        if last_leaf.type == token.COMMA:\n            trailing_comma = True\n            exclude.add(id(last_leaf))\n        max_priority = line.bracket_tracker.max_delimiter_priority(exclude=exclude)\n    except (IndexError, ValueError):\n        return False\n\n    return max_priority == COMMA_PRIORITY and (\n        (line.mode.magic_trailing_comma and trailing_comma)\n        # always explode imports\n        or opening_bracket.parent.type in {syms.atom, syms.import_from}\n    )", "loc": 25}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "generate_trailers_to_omit", "parameters": ["line", "line_length"], "param_types": {"line": "Line", "line_length": "int"}, "return_type": "Iterator[set[LeafID]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["id", "inner_brackets.add", "inner_brackets.clear", "is_one_sequence_between", "len", "line.enumerate_with_length", "omit.add", "omit.update", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Generate sets of closing bracket IDs that should be omitted in a RHS. Brackets can be omitted if the entire trailer up to and including a preceding closing bracket fits in one line.", "source_code": "def generate_trailers_to_omit(line: Line, line_length: int) -> Iterator[set[LeafID]]:\n    \"\"\"Generate sets of closing bracket IDs that should be omitted in a RHS.\n\n    Brackets can be omitted if the entire trailer up to and including\n    a preceding closing bracket fits in one line.\n\n    Yielded sets are cumulative (contain results of previous yields, too).  First\n    set is empty, unless the line should explode, in which case bracket pairs until\n    the one that needs to explode are omitted.\n    \"\"\"\n\n    omit: set[LeafID] = set()\n    if not line.magic_trailing_comma:\n        yield omit\n\n    length = 4 * line.depth\n    opening_bracket: Optional[Leaf] = None\n    closing_bracket: Optional[Leaf] = None\n    inner_brackets: set[LeafID] = set()\n    for index, leaf, leaf_length in line.enumerate_with_length(is_reversed=True):\n        length += leaf_length\n        if length > line_length:\n            break\n\n        has_inline_comment = leaf_length > len(leaf.value) + len(leaf.prefix)\n        if leaf.type == STANDALONE_COMMENT or has_inline_comment:\n            break\n\n        if opening_bracket:\n            if leaf is opening_bracket:\n                opening_bracket = None\n            elif leaf.type in CLOSING_BRACKETS:\n                prev = line.leaves[index - 1] if index > 0 else None\n                if (\n                    prev\n                    and prev.type == token.COMMA\n                    and leaf.opening_bracket is not None\n                    and not is_one_sequence_between(\n                        leaf.opening_bracket, leaf, line.leaves\n                    )\n                ):\n                    # Never omit bracket pairs with trailing commas.\n                    # We need to explode on those.\n                    break\n\n                inner_brackets.add(id(leaf))\n        elif leaf.type in CLOSING_BRACKETS:\n            prev = line.leaves[index - 1] if index > 0 else None\n            if prev and prev.type in OPENING_BRACKETS:\n                # Empty brackets would fail a split so treat them as \"inner\"\n                # brackets (e.g. only add them to the `omit` set if another\n                # pair of brackets was good enough.\n                inner_brackets.add(id(leaf))\n                continue\n\n            if closing_bracket:\n                omit.add(id(closing_bracket))\n                omit.update(inner_brackets)\n                inner_brackets.clear()\n                yield omit\n\n            if (\n                prev\n                and prev.type == token.COMMA\n                and leaf.opening_bracket is not None\n                and not is_one_sequence_between(leaf.opening_bracket, leaf, line.leaves)\n            ):\n                # Never omit bracket pairs with trailing commas.\n                # We need to explode on those.\n                break\n\n            if leaf.value:\n                opening_bracket = leaf.opening_bracket\n                closing_bracket = leaf", "loc": 74}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "run_transformer", "parameters": ["line", "transform", "mode", "features"], "param_types": {"line": "Line", "transform": "Transformer", "mode": "Mode", "features": "Collection[Feature]"}, "return_type": "list[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CannotTransform", "all", "any", "append_leaves", "is_line_short_enough", "line.clone", "line.contains_multiline_strings", "line_to_string", "result.extend", "result[0].contains_uncollapsable_type_comments", "result[0].contains_unsplittable_type_ignore", "run_transformer", "set", "str", "str(transformed_line).strip", "transform", "transform_line"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run_transformer(\n    line: Line,\n    transform: Transformer,\n    mode: Mode,\n    features: Collection[Feature],\n    *,\n    line_str: str = \"\",\n) -> list[Line]:\n    if not line_str:\n        line_str = line_to_string(line)\n    result: list[Line] = []\n    for transformed_line in transform(line, features, mode):\n        if str(transformed_line).strip(\"\\n\") == line_str:\n            raise CannotTransform(\"Line transformer returned an unchanged result\")\n\n        result.extend(transform_line(transformed_line, mode=mode, features=features))\n\n    features_set = set(features)\n    if (\n        Feature.FORCE_OPTIONAL_PARENTHESES in features_set\n        or transform.__class__.__name__ != \"rhs\"\n        or not line.bracket_tracker.invisible\n        or any(bracket.value for bracket in line.bracket_tracker.invisible)\n        or line.contains_multiline_strings()\n        or result[0].contains_uncollapsable_type_comments()\n        or result[0].contains_unsplittable_type_ignore()\n        or is_line_short_enough(result[0], mode=mode)\n        # If any leaves have no parents (which _can_ occur since\n        # `transform(line)` potentially destroys the line's underlying node\n        # structure), then we can't proceed. Doing so would cause the below\n        # call to `append_leaves()` to fail.\n        or any(leaf.parent is None for leaf in line.leaves)\n    ):\n        return result\n\n    line_copy = line.clone()\n    append_leaves(line_copy, line, line.leaves)\n    features_fop = features_set | {Feature.FORCE_OPTIONAL_PARENTHESES}\n    second_opinion = run_transformer(\n        line_copy, transform, mode, features_fop, line_str=line_str\n    )\n    if all(is_line_short_enough(ln, mode=mode) for ln in second_opinion):\n        result = second_opinion\n    return result", "loc": 44}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "line", "parameters": ["self", "indent"], "param_types": {"indent": "int"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Line", "is_async_stmt_or_funcdef", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generate a line. If the line is empty, only emit if it makes sense. If the line is too long, split it first and then generate.", "source_code": "def line(self, indent: int = 0) -> Iterator[Line]:\n    \"\"\"Generate a line.\n\n    If the line is empty, only emit if it makes sense.\n    If the line is too long, split it first and then generate.\n\n    If any lines were generated, set up a new current_line.\n    \"\"\"\n    if not self.current_line:\n        self.current_line.depth += indent\n        return  # Line is empty, don't emit. Creating a new one unnecessary.\n\n    if len(self.current_line.leaves) == 1 and is_async_stmt_or_funcdef(\n        self.current_line.leaves[0]\n    ):\n        # Special case for async def/for/with statements. `visit_async_stmt`\n        # adds an `ASYNC` leaf then visits the child def/for/with statement\n        # nodes. Line yields from those nodes shouldn't treat the former\n        # `ASYNC` leaf as a complete line.\n        return\n\n    complete_line = self.current_line\n    self.current_line = Line(mode=self.mode, depth=complete_line.depth + indent)\n    yield complete_line", "loc": 24}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_test", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "node.append_child", "node.insert_child", "self.visit_default"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Visit an `x if y else z` test", "source_code": "def visit_test(self, node: Node) -> Iterator[Line]:\n    \"\"\"Visit an `x if y else z` test\"\"\"\n\n    already_parenthesized = (\n        node.prev_sibling and node.prev_sibling.type == token.LPAR\n    )\n\n    if not already_parenthesized:\n        # Similar to logic in wrap_in_parentheses\n        lpar = Leaf(token.LPAR, \"\")\n        rpar = Leaf(token.RPAR, \"\")\n        prefix = node.prefix\n        node.prefix = \"\"\n        lpar.prefix = prefix\n        node.insert_child(0, lpar)\n        node.append_child(rpar)\n\n    yield from self.visit_default(node)", "loc": 18}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_INDENT", "parameters": ["self", "node"], "param_types": {"node": "Leaf"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.line", "self.visit_default"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Increase indentation level, maybe yield a line.", "source_code": "def visit_INDENT(self, node: Leaf) -> Iterator[Line]:\n    \"\"\"Increase indentation level, maybe yield a line.\"\"\"\n    # In blib2to3 INDENT never holds comments.\n    yield from self.line(+1)\n    yield from self.visit_default(node)", "loc": 5}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_DEDENT", "parameters": ["self", "node"], "param_types": {"node": "Leaf"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.line", "self.visit_default"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Decrease indentation level, maybe yield a line.", "source_code": "def visit_DEDENT(self, node: Leaf) -> Iterator[Line]:\n    \"\"\"Decrease indentation level, maybe yield a line.\"\"\"\n    # The current line might still wait for trailing comments.  At DEDENT time\n    # there won't be any (they would be prefixes on the preceding NEWLINE).\n    # Emit the line then.\n    yield from self.line()\n\n    # While DEDENT has no value, its prefix may contain standalone comments\n    # that belong to the current indentation level.  Get 'em.\n    yield from self.visit_default(node)\n\n    # Finally, emit the dedent.\n    yield from self.line(-1)", "loc": 13}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_stmt", "parameters": ["self", "node", "keywords", "parens"], "param_types": {"node": "Node", "keywords": "set[str]", "parens": "set[str]"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_name_token", "normalize_invisible_parens", "self.line", "self.visit"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Visit a statement. This implementation is shared for `if`, `while`, `for`, `try`, `except`, `def`, `with`, `class`, `assert`, and assignments.", "source_code": "def visit_stmt(\n    self, node: Node, keywords: set[str], parens: set[str]\n) -> Iterator[Line]:\n    \"\"\"Visit a statement.\n\n    This implementation is shared for `if`, `while`, `for`, `try`, `except`,\n    `def`, `with`, `class`, `assert`, and assignments.\n\n    The relevant Python language `keywords` for a given statement will be\n    NAME leaves within it. This methods puts those on a separate line.\n\n    `parens` holds a set of string leaf values immediately after which\n    invisible parens should be put.\n    \"\"\"\n    normalize_invisible_parens(\n        node, parens_after=parens, mode=self.mode, features=self.features\n    )\n    for child in node.children:\n        if is_name_token(child) and child.value in keywords:\n            yield from self.line()\n\n        yield from self.visit(child)", "loc": 22}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_dictsetmaker", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "is_walrus_assignment", "maybe_make_parens_invisible_in_atom", "self.visit_default", "wrap_in_parentheses"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_dictsetmaker(self, node: Node) -> Iterator[Line]:\n    if Preview.wrap_long_dict_values_in_parens in self.mode:\n        for i, child in enumerate(node.children):\n            if i == 0:\n                continue\n            if node.children[i - 1].type == token.COLON:\n                if (\n                    child.type == syms.atom\n                    and child.children[0].type in OPENING_BRACKETS\n                    and not is_walrus_assignment(child)\n                ):\n                    maybe_make_parens_invisible_in_atom(\n                        child,\n                        parent=node,\n                        mode=self.mode,\n                        features=self.features,\n                        remove_brackets_around_comma=False,\n                    )\n                else:\n                    wrap_in_parentheses(node, child, visible=False)\n    yield from self.visit_default(node)", "loc": 21}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_funcdef", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["maybe_make_parens_invisible_in_atom", "self.line", "self.visit", "wrap_in_parentheses"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Visit function definition.", "source_code": "def visit_funcdef(self, node: Node) -> Iterator[Line]:\n    \"\"\"Visit function definition.\"\"\"\n    yield from self.line()\n\n    # Remove redundant brackets around return type annotation.\n    is_return_annotation = False\n    for child in node.children:\n        if child.type == token.RARROW:\n            is_return_annotation = True\n        elif is_return_annotation:\n            if child.type == syms.atom and child.children[0].type == token.LPAR:\n                if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    mode=self.mode,\n                    features=self.features,\n                    remove_brackets_around_comma=False,\n                ):\n                    wrap_in_parentheses(node, child, visible=False)\n            else:\n                wrap_in_parentheses(node, child, visible=False)\n            is_return_annotation = False\n\n    for child in node.children:\n        yield from self.visit(child)", "loc": 25}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_match_case", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["normalize_invisible_parens", "self.line", "self.visit", "set"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Visit either a match or case statement.", "source_code": "def visit_match_case(self, node: Node) -> Iterator[Line]:\n    \"\"\"Visit either a match or case statement.\"\"\"\n    normalize_invisible_parens(\n        node, parens_after=set(), mode=self.mode, features=self.features\n    )\n\n    yield from self.line()\n    for child in node.children:\n        yield from self.visit(child)", "loc": 9}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_suite", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_stub_suite", "self.visit", "self.visit_default"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Visit a suite.", "source_code": "def visit_suite(self, node: Node) -> Iterator[Line]:\n    \"\"\"Visit a suite.\"\"\"\n    if is_stub_suite(node):\n        yield from self.visit(node.children[2])\n    else:\n        yield from self.visit_default(node)", "loc": 6}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_simple_stmt", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_arith_like", "is_parent_function_or_class", "is_stub_body", "is_stub_suite", "self.line", "self.visit_default", "wrap_in_parentheses"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Visit a statement without nested statements.", "source_code": "def visit_simple_stmt(self, node: Node) -> Iterator[Line]:\n    \"\"\"Visit a statement without nested statements.\"\"\"\n    prev_type: Optional[int] = None\n    for child in node.children:\n        if (prev_type is None or prev_type == token.SEMI) and is_arith_like(child):\n            wrap_in_parentheses(node, child, visible=False)\n        prev_type = child.type\n\n    if node.parent and node.parent.type in STATEMENT:\n        if is_parent_function_or_class(node) and is_stub_body(node):\n            yield from self.visit_default(node)\n        else:\n            yield from self.line(+1)\n            yield from self.visit_default(node)\n            yield from self.line(-1)\n\n    else:\n        if node.parent and is_stub_suite(node.parent):\n            node.prefix = \"\"\n            yield from self.visit_default(node)\n            return\n        yield from self.line()\n        yield from self.visit_default(node)", "loc": 23}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_async_stmt", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["iter", "next", "self.line", "self.visit"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Visit `async def`, `async for`, `async with`.", "source_code": "def visit_async_stmt(self, node: Node) -> Iterator[Line]:\n    \"\"\"Visit `async def`, `async for`, `async with`.\"\"\"\n    yield from self.line()\n\n    children = iter(node.children)\n    for child in children:\n        yield from self.visit(child)\n\n        if child.type == token.ASYNC or child.type == STANDALONE_COMMENT:\n            # STANDALONE_COMMENT happens when `# fmt: skip` is applied on the async\n            # line.\n            break\n\n    internal_stmt = next(children)\n    yield from self.visit(internal_stmt)", "loc": 15}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_decorators", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.line", "self.visit"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Visit decorators.", "source_code": "def visit_decorators(self, node: Node) -> Iterator[Line]:\n    \"\"\"Visit decorators.\"\"\"\n    for child in node.children:\n        yield from self.line()\n        yield from self.visit(child)", "loc": 5}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_power", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "isinstance", "leaf.value.lower", "remove_await_parens", "self.visit_default", "value.startswith", "wrap_in_parentheses"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_power(self, node: Node) -> Iterator[Line]:\n    for idx, leaf in enumerate(node.children[:-1]):\n        next_leaf = node.children[idx + 1]\n\n        if not isinstance(leaf, Leaf):\n            continue\n\n        value = leaf.value.lower()\n        if (\n            leaf.type == token.NUMBER\n            and next_leaf.type == syms.trailer\n            # Ensure that we are in an attribute trailer\n            and next_leaf.children[0].type == token.DOT\n            # It shouldn't wrap hexadecimal, binary and octal literals\n            and not value.startswith((\"0x\", \"0b\", \"0o\"))\n            # It shouldn't wrap complex literals\n            and \"j\" not in value\n        ):\n            wrap_in_parentheses(node, leaf)\n\n    remove_await_parens(node, mode=self.mode, features=self.features)\n\n    yield from self.visit_default(node)", "loc": 23}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_factor", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "Node", "len", "node.insert_child", "operand.remove", "self.visit_default"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Force parentheses between a unary op and a binary power: -2 ** 8 -> -(2 ** 8)", "source_code": "def visit_factor(self, node: Node) -> Iterator[Line]:\n    \"\"\"Force parentheses between a unary op and a binary power:\n\n    -2 ** 8 -> -(2 ** 8)\n    \"\"\"\n    _operator, operand = node.children\n    if (\n        operand.type == syms.power\n        and len(operand.children) == 3\n        and operand.children[1].type == token.DOUBLESTAR\n    ):\n        lpar = Leaf(token.LPAR, \"(\")\n        rpar = Leaf(token.RPAR, \")\")\n        index = operand.remove() or 0\n        node.insert_child(index, Node(syms.atom, [lpar, operand, rpar]))\n    yield from self.visit_default(node)", "loc": 16}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_tname", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "maybe_make_parens_invisible_in_atom", "self.visit_default", "wrap_in_parentheses"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Add potential parentheses around types in function parameter lists to be made into real parentheses in case the type hint is too long to fit on a line Examples:", "source_code": "def visit_tname(self, node: Node) -> Iterator[Line]:\n    \"\"\"\n    Add potential parentheses around types in function parameter lists to be made\n    into real parentheses in case the type hint is too long to fit on a line\n    Examples:\n    def foo(a: int, b: float = 7): ...\n\n    ->\n\n    def foo(a: (int), b: (float) = 7): ...\n    \"\"\"\n    assert len(node.children) == 3\n    if maybe_make_parens_invisible_in_atom(\n        node.children[2], parent=node, mode=self.mode, features=self.features\n    ):\n        wrap_in_parentheses(node, node.children[2], visible=False)\n\n    yield from self.visit_default(node)", "loc": 18}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_STRING", "parameters": ["self", "leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["docstring.rstrip", "docstring.splitlines", "docstring.strip", "fix_multiline_docstring", "get_string_prefix", "is_docstring", "is_multiline_string", "len", "normalize_string_prefix", "normalize_string_quotes", "normalize_unicode_escape_sequences", "re.search", "self.visit_default"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_STRING(self, leaf: Leaf) -> Iterator[Line]:\n    normalize_unicode_escape_sequences(leaf)\n\n    if is_docstring(leaf) and not re.search(r\"\\\\\\s*\\n\", leaf.value):\n        # We're ignoring docstrings with backslash newline escapes because changing\n        # indentation of those changes the AST representation of the code.\n        if self.mode.string_normalization:\n            docstring = normalize_string_prefix(leaf.value)\n            # We handle string normalization at the end of this method, but since\n            # what we do right now acts differently depending on quote style (ex.\n            # see padding logic below), there's a possibility for unstable\n            # formatting. To avoid a situation where this function formats a\n            # docstring differently on the second pass, normalize it early.\n            docstring = normalize_string_quotes(docstring)\n        else:\n            docstring = leaf.value\n        prefix = get_string_prefix(docstring)\n        docstring = docstring[len(prefix) :]  # Remove the prefix\n        quote_char = docstring[0]\n        # A natural way to remove the outer quotes is to do:\n        #   docstring = docstring.strip(quote_char)\n        # but that breaks on \"\"\"\"\"x\"\"\" (which is '\"\"x').\n        # So we actually need to remove the first character and the next two\n        # characters but only if they are the same as the first.\n        quote_len = 1 if docstring[1] != quote_char else 3\n        docstring = docstring[quote_len:-quote_len]\n        docstring_started_empty = not docstring\n        indent = \" \" * 4 * self.current_line.depth\n\n        if is_multiline_string(leaf):\n            docstring = fix_multiline_docstring(docstring, indent)\n        else:\n            docstring = docstring.strip()\n\n        has_trailing_backslash = False\n        if docstring:\n            # Add some padding if the docstring starts / ends with a quote mark.\n            if docstring[0] == quote_char:\n                docstring = \" \" + docstring\n            if docstring[-1] == quote_char:\n                docstring += \" \"\n            if docstring[-1] == \"\\\\\":\n                backslash_count = len(docstring) - len(docstring.rstrip(\"\\\\\"))\n                if backslash_count % 2:\n                    # Odd number of tailing backslashes, add some padding to\n                    # avoid escaping the closing string quote.\n                    docstring += \" \"\n                    has_trailing_backslash = True\n        elif not docstring_started_empty:\n            docstring = \" \"\n\n        # We could enforce triple quotes at this point.\n        quote = quote_char * quote_len\n\n        # It's invalid to put closing single-character quotes on a new line.\n        if quote_len == 3:\n            # We need to find the length of the last line of the docstring\n            # to find if we can add the closing quotes to the line without\n            # exceeding the maximum line length.\n            # If docstring is one line, we don't put the closing quotes on a\n            # separate line because it looks ugly (#3320).\n            lines = docstring.splitlines()\n            last_line_length = len(lines[-1]) if docstring else 0\n\n            # If adding closing quotes would cause the last line to exceed\n            # the maximum line length, and the closing quote is not\n            # prefixed by a newline then put a line break before\n            # the closing quotes\n            if (\n                len(lines) > 1\n                and last_line_length + quote_len > self.mode.line_length\n                and len(indent) + quote_len <= self.mode.line_length\n                and not has_trailing_backslash\n            ):\n                if leaf.value[-1 - quote_len] == \"\\n\":\n                    leaf.value = prefix + quote + docstring + quote\n                else:\n                    leaf.value = prefix + quote + docstring + \"\\n\" + indent + quote\n            else:\n                leaf.value = prefix + quote + docstring + quote\n        else:\n            leaf.value = prefix + quote + docstring + quote\n\n    if self.mode.string_normalization and leaf.type == token.STRING:\n        leaf.value = normalize_string_prefix(leaf.value)\n        leaf.value = normalize_string_quotes(leaf.value)\n    yield from self.visit_default(leaf)", "loc": 87}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_atom", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "maybe_make_parens_invisible_in_atom", "self.visit_default"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Visit any atom", "source_code": "def visit_atom(self, node: Node) -> Iterator[Line]:\n    \"\"\"Visit any atom\"\"\"\n    if len(node.children) == 3:\n        first = node.children[0]\n        last = node.children[-1]\n        if (first.type == token.LSQB and last.type == token.RSQB) or (\n            first.type == token.LBRACE and last.type == token.RBRACE\n        ):\n            # Lists or sets of one item\n            maybe_make_parens_invisible_in_atom(\n                node.children[1],\n                parent=node,\n                mode=self.mode,\n                features=self.features,\n            )\n\n    yield from self.visit_default(node)", "loc": 17}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_fstring", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "fstring_to_string", "node.replace", "self.visit_STRING", "self.visit_default", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_fstring(self, node: Node) -> Iterator[Line]:\n    # currently we don't want to format and split f-strings at all.\n    string_leaf = fstring_to_string(node)\n    node.replace(string_leaf)\n    if \"\\\\\" in string_leaf.value and any(\n        \"\\\\\" in str(child)\n        for child in node.children\n        if child.type == syms.fstring_replacement_field\n    ):\n        # string normalization doesn't account for nested quotes,\n        # causing breakages. skip normalization when nested quotes exist\n        yield from self.visit_default(string_leaf)\n        return\n    yield from self.visit_STRING(string_leaf)", "loc": 14}
{"file": "black\\src\\black\\linegen.py", "class_name": "LineGenerator", "function_name": "visit_comp_for", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["normalize_invisible_parens", "self.visit_default"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_comp_for(self, node: Node) -> Iterator[Line]:\n    if Preview.wrap_comprehension_in in self.mode:\n        normalize_invisible_parens(\n            node, parens_after={\"in\"}, mode=self.mode, features=self.features\n        )\n    yield from self.visit_default(node)", "loc": 6}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "split_wrapper", "parameters": ["line", "features", "mode"], "param_types": {"line": "Line", "features": "Collection[Feature]", "mode": "Mode"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["split_func", "wraps"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def split_wrapper(\n    line: Line, features: Collection[Feature], mode: Mode\n) -> Iterator[Line]:\n    for split_line in split_func(line, features, mode):\n        split_line.leaves[0].prefix = \"\"\n        yield split_line", "loc": 6}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "append_to_line", "parameters": ["leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Line", "current_line.append", "current_line.append_safe"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Append `leaf` to current line or to new line if appending impossible.", "source_code": "def append_to_line(leaf: Leaf) -> Iterator[Line]:\n    \"\"\"Append `leaf` to current line or to new line if appending impossible.\"\"\"\n    nonlocal current_line\n    try:\n        current_line.append_safe(leaf, preformatted=True)\n    except ValueError:\n        yield current_line\n\n        current_line = Line(\n            mode=line.mode, depth=line.depth, inside_brackets=line.inside_brackets\n        )\n        current_line.append(leaf)", "loc": 12}
{"file": "black\\src\\black\\linegen.py", "class_name": null, "function_name": "append_to_line", "parameters": ["leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Line", "current_line.append", "current_line.append_safe"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Append `leaf` to current line or to new line if appending impossible.", "source_code": "def append_to_line(leaf: Leaf) -> Iterator[Line]:\n    \"\"\"Append `leaf` to current line or to new line if appending impossible.\"\"\"\n    nonlocal current_line\n    try:\n        current_line.append_safe(leaf, preformatted=True)\n    except ValueError:\n        yield current_line\n\n        current_line = Line(\n            line.mode, depth=line.depth, inside_brackets=line.inside_brackets\n        )\n        current_line.append(leaf)", "loc": 12}
{"file": "black\\src\\black\\lines.py", "class_name": null, "function_name": "enumerate_reversed", "parameters": ["sequence"], "param_types": {"sequence": "Sequence[T]"}, "return_type": "Iterator[tuple[Index, T]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "reversed"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Like `reversed(enumerate(sequence))` if that were possible.", "source_code": "def enumerate_reversed(sequence: Sequence[T]) -> Iterator[tuple[Index, T]]:\n    \"\"\"Like `reversed(enumerate(sequence))` if that were possible.\"\"\"\n    index = len(sequence) - 1\n    for element in reversed(sequence):\n        yield (index, element)\n        index -= 1", "loc": 6}
{"file": "black\\src\\black\\lines.py", "class_name": null, "function_name": "append_leaves", "parameters": ["new_line", "old_line", "leaves", "preformatted"], "param_types": {"new_line": "Line", "old_line": "Line", "leaves": "list[Leaf]", "preformatted": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "new_line.append", "old_line.comments_after", "replace_child"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Append leaves (taken from @old_line) to @new_line, making sure to fix the underlying Node structure where appropriate. All of the leaves in @leaves are duplicated. The duplicates are then", "source_code": "def append_leaves(\n    new_line: Line, old_line: Line, leaves: list[Leaf], preformatted: bool = False\n) -> None:\n    \"\"\"\n    Append leaves (taken from @old_line) to @new_line, making sure to fix the\n    underlying Node structure where appropriate.\n\n    All of the leaves in @leaves are duplicated. The duplicates are then\n    appended to @new_line and used to replace their originals in the underlying\n    Node structure. Any comments attached to the old leaves are reattached to\n    the new leaves.\n\n    Pre-conditions:\n        set(@leaves) is a subset of set(@old_line.leaves).\n    \"\"\"\n    for old_leaf in leaves:\n        new_leaf = Leaf(old_leaf.type, old_leaf.value)\n        replace_child(old_leaf, new_leaf)\n        new_line.append(new_leaf, preformatted=preformatted)\n\n        for comment_leaf in old_line.comments_after(old_leaf):\n            new_line.append(comment_leaf, preformatted=True)", "loc": 22}
{"file": "black\\src\\black\\lines.py", "class_name": null, "function_name": "is_line_short_enough", "parameters": ["line"], "param_types": {"line": "Line"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["all", "commas.append", "commas.pop", "enumerate", "is_multiline_string", "len", "line.contains_standalone_comments", "line_str.split", "line_to_string", "min", "multiline_string_contexts.append", "str", "str_width"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "For non-multiline strings, return True if `line` is no longer than `line_length`. For multiline strings, looks at the context around `line` to determine if it should be inlined or split up.", "source_code": "def is_line_short_enough(  # noqa: C901\n    line: Line, *, mode: Mode, line_str: str = \"\"\n) -> bool:\n    \"\"\"For non-multiline strings, return True if `line` is no longer than `line_length`.\n    For multiline strings, looks at the context around `line` to determine\n    if it should be inlined or split up.\n    Uses the provided `line_str` rendering, if any, otherwise computes a new one.\n    \"\"\"\n    if not line_str:\n        line_str = line_to_string(line)\n\n    if Preview.multiline_string_handling not in mode:\n        return (\n            str_width(line_str) <= mode.line_length\n            and \"\\n\" not in line_str  # multiline strings\n            and not line.contains_standalone_comments()\n        )\n\n    if line.contains_standalone_comments():\n        return False\n    if \"\\n\" not in line_str:\n        # No multiline strings (MLS) present\n        return str_width(line_str) <= mode.line_length\n\n    first, *_, last = line_str.split(\"\\n\")\n    if str_width(first) > mode.line_length or str_width(last) > mode.line_length:\n        return False\n\n    # Traverse the AST to examine the context of the multiline string (MLS),\n    # tracking aspects such as depth and comma existence,\n    # to determine whether to split the MLS or keep it together.\n    # Depth (which is based on the existing bracket_depth concept)\n    # is needed to determine nesting level of the MLS.\n    # Includes special case for trailing commas.\n    commas: list[int] = []  # tracks number of commas per depth level\n    multiline_string: Optional[Leaf] = None\n    # store the leaves that contain parts of the MLS\n    multiline_string_contexts: list[LN] = []\n\n    max_level_to_update: Union[int, float] = math.inf  # track the depth of the MLS\n    for i, leaf in enumerate(line.leaves):\n        if max_level_to_update == math.inf:\n            had_comma: Optional[int] = None\n            if leaf.bracket_depth + 1 > len(commas):\n                commas.append(0)\n            elif leaf.bracket_depth + 1 < len(commas):\n                had_comma = commas.pop()\n            if (\n                had_comma is not None\n                and multiline_string is not None\n                and multiline_string.bracket_depth == leaf.bracket_depth + 1\n            ):\n                # Have left the level with the MLS, stop tracking commas\n                max_level_to_update = leaf.bracket_depth\n                if had_comma > 0:\n                    # MLS was in parens with at least one comma - force split\n                    return False\n\n        if leaf.bracket_depth <= max_level_to_update and leaf.type == token.COMMA:\n            # Inside brackets, ignore trailing comma\n            # directly after MLS/MLS-containing expression\n            ignore_ctxs: list[Optional[LN]] = [None]\n            ignore_ctxs += multiline_string_contexts\n            if (line.inside_brackets or leaf.bracket_depth > 0) and (\n                i != len(line.leaves) - 1 or leaf.prev_sibling not in ignore_ctxs\n            ):\n                commas[leaf.bracket_depth] += 1\n        if max_level_to_update != math.inf:\n            max_level_to_update = min(max_level_to_update, leaf.bracket_depth)\n\n        if is_multiline_string(leaf):\n            if leaf.parent and (\n                leaf.parent.type == syms.test\n                or (leaf.parent.parent and leaf.parent.parent.type == syms.dictsetmaker)\n            ):\n                # Keep ternary and dictionary values parenthesized\n                return False\n            if len(multiline_string_contexts) > 0:\n                # >1 multiline string cannot fit on a single line - force split\n                return False\n            multiline_string = leaf\n            ctx: LN = leaf\n            # fetch the leaf components of the MLS in the AST\n            while str(ctx) in line_str:\n                multiline_string_contexts.append(ctx)\n                if ctx.parent is None:\n                    break\n                ctx = ctx.parent\n\n    # May not have a triple-quoted multiline string at all,\n    # in case of a regular string with embedded newlines and line continuations\n    if len(multiline_string_contexts) == 0:\n        return True\n\n    return all(val == 0 for val in commas)", "loc": 95}
{"file": "black\\src\\black\\lines.py", "class_name": null, "function_name": "can_be_split", "parameters": ["line"], "param_types": {"line": "Line"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return False if the line cannot be split *for sure*. This is not an exhaustive search but a cheap heuristic that we can use to avoid some unfortunate formattings (mostly around wrapping unsplittable code", "source_code": "def can_be_split(line: Line) -> bool:\n    \"\"\"Return False if the line cannot be split *for sure*.\n\n    This is not an exhaustive search but a cheap heuristic that we can use to\n    avoid some unfortunate formattings (mostly around wrapping unsplittable code\n    in unnecessary parentheses).\n    \"\"\"\n    leaves = line.leaves\n    if len(leaves) < 2:\n        return False\n\n    if leaves[0].type == token.STRING and leaves[1].type == token.DOT:\n        call_count = 0\n        dot_count = 0\n        next = leaves[-1]\n        for leaf in leaves[-2::-1]:\n            if leaf.type in OPENING_BRACKETS:\n                if next.type not in CLOSING_BRACKETS:\n                    return False\n\n                call_count += 1\n            elif leaf.type == token.DOT:\n                dot_count += 1\n            elif leaf.type == token.NAME:\n                if not (next.type == token.DOT or next.type in OPENING_BRACKETS):\n                    return False\n\n            elif leaf.type not in CLOSING_BRACKETS:\n                return False\n\n            if dot_count > 1 and call_count > 1:\n                return False\n\n    return True", "loc": 34}
{"file": "black\\src\\black\\lines.py", "class_name": null, "function_name": "line_to_string", "parameters": ["line"], "param_types": {"line": "Line"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["str", "str(line).strip"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def line_to_string(line: Line) -> str:\n    \"\"\"Returns the string representation of @line.\n\n    WARNING: This is known to be computationally expensive.\n    \"\"\"\n    return str(line).strip(\"\\n\")", "loc": 6}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "append", "parameters": ["self", "leaf", "preformatted", "track_bracket"], "param_types": {"leaf": "Leaf", "preformatted": "bool", "track_bracket": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bool", "leaf.value.strip", "self.append_comment", "self.bracket_tracker.mark", "self.has_magic_trailing_comma", "self.is_complex_subscript", "self.leaves.append", "self.remove_trailing_comma", "whitespace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Add a new `leaf` to the end of the line. Unless `preformatted` is True, the `leaf` will receive a new consistent whitespace prefix and metadata applied by :class:`BracketTracker`.", "source_code": "def append(\n    self, leaf: Leaf, preformatted: bool = False, track_bracket: bool = False\n) -> None:\n    \"\"\"Add a new `leaf` to the end of the line.\n\n    Unless `preformatted` is True, the `leaf` will receive a new consistent\n    whitespace prefix and metadata applied by :class:`BracketTracker`.\n    Trailing commas are maybe removed, unpacked for loop variables are\n    demoted from being delimiters.\n\n    Inline comments are put aside.\n    \"\"\"\n    has_value = (\n        leaf.type in BRACKETS\n        # empty fstring-middles must not be truncated\n        or leaf.type == token.FSTRING_MIDDLE\n        or bool(leaf.value.strip())\n    )\n    if not has_value:\n        return\n\n    if leaf.type == token.COLON and self.is_class_paren_empty:\n        del self.leaves[-2:]\n    if self.leaves and not preformatted:\n        # Note: at this point leaf.prefix should be empty except for\n        # imports, for which we only preserve newlines.\n        leaf.prefix += whitespace(\n            leaf,\n            complex_subscript=self.is_complex_subscript(leaf),\n            mode=self.mode,\n        )\n    if self.inside_brackets or not preformatted or track_bracket:\n        self.bracket_tracker.mark(leaf)\n        if self.mode.magic_trailing_comma:\n            if self.has_magic_trailing_comma(leaf):\n                self.magic_trailing_comma = leaf\n        elif self.has_magic_trailing_comma(leaf):\n            self.remove_trailing_comma()\n    if not self.append_comment(leaf):\n        self.leaves.append(leaf)", "loc": 40}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "is_stub_class", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "range"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Is this line a class definition with a body consisting only of \"...\"?", "source_code": "def is_stub_class(self) -> bool:\n    \"\"\"Is this line a class definition with a body consisting only of \"...\"?\"\"\"\n    return self.is_class and self.leaves[-3:] == [\n        Leaf(token.DOT, \".\") for _ in range(3)\n    ]", "loc": 5}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "is_def", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Is this a function definition? (Also returns True for async defs.)", "source_code": "def is_def(self) -> bool:\n    \"\"\"Is this a function definition? (Also returns True for async defs.)\"\"\"\n    try:\n        first_leaf = self.leaves[0]\n    except IndexError:\n        return False\n\n    try:\n        second_leaf: Optional[Leaf] = self.leaves[1]\n    except IndexError:\n        second_leaf = None\n    return (first_leaf.type == token.NAME and first_leaf.value == \"def\") or (\n        first_leaf.type == token.ASYNC\n        and second_leaf is not None\n        and second_leaf.type == token.NAME\n        and second_leaf.value == \"def\"\n    )", "loc": 17}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "is_stub_def", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "range"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Is this line a function definition with a body consisting only of \"...\"?", "source_code": "def is_stub_def(self) -> bool:\n    \"\"\"Is this line a function definition with a body consisting only of \"...\"?\"\"\"\n    return self.is_def and self.leaves[-4:] == [Leaf(token.COLON, \":\")] + [\n        Leaf(token.DOT, \".\") for _ in range(3)\n    ]", "loc": 5}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "is_class_paren_empty", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bool", "len"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Is this a class with no base classes but using parentheses? Those are unnecessary and should be removed.", "source_code": "def is_class_paren_empty(self) -> bool:\n    \"\"\"Is this a class with no base classes but using parentheses?\n\n    Those are unnecessary and should be removed.\n    \"\"\"\n    return (\n        bool(self)\n        and len(self.leaves) == 4\n        and self.is_class\n        and self.leaves[2].type == token.LPAR\n        and self.leaves[2].value == \"(\"\n        and self.leaves[3].type == token.RPAR\n        and self.leaves[3].value == \")\"\n    )", "loc": 14}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "opens_block", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Does this line open a new level of indentation.", "source_code": "def opens_block(self) -> bool:\n    \"\"\"Does this line open a new level of indentation.\"\"\"\n    if len(self.leaves) == 0:\n        return False\n    return self.leaves[-1].type == token.COLON", "loc": 5}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "is_fmt_pass_converted", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["first_leaf_matches", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Is this line converted from fmt off/skip code? If first_leaf_matches is not None, it only returns True if the first leaf of converted code matches.", "source_code": "def is_fmt_pass_converted(\n    self, *, first_leaf_matches: Optional[Callable[[Leaf], bool]] = None\n) -> bool:\n    \"\"\"Is this line converted from fmt off/skip code?\n\n    If first_leaf_matches is not None, it only returns True if the first\n    leaf of converted code matches.\n    \"\"\"\n    if len(self.leaves) != 1:\n        return False\n    leaf = self.leaves[0]\n    if (\n        leaf.type != STANDALONE_COMMENT\n        or leaf.fmt_pass_converted_first_leaf is None\n    ):\n        return False\n    return first_leaf_matches is None or first_leaf_matches(\n        leaf.fmt_pass_converted_first_leaf\n    )", "loc": 19}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "contains_standalone_comments", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "If so, needs to be split before emitting.", "source_code": "def contains_standalone_comments(self) -> bool:\n    \"\"\"If so, needs to be split before emitting.\"\"\"\n    for leaf in self.leaves:\n        if leaf.type == STANDALONE_COMMENT:\n            return True\n\n    return False", "loc": 7}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "contains_implicit_multiline_string_with_comments", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["itertools.groupby", "len", "list", "self.comments_after"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Chck if we have an implicit multiline string with comments on the line", "source_code": "def contains_implicit_multiline_string_with_comments(self) -> bool:\n    \"\"\"Chck if we have an implicit multiline string with comments on the line\"\"\"\n    for leaf_type, leaf_group_iterator in itertools.groupby(\n        self.leaves, lambda leaf: leaf.type\n    ):\n        if leaf_type != token.STRING:\n            continue\n        leaf_list = list(leaf_group_iterator)\n        if len(leaf_list) == 1:\n            continue\n        for leaf in leaf_list:\n            if self.comments_after(leaf):\n                return True\n    return False", "loc": 14}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "contains_uncollapsable_type_comments", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["id", "ignored_ids.add", "is_type_comment", "is_type_ignore_comment", "self.comments.items", "set"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def contains_uncollapsable_type_comments(self) -> bool:\n    ignored_ids = set()\n    try:\n        last_leaf = self.leaves[-1]\n        ignored_ids.add(id(last_leaf))\n        if last_leaf.type == token.COMMA or (\n            last_leaf.type == token.RPAR and not last_leaf.value\n        ):\n            # When trailing commas or optional parens are inserted by Black for\n            # consistency, comments after the previous last element are not moved\n            # (they don't have to, rendering will still be correct).  So we ignore\n            # trailing commas and invisible.\n            last_leaf = self.leaves[-2]\n            ignored_ids.add(id(last_leaf))\n    except IndexError:\n        return False\n\n    # A type comment is uncollapsable if it is attached to a leaf\n    # that isn't at the end of the line (since that could cause it\n    # to get associated to a different argument) or if there are\n    # comments before it (since that could cause it to get hidden\n    # behind a comment.\n    comment_seen = False\n    for leaf_id, comments in self.comments.items():\n        for comment in comments:\n            if is_type_comment(comment):\n                if comment_seen or (\n                    not is_type_ignore_comment(comment)\n                    and leaf_id not in ignored_ids\n                ):\n                    return True\n\n            comment_seen = True\n\n    return False", "loc": 35}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "contains_unsplittable_type_ignore", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["id", "is_type_ignore_comment", "next", "reversed", "self.comments.get"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def contains_unsplittable_type_ignore(self) -> bool:\n    if not self.leaves:\n        return False\n\n    # If a 'type: ignore' is attached to the end of a line, we\n    # can't split the line, because we can't know which of the\n    # subexpressions the ignore was meant to apply to.\n    #\n    # We only want this to apply to actual physical lines from the\n    # original source, though: we don't want the presence of a\n    # 'type: ignore' at the end of a multiline expression to\n    # justify pushing it all onto one line. Thus we\n    # (unfortunately) need to check the actual source lines and\n    # only report an unsplittable 'type: ignore' if this line was\n    # one line in the original code.\n\n    # Grab the first and last line numbers, skipping generated leaves\n    first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n    last_line = next(\n        (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n    )\n\n    if first_line == last_line:\n        # We look at the last two leaves since a comma or an\n        # invisible paren could have been added at the end of the\n        # line.\n        for node in self.leaves[-2:]:\n            for comment in self.comments.get(id(node), []):\n                if is_type_ignore_comment(comment):\n                    return True\n\n    return False", "loc": 32}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "has_magic_trailing_comma", "parameters": ["self", "closing"], "param_types": {"closing": "Leaf"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_one_sequence_between"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if we have a magic trailing comma, that is when: - there's a trailing comma here - it's not from single-element square bracket indexing", "source_code": "def has_magic_trailing_comma(self, closing: Leaf) -> bool:\n    \"\"\"Return True if we have a magic trailing comma, that is when:\n    - there's a trailing comma here\n    - it's not from single-element square bracket indexing\n    - it's not a one-tuple\n    \"\"\"\n    if not (\n        closing.type in CLOSING_BRACKETS\n        and self.leaves\n        and self.leaves[-1].type == token.COMMA\n    ):\n        return False\n\n    if closing.type == token.RBRACE:\n        return True\n\n    if closing.type == token.RSQB:\n        if (\n            closing.parent is not None\n            and closing.parent.type == syms.trailer\n            and closing.opening_bracket is not None\n            and is_one_sequence_between(\n                closing.opening_bracket,\n                closing,\n                self.leaves,\n                brackets=(token.LSQB, token.RSQB),\n            )\n        ):\n            assert closing.prev_sibling is not None\n            assert closing.prev_sibling.type == syms.subscriptlist\n            return False\n\n        return True\n\n    if self.is_import:\n        return True\n\n    if closing.opening_bracket is not None and not is_one_sequence_between(\n        closing.opening_bracket, closing, self.leaves\n    ):\n        return True\n\n    return False", "loc": 43}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "remove_trailing_comma", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["id", "self.comments.pop", "self.comments.setdefault", "self.comments.setdefault(id(self.leaves[-1]), []).extend", "self.leaves.pop"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Remove the trailing comma and moves the comments attached to it.", "source_code": "def remove_trailing_comma(self) -> None:\n    \"\"\"Remove the trailing comma and moves the comments attached to it.\"\"\"\n    trailing_comma = self.leaves.pop()\n    trailing_comma_comments = self.comments.pop(id(trailing_comma), [])\n    self.comments.setdefault(id(self.leaves[-1]), []).extend(\n        trailing_comma_comments\n    )", "loc": 7}
{"file": "black\\src\\black\\lines.py", "class_name": "Line", "function_name": "enumerate_with_length", "parameters": ["self", "is_reversed"], "param_types": {"is_reversed": "bool"}, "return_type": "Iterator[tuple[Index, Leaf, int]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "len", "op", "self.comments_after"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return an enumeration of leaves with their length. Stops prematurely on multiline strings and standalone comments.", "source_code": "def enumerate_with_length(\n    self, is_reversed: bool = False\n) -> Iterator[tuple[Index, Leaf, int]]:\n    \"\"\"Return an enumeration of leaves with their length.\n\n    Stops prematurely on multiline strings and standalone comments.\n    \"\"\"\n    op = cast(\n        Callable[[Sequence[Leaf]], Iterator[tuple[Index, Leaf]]],\n        enumerate_reversed if is_reversed else enumerate,\n    )\n    for index, leaf in op(self.leaves):\n        length = len(leaf.prefix) + len(leaf.value)\n        if \"\\n\" in leaf.value:\n            return  # Multiline strings, we can't continue.\n\n        for comment in self.comments_after(leaf):\n            length += len(comment.value)\n\n        yield index, leaf, length", "loc": 20}
{"file": "black\\src\\black\\lines.py", "class_name": "EmptyLineTracker", "function_name": "maybe_empty_lines", "parameters": ["self", "current_line"], "param_types": {"current_line": "Line"}, "return_type": "LinesBlock", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["LinesBlock", "bool", "len", "max", "self._line_is_module_docstring", "self._maybe_empty_lines"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the number of extra empty lines before and after the `current_line`. This is for separating `def`, `async def` and `class` with extra empty lines (two on module-level).", "source_code": "def maybe_empty_lines(self, current_line: Line) -> LinesBlock:\n    \"\"\"Return the number of extra empty lines before and after the `current_line`.\n\n    This is for separating `def`, `async def` and `class` with extra empty\n    lines (two on module-level).\n    \"\"\"\n    form_feed = (\n        current_line.depth == 0\n        and bool(current_line.leaves)\n        and \"\\f\\n\" in current_line.leaves[0].prefix\n    )\n    before, after = self._maybe_empty_lines(current_line)\n    previous_after = self.previous_block.after if self.previous_block else 0\n    before = max(0, before - previous_after)\n    if Preview.fix_module_docstring_detection in self.mode:\n        # Always have one empty line after a module docstring\n        if self._line_is_module_docstring(current_line):\n            before = 1\n    else:\n        if (\n            # Always have one empty line after a module docstring\n            self.previous_block\n            and self.previous_block.previous_block is None\n            and len(self.previous_block.original_line.leaves) == 1\n            and self.previous_block.original_line.is_docstring\n            and not (current_line.is_class or current_line.is_def)\n        ):\n            before = 1\n\n    block = LinesBlock(\n        mode=self.mode,\n        previous_block=self.previous_block,\n        original_line=current_line,\n        before=before,\n        after=after,\n        form_feed=form_feed,\n    )\n\n    # Maintain the semantic_leading_comment state.\n    if current_line.is_comment:\n        if self.previous_line is None or (\n            not self.previous_line.is_decorator\n            # `or before` means this comment already has an empty line before\n            and (not self.previous_line.is_comment or before)\n            and (self.semantic_leading_comment is None or before)\n        ):\n            self.semantic_leading_comment = block\n    # `or before` means this decorator already has an empty line before\n    elif not current_line.is_decorator or before:\n        self.semantic_leading_comment = None\n\n    self.previous_line = current_line\n    self.previous_block = block\n    return block", "loc": 54}
{"file": "black\\src\\black\\mode.py", "class_name": null, "function_name": "supports_feature", "parameters": ["target_versions", "feature"], "param_types": {"target_versions": "set[TargetVersion]", "feature": "Feature"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "all"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def supports_feature(target_versions: set[TargetVersion], feature: Feature) -> bool:\n    if not target_versions:\n        raise ValueError(\"target_versions must not be empty\")\n\n    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)", "loc": 5}
{"file": "black\\src\\black\\mode.py", "class_name": "Mode", "function_name": "get_cache_key", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["','.join", "'.'.join", "attrgetter", "features_and_magics.encode", "int", "len", "sha256", "sha256(features_and_magics.encode()).hexdigest", "sha256(version_str.encode()).hexdigest", "sorted", "str", "version_str.encode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_cache_key(self) -> str:\n    if self.target_versions:\n        version_str = \",\".join(\n            str(version.value)\n            for version in sorted(self.target_versions, key=attrgetter(\"value\"))\n        )\n    else:\n        version_str = \"-\"\n    if len(version_str) > _MAX_CACHE_KEY_PART_LENGTH:\n        version_str = sha256(version_str.encode()).hexdigest()[\n            :_MAX_CACHE_KEY_PART_LENGTH\n        ]\n    features_and_magics = (\n        \",\".join(sorted(f.name for f in self.enabled_features))\n        + \"@\"\n        + \",\".join(sorted(self.python_cell_magics))\n    )\n    if len(features_and_magics) > _MAX_CACHE_KEY_PART_LENGTH:\n        features_and_magics = sha256(features_and_magics.encode()).hexdigest()[\n            :_MAX_CACHE_KEY_PART_LENGTH\n        ]\n    parts = [\n        version_str,\n        str(self.line_length),\n        str(int(self.string_normalization)),\n        str(int(self.is_pyi)),\n        str(int(self.is_ipynb)),\n        str(int(self.skip_source_first_line)),\n        str(int(self.magic_trailing_comma)),\n        str(int(self.preview)),\n        str(int(self.unstable)),\n        features_and_magics,\n    ]\n    return \".\".join(parts)", "loc": 34}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "make_simple_prefix", "parameters": ["nl_count", "form_feed", "empty_line"], "param_types": {"nl_count": "int", "form_feed": "bool", "empty_line": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generate a normalized prefix string.", "source_code": "def make_simple_prefix(nl_count: int, form_feed: bool, empty_line: str = \"\\n\") -> str:\n    \"\"\"Generate a normalized prefix string.\"\"\"\n    if form_feed:\n        return (empty_line * (nl_count - 1)) + \"\\f\" + empty_line\n    return empty_line * nl_count", "loc": 5}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "preceding_leaf", "parameters": ["node"], "param_types": {"node": "Optional[LN]"}, "return_type": "Optional[Leaf]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "list", "res.leaves"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Return the first leaf that precedes `node`, if any.", "source_code": "def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:\n    \"\"\"Return the first leaf that precedes `node`, if any.\"\"\"\n    while node:\n        res = node.prev_sibling\n        if res:\n            if isinstance(res, Leaf):\n                return res\n\n            try:\n                return list(res.leaves())[-1]\n\n            except IndexError:\n                return None\n\n        node = node.parent\n    return None", "loc": 16}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "prev_siblings_are", "parameters": ["node", "tokens"], "param_types": {"node": "Optional[LN]", "tokens": "list[Optional[NodeType]]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["prev_siblings_are"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return if the `node` and its previous siblings match types against the provided list of tokens; the provided `node`has its type matched against the last element in the list.  `None` can be used as the first element to declare that the start of the", "source_code": "def prev_siblings_are(node: Optional[LN], tokens: list[Optional[NodeType]]) -> bool:\n    \"\"\"Return if the `node` and its previous siblings match types against the provided\n    list of tokens; the provided `node`has its type matched against the last element in\n    the list.  `None` can be used as the first element to declare that the start of the\n    list is anchored at the start of its parent's children.\"\"\"\n    if not tokens:\n        return True\n    if tokens[-1] is None:\n        return node is None\n    if not node:\n        return False\n    if node.type != tokens[-1]:\n        return False\n    return prev_siblings_are(node.prev_sibling, tokens[:-1])", "loc": 14}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "parent_type", "parameters": ["node"], "param_types": {"node": "Optional[LN]"}, "return_type": "Optional[NodeType]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parent_type(node: Optional[LN]) -> Optional[NodeType]:\n    \"\"\"\n    Returns:\n        @node.parent.type, if @node is not None and has a parent.\n            OR\n        None, otherwise.\n    \"\"\"\n    if node is None or node.parent is None:\n        return None\n\n    return node.parent.type", "loc": 11}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "child_towards", "parameters": ["ancestor", "descendant"], "param_types": {"ancestor": "Node", "descendant": "LN"}, "return_type": "Optional[LN]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "Return the child of `ancestor` that contains `descendant`.", "source_code": "def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:\n    \"\"\"Return the child of `ancestor` that contains `descendant`.\"\"\"\n    node: Optional[LN] = descendant\n    while node and node.parent != ancestor:\n        node = node.parent\n    return node", "loc": 6}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "replace_child", "parameters": ["old_child", "new_child"], "param_types": {"old_child": "LN", "new_child": "LN"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["old_child.remove", "parent.insert_child"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Side Effects: * If @old_child.parent is set, replace @old_child with @new_child in @old_child's underlying Node structure.", "source_code": "def replace_child(old_child: LN, new_child: LN) -> None:\n    \"\"\"\n    Side Effects:\n        * If @old_child.parent is set, replace @old_child with @new_child in\n        @old_child's underlying Node structure.\n            OR\n        * Otherwise, this function does nothing.\n    \"\"\"\n    parent = old_child.parent\n    if not parent:\n        return\n\n    child_idx = old_child.remove()\n    if child_idx is not None:\n        parent.insert_child(child_idx, new_child)", "loc": 15}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "container_of", "parameters": ["leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "LN", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Return `leaf` or one of its ancestors that is the topmost container of it. By \"container\" we mean a node where `leaf` is the very first child.", "source_code": "def container_of(leaf: Leaf) -> LN:\n    \"\"\"Return `leaf` or one of its ancestors that is the topmost container of it.\n\n    By \"container\" we mean a node where `leaf` is the very first child.\n    \"\"\"\n    same_prefix = leaf.prefix\n    container: LN = leaf\n    while container:\n        parent = container.parent\n        if parent is None:\n            break\n\n        if parent.children[0].prefix != same_prefix:\n            break\n\n        if parent.type == syms.file_input:\n            break\n\n        if parent.prev_sibling is not None and parent.prev_sibling.type in BRACKETS:\n            break\n\n        container = parent\n    return container", "loc": 23}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "first_leaf_of", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "Optional[Leaf]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["first_leaf_of", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def first_leaf_of(node: LN) -> Optional[Leaf]:\n    \"\"\"Returns the first leaf of the node tree.\"\"\"\n    if isinstance(node, Leaf):\n        return node\n    if node.children:\n        return first_leaf_of(node.children[0])\n    else:\n        return None", "loc": 8}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_docstring", "parameters": ["node"], "param_types": {"node": "NL"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_string_prefix", "isinstance", "prev_siblings_are", "set", "set(prefix).intersection"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_docstring(node: NL) -> bool:\n    if isinstance(node, Leaf):\n        if node.type != token.STRING:\n            return False\n\n        prefix = get_string_prefix(node.value)\n        if set(prefix).intersection(\"bBfF\"):\n            return False\n\n    if (\n        node.parent\n        and node.parent.type == syms.simple_stmt\n        and not node.parent.prev_sibling\n        and node.parent.parent\n        and node.parent.parent.type == syms.file_input\n    ):\n        return True\n\n    if prev_siblings_are(\n        node.parent, [None, token.NEWLINE, token.INDENT, syms.simple_stmt]\n    ):\n        return True\n\n    # Multiline docstring on the same line as the `def`.\n    if prev_siblings_are(node.parent, [syms.parameters, token.COLON, syms.simple_stmt]):\n        # `syms.parameters` is only used in funcdefs and async_funcdefs in the Python\n        # grammar. We're safe to return True without further checks.\n        return True\n\n    return False", "loc": 30}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_one_tuple", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "unwrap_singleton_parenthesis"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if `node` holds a tuple with one element, with or without parens.", "source_code": "def is_one_tuple(node: LN) -> bool:\n    \"\"\"Return True if `node` holds a tuple with one element, with or without parens.\"\"\"\n    if node.type == syms.atom:\n        gexp = unwrap_singleton_parenthesis(node)\n        if gexp is None or gexp.type != syms.testlist_gexp:\n            return False\n\n        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA\n\n    return (\n        node.type in IMPLICIT_TUPLE\n        and len(node.children) == 2\n        and node.children[1].type == token.COMMA\n    )", "loc": 14}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_tuple", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["unwrap_singleton_parenthesis"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if `node` holds a tuple.", "source_code": "def is_tuple(node: LN) -> bool:\n    \"\"\"Return True if `node` holds a tuple.\"\"\"\n    if node.type != syms.atom:\n        return False\n    gexp = unwrap_singleton_parenthesis(node)\n    if gexp is None or gexp.type != syms.testlist_gexp:\n        return False\n\n    return True", "loc": 9}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_tuple_containing_walrus", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "unwrap_singleton_parenthesis"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if `node` holds a tuple that contains a walrus operator.", "source_code": "def is_tuple_containing_walrus(node: LN) -> bool:\n    \"\"\"Return True if `node` holds a tuple that contains a walrus operator.\"\"\"\n    if node.type != syms.atom:\n        return False\n    gexp = unwrap_singleton_parenthesis(node)\n    if gexp is None or gexp.type != syms.testlist_gexp:\n        return False\n\n    return any(child.type == syms.namedexpr_test for child in gexp.children)", "loc": 9}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_tuple_containing_star", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "unwrap_singleton_parenthesis"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if `node` holds a tuple that contains a star operator.", "source_code": "def is_tuple_containing_star(node: LN) -> bool:\n    \"\"\"Return True if `node` holds a tuple that contains a star operator.\"\"\"\n    if node.type != syms.atom:\n        return False\n    gexp = unwrap_singleton_parenthesis(node)\n    if gexp is None or gexp.type != syms.testlist_gexp:\n        return False\n\n    return any(child.type == syms.star_expr for child in gexp.children)", "loc": 9}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_generator", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "unwrap_singleton_parenthesis"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if `node` holds a generator.", "source_code": "def is_generator(node: LN) -> bool:\n    \"\"\"Return True if `node` holds a generator.\"\"\"\n    if node.type != syms.atom:\n        return False\n    gexp = unwrap_singleton_parenthesis(node)\n    if gexp is None or gexp.type != syms.testlist_gexp:\n        return False\n\n    return any(child.type == syms.old_comp_for for child in gexp.children)", "loc": 9}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_one_sequence_between", "parameters": ["opening", "closing", "leaves", "brackets"], "param_types": {"opening": "Leaf", "closing": "Leaf", "leaves": "list[Leaf]", "brackets": "tuple[int, int]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["LookupError", "enumerate"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return True if content between `opening` and `closing` is a one-sequence.", "source_code": "def is_one_sequence_between(\n    opening: Leaf,\n    closing: Leaf,\n    leaves: list[Leaf],\n    brackets: tuple[int, int] = (token.LPAR, token.RPAR),\n) -> bool:\n    \"\"\"Return True if content between `opening` and `closing` is a one-sequence.\"\"\"\n    if (opening.type, closing.type) != brackets:\n        return False\n\n    depth = closing.bracket_depth + 1\n    for _opening_index, leaf in enumerate(leaves):\n        if leaf is opening:\n            break\n\n    else:\n        raise LookupError(\"Opening paren not found in `leaves`\")\n\n    commas = 0\n    _opening_index += 1\n    for leaf in leaves[_opening_index:]:\n        if leaf is closing:\n            break\n\n        bracket_depth = leaf.bracket_depth\n        if bracket_depth == depth and leaf.type == token.COMMA:\n            commas += 1\n            if leaf.parent and leaf.parent.type in {\n                syms.arglist,\n                syms.typedargslist,\n            }:\n                commas += 1\n                break\n\n    return commas < 2", "loc": 35}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_simple_decorator_expression", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["all", "is_simple_decorator_trailer", "len", "map"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True iff `node` could be a 'dotted name' decorator This function takes the node of the 'namedexpr_test' of the new decorator grammar and test if it would be valid under the old decorator grammar.", "source_code": "def is_simple_decorator_expression(node: LN) -> bool:\n    \"\"\"Return True iff `node` could be a 'dotted name' decorator\n\n    This function takes the node of the 'namedexpr_test' of the new decorator\n    grammar and test if it would be valid under the old decorator grammar.\n\n    The old grammar was: decorator: @ dotted_name [arguments] NEWLINE\n    The new grammar is : decorator: @ namedexpr_test NEWLINE\n    \"\"\"\n    if node.type == token.NAME:\n        return True\n    if node.type == syms.power:\n        if node.children:\n            return (\n                node.children[0].type == token.NAME\n                and all(map(is_simple_decorator_trailer, node.children[1:-1]))\n                and (\n                    len(node.children) < 2\n                    or is_simple_decorator_trailer(node.children[-1], last=True)\n                )\n            )\n    return False", "loc": 22}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_yield", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_name_token", "is_yield", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if `node` holds a `yield` or `yield from` expression.", "source_code": "def is_yield(node: LN) -> bool:\n    \"\"\"Return True if `node` holds a `yield` or `yield from` expression.\"\"\"\n    if node.type == syms.yield_expr:\n        return True\n\n    if is_name_token(node) and node.value == \"yield\":\n        return True\n\n    if node.type != syms.atom:\n        return False\n\n    if len(node.children) != 3:\n        return False\n\n    lpar, expr, rpar = node.children\n    if lpar.type == token.LPAR and rpar.type == token.RPAR:\n        return is_yield(expr)\n\n    return False", "loc": 19}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_vararg", "parameters": ["leaf", "within"], "param_types": {"leaf": "Leaf", "within": "set[NodeType]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if `leaf` is a star or double star in a vararg or kwarg. If `within` includes VARARGS_PARENTS, this applies to function signatures. If `within` includes UNPACKING_PARENTS, it applies to right hand-side", "source_code": "def is_vararg(leaf: Leaf, within: set[NodeType]) -> bool:\n    \"\"\"Return True if `leaf` is a star or double star in a vararg or kwarg.\n\n    If `within` includes VARARGS_PARENTS, this applies to function signatures.\n    If `within` includes UNPACKING_PARENTS, it applies to right hand-side\n    extended iterable unpacking (PEP 3132) and additional unpacking\n    generalizations (PEP 448).\n    \"\"\"\n    if leaf.type not in VARARGS_SPECIALS or not leaf.parent:\n        return False\n\n    p = leaf.parent\n    if p.type == syms.star_expr:\n        # Star expressions are also used as assignment targets in extended\n        # iterable unpacking (PEP 3132).  See what its parent is instead.\n        if not p.parent:\n            return False\n\n        p = p.parent\n\n    return p.type in within", "loc": 21}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "fstring_to_string", "parameters": ["node"], "param_types": {"node": "Node"}, "return_type": "Leaf", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "len", "node.get_lineno", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Converts an fstring node back to a string node.", "source_code": "def fstring_to_string(node: Node) -> Leaf:\n    \"\"\"Converts an fstring node back to a string node.\"\"\"\n    string_without_prefix = str(node)[len(node.prefix) :]\n    string_leaf = Leaf(token.STRING, string_without_prefix, prefix=node.prefix)\n    string_leaf.lineno = node.get_lineno() or 0\n    return string_leaf", "loc": 6}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_multiline_string", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fstring_to_string", "has_triple_quotes", "is_fstring", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if `leaf` is a multiline string that actually spans many lines.", "source_code": "def is_multiline_string(node: LN) -> bool:\n    \"\"\"Return True if `leaf` is a multiline string that actually spans many lines.\"\"\"\n    if isinstance(node, Node) and is_fstring(node):\n        leaf = fstring_to_string(node)\n    elif isinstance(node, Leaf):\n        leaf = node\n    else:\n        return False\n\n    return has_triple_quotes(leaf.value) and \"\\n\" in leaf.value", "loc": 10}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_stub_suite", "parameters": ["node"], "param_types": {"node": "Node"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_parent_function_or_class", "is_stub_body", "len", "node.children[3].prefix.strip", "node.prefix.strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if `node` is a suite with a stub body.", "source_code": "def is_stub_suite(node: Node) -> bool:\n    \"\"\"Return True if `node` is a suite with a stub body.\"\"\"\n    if node.parent is not None and not is_parent_function_or_class(node):\n        return False\n\n    # If there is a comment, we want to keep it.\n    if node.prefix.strip():\n        return False\n\n    if (\n        len(node.children) != 4\n        or node.children[0].type != token.NEWLINE\n        or node.children[1].type != token.INDENT\n        or node.children[3].type != token.DEDENT\n    ):\n        return False\n\n    if node.children[3].prefix.strip():\n        return False\n\n    return is_stub_body(node.children[2])", "loc": 21}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_stub_body", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "all", "child.prefix.strip", "isinstance", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return True if `node` is a simple statement containing an ellipsis.", "source_code": "def is_stub_body(node: LN) -> bool:\n    \"\"\"Return True if `node` is a simple statement containing an ellipsis.\"\"\"\n    if not isinstance(node, Node) or node.type != syms.simple_stmt:\n        return False\n\n    if len(node.children) != 2:\n        return False\n\n    child = node.children[0]\n    return (\n        not child.prefix.strip()\n        and child.type == syms.atom\n        and len(child.children) == 3\n        and all(leaf == Leaf(token.DOT, \".\") for leaf in child.children)\n    )", "loc": 15}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "is_atom_with_invisible_parens", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Given a `LN`, determines whether it's an atom `node` with invisible parens. Useful in dedupe-ing and normalizing parens.", "source_code": "def is_atom_with_invisible_parens(node: LN) -> bool:\n    \"\"\"Given a `LN`, determines whether it's an atom `node` with invisible\n    parens. Useful in dedupe-ing and normalizing parens.\n    \"\"\"\n    if isinstance(node, Leaf) or node.type != syms.atom:\n        return False\n\n    first, last = node.children[0], node.children[-1]\n    return (\n        isinstance(first, Leaf)\n        and first.type == token.LPAR\n        and first.value == \"\"\n        and isinstance(last, Leaf)\n        and last.type == token.RPAR\n        and last.value == \"\"\n    )", "loc": 16}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "wrap_in_parentheses", "parameters": ["parent", "child"], "param_types": {"parent": "Node", "child": "LN"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "Node", "child.remove", "parent.insert_child"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Wrap `child` in parentheses. This replaces `child` with an atom holding the parentheses and the old child.  That requires moving the prefix.", "source_code": "def wrap_in_parentheses(parent: Node, child: LN, *, visible: bool = True) -> None:\n    \"\"\"Wrap `child` in parentheses.\n\n    This replaces `child` with an atom holding the parentheses and the old\n    child.  That requires moving the prefix.\n\n    If `visible` is False, the leaves will be valueless (and thus invisible).\n    \"\"\"\n    lpar = Leaf(token.LPAR, \"(\" if visible else \"\")\n    rpar = Leaf(token.RPAR, \")\" if visible else \"\")\n    prefix = child.prefix\n    child.prefix = \"\"\n    index = child.remove() or 0\n    new_child = Node(syms.atom, [lpar, child, rpar])\n    new_child.prefix = prefix\n    parent.insert_child(index, new_child)", "loc": 16}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "unwrap_singleton_parenthesis", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "Optional[LN]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unwrap_singleton_parenthesis(node: LN) -> Optional[LN]:\n    \"\"\"Returns `wrapped` if `node` is of the shape ( wrapped ).\n\n    Parenthesis can be optional. Returns None otherwise\"\"\"\n    if len(node.children) != 3:\n        return None\n\n    lpar, wrapped, rpar = node.children\n    if not (lpar.type == token.LPAR and rpar.type == token.RPAR):\n        return None\n\n    return wrapped", "loc": 12}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "ensure_visible", "parameters": ["leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Make sure parentheses are visible. They could be invisible as part of some statements (see :func:`normalize_invisible_parens` and :func:`visit_import_from`).", "source_code": "def ensure_visible(leaf: Leaf) -> None:\n    \"\"\"Make sure parentheses are visible.\n\n    They could be invisible as part of some statements (see\n    :func:`normalize_invisible_parens` and :func:`visit_import_from`).\n    \"\"\"\n    if leaf.type == token.LPAR:\n        leaf.value = \"(\"\n    elif leaf.type == token.RPAR:\n        leaf.value = \")\"", "loc": 10}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "get_annotation_type", "parameters": ["leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "Literal['return', 'param', None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_annotation_type(leaf: Leaf) -> Literal[\"return\", \"param\", None]:\n    \"\"\"Returns the type of annotation this leaf is part of, if any.\"\"\"\n    ancestor = leaf.parent\n    while ancestor is not None:\n        if ancestor.prev_sibling and ancestor.prev_sibling.type == token.RARROW:\n            return \"return\"\n        if ancestor.parent and ancestor.parent.type == syms.tname:\n            return \"param\"\n        ancestor = ancestor.parent\n    return None", "loc": 10}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "first_leaf", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "Optional[Leaf]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["first_leaf", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def first_leaf(node: LN) -> Optional[Leaf]:\n    \"\"\"Returns the first leaf of the ancestor node.\"\"\"\n    if isinstance(node, Leaf):\n        return node\n    elif not node.children:\n        return None\n    else:\n        return first_leaf(node.children[0])", "loc": 8}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "last_leaf", "parameters": ["node"], "param_types": {"node": "LN"}, "return_type": "Optional[Leaf]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "last_leaf"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def last_leaf(node: LN) -> Optional[Leaf]:\n    \"\"\"Returns the last leaf of the ancestor node.\"\"\"\n    if isinstance(node, Leaf):\n        return node\n    elif not node.children:\n        return None\n    else:\n        return last_leaf(node.children[-1])", "loc": 8}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "furthest_ancestor_with_last_leaf", "parameters": ["leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "LN", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def furthest_ancestor_with_last_leaf(leaf: Leaf) -> LN:\n    \"\"\"Returns the furthest ancestor that has this leaf node as the last leaf.\"\"\"\n    node: LN = leaf\n    while node.parent and node.parent.children and node is node.parent.children[-1]:\n        node = node.parent\n    return node", "loc": 6}
{"file": "black\\src\\black\\nodes.py", "class_name": null, "function_name": "has_sibling_with_type", "parameters": ["node", "type"], "param_types": {"node": "LN", "type": "int"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def has_sibling_with_type(node: LN, type: int) -> bool:\n    # Check previous siblings\n    sibling = node.prev_sibling\n    while sibling is not None:\n        if sibling.type == type:\n            return True\n        sibling = sibling.prev_sibling\n\n    # Check next siblings\n    sibling = node.next_sibling\n    while sibling is not None:\n        if sibling.type == type:\n            return True\n        sibling = sibling.next_sibling\n\n    return False", "loc": 16}
{"file": "black\\src\\black\\nodes.py", "class_name": "Visitor", "function_name": "visit", "parameters": ["self", "node"], "param_types": {"node": "LN"}, "return_type": "Iterator[T]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "self.visit_default", "str", "type_repr", "visitf"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Main method to visit `node` and its children. It tries to find a `visit_*()` method for the given `node.type`, like `visit_simple_stmt` for Node objects or `visit_INDENT` for Leaf objects.", "source_code": "def visit(self, node: LN) -> Iterator[T]:\n    \"\"\"Main method to visit `node` and its children.\n\n    It tries to find a `visit_*()` method for the given `node.type`, like\n    `visit_simple_stmt` for Node objects or `visit_INDENT` for Leaf objects.\n    If no dedicated `visit_*()` method is found, chooses `visit_default()`\n    instead.\n\n    Then yields objects of type `T` from the selected visitor.\n    \"\"\"\n    if node.type < 256:\n        name = token.tok_name[node.type]\n    else:\n        name = str(type_repr(node.type))\n    # We explicitly branch on whether a visitor exists (instead of\n    # using self.visit_default as the default arg to getattr) in order\n    # to save needing to create a bound method object and so mypyc can\n    # generate a native call to visit_default.\n    visitf = getattr(self, f\"visit_{name}\", None)\n    if visitf:\n        yield from visitf(node)\n    else:\n        yield from self.visit_default(node)", "loc": 23}
{"file": "black\\src\\black\\nodes.py", "class_name": "Visitor", "function_name": "visit_default", "parameters": ["self", "node"], "param_types": {"node": "LN"}, "return_type": "Iterator[T]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self.visit"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Default `visit_*()` implementation. Recurses to children of `node`.", "source_code": "def visit_default(self, node: LN) -> Iterator[T]:\n    \"\"\"Default `visit_*()` implementation. Recurses to children of `node`.\"\"\"\n    if isinstance(node, Node):\n        for child in node.children:\n            yield from self.visit(child)", "loc": 5}
{"file": "black\\src\\black\\numerics.py", "class_name": null, "function_name": "format_scientific_notation", "parameters": ["text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["after.startswith", "format_float_or_int_string", "text.split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Formats a numeric string utilizing scientific notation", "source_code": "def format_scientific_notation(text: str) -> str:\n    \"\"\"Formats a numeric string utilizing scientific notation\"\"\"\n    before, after = text.split(\"e\")\n    sign = \"\"\n    if after.startswith(\"-\"):\n        after = after[1:]\n        sign = \"-\"\n    elif after.startswith(\"+\"):\n        after = after[1:]\n    before = format_float_or_int_string(before)\n    return f\"{before}e{sign}{after}\"", "loc": 11}
{"file": "black\\src\\black\\numerics.py", "class_name": null, "function_name": "format_float_or_int_string", "parameters": ["text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["text.split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Formats a float string like \"1.0\".", "source_code": "def format_float_or_int_string(text: str) -> str:\n    \"\"\"Formats a float string like \"1.0\".\"\"\"\n    if \".\" not in text:\n        return text\n\n    before, after = text.split(\".\")\n    return f\"{before or 0}.{after or 0}\"", "loc": 7}
{"file": "black\\src\\black\\numerics.py", "class_name": null, "function_name": "normalize_numeric_literal", "parameters": ["leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["format_complex_number", "format_float_or_int_string", "format_hex", "format_scientific_notation", "leaf.value.lower", "text.endswith", "text.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Normalizes numeric (float, int, and complex) literals. All letters used in the representation are normalized to lowercase.", "source_code": "def normalize_numeric_literal(leaf: Leaf) -> None:\n    \"\"\"Normalizes numeric (float, int, and complex) literals.\n\n    All letters used in the representation are normalized to lowercase.\"\"\"\n    text = leaf.value.lower()\n    if text.startswith((\"0o\", \"0b\")):\n        # Leave octal and binary literals alone.\n        pass\n    elif text.startswith(\"0x\"):\n        text = format_hex(text)\n    elif \"e\" in text:\n        text = format_scientific_notation(text)\n    elif text.endswith(\"j\"):\n        text = format_complex_number(text)\n    else:\n        text = format_float_or_int_string(text)\n    leaf.value = text", "loc": 17}
{"file": "black\\src\\black\\output.py", "class_name": null, "function_name": "ipynb_diff", "parameters": ["a", "b", "a_name", "b_name"], "param_types": {"a": "str", "b": "str", "a_name": "str", "b_name": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "diff", "enumerate", "json.loads"], "control_structures": [], "behavior_type": ["serialization"], "doc_summary": "Return a unified diff string between each cell in notebooks `a` and `b`.", "source_code": "def ipynb_diff(a: str, b: str, a_name: str, b_name: str) -> str:\n    \"\"\"Return a unified diff string between each cell in notebooks `a` and `b`.\"\"\"\n    a_nb = json.loads(a)\n    b_nb = json.loads(b)\n    diff_lines = [\n        diff(\n            \"\".join(a_nb[\"cells\"][cell_number][\"source\"]) + \"\\n\",\n            \"\".join(b_nb[\"cells\"][cell_number][\"source\"]) + \"\\n\",\n            f\"{a_name}:cell_{cell_number}\",\n            f\"{b_name}:cell_{cell_number}\",\n        )\n        for cell_number, cell in enumerate(a_nb[\"cells\"])\n        if cell[\"cell_type\"] == \"code\"\n    ]\n    return \"\".join(diff_lines)", "loc": 15}
{"file": "black\\src\\black\\output.py", "class_name": null, "function_name": "diff", "parameters": ["a", "b", "a_name", "b_name"], "param_types": {"a": "str", "b": "str", "a_name": "str", "b_name": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "_splitlines_no_ff", "diff_lines.append", "difflib.unified_diff"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return a unified diff string between strings `a` and `b`.", "source_code": "def diff(a: str, b: str, a_name: str, b_name: str) -> str:\n    \"\"\"Return a unified diff string between strings `a` and `b`.\"\"\"\n    import difflib\n\n    a_lines = _splitlines_no_ff(a)\n    b_lines = _splitlines_no_ff(b)\n    diff_lines = []\n    for line in difflib.unified_diff(\n        a_lines, b_lines, fromfile=a_name, tofile=b_name, n=5\n    ):\n        # Work around https://bugs.python.org/issue2142\n        # See:\n        # https://www.gnu.org/software/diffutils/manual/html_node/Incomplete-Lines.html\n        if line[-1] == \"\\n\":\n            diff_lines.append(line)\n        else:\n            diff_lines.append(line + \"\\n\")\n            diff_lines.append(\"\\\\ No newline at end of file\\n\")\n    return \"\".join(diff_lines)", "loc": 19}
{"file": "black\\src\\black\\output.py", "class_name": null, "function_name": "color_diff", "parameters": ["contents"], "param_types": {"contents": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "contents.split", "enumerate", "line.startswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Inject the ANSI color codes to the diff.", "source_code": "def color_diff(contents: str) -> str:\n    \"\"\"Inject the ANSI color codes to the diff.\"\"\"\n    lines = contents.split(\"\\n\")\n    for i, line in enumerate(lines):\n        if line.startswith(\"+++\") or line.startswith(\"---\"):\n            line = \"\\033[1m\" + line + \"\\033[0m\"  # bold, reset\n        elif line.startswith(\"@@\"):\n            line = \"\\033[36m\" + line + \"\\033[0m\"  # cyan, reset\n        elif line.startswith(\"+\"):\n            line = \"\\033[32m\" + line + \"\\033[0m\"  # green, reset\n        elif line.startswith(\"-\"):\n            line = \"\\033[31m\" + line + \"\\033[0m\"  # red, reset\n        lines[i] = line\n    return \"\\n\".join(lines)", "loc": 14}
{"file": "black\\src\\black\\output.py", "class_name": null, "function_name": "dump_to_file", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["f.write", "mypyc_attr", "tempfile.NamedTemporaryFile"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Dump `output` to a temporary file. Return path to the file.", "source_code": "def dump_to_file(*output: str, ensure_final_newline: bool = True) -> str:\n    \"\"\"Dump `output` to a temporary file. Return path to the file.\"\"\"\n    with tempfile.NamedTemporaryFile(\n        mode=\"w\", prefix=\"blk_\", suffix=\".log\", delete=False, encoding=\"utf8\"\n    ) as f:\n        for lines in output:\n            f.write(lines)\n            if ensure_final_newline and lines and lines[-1] != \"\\n\":\n                f.write(\"\\n\")\n    return f.name", "loc": 10}
{"file": "black\\src\\black\\parsing.py", "class_name": null, "function_name": "get_grammars", "parameters": ["target_versions"], "param_types": {"target_versions": "set[TargetVersion]"}, "return_type": "list[Grammar]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "grammars.append", "supports_feature"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_grammars(target_versions: set[TargetVersion]) -> list[Grammar]:\n    if not target_versions:\n        # No target_version specified, so try all grammars.\n        return [\n            # Python 3.7-3.9\n            pygram.python_grammar_async_keywords,\n            # Python 3.0-3.6\n            pygram.python_grammar,\n            # Python 3.10+\n            pygram.python_grammar_soft_keywords,\n        ]\n\n    grammars = []\n    # If we have to parse both, try to parse async as a keyword first\n    if not supports_feature(\n        target_versions, Feature.ASYNC_IDENTIFIERS\n    ) and not supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.7-3.9\n        grammars.append(pygram.python_grammar_async_keywords)\n    if not supports_feature(target_versions, Feature.ASYNC_KEYWORDS):\n        # Python 3.0-3.6\n        grammars.append(pygram.python_grammar)\n    if any(Feature.PATTERN_MATCHING in VERSION_TO_FEATURES[v] for v in target_versions):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n\n    # At least one of the above branches must have been taken, because every Python\n    # version has exactly one of the two 'ASYNC_*' flags\n    return grammars", "loc": 29}
{"file": "black\\src\\black\\parsing.py", "class_name": null, "function_name": "lib2to3_parse", "parameters": ["src_txt", "target_versions"], "param_types": {"src_txt": "str", "target_versions": "Collection[TargetVersion]"}, "return_type": "Node", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InvalidInput", "Node", "driver.Driver", "drv.parse_string", "get_grammars", "isinstance", "len", "max", "max_tv.pretty", "set", "src_txt.endswith", "src_txt.splitlines"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Given a string with source, return the lib2to3 Node.", "source_code": "def lib2to3_parse(\n    src_txt: str, target_versions: Collection[TargetVersion] = ()\n) -> Node:\n    \"\"\"Given a string with source, return the lib2to3 Node.\"\"\"\n    if not src_txt.endswith(\"\\n\"):\n        src_txt += \"\\n\"\n\n    grammars = get_grammars(set(target_versions))\n    if target_versions:\n        max_tv = max(target_versions, key=lambda tv: tv.value)\n        tv_str = f\" for target version {max_tv.pretty()}\"\n    else:\n        tv_str = \"\"\n\n    errors = {}\n    for grammar in grammars:\n        drv = driver.Driver(grammar)\n        try:\n            result = drv.parse_string(src_txt, False)\n            break\n\n        except ParseError as pe:\n            lineno, column = pe.context[1]\n            lines = src_txt.splitlines()\n            try:\n                faulty_line = lines[lineno - 1]\n            except IndexError:\n                faulty_line = \"<line number missing in source>\"\n            errors[grammar.version] = InvalidInput(\n                f\"Cannot parse{tv_str}: {lineno}:{column}: {faulty_line}\"\n            )\n\n        except TokenError as te:\n            # In edge cases these are raised; and typically don't have a \"faulty_line\".\n            lineno, column = te.args[1]\n            errors[grammar.version] = InvalidInput(\n                f\"Cannot parse{tv_str}: {lineno}:{column}: {te.args[0]}\"\n            )\n\n    else:\n        # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)]\n        raise exc from None\n\n    if isinstance(result, Leaf):\n        result = Node(syms.file_input, [result])\n    return result", "loc": 48}
{"file": "black\\src\\black\\parsing.py", "class_name": null, "function_name": "matches_grammar", "parameters": ["src_txt", "grammar"], "param_types": {"src_txt": "str", "grammar": "Grammar"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["driver.Driver", "drv.parse_string"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def matches_grammar(src_txt: str, grammar: Grammar) -> bool:\n    drv = driver.Driver(grammar)\n    try:\n        drv.parse_string(src_txt, False)\n    except (ParseError, TokenError, IndentationError):\n        return False\n    else:\n        return True", "loc": 8}
{"file": "black\\src\\black\\parsing.py", "class_name": null, "function_name": "parse_ast", "parameters": ["src"], "param_types": {"src": "str"}, "return_type": "ast.AST", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SyntaxError", "_parse_single_version", "range", "sorted", "str"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_ast(src: str) -> ast.AST:\n    # TODO: support Python 4+ ;)\n    versions = [(3, minor) for minor in range(3, sys.version_info[1] + 1)]\n\n    first_error = \"\"\n    for version in sorted(versions, reverse=True):\n        try:\n            return _parse_single_version(src, version, type_comments=True)\n        except SyntaxError as e:\n            if not first_error:\n                first_error = str(e)\n\n    # Try to parse without type comments\n    for version in sorted(versions, reverse=True):\n        try:\n            return _parse_single_version(src, version, type_comments=False)\n        except SyntaxError:\n            pass\n\n    raise SyntaxError(first_error)", "loc": 20}
{"file": "black\\src\\black\\ranges.py", "class_name": null, "function_name": "parse_line_ranges", "parameters": ["line_ranges"], "param_types": {"line_ranges": "Sequence[str]"}, "return_type": "list[tuple[int, int]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "int", "len", "lines.append", "lines_str.split"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_line_ranges(line_ranges: Sequence[str]) -> list[tuple[int, int]]:\n    lines: list[tuple[int, int]] = []\n    for lines_str in line_ranges:\n        parts = lines_str.split(\"-\")\n        if len(parts) != 2:\n            raise ValueError(\n                \"Incorrect --line-ranges format, expect 'START-END', found\"\n                f\" {lines_str!r}\"\n            )\n        try:\n            start = int(parts[0])\n            end = int(parts[1])\n        except ValueError:\n            raise ValueError(\n                \"Incorrect --line-ranges value, expect integer ranges, found\"\n                f\" {lines_str!r}\"\n            ) from None\n        else:\n            lines.append((start, end))\n    return lines", "loc": 20}
{"file": "black\\src\\black\\ranges.py", "class_name": null, "function_name": "sanitized_lines", "parameters": ["lines", "src_contents"], "param_types": {"lines": "Collection[tuple[int, int]]", "src_contents": "str"}, "return_type": "Collection[tuple[int, int]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["good_lines.append", "max", "min", "src_contents.count", "src_contents.endswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def sanitized_lines(\n    lines: Collection[tuple[int, int]], src_contents: str\n) -> Collection[tuple[int, int]]:\n    \"\"\"Returns the valid line ranges for the given source.\n\n    This removes ranges that are entirely outside the valid lines.\n\n    Other ranges are normalized so that the start values are at least 1 and the\n    end values are at most the (1-based) index of the last source line.\n    \"\"\"\n    if not src_contents:\n        return []\n    good_lines = []\n    src_line_count = src_contents.count(\"\\n\")\n    if not src_contents.endswith(\"\\n\"):\n        src_line_count += 1\n    for start, end in lines:\n        if start > src_line_count:\n            continue\n        # line-ranges are 1-based\n        start = max(start, 1)\n        if end < start:\n            continue\n        end = min(end, src_line_count)\n        good_lines.append((start, end))\n    return good_lines", "loc": 26}
{"file": "black\\src\\black\\ranges.py", "class_name": null, "function_name": "adjusted_lines", "parameters": ["lines", "original_source", "modified_source"], "param_types": {"lines": "Collection[tuple[int, int]]", "original_source": "str", "modified_source": "str"}, "return_type": "list[tuple[int, int]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_calculate_lines_mappings", "_find_lines_mapping_index", "is_valid_line_range", "len", "new_lines.append", "sorted"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def adjusted_lines(\n    lines: Collection[tuple[int, int]],\n    original_source: str,\n    modified_source: str,\n) -> list[tuple[int, int]]:\n    \"\"\"Returns the adjusted line ranges based on edits from the original code.\n\n    This computes the new line ranges by diffing original_source and\n    modified_source, and adjust each range based on how the range overlaps with\n    the diffs.\n\n    Note the diff can contain lines outside of the original line ranges. This can\n    happen when the formatting has to be done in adjacent to maintain consistent\n    local results. For example:\n\n    1. def my_func(arg1, arg2,\n    2.             arg3,):\n    3.   pass\n\n    If it restricts to line 2-2, it can't simply reformat line 2, it also has\n    to reformat line 1:\n\n    1. def my_func(\n    2.     arg1,\n    3.     arg2,\n    4.     arg3,\n    5. ):\n    6.   pass\n\n    In this case, we will expand the line ranges to also include the whole diff\n    block.\n\n    Args:\n      lines: a collection of line ranges.\n      original_source: the original source.\n      modified_source: the modified source.\n    \"\"\"\n    lines_mappings = _calculate_lines_mappings(original_source, modified_source)\n\n    new_lines = []\n    # Keep an index of the current search. Since the lines and lines_mappings are\n    # sorted, this makes the search complexity linear.\n    current_mapping_index = 0\n    for start, end in sorted(lines):\n        start_mapping_index = _find_lines_mapping_index(\n            start,\n            lines_mappings,\n            current_mapping_index,\n        )\n        end_mapping_index = _find_lines_mapping_index(\n            end,\n            lines_mappings,\n            start_mapping_index,\n        )\n        current_mapping_index = start_mapping_index\n        if start_mapping_index >= len(lines_mappings) or end_mapping_index >= len(\n            lines_mappings\n        ):\n            # Protect against invalid inputs.\n            continue\n        start_mapping = lines_mappings[start_mapping_index]\n        end_mapping = lines_mappings[end_mapping_index]\n        if start_mapping.is_changed_block:\n            # When the line falls into a changed block, expands to the whole block.\n            new_start = start_mapping.modified_start\n        else:\n            new_start = (\n                start - start_mapping.original_start + start_mapping.modified_start\n            )\n        if end_mapping.is_changed_block:\n            # When the line falls into a changed block, expands to the whole block.\n            new_end = end_mapping.modified_end\n        else:\n            new_end = end - end_mapping.original_start + end_mapping.modified_start\n        new_range = (new_start, new_end)\n        if is_valid_line_range(new_range):\n            new_lines.append(new_range)\n    return new_lines", "loc": 78}
{"file": "black\\src\\black\\ranges.py", "class_name": null, "function_name": "convert_unchanged_lines", "parameters": ["src_node", "lines"], "param_types": {"src_node": "Node", "lines": "Collection[tuple[int, int]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_TopLevelStatementsVisitor", "_convert_unchanged_line_by_line", "lines_set.update", "list", "range", "set", "visitor.visit"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Converts unchanged lines to STANDALONE_COMMENT. The idea is similar to how `# fmt: on/off` is implemented. It also converts the nodes between those markers as a single `STANDALONE_COMMENT` leaf node with", "source_code": "def convert_unchanged_lines(src_node: Node, lines: Collection[tuple[int, int]]) -> None:\n    r\"\"\"Converts unchanged lines to STANDALONE_COMMENT.\n\n    The idea is similar to how `# fmt: on/off` is implemented. It also converts the\n    nodes between those markers as a single `STANDALONE_COMMENT` leaf node with\n    the unformatted code as its value. `STANDALONE_COMMENT` is a \"fake\" token\n    that will be formatted as-is with its prefix normalized.\n\n    Here we perform two passes:\n\n    1. Visit the top-level statements, and convert them to a single\n       `STANDALONE_COMMENT` when unchanged. This speeds up formatting when some\n       of the top-level statements aren't changed.\n    2. Convert unchanged \"unwrapped lines\" to `STANDALONE_COMMENT` nodes line by\n       line. \"unwrapped lines\" are divided by the `NEWLINE` token. e.g. a\n       multi-line statement is *one* \"unwrapped line\" that ends with `NEWLINE`,\n       even though this statement itself can span multiple lines, and the\n       tokenizer only sees the last '\\n' as the `NEWLINE` token.\n\n    NOTE: During pass (2), comment prefixes and indentations are ALWAYS\n    normalized even when the lines aren't changed. This is fixable by moving\n    more formatting to pass (1). However, it's hard to get it correct when\n    incorrect indentations are used. So we defer this to future optimizations.\n    \"\"\"\n    lines_set: set[int] = set()\n    for start, end in lines:\n        lines_set.update(range(start, end + 1))\n    visitor = _TopLevelStatementsVisitor(lines_set)\n    _ = list(visitor.visit(src_node))  # Consume all results.\n    _convert_unchanged_line_by_line(src_node, lines_set)", "loc": 30}
{"file": "black\\src\\black\\ranges.py", "class_name": "_TopLevelStatementsVisitor", "function_name": "visit_simple_stmt", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_convert_node_to_standalone_comment", "_get_line_range", "_get_line_range(ancestor).intersection", "furthest_ancestor_with_last_leaf", "last_leaf"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_simple_stmt(self, node: Node) -> Iterator[None]:\n    # This is only called for top-level statements, since `visit_suite`\n    # won't visit its children nodes.\n    yield from []\n    newline_leaf = last_leaf(node)\n    if not newline_leaf:\n        return\n    assert (\n        newline_leaf.type == NEWLINE\n    ), f\"Unexpectedly found leaf.type={newline_leaf.type}\"\n    # We need to find the furthest ancestor with the NEWLINE as the last\n    # leaf, since a `suite` can simply be a `simple_stmt` when it puts\n    # its body on the same line. Example: `if cond: pass`.\n    ancestor = furthest_ancestor_with_last_leaf(newline_leaf)\n    if not _get_line_range(ancestor).intersection(self._lines_set):\n        _convert_node_to_standalone_comment(ancestor)", "loc": 16}
{"file": "black\\src\\black\\ranges.py", "class_name": "_TopLevelStatementsVisitor", "function_name": "visit_suite", "parameters": ["self", "node"], "param_types": {"node": "Node"}, "return_type": "Iterator[None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_contains_standalone_comment", "_convert_node_to_standalone_comment", "_get_line_range", "_get_line_range(semantic_parent).intersection"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_suite(self, node: Node) -> Iterator[None]:\n    yield from []\n    # If there is a STANDALONE_COMMENT node, it means parts of the node tree\n    # have fmt on/off/skip markers. Those STANDALONE_COMMENT nodes can't\n    # be simply converted by calling str(node). So we just don't convert\n    # here.\n    if _contains_standalone_comment(node):\n        return\n    # Find the semantic parent of this suite. For `async_stmt` and\n    # `async_funcdef`, the ASYNC token is defined on a separate level by the\n    # grammar.\n    semantic_parent = node.parent\n    if semantic_parent is not None:\n        if (\n            semantic_parent.prev_sibling is not None\n            and semantic_parent.prev_sibling.type == ASYNC\n        ):\n            semantic_parent = semantic_parent.parent\n    if semantic_parent is not None and not _get_line_range(\n        semantic_parent\n    ).intersection(self._lines_set):\n        _convert_node_to_standalone_comment(semantic_parent)", "loc": 22}
{"file": "black\\src\\black\\report.py", "class_name": "Report", "function_name": "done", "parameters": ["self", "src", "changed"], "param_types": {"src": "Path", "changed": "Changed"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["out"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Increment the counter for successful reformatting. Write out a message.", "source_code": "def done(self, src: Path, changed: Changed) -> None:\n    \"\"\"Increment the counter for successful reformatting. Write out a message.\"\"\"\n    if changed is Changed.YES:\n        reformatted = \"would reformat\" if self.check or self.diff else \"reformatted\"\n        if self.verbose or not self.quiet:\n            out(f\"{reformatted} {src}\")\n        self.change_count += 1\n    else:\n        if self.verbose:\n            if changed is Changed.NO:\n                msg = f\"{src} already well formatted, good job.\"\n            else:\n                msg = f\"{src} wasn't modified on disk since last run.\"\n            out(msg, bold=False)\n        self.same_count += 1", "loc": 15}
{"file": "black\\src\\black\\report.py", "class_name": "Report", "function_name": "return_code", "parameters": ["self"], "param_types": {}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the exit code that the app should use. This considers the current state of changed files and failures: - if there were any failures, return 123;", "source_code": "def return_code(self) -> int:\n    \"\"\"Return the exit code that the app should use.\n\n    This considers the current state of changed files and failures:\n    - if there were any failures, return 123;\n    - if any files were changed and --check is being used, return 1;\n    - otherwise return 0.\n    \"\"\"\n    # According to http://tldp.org/LDP/abs/html/exitcodes.html starting with\n    # 126 we have special return codes reserved by the shell.\n    if self.failure_count:\n        return 123\n\n    elif self.change_count and self.check:\n        return 1\n\n    return 0", "loc": 17}
{"file": "black\\src\\black\\schema.py", "class_name": null, "function_name": "get_schema", "parameters": ["tool_name"], "param_types": {"tool_name": "str"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["importlib.resources.files", "importlib.resources.files(pkg).joinpath", "json.load", "schema.open"], "control_structures": [], "behavior_type": ["file_io", "serialization"], "doc_summary": "Get the stored complete schema for black's settings.", "source_code": "def get_schema(tool_name: str = \"black\") -> Any:\n    \"\"\"Get the stored complete schema for black's settings.\"\"\"\n    assert tool_name == \"black\", \"Only black is supported.\"\n\n    pkg = \"black.resources\"\n    fname = \"black.schema.json\"\n\n    schema = importlib.resources.files(pkg).joinpath(fname)\n    with schema.open(encoding=\"utf-8\") as f:\n        return json.load(f)", "loc": 10}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "lines_with_leading_tabs_expanded", "parameters": ["s"], "param_types": {"s": "str"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "line.lstrip", "line[:prefix_length].expandtabs", "lines.append", "s.endswith", "s.splitlines"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Splits string into lines and expands only leading tabs (following the normal Python rules)", "source_code": "def lines_with_leading_tabs_expanded(s: str) -> list[str]:\n    \"\"\"\n    Splits string into lines and expands only leading tabs (following the normal\n    Python rules)\n    \"\"\"\n    lines = []\n    for line in s.splitlines():\n        stripped_line = line.lstrip()\n        if not stripped_line or stripped_line == line:\n            lines.append(line)\n        else:\n            prefix_length = len(line) - len(stripped_line)\n            prefix = line[:prefix_length].expandtabs()\n            lines.append(prefix + stripped_line)\n    if s.endswith(\"\\n\"):\n        lines.append(\"\")\n    return lines", "loc": 17}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "fix_multiline_docstring", "parameters": ["docstring", "prefix"], "param_types": {"docstring": "str", "prefix": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "enumerate", "len", "line.lstrip", "line[indent:].rstrip", "lines[0].strip", "lines_with_leading_tabs_expanded", "min", "trimmed.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fix_multiline_docstring(docstring: str, prefix: str) -> str:\n    # https://www.python.org/dev/peps/pep-0257/#handling-docstring-indentation\n    assert docstring, \"INTERNAL ERROR: Multiline docstrings cannot be empty\"\n    lines = lines_with_leading_tabs_expanded(docstring)\n    # Determine minimum indentation (first line doesn't count):\n    indent = sys.maxsize\n    for line in lines[1:]:\n        stripped = line.lstrip()\n        if stripped:\n            indent = min(indent, len(line) - len(stripped))\n    # Remove indentation (first line is special):\n    trimmed = [lines[0].strip()]\n    if indent < sys.maxsize:\n        last_line_idx = len(lines) - 2\n        for i, line in enumerate(lines[1:]):\n            stripped_line = line[indent:].rstrip()\n            if stripped_line or i == last_line_idx:\n                trimmed.append(prefix + stripped_line)\n            else:\n                trimmed.append(\"\")\n    return \"\\n\".join(trimmed)", "loc": 21}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "get_string_prefix", "parameters": ["string"], "param_types": {"string": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "assert_is_leaf_string", "prefix.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Pre-conditions: * assert_is_leaf_string(@string)", "source_code": "def get_string_prefix(string: str) -> str:\n    \"\"\"\n    Pre-conditions:\n        * assert_is_leaf_string(@string)\n\n    Returns:\n        @string's prefix (e.g. '', 'r', 'f', or 'rf').\n    \"\"\"\n    assert_is_leaf_string(string)\n\n    prefix = []\n    for char in string:\n        if char in STRING_PREFIX_CHARS:\n            prefix.append(char)\n        else:\n            break\n    return \"\".join(prefix)", "loc": 17}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "assert_is_leaf_string", "parameters": ["string"], "param_types": {"string": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "max", "min", "set", "set(string[:quote_idx]).issubset", "string.find"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Checks the pre-condition that @string has the format that you would expect of `leaf.value` where `leaf` is some Leaf such that `leaf.type == token.STRING`. A more precise description of the pre-conditions that are checked are listed below. Pre-conditions: * @string starts with either ', \", <prefix>', or <prefix>\" where `set(<prefix>)` is some subset of `set(STRING_PREFIX_CHARS)`. * @string ends with a quote character (' or \").", "source_code": "def assert_is_leaf_string(string: str) -> None:\n    \"\"\"\n    Checks the pre-condition that @string has the format that you would expect\n    of `leaf.value` where `leaf` is some Leaf such that `leaf.type ==\n    token.STRING`. A more precise description of the pre-conditions that are\n    checked are listed below.\n\n    Pre-conditions:\n        * @string starts with either ', \", <prefix>', or <prefix>\" where\n        `set(<prefix>)` is some subset of `set(STRING_PREFIX_CHARS)`.\n        * @string ends with a quote character (' or \").\n\n    Raises:\n        AssertionError(...) if the pre-conditions listed above are not\n        satisfied.\n    \"\"\"\n    dquote_idx = string.find('\"')\n    squote_idx = string.find(\"'\")\n    if -1 in [dquote_idx, squote_idx]:\n        quote_idx = max(dquote_idx, squote_idx)\n    else:\n        quote_idx = min(squote_idx, dquote_idx)\n\n    assert (\n        0 <= quote_idx < len(string) - 1\n    ), f\"{string!r} is missing a starting quote character (' or \\\").\"\n    assert string[-1] in (\n        \"'\",\n        '\"',\n    ), f\"{string!r} is missing an ending quote character (' or \\\").\"\n    assert set(string[:quote_idx]).issubset(\n        set(STRING_PREFIX_CHARS)\n    ), f\"{set(string[:quote_idx])} is NOT a subset of {set(STRING_PREFIX_CHARS)}.\"", "loc": 33}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "normalize_string_prefix", "parameters": ["s"], "param_types": {"s": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["STRING_PREFIX_RE.match", "len", "match.group", "new_prefix[0].lower", "orig_prefix.replace", "orig_prefix.replace('F', 'f').replace", "orig_prefix.replace('F', 'f').replace('B', 'b').replace", "orig_prefix.replace('F', 'f').replace('B', 'b').replace('U', '').replace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Make all string prefixes lowercase.", "source_code": "def normalize_string_prefix(s: str) -> str:\n    \"\"\"Make all string prefixes lowercase.\"\"\"\n    match = STRING_PREFIX_RE.match(s)\n    assert match is not None, f\"failed to match string {s!r}\"\n    orig_prefix = match.group(1)\n    new_prefix = (\n        orig_prefix.replace(\"F\", \"f\")\n        .replace(\"B\", \"b\")\n        .replace(\"U\", \"\")\n        .replace(\"u\", \"\")\n    )\n\n    # Python syntax guarantees max 2 prefixes and that one of them is \"r\"\n    if len(new_prefix) == 2 and new_prefix[0].lower() != \"r\":\n        new_prefix = new_prefix[::-1]\n    return f\"{new_prefix}{match.group(2)}\"", "loc": 16}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "normalize_string_quotes", "parameters": ["s"], "param_types": {"s": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_cached_compile", "body.count", "len", "new_body.count", "prefix.casefold", "re.findall", "s.find", "s.lstrip", "str", "sub_twice", "unescaped_new_quote.search"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Prefer double quotes but only if it doesn't cause more escaping. Adds or removes backslashes as appropriate.", "source_code": "def normalize_string_quotes(s: str) -> str:\n    \"\"\"Prefer double quotes but only if it doesn't cause more escaping.\n\n    Adds or removes backslashes as appropriate.\n    \"\"\"\n    value = s.lstrip(STRING_PREFIX_CHARS)\n    if value[:3] == '\"\"\"':\n        return s\n\n    elif value[:3] == \"'''\":\n        orig_quote = \"'''\"\n        new_quote = '\"\"\"'\n    elif value[0] == '\"':\n        orig_quote = '\"'\n        new_quote = \"'\"\n    else:\n        orig_quote = \"'\"\n        new_quote = '\"'\n    first_quote_pos = s.find(orig_quote)\n    assert first_quote_pos != -1, f\"INTERNAL ERROR: Malformed string {s!r}\"\n\n    prefix = s[:first_quote_pos]\n    unescaped_new_quote = _cached_compile(rf\"(([^\\\\]|^)(\\\\\\\\)*){new_quote}\")\n    escaped_new_quote = _cached_compile(rf\"([^\\\\]|^)\\\\((?:\\\\\\\\)*){new_quote}\")\n    escaped_orig_quote = _cached_compile(rf\"([^\\\\]|^)\\\\((?:\\\\\\\\)*){orig_quote}\")\n    body = s[first_quote_pos + len(orig_quote) : -len(orig_quote)]\n    if \"r\" in prefix.casefold():\n        if unescaped_new_quote.search(body):\n            # There's at least one unescaped new_quote in this raw string\n            # so converting is impossible\n            return s\n\n        # Do not introduce or remove backslashes in raw strings\n        new_body = body\n    else:\n        # remove unnecessary escapes\n        new_body = sub_twice(escaped_new_quote, rf\"\\1\\2{new_quote}\", body)\n        if body != new_body:\n            # Consider the string without unnecessary escapes as the original\n            body = new_body\n            s = f\"{prefix}{orig_quote}{body}{orig_quote}\"\n        new_body = sub_twice(escaped_orig_quote, rf\"\\1\\2{orig_quote}\", new_body)\n        new_body = sub_twice(unescaped_new_quote, rf\"\\1\\\\{new_quote}\", new_body)\n\n    if \"f\" in prefix.casefold():\n        matches = re.findall(\n            r\"\"\"\n            (?:(?<!\\{)|^)\\{  # start of the string or a non-{ followed by a single {\n                ([^{].*?)  # contents of the brackets except if begins with {{\n            \\}(?:(?!\\})|$)  # A } followed by end of the string or a non-}\n            \"\"\",\n            new_body,\n            re.VERBOSE,\n        )\n        for m in matches:\n            if \"\\\\\" in str(m):\n                # Do not introduce backslashes in interpolated expressions\n                return s\n\n    if new_quote == '\"\"\"' and new_body[-1:] == '\"':\n        # edge case:\n        new_body = new_body[:-1] + '\\\\\"'\n    orig_escape_count = body.count(\"\\\\\")\n    new_escape_count = new_body.count(\"\\\\\")\n    if new_escape_count > orig_escape_count:\n        return s  # Do not introduce more escaping\n\n    if new_escape_count == orig_escape_count and orig_quote == '\"':\n        return s  # Prefer double quotes\n\n    return f\"{prefix}{new_quote}{new_body}{new_quote}\"", "loc": 71}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "normalize_fstring_quotes", "parameters": ["quote", "middles", "is_raw_fstring"], "param_types": {"quote": "str", "middles": "list[Leaf]", "is_raw_fstring": "bool"}, "return_type": "tuple[list[Leaf], str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_cached_compile", "middle.value.count", "new_segment.count", "new_segments.append", "new_segments[-1].endswith", "sub_twice", "unescaped_new_quote.search", "zip"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Prefer double quotes but only if it doesn't cause more escaping. Adds or removes backslashes as appropriate.", "source_code": "def normalize_fstring_quotes(\n    quote: str,\n    middles: list[Leaf],\n    is_raw_fstring: bool,\n) -> tuple[list[Leaf], str]:\n    \"\"\"Prefer double quotes but only if it doesn't cause more escaping.\n\n    Adds or removes backslashes as appropriate.\n    \"\"\"\n    if quote == '\"\"\"':\n        return middles, quote\n\n    elif quote == \"'''\":\n        new_quote = '\"\"\"'\n    elif quote == '\"':\n        new_quote = \"'\"\n    else:\n        new_quote = '\"'\n\n    unescaped_new_quote = _cached_compile(rf\"(([^\\\\]|^)(\\\\\\\\)*){new_quote}\")\n    escaped_new_quote = _cached_compile(rf\"([^\\\\]|^)\\\\((?:\\\\\\\\)*){new_quote}\")\n    escaped_orig_quote = _cached_compile(rf\"([^\\\\]|^)\\\\((?:\\\\\\\\)*){quote}\")\n    if is_raw_fstring:\n        for middle in middles:\n            if unescaped_new_quote.search(middle.value):\n                # There's at least one unescaped new_quote in this raw string\n                # so converting is impossible\n                return middles, quote\n\n        # Do not introduce or remove backslashes in raw strings, just use double quote\n        return middles, '\"'\n\n    new_segments = []\n    for middle in middles:\n        segment = middle.value\n        # remove unnecessary escapes\n        new_segment = sub_twice(escaped_new_quote, rf\"\\1\\2{new_quote}\", segment)\n        if segment != new_segment:\n            # Consider the string without unnecessary escapes as the original\n            middle.value = new_segment\n\n        new_segment = sub_twice(escaped_orig_quote, rf\"\\1\\2{quote}\", new_segment)\n        new_segment = sub_twice(unescaped_new_quote, rf\"\\1\\\\{new_quote}\", new_segment)\n        new_segments.append(new_segment)\n\n    if new_quote == '\"\"\"' and new_segments[-1].endswith('\"'):\n        # edge case:\n        new_segments[-1] = new_segments[-1][:-1] + '\\\\\"'\n\n    for middle, new_segment in zip(middles, new_segments):\n        orig_escape_count = middle.value.count(\"\\\\\")\n        new_escape_count = new_segment.count(\"\\\\\")\n\n    if new_escape_count > orig_escape_count:\n        return middles, quote  # Do not introduce more escaping\n\n    if new_escape_count == orig_escape_count and quote == '\"':\n        return middles, quote  # Prefer double quotes\n\n    for middle, new_segment in zip(middles, new_segments):\n        middle.value = new_segment\n\n    return middles, new_quote", "loc": 63}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "normalize_unicode_escape_sequences", "parameters": ["leaf"], "param_types": {"leaf": "Leaf"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_string_prefix", "groups['N'].upper", "groups['U'].lower", "groups['u'].lower", "groups['x'].lower", "len", "m.groupdict", "prefix.lower", "re.sub"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Replace hex codes in Unicode escape sequences with lowercase representation.", "source_code": "def normalize_unicode_escape_sequences(leaf: Leaf) -> None:\n    \"\"\"Replace hex codes in Unicode escape sequences with lowercase representation.\"\"\"\n    text = leaf.value\n    prefix = get_string_prefix(text)\n    if \"r\" in prefix.lower():\n        return\n\n    def replace(m: Match[str]) -> str:\n        groups = m.groupdict()\n        back_slashes = groups[\"backslashes\"]\n\n        if len(back_slashes) % 2 == 0:\n            return back_slashes + groups[\"body\"]\n\n        if groups[\"u\"]:\n            # \\u\n            return back_slashes + \"u\" + groups[\"u\"].lower()\n        elif groups[\"U\"]:\n            # \\U\n            return back_slashes + \"U\" + groups[\"U\"].lower()\n        elif groups[\"x\"]:\n            # \\x\n            return back_slashes + \"x\" + groups[\"x\"].lower()\n        else:\n            assert groups[\"N\"], f\"Unexpected match: {m}\"\n            # \\N{}\n            return back_slashes + \"N{\" + groups[\"N\"].upper() + \"}\"\n\n    leaf.value = re.sub(UNICODE_ESCAPE_RE, replace, text)", "loc": 29}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "char_width", "parameters": ["char"], "param_types": {"char": "str"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "lru_cache", "ord"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Return the width of a single character as it would be displayed in a terminal or editor (which respects Unicode East Asian Width). Full width characters are counted as 2, while half width characters are", "source_code": "def char_width(char: str) -> int:\n    \"\"\"Return the width of a single character as it would be displayed in a\n    terminal or editor (which respects Unicode East Asian Width).\n\n    Full width characters are counted as 2, while half width characters are\n    counted as 1.  Also control characters are counted as 0.\n    \"\"\"\n    table = WIDTH_TABLE\n    codepoint = ord(char)\n    highest = len(table) - 1\n    lowest = 0\n    idx = highest // 2\n    while True:\n        start_codepoint, end_codepoint, width = table[idx]\n        if codepoint < start_codepoint:\n            highest = idx - 1\n        elif codepoint > end_codepoint:\n            lowest = idx + 1\n        else:\n            return 0 if width < 0 else width\n        if highest < lowest:\n            break\n        idx = (highest + lowest) // 2\n    return 1", "loc": 24}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "str_width", "parameters": ["line_str"], "param_types": {"line_str": "str"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "line_str.isascii", "map", "sum"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the width of `line_str` as it would be displayed in a terminal or editor (which respects Unicode East Asian Width). You could utilize this function to determine, for example, if a string", "source_code": "def str_width(line_str: str) -> int:\n    \"\"\"Return the width of `line_str` as it would be displayed in a terminal\n    or editor (which respects Unicode East Asian Width).\n\n    You could utilize this function to determine, for example, if a string\n    is too wide to display in a terminal or editor.\n    \"\"\"\n    if line_str.isascii():\n        # Fast path for a line consisting of only ASCII characters\n        return len(line_str)\n    return sum(map(char_width, line_str))", "loc": 11}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "count_chars_in_width", "parameters": ["line_str", "max_width"], "param_types": {"line_str": "str", "max_width": "int"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["char_width", "enumerate", "len"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Count the number of characters in `line_str` that would fit in a terminal or editor of `max_width` (which respects Unicode East Asian Width).", "source_code": "def count_chars_in_width(line_str: str, max_width: int) -> int:\n    \"\"\"Count the number of characters in `line_str` that would fit in a\n    terminal or editor of `max_width` (which respects Unicode East Asian\n    Width).\n    \"\"\"\n    total_width = 0\n    for i, char in enumerate(line_str):\n        width = char_width(char)\n        if width + total_width > max_width:\n            return i\n        total_width += width\n    return len(line_str)", "loc": 12}
{"file": "black\\src\\black\\strings.py", "class_name": null, "function_name": "replace", "parameters": ["m"], "param_types": {"m": "Match[str]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["groups['N'].upper", "groups['U'].lower", "groups['u'].lower", "groups['x'].lower", "len", "m.groupdict"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def replace(m: Match[str]) -> str:\n    groups = m.groupdict()\n    back_slashes = groups[\"backslashes\"]\n\n    if len(back_slashes) % 2 == 0:\n        return back_slashes + groups[\"body\"]\n\n    if groups[\"u\"]:\n        # \\u\n        return back_slashes + \"u\" + groups[\"u\"].lower()\n    elif groups[\"U\"]:\n        # \\U\n        return back_slashes + \"U\" + groups[\"U\"].lower()\n    elif groups[\"x\"]:\n        # \\x\n        return back_slashes + \"x\" + groups[\"x\"].lower()\n    else:\n        assert groups[\"N\"], f\"Unexpected match: {m}\"\n        # \\N{}\n        return back_slashes + \"N{\" + groups[\"N\"].upper() + \"}\"", "loc": 20}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "TErr", "parameters": ["err_msg"], "param_types": {"err_msg": "str"}, "return_type": "Err[CannotTransform]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CannotTransform", "Err"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "(T)ransform Err Convenience function used when working with the TResult type.", "source_code": "def TErr(err_msg: str) -> Err[CannotTransform]:\n    \"\"\"(T)ransform Err\n\n    Convenience function used when working with the TResult type.\n    \"\"\"\n    cant_transform = CannotTransform(err_msg)\n    return Err(cant_transform)", "loc": 7}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "hug_power_op", "parameters": ["line", "features", "mode"], "param_types": {"line": "Line", "features": "Collection[Feature]", "mode": "Mode"}, "return_type": "Iterator[Line]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CannotTransform", "enumerate", "handle_is_simple_look_up_prev", "handle_is_simple_lookup_forward", "is_simple_lookup", "is_simple_operand", "leaf.clone", "len", "line.clone", "line.comments_after", "new_line.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "A transformer which normalizes spacing around power operators.", "source_code": "def hug_power_op(\n    line: Line, features: Collection[Feature], mode: Mode\n) -> Iterator[Line]:\n    \"\"\"A transformer which normalizes spacing around power operators.\"\"\"\n\n    # Performance optimization to avoid unnecessary Leaf clones and other ops.\n    for leaf in line.leaves:\n        if leaf.type == token.DOUBLESTAR:\n            break\n    else:\n        raise CannotTransform(\"No doublestar token was found in the line.\")\n\n    def is_simple_lookup(index: int, kind: Literal[1, -1]) -> bool:\n        # Brackets and parentheses indicate calls, subscripts, etc. ...\n        # basically stuff that doesn't count as \"simple\". Only a NAME lookup\n        # or dotted lookup (eg. NAME.NAME) is OK.\n        if kind == -1:\n            return handle_is_simple_look_up_prev(line, index, {token.RPAR, token.RSQB})\n        else:\n            return handle_is_simple_lookup_forward(\n                line, index, {token.LPAR, token.LSQB}\n            )\n\n    def is_simple_operand(index: int, kind: Literal[1, -1]) -> bool:\n        # An operand is considered \"simple\" if's a NAME, a numeric CONSTANT, a simple\n        # lookup (see above), with or without a preceding unary operator.\n        start = line.leaves[index]\n        if start.type in {token.NAME, token.NUMBER}:\n            return is_simple_lookup(index, kind)\n\n        if start.type in {token.PLUS, token.MINUS, token.TILDE}:\n            if line.leaves[index + 1].type in {token.NAME, token.NUMBER}:\n                # kind is always one as bases with a preceding unary op will be checked\n                # for simplicity starting from the next token (so it'll hit the check\n                # above).\n                return is_simple_lookup(index + 1, kind=1)\n\n        return False\n\n    new_line = line.clone()\n    should_hug = False\n    for idx, leaf in enumerate(line.leaves):\n        new_leaf = leaf.clone()\n        if should_hug:\n            new_leaf.prefix = \"\"\n            should_hug = False\n\n        should_hug = (\n            (0 < idx < len(line.leaves) - 1)\n            and leaf.type == token.DOUBLESTAR\n            and is_simple_operand(idx - 1, kind=-1)\n            and line.leaves[idx - 1].value != \"lambda\"\n            and is_simple_operand(idx + 1, kind=1)\n        )\n        if should_hug:\n            new_leaf.prefix = \"\"\n\n        # We have to be careful to make a new line properly:\n        # - bracket related metadata must be maintained (handled by Line.append)\n        # - comments need to copied over, updating the leaf IDs they're attached to\n        new_line.append(new_leaf, preformatted=True)\n        for comment_leaf in line.comments_after(leaf):\n            new_line.append(comment_leaf, preformatted=True)\n\n    yield new_line", "loc": 65}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "handle_is_simple_look_up_prev", "parameters": ["line", "index", "disallowed"], "param_types": {"line": "Line", "index": "int", "disallowed": "set[int]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["chain.append", "is_expression_chained", "len"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Handling the determination of is_simple_lookup for the lines prior to the doublestar token. This is required because of the need to isolate the chained expression to determine the bracket or parenthesis belong to the single expression.", "source_code": "def handle_is_simple_look_up_prev(line: Line, index: int, disallowed: set[int]) -> bool:\n    \"\"\"\n    Handling the determination of is_simple_lookup for the lines prior to the doublestar\n    token. This is required because of the need to isolate the chained expression\n    to determine the bracket or parenthesis belong to the single expression.\n    \"\"\"\n    contains_disallowed = False\n    chain = []\n\n    while 0 <= index < len(line.leaves):\n        current = line.leaves[index]\n        chain.append(current)\n        if not contains_disallowed and current.type in disallowed:\n            contains_disallowed = True\n        if not is_expression_chained(chain):\n            return not contains_disallowed\n\n        index -= 1\n\n    return True", "loc": 20}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "handle_is_simple_lookup_forward", "parameters": ["line", "index", "disallowed"], "param_types": {"line": "Line", "index": "int", "disallowed": "set[int]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Handling decision is_simple_lookup for the lines behind the doublestar token. This function is simplified to keep consistent with the prior logic and the forward case are more straightforward and do not need to care about chained expressions.", "source_code": "def handle_is_simple_lookup_forward(\n    line: Line, index: int, disallowed: set[int]\n) -> bool:\n    \"\"\"\n    Handling decision is_simple_lookup for the lines behind the doublestar token.\n    This function is simplified to keep consistent with the prior logic and the forward\n    case are more straightforward and do not need to care about chained expressions.\n    \"\"\"\n    while 0 <= index < len(line.leaves):\n        current = line.leaves[index]\n        if current.type in disallowed:\n            return False\n        if current.type not in {token.NAME, token.DOT} or (\n            current.type == token.NAME and current.value == \"for\"\n        ):\n            # If the current token isn't disallowed, we'll assume this is simple as\n            # only the disallowed tokens are semantically attached to this lookup\n            # expression we're checking. Also, stop early if we hit the 'for' bit\n            # of a comprehension.\n            return True\n\n        index += 1\n\n    return True", "loc": 24}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "is_expression_chained", "parameters": ["chained_leaves"], "param_types": {"chained_leaves": "list[Leaf]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Function to determine if the variable is a chained call. (e.g., foo.lookup, foo().lookup, (foo.lookup())) will be recognized as chained call)", "source_code": "def is_expression_chained(chained_leaves: list[Leaf]) -> bool:\n    \"\"\"\n    Function to determine if the variable is a chained call.\n    (e.g., foo.lookup, foo().lookup, (foo.lookup())) will be recognized as chained call)\n    \"\"\"\n    if len(chained_leaves) < 2:\n        return True\n\n    current_leaf = chained_leaves[-1]\n    past_leaf = chained_leaves[-2]\n\n    if past_leaf.type == token.NAME:\n        return current_leaf.type in {token.DOT}\n    elif past_leaf.type in {token.RPAR, token.RSQB}:\n        return current_leaf.type in {token.RSQB, token.RPAR}\n    elif past_leaf.type in {token.LPAR, token.LSQB}:\n        return current_leaf.type in {token.NAME, token.LPAR, token.LSQB}\n    else:\n        return False", "loc": 19}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "iter_fexpr_spans", "parameters": ["s"], "param_types": {"s": "str"}, "return_type": "Iterator[tuple[int, int]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "stack.append", "stack.pop"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Yields spans corresponding to expressions in a given f-string. Spans are half-open ranges (left inclusive, right exclusive). Assumes the input string is a valid f-string, but will not crash if the input", "source_code": "def iter_fexpr_spans(s: str) -> Iterator[tuple[int, int]]:\n    \"\"\"\n    Yields spans corresponding to expressions in a given f-string.\n    Spans are half-open ranges (left inclusive, right exclusive).\n    Assumes the input string is a valid f-string, but will not crash if the input\n    string is invalid.\n    \"\"\"\n    stack: list[int] = []  # our curly paren stack\n    i = 0\n    while i < len(s):\n        if s[i] == \"{\":\n            # if we're in a string part of the f-string, ignore escaped curly braces\n            if not stack and i + 1 < len(s) and s[i + 1] == \"{\":\n                i += 2\n                continue\n            stack.append(i)\n            i += 1\n            continue\n\n        if s[i] == \"}\":\n            if not stack:\n                i += 1\n                continue\n            j = stack.pop()\n            # we've made it back out of the expression! yield the span\n            if not stack:\n                yield (j, i + 1)\n            i += 1\n            continue\n\n        # if we're in an expression part of the f-string, fast-forward through strings\n        # note that backslashes are not legal in the expression portion of f-strings\n        if stack:\n            delim = None\n            if s[i : i + 3] in (\"'''\", '\"\"\"'):\n                delim = s[i : i + 3]\n            elif s[i] in (\"'\", '\"'):\n                delim = s[i]\n            if delim:\n                i += len(delim)\n                while i < len(s) and s[i : i + len(delim)] != delim:\n                    i += 1\n                i += len(delim)\n                continue\n        i += 1", "loc": 45}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "insert_str_child_factory", "parameters": ["string_leaf"], "param_types": {"string_leaf": "Leaf"}, "return_type": "Callable[[LN], None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["string_leaf.remove", "string_parent.insert_child"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Factory for a convenience function that is used to orphan @string_leaf and then insert multiple new leaves into the same part of the node structure that @string_leaf had originally occupied.", "source_code": "def insert_str_child_factory(string_leaf: Leaf) -> Callable[[LN], None]:\n    \"\"\"\n    Factory for a convenience function that is used to orphan @string_leaf\n    and then insert multiple new leaves into the same part of the node\n    structure that @string_leaf had originally occupied.\n\n    Examples:\n        Let `string_leaf = Leaf(token.STRING, '\"foo\"')` and `N =\n        string_leaf.parent`. Assume the node `N` has the following\n        original structure:\n\n        Node(\n            expr_stmt, [\n                Leaf(NAME, 'x'),\n                Leaf(EQUAL, '='),\n                Leaf(STRING, '\"foo\"'),\n            ]\n        )\n\n        We then run the code snippet shown below.\n        ```\n        insert_str_child = insert_str_child_factory(string_leaf)\n\n        lpar = Leaf(token.LPAR, '(')\n        insert_str_child(lpar)\n\n        bar = Leaf(token.STRING, '\"bar\"')\n        insert_str_child(bar)\n\n        rpar = Leaf(token.RPAR, ')')\n        insert_str_child(rpar)\n        ```\n\n        After which point, it follows that `string_leaf.parent is None` and\n        the node `N` now has the following structure:\n\n        Node(\n            expr_stmt, [\n                Leaf(NAME, 'x'),\n                Leaf(EQUAL, '='),\n                Leaf(LPAR, '('),\n                Leaf(STRING, '\"bar\"'),\n                Leaf(RPAR, ')'),\n            ]\n        )\n    \"\"\"\n    string_parent = string_leaf.parent\n    string_child_idx = string_leaf.remove()\n\n    def insert_str_child(child: LN) -> None:\n        nonlocal string_child_idx\n\n        assert string_parent is not None\n        assert string_child_idx is not None\n\n        string_parent.insert_child(string_child_idx, child)\n        string_child_idx += 1\n\n    return insert_str_child", "loc": 59}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "is_simple_lookup", "parameters": ["index", "kind"], "param_types": {"index": "int", "kind": "Literal[1, -1]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["handle_is_simple_look_up_prev", "handle_is_simple_lookup_forward"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_simple_lookup(index: int, kind: Literal[1, -1]) -> bool:\n    # Brackets and parentheses indicate calls, subscripts, etc. ...\n    # basically stuff that doesn't count as \"simple\". Only a NAME lookup\n    # or dotted lookup (eg. NAME.NAME) is OK.\n    if kind == -1:\n        return handle_is_simple_look_up_prev(line, index, {token.RPAR, token.RSQB})\n    else:\n        return handle_is_simple_lookup_forward(\n            line, index, {token.LPAR, token.LSQB}\n        )", "loc": 10}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "is_simple_operand", "parameters": ["index", "kind"], "param_types": {"index": "int", "kind": "Literal[1, -1]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_simple_lookup"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_simple_operand(index: int, kind: Literal[1, -1]) -> bool:\n    # An operand is considered \"simple\" if's a NAME, a numeric CONSTANT, a simple\n    # lookup (see above), with or without a preceding unary operator.\n    start = line.leaves[index]\n    if start.type in {token.NAME, token.NUMBER}:\n        return is_simple_lookup(index, kind)\n\n    if start.type in {token.PLUS, token.MINUS, token.TILDE}:\n        if line.leaves[index + 1].type in {token.NAME, token.NUMBER}:\n            # kind is always one as bases with a preceding unary op will be checked\n            # for simplicity starting from the next token (so it'll hit the check\n            # above).\n            return is_simple_lookup(index + 1, kind=1)\n\n    return False", "loc": 15}
{"file": "black\\src\\black\\trans.py", "class_name": "CustomSplitMapMixin", "function_name": "add_custom_splits", "parameters": ["self", "string", "custom_splits"], "param_types": {"string": "str", "custom_splits": "Iterable[CustomSplit]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_key", "tuple"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Custom Split Map Setter Method Side Effects: Adds a mapping from @string to the custom splits @custom_splits.", "source_code": "def add_custom_splits(\n    self, string: str, custom_splits: Iterable[CustomSplit]\n) -> None:\n    \"\"\"Custom Split Map Setter Method\n\n    Side Effects:\n        Adds a mapping from @string to the custom splits @custom_splits.\n    \"\"\"\n    key = self._get_key(string)\n    self._CUSTOM_SPLIT_MAP[key] = tuple(custom_splits)", "loc": 10}
{"file": "black\\src\\black\\trans.py", "class_name": "CustomSplitMapMixin", "function_name": "pop_custom_splits", "parameters": ["self", "string"], "param_types": {"string": "str"}, "return_type": "list[CustomSplit]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["list", "self._get_key"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Custom Split Map Getter Method", "source_code": "def pop_custom_splits(self, string: str) -> list[CustomSplit]:\n    \"\"\"Custom Split Map Getter Method\n\n    Returns:\n        * A list of the custom splits that are mapped to @string, if any\n          exist.\n          OR\n        * [], otherwise.\n\n    Side Effects:\n        Deletes the mapping between @string and its associated custom\n        splits (which are returned to the caller).\n    \"\"\"\n    key = self._get_key(string)\n\n    custom_splits = self._CUSTOM_SPLIT_MAP[key]\n    del self._CUSTOM_SPLIT_MAP[key]\n\n    return list(custom_splits)", "loc": 19}
{"file": "black\\src\\black\\trans.py", "class_name": "StringMerger", "function_name": "do_match", "parameters": ["self", "line"], "param_types": {"line": "Line"}, "return_type": "TMatchResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Ok", "TErr", "is_part_of_annotation", "is_valid_index", "is_valid_index_factory", "line.comments_after", "string_indices.append"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def do_match(self, line: Line) -> TMatchResult:\n    LL = line.leaves\n\n    is_valid_index = is_valid_index_factory(LL)\n\n    string_indices = []\n    idx = 0\n    while is_valid_index(idx):\n        leaf = LL[idx]\n        if (\n            leaf.type == token.STRING\n            and is_valid_index(idx + 1)\n            and LL[idx + 1].type == token.STRING\n        ):\n            # Let's check if the string group contains an inline comment\n            # If we have a comment inline, we don't merge the strings\n            contains_comment = False\n            i = idx\n            while is_valid_index(i):\n                if LL[i].type != token.STRING:\n                    break\n                if line.comments_after(LL[i]):\n                    contains_comment = True\n                    break\n                i += 1\n\n            if not contains_comment and not is_part_of_annotation(leaf):\n                string_indices.append(idx)\n\n            # Advance to the next non-STRING leaf.\n            idx += 2\n            while is_valid_index(idx) and LL[idx].type == token.STRING:\n                idx += 1\n\n        elif leaf.type == token.STRING and \"\\\\\\n\" in leaf.value:\n            string_indices.append(idx)\n            # Advance to the next non-STRING leaf.\n            idx += 1\n            while is_valid_index(idx) and LL[idx].type == token.STRING:\n                idx += 1\n\n        else:\n            idx += 1\n\n    if string_indices:\n        return Ok(string_indices)\n    else:\n        return TErr(\"This line has no strings that need merging.\")", "loc": 48}
{"file": "black\\src\\black\\trans.py", "class_name": "StringMerger", "function_name": "do_transform", "parameters": ["self", "line", "string_indices"], "param_types": {"line": "Line", "string_indices": "list[int]"}, "return_type": "Iterator[TResult[Line]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CannotTransform", "Err", "Ok", "isinstance", "msg_result.err", "msg_result.ok", "rblc_result.err", "rblc_result.ok", "self._merge_string_group", "self._remove_backslash_line_continuation_chars"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def do_transform(\n    self, line: Line, string_indices: list[int]\n) -> Iterator[TResult[Line]]:\n    new_line = line\n\n    rblc_result = self._remove_backslash_line_continuation_chars(\n        new_line, string_indices\n    )\n    if isinstance(rblc_result, Ok):\n        new_line = rblc_result.ok()\n\n    msg_result = self._merge_string_group(new_line, string_indices)\n    if isinstance(msg_result, Ok):\n        new_line = msg_result.ok()\n\n    if isinstance(rblc_result, Err) and isinstance(msg_result, Err):\n        msg_cant_transform = msg_result.err()\n        rblc_cant_transform = rblc_result.err()\n        cant_transform = CannotTransform(\n            \"StringMerger failed to merge any strings in this line.\"\n        )\n\n        # Chain the errors together using `__cause__`.\n        msg_cant_transform.__cause__ = rblc_cant_transform\n        cant_transform.__cause__ = msg_cant_transform\n\n        yield Err(cant_transform)\n    else:\n        yield Ok(new_line)", "loc": 29}
{"file": "black\\src\\black\\trans.py", "class_name": "StringParenStripper", "function_name": "do_transform", "parameters": ["self", "line", "string_indices"], "param_types": {"line": "Line", "string_indices": "list[int]"}, "return_type": "Iterator[TResult[Line]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CannotTransform", "Err", "Ok", "StringParser", "line.comments_after", "self._transform_to_new_line", "string_and_rpar_indices.extend", "string_parser.parse"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def do_transform(\n    self, line: Line, string_indices: list[int]\n) -> Iterator[TResult[Line]]:\n    LL = line.leaves\n\n    string_and_rpar_indices: list[int] = []\n    for string_idx in string_indices:\n        string_parser = StringParser()\n        rpar_idx = string_parser.parse(LL, string_idx)\n\n        should_transform = True\n        for leaf in (LL[string_idx - 1], LL[rpar_idx]):\n            if line.comments_after(leaf):\n                # Should not strip parentheses which have comments attached\n                # to them.\n                should_transform = False\n                break\n        if should_transform:\n            string_and_rpar_indices.extend((string_idx, rpar_idx))\n\n    if string_and_rpar_indices:\n        yield Ok(self._transform_to_new_line(line, string_and_rpar_indices))\n    else:\n        yield Err(\n            CannotTransform(\"All string groups have comments attached to them.\")\n        )", "loc": 26}
{"file": "black\\src\\black\\trans.py", "class_name": "BaseStringSplitter", "function_name": "do_match", "parameters": ["self", "line"], "param_types": {"line": "Line"}, "return_type": "TMatchResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "len", "match_result.ok", "self._validate", "self.do_splitter_match"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def do_match(self, line: Line) -> TMatchResult:\n    match_result = self.do_splitter_match(line)\n    if isinstance(match_result, Err):\n        return match_result\n\n    string_indices = match_result.ok()\n    assert len(string_indices) == 1, (\n        f\"{self.__class__.__name__} should only find one match at a time, found\"\n        f\" {len(string_indices)}\"\n    )\n    string_idx = string_indices[0]\n    vresult = self._validate(line, string_idx)\n    if isinstance(vresult, Err):\n        return vresult\n\n    return match_result", "loc": 16}
{"file": "black\\src\\black\\trans.py", "class_name": "StringSplitter", "function_name": "do_splitter_match", "parameters": ["self", "line"], "param_types": {"line": "Line"}, "return_type": "TMatchResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Ok", "StringParser", "TErr", "is_empty_lpar", "is_empty_rpar", "is_valid_index", "is_valid_index_factory", "self._prefer_paren_wrap_match", "str", "string_parser.parse"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def do_splitter_match(self, line: Line) -> TMatchResult:\n    LL = line.leaves\n\n    if self._prefer_paren_wrap_match(LL) is not None:\n        return TErr(\"Line needs to be wrapped in parens first.\")\n\n    is_valid_index = is_valid_index_factory(LL)\n\n    idx = 0\n\n    # The first two leaves MAY be the 'not in' keywords...\n    if (\n        is_valid_index(idx)\n        and is_valid_index(idx + 1)\n        and [LL[idx].type, LL[idx + 1].type] == [token.NAME, token.NAME]\n        and str(LL[idx]) + str(LL[idx + 1]) == \"not in\"\n    ):\n        idx += 2\n    # Else the first leaf MAY be a string operator symbol or the 'in' keyword...\n    elif is_valid_index(idx) and (\n        LL[idx].type in self.STRING_OPERATORS\n        or LL[idx].type == token.NAME\n        and str(LL[idx]) == \"in\"\n    ):\n        idx += 1\n\n    # The next/first leaf MAY be an empty LPAR...\n    if is_valid_index(idx) and is_empty_lpar(LL[idx]):\n        idx += 1\n\n    # The next/first leaf MUST be a string...\n    if not is_valid_index(idx) or LL[idx].type != token.STRING:\n        return TErr(\"Line does not start with a string.\")\n\n    string_idx = idx\n\n    # Skip the string trailer, if one exists.\n    string_parser = StringParser()\n    idx = string_parser.parse(LL, string_idx)\n\n    # That string MAY be followed by an empty RPAR...\n    if is_valid_index(idx) and is_empty_rpar(LL[idx]):\n        idx += 1\n\n    # That string / empty RPAR leaf MAY be followed by a comma...\n    if is_valid_index(idx) and LL[idx].type == token.COMMA:\n        idx += 1\n\n    # But no more leaves are allowed...\n    if is_valid_index(idx):\n        return TErr(\"This line does not end with a string.\")\n\n    return Ok([string_idx])", "loc": 53}
{"file": "black\\src\\black\\trans.py", "class_name": "StringParenWrapper", "function_name": "do_splitter_match", "parameters": ["self", "line"], "param_types": {"line": "Line"}, "return_type": "TMatchResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Ok", "TErr", "any", "self._assert_match", "self._assign_match", "self._dict_or_lambda_match", "self._else_match", "self._prefer_paren_wrap_match", "self._return_match", "self.has_custom_splits", "str_width"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def do_splitter_match(self, line: Line) -> TMatchResult:\n    LL = line.leaves\n\n    if line.leaves[-1].type in OPENING_BRACKETS:\n        return TErr(\n            \"Cannot wrap parens around a line that ends in an opening bracket.\"\n        )\n\n    string_idx = (\n        self._return_match(LL)\n        or self._else_match(LL)\n        or self._assert_match(LL)\n        or self._assign_match(LL)\n        or self._dict_or_lambda_match(LL)\n        or self._prefer_paren_wrap_match(LL)\n    )\n\n    if string_idx is not None:\n        string_value = line.leaves[string_idx].value\n        # If the string has neither spaces nor East Asian stops...\n        if not any(\n            char == \" \" or char in SPLIT_SAFE_CHARS for char in string_value\n        ):\n            # And will still violate the line length limit when split...\n            max_string_width = self.line_length - ((line.depth + 1) * 4)\n            if str_width(string_value) > max_string_width:\n                # And has no associated custom splits...\n                if not self.has_custom_splits(string_value):\n                    # Then we should NOT put this string on its own line.\n                    return TErr(\n                        \"We do not wrap long strings in parentheses when the\"\n                        \" resultant line would still be over the specified line\"\n                        \" length and can't be split further by StringSplitter.\"\n                    )\n        return Ok([string_idx])\n\n    return TErr(\"This line does not contain any non-atomic strings.\")", "loc": 37}
{"file": "black\\src\\black\\trans.py", "class_name": "StringParser", "function_name": "parse", "parameters": ["self", "leaves", "string_idx"], "param_types": {"leaves": "list[Leaf]", "string_idx": "int"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self._next_state"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "Pre-conditions: * @leaves[@string_idx].type == token.STRING", "source_code": "def parse(self, leaves: list[Leaf], string_idx: int) -> int:\n    \"\"\"\n    Pre-conditions:\n        * @leaves[@string_idx].type == token.STRING\n\n    Returns:\n        The index directly after the last leaf which is a part of the string\n        trailer, if a \"trailer\" exists.\n        OR\n        @string_idx + 1, if no string \"trailer\" exists.\n    \"\"\"\n    assert leaves[string_idx].type == token.STRING\n\n    idx = string_idx + 1\n    while idx < len(leaves) and self._next_state(leaves[idx]):\n        idx += 1\n    return idx", "loc": 17}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "make_naked", "parameters": ["string", "string_prefix"], "param_types": {"string": "str", "string_prefix": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_toggle_fexpr_quotes", "any", "assert_is_leaf_string", "iter_fexpr_spans", "len", "re.search", "re.sub"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Strip @string (i.e. make it a \"naked\" string) Pre-conditions: * assert_is_leaf_string(@string)", "source_code": "def make_naked(string: str, string_prefix: str) -> str:\n    \"\"\"Strip @string (i.e. make it a \"naked\" string)\n\n    Pre-conditions:\n        * assert_is_leaf_string(@string)\n\n    Returns:\n        A string that is identical to @string except that\n        @string_prefix has been stripped, the surrounding QUOTE\n        characters have been removed, and any remaining QUOTE\n        characters have been escaped.\n    \"\"\"\n    assert_is_leaf_string(string)\n    if \"f\" in string_prefix:\n        f_expressions = [\n            string[span[0] + 1 : span[1] - 1]  # +-1 to get rid of curly braces\n            for span in iter_fexpr_spans(string)\n        ]\n        debug_expressions_contain_visible_quotes = any(\n            re.search(r\".*[\\'\\\"].*(?<![!:=])={1}(?!=)(?![^\\s:])\", expression)\n            for expression in f_expressions\n        )\n        if not debug_expressions_contain_visible_quotes:\n            # We don't want to toggle visible quotes in debug f-strings, as\n            # that would modify the AST\n            string = _toggle_fexpr_quotes(string, QUOTE)\n            # After quotes toggling, quotes in expressions won't be escaped\n            # because quotes can't be reused in f-strings. So we can simply\n            # let the escaping logic below run without knowing f-string\n            # expressions.\n\n    RE_EVEN_BACKSLASHES = r\"(?:(?<!\\\\)(?:\\\\\\\\)*)\"\n    naked_string = string[len(string_prefix) + 1 : -1]\n    naked_string = re.sub(\n        \"(\" + RE_EVEN_BACKSLASHES + \")\" + QUOTE, r\"\\1\\\\\" + QUOTE, naked_string\n    )\n    return naked_string", "loc": 37}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "maybe_append_string_operators", "parameters": ["new_line"], "param_types": {"new_line": "Line"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "new_line.append", "replace_child"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Side Effects: If @line starts with a string operator and this is the first line we are constructing, this function appends the string", "source_code": "def maybe_append_string_operators(new_line: Line) -> None:\n    \"\"\"\n    Side Effects:\n        If @line starts with a string operator and this is the first\n        line we are constructing, this function appends the string\n        operator to @new_line and replaces the old string operator leaf\n        in the node structure. Otherwise this function does nothing.\n    \"\"\"\n    maybe_prefix_leaves = string_op_leaves if first_string_line else []\n    for i, prefix_leaf in enumerate(maybe_prefix_leaves):\n        replace_child(LL[i], prefix_leaf)\n        new_line.append(prefix_leaf)", "loc": 12}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "more_splits_should_be_made", "parameters": [], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "max_last_string_column", "str_width"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def more_splits_should_be_made() -> bool:\n    \"\"\"\n    Returns:\n        True iff `rest_value` (the remaining string value from the last\n        split), should be split again.\n    \"\"\"\n    if use_custom_breakpoints:\n        return len(custom_splits) > 1\n    else:\n        return str_width(rest_value) > max_last_string_column()", "loc": 10}
{"file": "black\\src\\black\\trans.py", "class_name": null, "function_name": "passes_all_checks", "parameters": ["i"], "param_types": {"i": "Index"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["breaks_unsplittable_expression", "is_valid_index", "len"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def passes_all_checks(i: Index) -> bool:\n    \"\"\"\n    Returns:\n        True iff ALL of the conditions listed in the 'Transformations'\n        section of this classes' docstring would be met by returning @i.\n    \"\"\"\n    is_space = string[i] == \" \"\n    is_split_safe = is_valid_index(i - 1) and string[i - 1] in SPLIT_SAFE_CHARS\n\n    is_not_escaped = True\n    j = i - 1\n    while is_valid_index(j) and string[j] == \"\\\\\":\n        is_not_escaped = not is_not_escaped\n        j -= 1\n\n    is_big_enough = (\n        len(string[i:]) >= self.MIN_SUBSTR_SIZE\n        and len(string[:i]) >= self.MIN_SUBSTR_SIZE\n    )\n    return (\n        (is_space or is_split_safe)\n        and is_not_escaped\n        and is_big_enough\n        and not breaks_unsplittable_expression(i)\n    )", "loc": 25}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "read_pyproject_toml", "parameters": ["ctx", "param", "value"], "param_types": {"ctx": "click.Context", "param": "click.Parameter", "value": "Optional[str]"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["click.BadOptionUsage", "click.FileError", "config.get", "config.items", "ctx.params.get", "default_map.update", "find_pyproject_toml", "isinstance", "list", "parse_pyproject_toml", "spellcheck_pyproject_toml_keys", "str"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Inject Black configuration from \"pyproject.toml\" into defaults in `ctx`.", "source_code": "def read_pyproject_toml(\n    ctx: click.Context, param: click.Parameter, value: Optional[str]\n) -> Optional[str]:\n    \"\"\"Inject Black configuration from \"pyproject.toml\" into defaults in `ctx`.\n\n    Returns the path to a successfully found and read configuration file, None\n    otherwise.\n    \"\"\"\n    if not value:\n        value = find_pyproject_toml(\n            ctx.params.get(\"src\", ()), ctx.params.get(\"stdin_filename\", None)\n        )\n        if value is None:\n            return None\n\n    try:\n        config = parse_pyproject_toml(value)\n    except (OSError, ValueError) as e:\n        raise click.FileError(\n            filename=value, hint=f\"Error reading configuration file: {e}\"\n        ) from None\n\n    if not config:\n        return None\n    else:\n        spellcheck_pyproject_toml_keys(ctx, list(config), value)\n        # Sanitize the values to be Click friendly. For more information please see:\n        # https://github.com/psf/black/issues/1458\n        # https://github.com/pallets/click/issues/1567\n        config = {\n            k: str(v) if not isinstance(v, (list, dict)) else v\n            for k, v in config.items()\n        }\n\n    target_version = config.get(\"target_version\")\n    if target_version is not None and not isinstance(target_version, list):\n        raise click.BadOptionUsage(\n            \"target-version\", \"Config key target-version must be a list\"\n        )\n\n    exclude = config.get(\"exclude\")\n    if exclude is not None and not isinstance(exclude, str):\n        raise click.BadOptionUsage(\"exclude\", \"Config key exclude must be a string\")\n\n    extend_exclude = config.get(\"extend_exclude\")\n    if extend_exclude is not None and not isinstance(extend_exclude, str):\n        raise click.BadOptionUsage(\n            \"extend-exclude\", \"Config key extend-exclude must be a string\"\n        )\n\n    line_ranges = config.get(\"line_ranges\")\n    if line_ranges is not None:\n        raise click.BadOptionUsage(\n            \"line-ranges\", \"Cannot use line-ranges in the pyproject.toml file.\"\n        )\n\n    default_map: dict[str, Any] = {}\n    if ctx.default_map:\n        default_map.update(ctx.default_map)\n    default_map.update(config)\n\n    ctx.default_map = default_map\n    return value", "loc": 63}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "spellcheck_pyproject_toml_keys", "parameters": ["ctx", "config_keys", "config_file_path"], "param_types": {"ctx": "click.Context", "config_keys": "list[str]", "config_file_path": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "map", "out"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def spellcheck_pyproject_toml_keys(\n    ctx: click.Context, config_keys: list[str], config_file_path: str\n) -> None:\n    invalid_keys: list[str] = []\n    available_config_options = {param.name for param in ctx.command.params}\n    invalid_keys = [key for key in config_keys if key not in available_config_options]\n    if invalid_keys:\n        keys_str = \", \".join(map(repr, invalid_keys))\n        out(\n            f\"Invalid config keys detected: {keys_str} (in {config_file_path})\",\n            fg=\"red\",\n        )", "loc": 12}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "re_compile_maybe_verbose", "parameters": ["regex"], "param_types": {"regex": "str"}, "return_type": "Pattern[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["re.compile"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Compile a regular expression string in `regex`. If it contains newlines, use verbose mode.", "source_code": "def re_compile_maybe_verbose(regex: str) -> Pattern[str]:\n    \"\"\"Compile a regular expression string in `regex`.\n\n    If it contains newlines, use verbose mode.\n    \"\"\"\n    if \"\\n\" in regex:\n        regex = \"(?x)\" + regex\n    compiled: Pattern[str] = re.compile(regex)\n    return compiled", "loc": 9}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "validate_regex", "parameters": ["ctx", "param", "value"], "param_types": {"ctx": "click.Context", "param": "click.Parameter", "value": "Optional[str]"}, "return_type": "Optional[Pattern[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["click.BadParameter", "re_compile_maybe_verbose"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate_regex(\n    ctx: click.Context,\n    param: click.Parameter,\n    value: Optional[str],\n) -> Optional[Pattern[str]]:\n    try:\n        return re_compile_maybe_verbose(value) if value is not None else None\n    except re.error as e:\n        raise click.BadParameter(f\"Not a valid regular expression: {e}\") from None", "loc": 9}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "get_sources", "parameters": [], "param_types": {}, "return_type": "set[Path]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "best_effort_relative_path", "best_effort_relative_path(path, root).as_posix", "err", "gen_python_files", "get_gitignore", "jupyter_dependencies_are_installed", "out", "path.is_dir", "path.is_file", "path.iterdir", "path.resolve", "path.resolve().relative_to", "path_is_excluded", "re_compile_maybe_verbose", "report.path_ignored", "resolves_outside_root_or_cannot_stat", "root.is_absolute", "set", "sources.add", "sources.update"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Compute the set of files to be formatted.", "source_code": "def get_sources(\n    *,\n    root: Path,\n    src: tuple[str, ...],\n    quiet: bool,\n    verbose: bool,\n    include: Pattern[str],\n    exclude: Optional[Pattern[str]],\n    extend_exclude: Optional[Pattern[str]],\n    force_exclude: Optional[Pattern[str]],\n    report: \"Report\",\n    stdin_filename: Optional[str],\n) -> set[Path]:\n    \"\"\"Compute the set of files to be formatted.\"\"\"\n    sources: set[Path] = set()\n\n    assert root.is_absolute(), f\"INTERNAL ERROR: `root` must be absolute but is {root}\"\n    using_default_exclude = exclude is None\n    exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES) if exclude is None else exclude\n    gitignore: Optional[dict[Path, PathSpec]] = None\n    root_gitignore = get_gitignore(root)\n\n    for s in src:\n        if s == \"-\" and stdin_filename:\n            path = Path(stdin_filename)\n            if path_is_excluded(stdin_filename, force_exclude):\n                report.path_ignored(\n                    path,\n                    \"--stdin-filename matches the --force-exclude regular expression\",\n                )\n                continue\n            is_stdin = True\n        else:\n            path = Path(s)\n            is_stdin = False\n\n        # Compare the logic here to the logic in `gen_python_files`.\n        if is_stdin or path.is_file():\n            if resolves_outside_root_or_cannot_stat(path, root, report):\n                if verbose:\n                    out(f'Skipping invalid source: \"{path}\"', fg=\"red\")\n                continue\n\n            root_relative_path = best_effort_relative_path(path, root).as_posix()\n            root_relative_path = \"/\" + root_relative_path\n\n            # Hard-exclude any files that matches the `--force-exclude` regex.\n            if path_is_excluded(root_relative_path, force_exclude):\n                report.path_ignored(\n                    path, \"matches the --force-exclude regular expression\"\n                )\n                continue\n\n            if is_stdin:\n                path = Path(f\"{STDIN_PLACEHOLDER}{path}\")\n\n            if path.suffix == \".ipynb\" and not jupyter_dependencies_are_installed(\n                warn=verbose or not quiet\n            ):\n                continue\n\n            if verbose:\n                out(f'Found input source: \"{path}\"', fg=\"blue\")\n            sources.add(path)\n        elif path.is_dir():\n            path = root / (path.resolve().relative_to(root))\n            if verbose:\n                out(f'Found input source directory: \"{path}\"', fg=\"blue\")\n\n            if using_default_exclude:\n                gitignore = {\n                    root: root_gitignore,\n                    path: get_gitignore(path),\n                }\n            sources.update(\n                gen_python_files(\n                    path.iterdir(),\n                    root,\n                    include,\n                    exclude,\n                    extend_exclude,\n                    force_exclude,\n                    report,\n                    gitignore,\n                    verbose=verbose,\n                    quiet=quiet,\n                )\n            )\n        elif s == \"-\":\n            if verbose:\n                out(\"Found input source stdin\", fg=\"blue\")\n            sources.add(path)\n        else:\n            err(f\"invalid path: {s}\")\n\n    return sources", "loc": 96}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "path_empty", "parameters": ["src", "msg", "quiet", "verbose", "ctx"], "param_types": {"src": "Sized", "msg": "str", "quiet": "bool", "verbose": "bool", "ctx": "click.Context"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ctx.exit", "out"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Exit if there is no `src` provided for formatting", "source_code": "def path_empty(\n    src: Sized, msg: str, quiet: bool, verbose: bool, ctx: click.Context\n) -> None:\n    \"\"\"\n    Exit if there is no `src` provided for formatting\n    \"\"\"\n    if not src:\n        if verbose or not quiet:\n            out(msg)\n        ctx.exit(0)", "loc": 10}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "reformat_code", "parameters": ["content", "fast", "write_back", "mode", "report"], "param_types": {"content": "str", "fast": "bool", "write_back": "WriteBack", "mode": "Mode", "report": "Report"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "format_stdin_to_stdout", "report.done", "report.failed", "str", "traceback.print_exc"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Reformat and print out `content` without spawning child processes. Similar to `reformat_one`, but for string content. `fast`, `write_back`, and `mode` options are passed to", "source_code": "def reformat_code(\n    content: str,\n    fast: bool,\n    write_back: WriteBack,\n    mode: Mode,\n    report: Report,\n    *,\n    lines: Collection[tuple[int, int]] = (),\n) -> None:\n    \"\"\"\n    Reformat and print out `content` without spawning child processes.\n    Similar to `reformat_one`, but for string content.\n\n    `fast`, `write_back`, and `mode` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`.\n    \"\"\"\n    path = Path(\"<string>\")\n    try:\n        changed = Changed.NO\n        if format_stdin_to_stdout(\n            content=content, fast=fast, write_back=write_back, mode=mode, lines=lines\n        ):\n            changed = Changed.YES\n        report.done(path, changed)\n    except Exception as exc:\n        if report.verbose:\n            traceback.print_exc()\n        report.failed(path, str(exc))", "loc": 28}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "reformat_one", "parameters": ["src", "fast", "write_back", "mode", "report"], "param_types": {"src": "Path", "fast": "bool", "write_back": "WriteBack", "mode": "Mode", "report": "'Report'"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Cache.read", "Path", "cache.is_changed", "cache.write", "format_file_in_place", "format_stdin_to_stdout", "len", "mypyc_attr", "replace", "report.done", "report.failed", "str", "str(src).startswith", "traceback.print_exc"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Reformat a single file under `src` without spawning child processes. `fast`, `write_back`, and `mode` options are passed to :func:`format_file_in_place` or :func:`format_stdin_to_stdout`.", "source_code": "def reformat_one(\n    src: Path,\n    fast: bool,\n    write_back: WriteBack,\n    mode: Mode,\n    report: \"Report\",\n    *,\n    lines: Collection[tuple[int, int]] = (),\n) -> None:\n    \"\"\"Reformat a single file under `src` without spawning child processes.\n\n    `fast`, `write_back`, and `mode` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`.\n    \"\"\"\n    try:\n        changed = Changed.NO\n\n        if str(src) == \"-\":\n            is_stdin = True\n        elif str(src).startswith(STDIN_PLACEHOLDER):\n            is_stdin = True\n            # Use the original name again in case we want to print something\n            # to the user\n            src = Path(str(src)[len(STDIN_PLACEHOLDER) :])\n        else:\n            is_stdin = False\n\n        if is_stdin:\n            if src.suffix == \".pyi\":\n                mode = replace(mode, is_pyi=True)\n            elif src.suffix == \".ipynb\":\n                mode = replace(mode, is_ipynb=True)\n            if format_stdin_to_stdout(\n                fast=fast, write_back=write_back, mode=mode, lines=lines\n            ):\n                changed = Changed.YES\n        else:\n            cache = Cache.read(mode)\n            if write_back not in (WriteBack.DIFF, WriteBack.COLOR_DIFF):\n                if not cache.is_changed(src):\n                    changed = Changed.CACHED\n            if changed is not Changed.CACHED and format_file_in_place(\n                src, fast=fast, write_back=write_back, mode=mode, lines=lines\n            ):\n                changed = Changed.YES\n            if (write_back is WriteBack.YES and changed is not Changed.CACHED) or (\n                write_back is WriteBack.CHECK and changed is Changed.NO\n            ):\n                cache.write([src])\n        report.done(src, changed)\n    except Exception as exc:\n        if report.verbose:\n            traceback.print_exc()\n        report.failed(src, str(exc))", "loc": 54}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "format_stdin_to_stdout", "parameters": ["fast"], "param_types": {"fast": "bool"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["color_diff", "datetime.now", "decode_bytes", "diff", "f.detach", "f.write", "format_file_contents", "io.TextIOWrapper", "sys.stdin.buffer.read", "wrap_stream_for_windows"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Format file on stdin. Return True if changed. If content is None, it's read from sys.stdin. If `write_back` is YES, write reformatted code back to stdout. If it is DIFF,", "source_code": "def format_stdin_to_stdout(\n    fast: bool,\n    *,\n    content: Optional[str] = None,\n    write_back: WriteBack = WriteBack.NO,\n    mode: Mode,\n    lines: Collection[tuple[int, int]] = (),\n) -> bool:\n    \"\"\"Format file on stdin. Return True if changed.\n\n    If content is None, it's read from sys.stdin.\n\n    If `write_back` is YES, write reformatted code back to stdout. If it is DIFF,\n    write a diff to stdout. The `mode` argument is passed to\n    :func:`format_file_contents`.\n    \"\"\"\n    then = datetime.now(timezone.utc)\n\n    if content is None:\n        src, encoding, newline = decode_bytes(sys.stdin.buffer.read(), mode)\n    elif Preview.normalize_cr_newlines in mode:\n        src, encoding, newline = content, \"utf-8\", \"\\n\"\n    else:\n        src, encoding, newline = content, \"utf-8\", \"\"\n\n    dst = src\n    try:\n        dst = format_file_contents(src, fast=fast, mode=mode, lines=lines)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        f = io.TextIOWrapper(\n            sys.stdout.buffer, encoding=encoding, newline=newline, write_through=True\n        )\n        if write_back == WriteBack.YES:\n            # Make sure there's a newline after the content\n            if Preview.normalize_cr_newlines in mode:\n                if dst and dst[-1] != \"\\n\" and dst[-1] != \"\\r\":\n                    dst += newline\n            else:\n                if dst and dst[-1] != \"\\n\":\n                    dst += \"\\n\"\n            f.write(dst)\n        elif write_back in (WriteBack.DIFF, WriteBack.COLOR_DIFF):\n            now = datetime.now(timezone.utc)\n            src_name = f\"STDIN\\t{then}\"\n            dst_name = f\"STDOUT\\t{now}\"\n            d = diff(src, dst, src_name, dst_name)\n            if write_back == WriteBack.COLOR_DIFF:\n                d = color_diff(d)\n                f = wrap_stream_for_windows(f)\n            f.write(d)\n        f.detach()", "loc": 56}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "check_stability_and_equivalence", "parameters": ["src_contents", "dst_contents"], "param_types": {"src_contents": "str", "dst_contents": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["assert_equivalent", "assert_stable"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Perform stability and equivalence checks. Raise AssertionError if source and destination contents are not equivalent, or if a second pass of the formatter would format the", "source_code": "def check_stability_and_equivalence(\n    src_contents: str,\n    dst_contents: str,\n    *,\n    mode: Mode,\n    lines: Collection[tuple[int, int]] = (),\n) -> None:\n    \"\"\"Perform stability and equivalence checks.\n\n    Raise AssertionError if source and destination contents are not\n    equivalent, or if a second pass of the formatter would format the\n    content differently.\n    \"\"\"\n    assert_equivalent(src_contents, dst_contents)\n    assert_stable(src_contents, dst_contents, mode=mode, lines=lines)", "loc": 15}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "format_file_contents", "parameters": ["src_contents"], "param_types": {"src_contents": "str"}, "return_type": "FileContent", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["check_stability_and_equivalence", "format_ipynb_string", "format_str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Reformat contents of a file and return new contents. If `fast` is False, additionally confirm that the reformatted code is valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.", "source_code": "def format_file_contents(\n    src_contents: str,\n    *,\n    fast: bool,\n    mode: Mode,\n    lines: Collection[tuple[int, int]] = (),\n) -> FileContent:\n    \"\"\"Reformat contents of a file and return new contents.\n\n    If `fast` is False, additionally confirm that the reformatted code is\n    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.\n    `mode` is passed to :func:`format_str`.\n    \"\"\"\n    if mode.is_ipynb:\n        dst_contents = format_ipynb_string(src_contents, fast=fast, mode=mode)\n    else:\n        dst_contents = format_str(src_contents, mode=mode, lines=lines)\n    if src_contents == dst_contents:\n        raise NothingChanged\n\n    if not fast and not mode.is_ipynb:\n        # Jupyter notebooks will already have been checked above.\n        check_stability_and_equivalence(\n            src_contents, dst_contents, mode=mode, lines=lines\n        )\n    return dst_contents", "loc": 26}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "format_cell", "parameters": ["src"], "param_types": {"src": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["check_stability_and_equivalence", "dst.rstrip", "format_str", "mask_cell", "put_trailing_semicolon_back", "remove_trailing_semicolon", "unmask_cell", "validate_cell"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Format code in given cell of Jupyter notebook. General idea is: - if cell has trailing semicolon, remove it;", "source_code": "def format_cell(src: str, *, fast: bool, mode: Mode) -> str:\n    \"\"\"Format code in given cell of Jupyter notebook.\n\n    General idea is:\n\n      - if cell has trailing semicolon, remove it;\n      - if cell has IPython magics, mask them;\n      - format cell;\n      - reinstate IPython magics;\n      - reinstate trailing semicolon (if originally present);\n      - strip trailing newlines.\n\n    Cells with syntax errors will not be processed, as they\n    could potentially be automagics or multi-line magics, which\n    are currently not supported.\n    \"\"\"\n    validate_cell(src, mode)\n    src_without_trailing_semicolon, has_trailing_semicolon = remove_trailing_semicolon(\n        src\n    )\n    try:\n        masked_src, replacements = mask_cell(src_without_trailing_semicolon)\n    except SyntaxError:\n        raise NothingChanged from None\n    masked_dst = format_str(masked_src, mode=mode)\n    if not fast:\n        check_stability_and_equivalence(masked_src, masked_dst, mode=mode)\n    dst_without_trailing_semicolon = unmask_cell(masked_dst, replacements)\n    dst = put_trailing_semicolon_back(\n        dst_without_trailing_semicolon, has_trailing_semicolon\n    )\n    dst = dst.rstrip(\"\\n\")\n    if dst == src:\n        raise NothingChanged from None\n    return dst", "loc": 35}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "validate_metadata", "parameters": ["nb"], "param_types": {"nb": "MutableMapping[str, Any]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["nb.get", "nb.get('metadata', {}).get", "nb.get('metadata', {}).get('language_info', {}).get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "If notebook is marked as non-Python, don't format it. All notebook metadata fields are optional, see https://nbformat.readthedocs.io/en/latest/format_description.html. So", "source_code": "def validate_metadata(nb: MutableMapping[str, Any]) -> None:\n    \"\"\"If notebook is marked as non-Python, don't format it.\n\n    All notebook metadata fields are optional, see\n    https://nbformat.readthedocs.io/en/latest/format_description.html. So\n    if a notebook has empty metadata, we will try to parse it anyway.\n    \"\"\"\n    language = nb.get(\"metadata\", {}).get(\"language_info\", {}).get(\"name\", None)\n    if language is not None and language != \"python\":\n        raise NothingChanged from None", "loc": 10}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "format_ipynb_string", "parameters": ["src_contents"], "param_types": {"src_contents": "str"}, "return_type": "FileContent", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "cell.get", "dst.splitlines", "format_cell", "json.dumps", "json.loads", "validate_metadata"], "control_structures": ["For", "If", "Try"], "behavior_type": ["serialization"], "doc_summary": "Format Jupyter notebook. Operate cell-by-cell, only on code cells, only for Python notebooks. If the ``.ipynb`` originally had a trailing newline, it'll be preserved.", "source_code": "def format_ipynb_string(src_contents: str, *, fast: bool, mode: Mode) -> FileContent:\n    \"\"\"Format Jupyter notebook.\n\n    Operate cell-by-cell, only on code cells, only for Python notebooks.\n    If the ``.ipynb`` originally had a trailing newline, it'll be preserved.\n    \"\"\"\n    if not src_contents:\n        raise NothingChanged\n\n    trailing_newline = src_contents[-1] == \"\\n\"\n    modified = False\n    nb = json.loads(src_contents)\n    validate_metadata(nb)\n    for cell in nb[\"cells\"]:\n        if cell.get(\"cell_type\", None) == \"code\":\n            try:\n                src = \"\".join(cell[\"source\"])\n                dst = format_cell(src, fast=fast, mode=mode)\n            except NothingChanged:\n                pass\n            else:\n                cell[\"source\"] = dst.splitlines(keepends=True)\n                modified = True\n    if modified:\n        dst_contents = json.dumps(nb, indent=1, ensure_ascii=False)\n        if trailing_newline:\n            dst_contents = dst_contents + \"\\n\"\n        return dst_contents\n    else:\n        raise NothingChanged", "loc": 30}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "format_str", "parameters": ["src_contents"], "param_types": {"src_contents": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_format_str_once", "adjusted_lines", "sanitized_lines"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Reformat a string and return new contents. `mode` determines formatting options, such as how many characters per line are allowed.  Example:", "source_code": "def format_str(\n    src_contents: str, *, mode: Mode, lines: Collection[tuple[int, int]] = ()\n) -> str:\n    \"\"\"Reformat a string and return new contents.\n\n    `mode` determines formatting options, such as how many characters per line are\n    allowed.  Example:\n\n    >>> import black\n    >>> print(black.format_str(\"def f(arg:str='')->None:...\", mode=black.Mode()))\n    def f(arg: str = \"\") -> None:\n        ...\n\n    A more complex example:\n\n    >>> print(\n    ...   black.format_str(\n    ...     \"def f(arg:str='')->None: hey\",\n    ...     mode=black.Mode(\n    ...       target_versions={black.TargetVersion.PY36},\n    ...       line_length=10,\n    ...       string_normalization=False,\n    ...       is_pyi=False,\n    ...     ),\n    ...   ),\n    ... )\n    def f(\n        arg: str = '',\n    ) -> None:\n        hey\n\n    \"\"\"\n    if lines:\n        lines = sanitized_lines(lines, src_contents)\n        if not lines:\n            return src_contents  # Nothing to format\n    dst_contents = _format_str_once(src_contents, mode=mode, lines=lines)\n    # Forced second pass to work around optional trailing commas (becoming\n    # forced trailing commas on pass 2) interacting differently with optional\n    # parentheses.  Admittedly ugly.\n    if src_contents != dst_contents:\n        if lines:\n            lines = adjusted_lines(lines, src_contents, dst_contents)\n        return _format_str_once(dst_contents, mode=mode, lines=lines)\n    return dst_contents", "loc": 45}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "decode_bytes", "parameters": ["src", "mode"], "param_types": {"src": "bytes", "mode": "Mode"}, "return_type": "tuple[FileContent, Encoding, NewLine]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["io.BytesIO", "io.TextIOWrapper", "srcbuf.seek", "tiow.read", "tokenize.detect_encoding"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return a tuple of (decoded_contents, encoding, newline). `newline` is either CRLF or LF but `decoded_contents` is decoded with universal newlines (i.e. only contains LF).", "source_code": "def decode_bytes(src: bytes, mode: Mode) -> tuple[FileContent, Encoding, NewLine]:\n    \"\"\"Return a tuple of (decoded_contents, encoding, newline).\n\n    `newline` is either CRLF or LF but `decoded_contents` is decoded with\n    universal newlines (i.e. only contains LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    if not lines:\n        return \"\", encoding, \"\\n\"\n\n    if Preview.normalize_cr_newlines in mode:\n        if lines[0][-2:] == b\"\\r\\n\":\n            if b\"\\r\" in lines[0][:-2]:\n                newline = \"\\r\"\n            else:\n                newline = \"\\r\\n\"\n        elif lines[0][-1:] == b\"\\n\":\n            if b\"\\r\" in lines[0][:-1]:\n                newline = \"\\r\"\n            else:\n                newline = \"\\n\"\n        else:\n            if b\"\\r\" in lines[0]:\n                newline = \"\\r\"\n            else:\n                newline = \"\\n\"\n    else:\n        newline = \"\\r\\n\" if lines[0][-2:] == b\"\\r\\n\" else \"\\n\"\n\n    srcbuf.seek(0)\n    with io.TextIOWrapper(srcbuf, encoding) as tiow:\n        return tiow.read(), encoding, newline", "loc": 33}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "get_future_imports", "parameters": ["node"], "param_types": {"node": "Node"}, "return_type": "set[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AssertionError", "get_imports_from_children", "isinstance", "len", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return a set of __future__ imports in the file.", "source_code": "def get_future_imports(node: Node) -> set[str]:\n    \"\"\"Return a set of __future__ imports in the file.\"\"\"\n    imports: set[str] = set()\n\n    def get_imports_from_children(children: list[LN]) -> Generator[str, None, None]:\n        for child in children:\n            if isinstance(child, Leaf):\n                if child.type == token.NAME:\n                    yield child.value\n\n            elif child.type == syms.import_as_name:\n                orig_name = child.children[0]\n                assert isinstance(orig_name, Leaf), \"Invalid syntax parsing imports\"\n                assert orig_name.type == token.NAME, \"Invalid syntax parsing imports\"\n                yield orig_name.value\n\n            elif child.type == syms.import_as_names:\n                yield from get_imports_from_children(child.children)\n\n            else:\n                raise AssertionError(\"Invalid syntax parsing imports\")\n\n    for child in node.children:\n        if child.type != syms.simple_stmt:\n            break\n\n        first_child = child.children[0]\n        if isinstance(first_child, Leaf):\n            # Continue looking if we see a docstring; otherwise stop.\n            if (\n                len(child.children) == 2\n                and first_child.type == token.STRING\n                and child.children[1].type == token.NEWLINE\n            ):\n                continue\n\n            break\n\n        elif first_child.type == syms.import_from:\n            module_name = first_child.children[1]\n            if not isinstance(module_name, Leaf) or module_name.value != \"__future__\":\n                break\n\n            imports |= set(get_imports_from_children(first_child.children[3:]))\n        else:\n            break\n\n    return imports", "loc": 48}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "assert_equivalent", "parameters": ["src", "dst"], "param_types": {"src": "str", "dst": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "'\\n'.join", "ASTSafetyError", "_black_info", "diff", "dump_to_file", "parse_ast", "stringify_ast", "traceback.format_tb"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Raise AssertionError if `src` and `dst` aren't equivalent.", "source_code": "def assert_equivalent(src: str, dst: str) -> None:\n    \"\"\"Raise AssertionError if `src` and `dst` aren't equivalent.\"\"\"\n    try:\n        src_ast = parse_ast(src)\n    except Exception as exc:\n        raise ASTSafetyError(\n            \"cannot use --safe with this file; failed to parse source file AST: \"\n            f\"{exc}\\n\"\n            \"This could be caused by running Black with an older Python version \"\n            \"that does not support new syntax used in your source file.\"\n        ) from exc\n\n    try:\n        dst_ast = parse_ast(dst)\n    except Exception as exc:\n        log = dump_to_file(\"\".join(traceback.format_tb(exc.__traceback__)), dst)\n        raise ASTSafetyError(\n            f\"INTERNAL ERROR: {_black_info()} produced invalid code: {exc}. \"\n            \"Please report a bug on https://github.com/psf/black/issues.  \"\n            f\"This invalid output might be helpful: {log}\"\n        ) from None\n\n    src_ast_str = \"\\n\".join(stringify_ast(src_ast))\n    dst_ast_str = \"\\n\".join(stringify_ast(dst_ast))\n    if src_ast_str != dst_ast_str:\n        log = dump_to_file(diff(src_ast_str, dst_ast_str, \"src\", \"dst\"))\n        raise ASTSafetyError(\n            f\"INTERNAL ERROR: {_black_info()} produced code that is not equivalent to\"\n            \" the source.  Please report a bug on https://github.com/psf/black/issues.\"\n            f\"  This diff might be helpful: {log}\"\n        ) from None", "loc": 31}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "assert_stable", "parameters": ["src", "dst", "mode"], "param_types": {"src": "str", "dst": "str", "mode": "Mode"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AssertionError", "_black_info", "_format_str_once", "diff", "dump_to_file", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Raise AssertionError if `dst` reformats differently the second time.", "source_code": "def assert_stable(\n    src: str, dst: str, mode: Mode, *, lines: Collection[tuple[int, int]] = ()\n) -> None:\n    \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n    if lines:\n        # Formatting specified lines requires `adjusted_lines` to map original lines\n        # to the formatted lines before re-formatting the previously formatted result.\n        # Due to less-ideal diff algorithm, some edge cases produce incorrect new line\n        # ranges. Hence for now, we skip the stable check.\n        # See https://github.com/psf/black/issues/4033 for context.\n        return\n    # We shouldn't call format_str() here, because that formats the string\n    # twice and may hide a bug where we bounce back and forth between two\n    # versions.\n    newdst = _format_str_once(dst, mode=mode, lines=lines)\n    if dst != newdst:\n        log = dump_to_file(\n            str(mode),\n            diff(src, dst, \"source\", \"first pass\"),\n            diff(dst, newdst, \"first pass\", \"second pass\"),\n        )\n        raise AssertionError(\n            f\"INTERNAL ERROR: {_black_info()} produced different code on the second\"\n            \" pass of the formatter.  Please report a bug on\"\n            f\" https://github.com/psf/black/issues.  This diff might be helpful: {log}\"\n        ) from None", "loc": 26}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "patched_main", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["freeze_support", "getattr", "main"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def patched_main() -> None:\n    # PyInstaller patches multiprocessing to need freeze_support() even in non-Windows\n    # environments so just assume we always need to call it if frozen.\n    if getattr(sys, \"frozen\", False):\n        from multiprocessing import freeze_support\n\n        freeze_support()\n\n    main()", "loc": 9}
{"file": "black\\src\\black\\__init__.py", "class_name": "WriteBack", "function_name": "from_configuration", "parameters": ["cls"], "param_types": {}, "return_type": "'WriteBack'", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def from_configuration(\n    cls, *, check: bool, diff: bool, color: bool = False\n) -> \"WriteBack\":\n    if check and not diff:\n        return cls.CHECK\n\n    if diff and color:\n        return cls.COLOR_DIFF\n\n    return cls.DIFF if diff else cls.YES", "loc": 10}
{"file": "black\\src\\black\\__init__.py", "class_name": null, "function_name": "get_imports_from_children", "parameters": ["children"], "param_types": {"children": "list[LN]"}, "return_type": "Generator[str, None, None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AssertionError", "get_imports_from_children", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_imports_from_children(children: list[LN]) -> Generator[str, None, None]:\n    for child in children:\n        if isinstance(child, Leaf):\n            if child.type == token.NAME:\n                yield child.value\n\n        elif child.type == syms.import_as_name:\n            orig_name = child.children[0]\n            assert isinstance(orig_name, Leaf), \"Invalid syntax parsing imports\"\n            assert orig_name.type == token.NAME, \"Invalid syntax parsing imports\"\n            yield orig_name.value\n\n        elif child.type == syms.import_as_names:\n            yield from get_imports_from_children(child.children)\n\n        else:\n            raise AssertionError(\"Invalid syntax parsing imports\")", "loc": 17}
{"file": "black\\src\\blackd\\middlewares.py", "class_name": null, "function_name": "cors", "parameters": ["allow_headers"], "param_types": {"allow_headers": "Iterable[str]"}, "return_type": "Middleware", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "StreamResponse", "handler", "request.headers.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cors(allow_headers: Iterable[str]) -> Middleware:\n    @middleware\n    async def impl(request: Request, handler: Handler) -> StreamResponse:\n        is_options = request.method == \"OPTIONS\"\n        is_preflight = is_options and \"Access-Control-Request-Method\" in request.headers\n        if is_preflight:\n            resp = StreamResponse()\n        else:\n            resp = await handler(request)\n\n        origin = request.headers.get(\"Origin\")\n        if not origin:\n            return resp\n\n        resp.headers[\"Access-Control-Allow-Origin\"] = \"*\"\n        resp.headers[\"Access-Control-Expose-Headers\"] = \"*\"\n        if is_options:\n            resp.headers[\"Access-Control-Allow-Headers\"] = \", \".join(allow_headers)\n            resp.headers[\"Access-Control-Allow-Methods\"] = \", \".join(\n                (\"OPTIONS\", \"POST\")\n            )\n\n        return resp\n\n    return impl", "loc": 25}
{"file": "black\\src\\blackd\\__init__.py", "class_name": null, "function_name": "main", "parameters": ["bind_host", "bind_port"], "param_types": {"bind_host": "str", "bind_port": "int"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["black.out", "click.command", "click.option", "click.version_option", "logging.basicConfig", "make_app", "web.run_app"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main(bind_host: str, bind_port: int) -> None:\n    logging.basicConfig(level=logging.INFO)\n    app = make_app()\n    ver = black.__version__\n    black.out(f\"blackd version {ver} listening on {bind_host} port {bind_port}\")\n    web.run_app(app, host=bind_host, port=bind_port, handle_signals=True, print=None)", "loc": 6}
{"file": "black\\src\\blackd\\__init__.py", "class_name": null, "function_name": "make_app", "parameters": [], "param_types": {}, "return_type": "web.Application", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["app.add_routes", "cors", "executor", "partial", "web.Application", "web.post"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_app() -> web.Application:\n    app = web.Application(\n        middlewares=[cors(allow_headers=(*BLACK_HEADERS, \"Content-Type\"))]\n    )\n    app.add_routes([web.post(\"/\", partial(handle, executor=executor()))])\n    return app", "loc": 6}
{"file": "black\\src\\blackd\\__init__.py", "class_name": null, "function_name": "parse_mode", "parameters": ["headers"], "param_types": {"headers": "MultiMapping[str]"}, "return_type": "black.Mode", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HeaderError", "black.FileMode", "bool", "enable_features.add", "headers.get", "headers.get(ENABLE_UNSTABLE_FEATURE, '').split", "int", "parse_python_variant_header", "piece.strip", "set"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_mode(headers: MultiMapping[str]) -> black.Mode:\n    try:\n        line_length = int(headers.get(LINE_LENGTH_HEADER, black.DEFAULT_LINE_LENGTH))\n    except ValueError:\n        raise HeaderError(\"Invalid line length header value\") from None\n\n    if PYTHON_VARIANT_HEADER in headers:\n        value = headers[PYTHON_VARIANT_HEADER]\n        try:\n            pyi, versions = parse_python_variant_header(value)\n        except InvalidVariantHeader as e:\n            raise HeaderError(\n                f\"Invalid value for {PYTHON_VARIANT_HEADER}: {e.args[0]}\",\n            ) from None\n    else:\n        pyi = False\n        versions = set()\n\n    skip_string_normalization = bool(\n        headers.get(SKIP_STRING_NORMALIZATION_HEADER, False)\n    )\n    skip_magic_trailing_comma = bool(headers.get(SKIP_MAGIC_TRAILING_COMMA, False))\n    skip_source_first_line = bool(headers.get(SKIP_SOURCE_FIRST_LINE, False))\n\n    preview = bool(headers.get(PREVIEW, False))\n    unstable = bool(headers.get(UNSTABLE, False))\n    enable_features: set[black.Preview] = set()\n    enable_unstable_features = headers.get(ENABLE_UNSTABLE_FEATURE, \"\").split(\",\")\n    for piece in enable_unstable_features:\n        piece = piece.strip()\n        if piece:\n            try:\n                enable_features.add(black.Preview[piece])\n            except KeyError:\n                raise HeaderError(\n                    f\"Invalid value for {ENABLE_UNSTABLE_FEATURE}: {piece}\",\n                ) from None\n\n    return black.FileMode(\n        target_versions=versions,\n        is_pyi=pyi,\n        line_length=line_length,\n        skip_source_first_line=skip_source_first_line,\n        string_normalization=not skip_string_normalization,\n        magic_trailing_comma=not skip_magic_trailing_comma,\n        preview=preview,\n        unstable=unstable,\n        enabled_features=enable_features,\n    )", "loc": 49}
{"file": "black\\src\\blackd\\__init__.py", "class_name": null, "function_name": "parse_python_variant_header", "parameters": ["value"], "param_types": {"value": "str"}, "return_type": "tuple[bool, set[black.TargetVersion]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InvalidVariantHeader", "hasattr", "int", "len", "set", "value.split", "version.split", "version.startswith", "versions.add"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_python_variant_header(value: str) -> tuple[bool, set[black.TargetVersion]]:\n    if value == \"pyi\":\n        return True, set()\n    else:\n        versions = set()\n        for version in value.split(\",\"):\n            if version.startswith(\"py\"):\n                version = version[len(\"py\") :]\n            if \".\" in version:\n                major_str, *rest = version.split(\".\")\n            else:\n                major_str = version[0]\n                rest = [version[1:]] if len(version) > 1 else []\n            try:\n                major = int(major_str)\n                if major not in (2, 3):\n                    raise InvalidVariantHeader(\"major version must be 2 or 3\")\n                if len(rest) > 0:\n                    minor = int(rest[0])\n                    if major == 2:\n                        raise InvalidVariantHeader(\"Python 2 is not supported\")\n                else:\n                    # Default to lowest supported minor version.\n                    minor = 7 if major == 2 else 3\n                version_str = f\"PY{major}{minor}\"\n                if major == 3 and not hasattr(black.TargetVersion, version_str):\n                    raise InvalidVariantHeader(f\"3.{minor} is not supported\")\n                versions.add(black.TargetVersion[version_str])\n            except (KeyError, ValueError):\n                raise InvalidVariantHeader(\"expected e.g. '3.7', 'py3.5'\") from None\n        return False, versions", "loc": 31}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": null, "function_name": "type_repr", "parameters": ["type_num"], "param_types": {"type_num": "int"}, "return_type": "Union[str, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_type_reprs.setdefault", "dir", "getattr", "hasattr", "pygram.initialize", "type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def type_repr(type_num: int) -> Union[str, int]:\n    global _type_reprs\n    if not _type_reprs:\n        from . import pygram\n\n        if not hasattr(pygram, \"python_symbols\"):\n            pygram.initialize(cache_dir=None)\n\n        # printing tokens is possible but not as useful\n        # from .pgen2 import token // token.__dict__.items():\n        for name in dir(pygram.python_symbols):\n            val = getattr(pygram.python_symbols, name)\n            if type(val) == int:\n                _type_reprs[val] = name\n    return _type_reprs.setdefault(type_num, type_num)", "loc": 15}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": null, "function_name": "convert", "parameters": ["gr", "raw_node"], "param_types": {"gr": "Grammar", "raw_node": "RawNode"}, "return_type": "NL", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Leaf", "Node", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convert raw node information to a Node or Leaf instance. This is passed to the parser driver which calls it whenever a reduction of a grammar rule produces a new complete node, so that the tree is build", "source_code": "def convert(gr: Grammar, raw_node: RawNode) -> NL:\n    \"\"\"\n    Convert raw node information to a Node or Leaf instance.\n\n    This is passed to the parser driver which calls it whenever a reduction of a\n    grammar rule produces a new complete node, so that the tree is build\n    strictly bottom-up.\n    \"\"\"\n    type, value, context, children = raw_node\n    if children or type in gr.number2symbol:\n        # If there's exactly one child, return that child instead of\n        # creating a new node.\n        assert children is not None\n        if len(children) == 1:\n            return children[0]\n        return Node(type, children, context=context)\n    else:\n        return Leaf(type, value or \"\", context=context)", "loc": 18}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": null, "function_name": "generate_matches", "parameters": ["patterns", "nodes"], "param_types": {"patterns": "list[BasePattern]", "nodes": "list[NL]"}, "return_type": "Iterator[tuple[int, _Results]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["generate_matches", "p.generate_matches", "r.update"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Generator yielding matches for a sequence of patterns and nodes.", "source_code": "def generate_matches(\n    patterns: list[BasePattern], nodes: list[NL]\n) -> Iterator[tuple[int, _Results]]:\n    \"\"\"\n    Generator yielding matches for a sequence of patterns and nodes.\n\n    Args:\n        patterns: a sequence of patterns\n        nodes: a sequence of nodes\n\n    Yields:\n        (count, results) tuples where:\n        count: the entire sequence of patterns matches nodes[:count];\n        results: dict containing named submatches.\n    \"\"\"\n    if not patterns:\n        yield 0, {}\n    else:\n        p, rest = patterns[0], patterns[1:]\n        for c0, r0 in p.generate_matches(nodes):\n            if not rest:\n                yield c0, r0\n            else:\n                for c1, r1 in generate_matches(rest, nodes[c0:]):\n                    r = {}\n                    r.update(r0)\n                    r.update(r1)\n                    yield c0 + c1, r", "loc": 28}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Base", "function_name": "replace", "parameters": ["self", "new"], "param_types": {"new": "Union[NL, list[NL]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "l_children.append", "l_children.extend", "self.parent.changed", "self.parent.invalidate_sibling_maps", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Replace this node with a new one in the parent.", "source_code": "def replace(self, new: Union[NL, list[NL]]) -> None:\n    \"\"\"Replace this node with a new one in the parent.\"\"\"\n    assert self.parent is not None, str(self)\n    assert new is not None\n    if not isinstance(new, list):\n        new = [new]\n    l_children = []\n    found = False\n    for ch in self.parent.children:\n        if ch is self:\n            assert not found, (self.parent.children, self, new)\n            if new is not None:\n                l_children.extend(new)\n            found = True\n        else:\n            l_children.append(ch)\n    assert found, (self.children, self, new)\n    self.parent.children = l_children\n    self.parent.changed()\n    self.parent.invalidate_sibling_maps()\n    for x in new:\n        x.parent = self.parent\n    self.parent = None", "loc": 23}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Base", "function_name": "get_lineno", "parameters": ["self"], "param_types": {}, "return_type": "Optional[int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Return the line number which generated the invocant node.", "source_code": "def get_lineno(self) -> Optional[int]:\n    \"\"\"Return the line number which generated the invocant node.\"\"\"\n    node = self\n    while not isinstance(node, Leaf):\n        if not node.children:\n            return None\n        node = node.children[0]\n    return node.lineno", "loc": 8}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Base", "function_name": "changed", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.parent.changed"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def changed(self) -> None:\n    if self.was_changed:\n        return\n    if self.parent:\n        self.parent.changed()\n    self.was_changed = True", "loc": 6}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Base", "function_name": "remove", "parameters": ["self"], "param_types": {}, "return_type": "Optional[int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "self.parent.changed", "self.parent.invalidate_sibling_maps"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Remove the node from the tree. Returns the position of the node in its parent's children before it was removed.", "source_code": "def remove(self) -> Optional[int]:\n    \"\"\"\n    Remove the node from the tree. Returns the position of the node in its\n    parent's children before it was removed.\n    \"\"\"\n    if self.parent:\n        for i, node in enumerate(self.parent.children):\n            if node is self:\n                del self.parent.children[i]\n                self.parent.changed()\n                self.parent.invalidate_sibling_maps()\n                self.parent = None\n                return i\n    return None", "loc": 14}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Base", "function_name": "next_sibling", "parameters": ["self"], "param_types": {}, "return_type": "Optional[NL]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["id", "self.parent.update_sibling_maps"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The node immediately following the invocant in their parent's children list. If the invocant does not have a next sibling, it is None", "source_code": "def next_sibling(self) -> Optional[NL]:\n    \"\"\"\n    The node immediately following the invocant in their parent's children\n    list. If the invocant does not have a next sibling, it is None\n    \"\"\"\n    if self.parent is None:\n        return None\n\n    if self.parent.next_sibling_map is None:\n        self.parent.update_sibling_maps()\n    assert self.parent.next_sibling_map is not None\n    return self.parent.next_sibling_map[id(self)]", "loc": 12}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Base", "function_name": "prev_sibling", "parameters": ["self"], "param_types": {}, "return_type": "Optional[NL]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["id", "self.parent.update_sibling_maps"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The node immediately preceding the invocant in their parent's children list. If the invocant does not have a previous sibling, it is None.", "source_code": "def prev_sibling(self) -> Optional[NL]:\n    \"\"\"\n    The node immediately preceding the invocant in their parent's children\n    list. If the invocant does not have a previous sibling, it is None.\n    \"\"\"\n    if self.parent is None:\n        return None\n\n    if self.parent.prev_sibling_map is None:\n        self.parent.update_sibling_maps()\n    assert self.parent.prev_sibling_map is not None\n    return self.parent.prev_sibling_map[id(self)]", "loc": 12}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Base", "function_name": "get_suffix", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the string immediately following the invocant node. This is effectively equivalent to node.next_sibling.prefix", "source_code": "def get_suffix(self) -> str:\n    \"\"\"\n    Return the string immediately following the invocant node. This is\n    effectively equivalent to node.next_sibling.prefix\n    \"\"\"\n    next_sib = self.next_sibling\n    if next_sib is None:\n        return \"\"\n    prefix = next_sib.prefix\n    return prefix", "loc": 10}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Node", "function_name": "clone", "parameters": ["self"], "param_types": {}, "return_type": "'Node'", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Node", "ch.clone"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def clone(self) -> \"Node\":\n    assert self.type is not None\n    \"\"\"Return a cloned (deep) copy of self.\"\"\"\n    return Node(\n        self.type,\n        [ch.clone() for ch in self.children],\n        fixers_applied=self.fixers_applied,\n    )", "loc": 8}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Node", "function_name": "post_order", "parameters": ["self"], "param_types": {}, "return_type": "Iterator[NL]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["child.post_order"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Return a post-order iterator for the tree.", "source_code": "def post_order(self) -> Iterator[NL]:\n    \"\"\"Return a post-order iterator for the tree.\"\"\"\n    for child in self.children:\n        yield from child.post_order()\n    yield self", "loc": 5}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Node", "function_name": "pre_order", "parameters": ["self"], "param_types": {}, "return_type": "Iterator[NL]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["child.pre_order"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Return a pre-order iterator for the tree.", "source_code": "def pre_order(self) -> Iterator[NL]:\n    \"\"\"Return a pre-order iterator for the tree.\"\"\"\n    yield self\n    for child in self.children:\n        yield from child.pre_order()", "loc": 5}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Node", "function_name": "prefix", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The whitespace and comments preceding this node in the input.", "source_code": "def prefix(self) -> str:\n    \"\"\"\n    The whitespace and comments preceding this node in the input.\n    \"\"\"\n    if not self.children:\n        return \"\"\n    return self.children[0].prefix", "loc": 7}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Node", "function_name": "set_child", "parameters": ["self", "i", "child"], "param_types": {"i": "int", "child": "NL"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.changed", "self.invalidate_sibling_maps"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Equivalent to 'node.children[i] = child'. This method also sets the child's parent attribute appropriately.", "source_code": "def set_child(self, i: int, child: NL) -> None:\n    \"\"\"\n    Equivalent to 'node.children[i] = child'. This method also sets the\n    child's parent attribute appropriately.\n    \"\"\"\n    child.parent = self\n    self.children[i].parent = None\n    self.children[i] = child\n    self.changed()\n    self.invalidate_sibling_maps()", "loc": 10}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Node", "function_name": "insert_child", "parameters": ["self", "i", "child"], "param_types": {"i": "int", "child": "NL"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.changed", "self.children.insert", "self.invalidate_sibling_maps"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Equivalent to 'node.children.insert(i, child)'. This method also sets the child's parent attribute appropriately.", "source_code": "def insert_child(self, i: int, child: NL) -> None:\n    \"\"\"\n    Equivalent to 'node.children.insert(i, child)'. This method also sets\n    the child's parent attribute appropriately.\n    \"\"\"\n    child.parent = self\n    self.children.insert(i, child)\n    self.changed()\n    self.invalidate_sibling_maps()", "loc": 9}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Node", "function_name": "append_child", "parameters": ["self", "child"], "param_types": {"child": "NL"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.changed", "self.children.append", "self.invalidate_sibling_maps"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Equivalent to 'node.children.append(child)'. This method also sets the child's parent attribute appropriately.", "source_code": "def append_child(self, child: NL) -> None:\n    \"\"\"\n    Equivalent to 'node.children.append(child)'. This method also sets the\n    child's parent attribute appropriately.\n    \"\"\"\n    child.parent = self\n    self.children.append(child)\n    self.changed()\n    self.invalidate_sibling_maps()", "loc": 9}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "Node", "function_name": "update_sibling_maps", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["id"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_sibling_maps(self) -> None:\n    _prev: dict[int, Optional[NL]] = {}\n    _next: dict[int, Optional[NL]] = {}\n    self.prev_sibling_map = _prev\n    self.next_sibling_map = _next\n    previous: Optional[NL] = None\n    for current in self.children:\n        _prev[id(current)] = previous\n        _next[id(previous)] = current\n        previous = current\n    _next[id(current)] = None", "loc": 11}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "BasePattern", "function_name": "match", "parameters": ["self", "node", "results"], "param_types": {"node": "NL", "results": "Optional[_Results]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["results.update", "self._submatch"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Does this pattern exactly match a node?", "source_code": "def match(self, node: NL, results: Optional[_Results] = None) -> bool:\n    \"\"\"\n    Does this pattern exactly match a node?\n\n    Returns True if it matches, False if not.\n\n    If results is not None, it must be a dict which will be\n    updated with the nodes matching named subpatterns.\n\n    Default implementation for non-wildcard patterns.\n    \"\"\"\n    if self.type is not None and node.type != self.type:\n        return False\n    if self.content is not None:\n        r: Optional[_Results] = None\n        if results is not None:\n            r = {}\n        if not self._submatch(node, r):\n            return False\n        if r:\n            assert results is not None\n            results.update(r)\n    if results is not None and self.name:\n        results[self.name] = node\n    return True", "loc": 25}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "BasePattern", "function_name": "match_seq", "parameters": ["self", "nodes", "results"], "param_types": {"nodes": "list[NL]", "results": "Optional[_Results]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.match"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Does this pattern exactly match a sequence of nodes? Default implementation for non-wildcard patterns.", "source_code": "def match_seq(self, nodes: list[NL], results: Optional[_Results] = None) -> bool:\n    \"\"\"\n    Does this pattern exactly match a sequence of nodes?\n\n    Default implementation for non-wildcard patterns.\n    \"\"\"\n    if len(nodes) != 1:\n        return False\n    return self.match(nodes[0], results)", "loc": 9}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "BasePattern", "function_name": "generate_matches", "parameters": ["self", "nodes"], "param_types": {"nodes": "list[NL]"}, "return_type": "Iterator[tuple[int, _Results]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.match"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generator yielding all matches for this pattern. Default implementation for non-wildcard patterns.", "source_code": "def generate_matches(self, nodes: list[NL]) -> Iterator[tuple[int, _Results]]:\n    \"\"\"\n    Generator yielding all matches for this pattern.\n\n    Default implementation for non-wildcard patterns.\n    \"\"\"\n    r: _Results = {}\n    if nodes and self.match(nodes[0], r):\n        yield 1, r", "loc": 9}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "LeafPattern", "function_name": "match", "parameters": ["self", "node", "results"], "param_types": {"node": "NL"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BasePattern.match", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Override match() to insist on a leaf node.", "source_code": "def match(self, node: NL, results=None) -> bool:\n    \"\"\"Override match() to insist on a leaf node.\"\"\"\n    if not isinstance(node, Leaf):\n        return False\n    return BasePattern.match(self, node, results)", "loc": 5}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "WildcardPattern", "function_name": "optimize", "parameters": ["self"], "param_types": {}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NodePattern", "WildcardPattern", "isinstance", "len", "subpattern.optimize"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Optimize certain stacked wildcard patterns.", "source_code": "def optimize(self) -> Any:\n    \"\"\"Optimize certain stacked wildcard patterns.\"\"\"\n    subpattern = None\n    if (\n        self.content is not None\n        and len(self.content) == 1\n        and len(self.content[0]) == 1\n    ):\n        subpattern = self.content[0][0]\n    if self.min == 1 and self.max == 1:\n        if self.content is None:\n            return NodePattern(name=self.name)\n        if subpattern is not None and self.name == subpattern.name:\n            return subpattern.optimize()\n    if (\n        self.min <= 1\n        and isinstance(subpattern, WildcardPattern)\n        and subpattern.min <= 1\n        and self.name == subpattern.name\n    ):\n        return WildcardPattern(\n            subpattern.content,\n            self.min * subpattern.min,\n            self.max * subpattern.max,\n            subpattern.name,\n        )\n    return self", "loc": 27}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "WildcardPattern", "function_name": "match_seq", "parameters": ["self", "nodes", "results"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "list", "results.update", "self.generate_matches"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Does this pattern exactly match a sequence of nodes?", "source_code": "def match_seq(self, nodes, results=None) -> bool:\n    \"\"\"Does this pattern exactly match a sequence of nodes?\"\"\"\n    for c, r in self.generate_matches(nodes):\n        if c == len(nodes):\n            if results is not None:\n                results.update(r)\n                if self.name:\n                    results[self.name] = list(nodes)\n            return True\n    return False", "loc": 10}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "WildcardPattern", "function_name": "generate_matches", "parameters": ["self", "nodes"], "param_types": {}, "return_type": "Iterator[tuple[int, _Results]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["StringIO", "hasattr", "len", "min", "range", "self._bare_name_matches", "self._iterative_matches", "self._recursive_matches"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Generator yielding matches for a sequence of nodes.", "source_code": "def generate_matches(self, nodes) -> Iterator[tuple[int, _Results]]:\n    \"\"\"\n    Generator yielding matches for a sequence of nodes.\n\n    Args:\n        nodes: sequence of nodes\n\n    Yields:\n        (count, results) tuples where:\n        count: the match comprises nodes[:count];\n        results: dict containing named submatches.\n    \"\"\"\n    if self.content is None:\n        # Shortcut for special case (see __init__.__doc__)\n        for count in range(self.min, 1 + min(len(nodes), self.max)):\n            r = {}\n            if self.name:\n                r[self.name] = nodes[:count]\n            yield count, r\n    elif self.name == \"bare_name\":\n        yield self._bare_name_matches(nodes)\n    else:\n        # The reason for this is that hitting the recursion limit usually\n        # results in some ugly messages about how RuntimeErrors are being\n        # ignored. We only have to do this on CPython, though, because other\n        # implementations don't have this nasty bug in the first place.\n        if hasattr(sys, \"getrefcount\"):\n            save_stderr = sys.stderr\n            sys.stderr = StringIO()\n        try:\n            for count, r in self._recursive_matches(nodes, 0):\n                if self.name:\n                    r[self.name] = nodes[:count]\n                yield count, r\n        except RuntimeError:\n            # We fall back to the iterative pattern matching scheme if the recursive\n            # scheme hits the recursion limit.\n            for count, r in self._iterative_matches(nodes):\n                if self.name:\n                    r[self.name] = nodes[:count]\n                yield count, r\n        finally:\n            if hasattr(sys, \"getrefcount\"):\n                sys.stderr = save_stderr", "loc": 44}
{"file": "black\\src\\blib2to3\\pytree.py", "class_name": "NegatedPattern", "function_name": "generate_matches", "parameters": ["self", "nodes"], "param_types": {"nodes": "list[NL]"}, "return_type": "Iterator[tuple[int, _Results]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.content.generate_matches"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def generate_matches(self, nodes: list[NL]) -> Iterator[tuple[int, _Results]]:\n    if self.content is None:\n        # Return a match if there is an empty sequence\n        if len(nodes) == 0:\n            yield 0, {}\n    else:\n        # Return a match if the argument pattern has no matches\n        for c, r in self.content.generate_matches(nodes):\n            return\n        yield 0, {}", "loc": 10}
{"file": "black\\src\\blib2to3\\pgen2\\conv.py", "class_name": "Converter", "function_name": "run", "parameters": ["self", "graminit_h", "graminit_c"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.finish_off", "self.parse_graminit_c", "self.parse_graminit_h"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Load the grammar tables from the text files written by pgen.", "source_code": "def run(self, graminit_h, graminit_c):\n    \"\"\"Load the grammar tables from the text files written by pgen.\"\"\"\n    self.parse_graminit_h(graminit_h)\n    self.parse_graminit_c(graminit_c)\n    self.finish_off()", "loc": 5}
{"file": "black\\src\\blib2to3\\pgen2\\conv.py", "class_name": "Converter", "function_name": "finish_off", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Create additional useful structures.  (Internal).", "source_code": "def finish_off(self):\n    \"\"\"Create additional useful structures.  (Internal).\"\"\"\n    self.keywords = {}  # map from keyword strings to arc labels\n    self.tokens = {}  # map from numeric token values to arc labels\n    for ilabel, (type, value) in enumerate(self.labels):\n        if type == token.NAME and value is not None:\n            self.keywords[value] = ilabel\n        elif value is None:\n            self.tokens[type] = ilabel", "loc": 9}
{"file": "black\\src\\blib2to3\\pgen2\\driver.py", "class_name": null, "function_name": "load_grammar", "parameters": ["gt", "gp", "save", "force", "logger"], "param_types": {"gt": "str", "gp": "Optional[str]", "save": "bool", "force": "bool", "logger": "Optional[Logger]"}, "return_type": "Grammar", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_generate_pickle_name", "_newer", "g.dump", "g.load", "grammar.Grammar", "logging.getLogger", "pgen.generate_grammar"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Load the grammar (maybe from a pickle).", "source_code": "def load_grammar(\n    gt: str = \"Grammar.txt\",\n    gp: Optional[str] = None,\n    save: bool = True,\n    force: bool = False,\n    logger: Optional[Logger] = None,\n) -> Grammar:\n    \"\"\"Load the grammar (maybe from a pickle).\"\"\"\n    if logger is None:\n        logger = logging.getLogger(__name__)\n    gp = _generate_pickle_name(gt) if gp is None else gp\n    if force or not _newer(gp, gt):\n        g: grammar.Grammar = pgen.generate_grammar(gt)\n        if save:\n            try:\n                g.dump(gp)\n            except OSError:\n                # Ignore error, caching is not vital.\n                pass\n    else:\n        g = grammar.Grammar()\n        g.load(gp)\n    return g", "loc": 23}
{"file": "black\\src\\blib2to3\\pgen2\\driver.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["load_grammar", "logging.basicConfig", "tuple"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Main program, when run as a script: produce grammar pickle files. Calls load_grammar for each argument, a path to a grammar text file.", "source_code": "def main(*args: str) -> bool:\n    \"\"\"Main program, when run as a script: produce grammar pickle files.\n\n    Calls load_grammar for each argument, a path to a grammar text file.\n    \"\"\"\n    if not args:\n        args = tuple(sys.argv[1:])\n    logging.basicConfig(level=logging.INFO, stream=sys.stdout, format=\"%(message)s\")\n    for gt in args:\n        load_grammar(gt, save=True, force=True)\n    return True", "loc": 11}
{"file": "black\\src\\blib2to3\\pgen2\\driver.py", "class_name": "TokenProxy", "function_name": "release", "parameters": ["self"], "param_types": {}, "return_type": "Iterator['TokenProxy']", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ReleaseRange", "release_range.lock", "self._release_ranges.append"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def release(self) -> Iterator[\"TokenProxy\"]:\n    release_range = ReleaseRange(self._counter)\n    self._release_ranges.append(release_range)\n    try:\n        yield self\n    finally:\n        # Lock the last release range to the final position that\n        # has been eaten.\n        release_range.lock()", "loc": 9}
{"file": "black\\src\\blib2to3\\pgen2\\driver.py", "class_name": "TokenProxy", "function_name": "eat", "parameters": ["self", "point"], "param_types": {"point": "int"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["eaten_tokens.append", "len", "next"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def eat(self, point: int) -> Any:\n    eaten_tokens = self._release_ranges[-1].tokens\n    if point < len(eaten_tokens):\n        return eaten_tokens[point]\n    else:\n        while point >= len(eaten_tokens):\n            token = next(self._tokens)\n            eaten_tokens.append(token)\n        return token", "loc": 9}
{"file": "black\\src\\blib2to3\\pgen2\\driver.py", "class_name": "TokenProxy", "function_name": "can_advance", "parameters": ["self", "to"], "param_types": {"to": "int"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.eat"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def can_advance(self, to: int) -> bool:\n    # Try to eat, fail if it can't. The eat operation is cached\n    # so there won't be any additional cost of eating here\n    try:\n        self.eat(to)\n    except StopIteration:\n        return False\n    else:\n        return True", "loc": 9}
{"file": "black\\src\\blib2to3\\pgen2\\driver.py", "class_name": "Driver", "function_name": "parse_tokens", "parameters": ["self", "tokens", "debug"], "param_types": {"tokens": "Iterable[TokenInfo]", "debug": "bool"}, "return_type": "NL", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TokenProxy", "cast", "indent_columns.append", "indent_columns.pop", "len", "p.addtoken", "p.setup", "parse.ParseError", "parse.Parser", "self._partially_consume_prefix", "self.logger.debug", "value.endswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Parse a series of tokens and return the syntax tree.", "source_code": "def parse_tokens(self, tokens: Iterable[TokenInfo], debug: bool = False) -> NL:\n    \"\"\"Parse a series of tokens and return the syntax tree.\"\"\"\n    # XXX Move the prefix computation into a wrapper around tokenize.\n    proxy = TokenProxy(tokens)\n\n    p = parse.Parser(self.grammar)\n    p.setup(proxy=proxy)\n\n    lineno = 1\n    column = 0\n    indent_columns: list[int] = []\n    type = value = start = end = line_text = None\n    prefix = \"\"\n\n    for quintuple in proxy:\n        type, value, start, end, line_text = quintuple\n        if start != (lineno, column):\n            assert (lineno, column) <= start, ((lineno, column), start)\n            s_lineno, s_column = start\n            if lineno < s_lineno:\n                prefix += \"\\n\" * (s_lineno - lineno)\n                lineno = s_lineno\n                column = 0\n            if column < s_column:\n                prefix += line_text[column:s_column]\n                column = s_column\n        if type in (tokenize.COMMENT, tokenize.NL):\n            prefix += value\n            lineno, column = end\n            if value.endswith(\"\\n\"):\n                lineno += 1\n                column = 0\n            continue\n        if type == token.OP:\n            type = grammar.opmap[value]\n        if debug:\n            assert type is not None\n            self.logger.debug(\n                \"%s %r (prefix=%r)\", token.tok_name[type], value, prefix\n            )\n        if type == token.INDENT:\n            indent_columns.append(len(value))\n            _prefix = prefix + value\n            prefix = \"\"\n            value = \"\"\n        elif type == token.DEDENT:\n            _indent_col = indent_columns.pop()\n            prefix, _prefix = self._partially_consume_prefix(prefix, _indent_col)\n        if p.addtoken(cast(int, type), value, (prefix, start)):\n            if debug:\n                self.logger.debug(\"Stop.\")\n            break\n        prefix = \"\"\n        if type in {token.INDENT, token.DEDENT}:\n            prefix = _prefix\n        lineno, column = end\n        # FSTRING_MIDDLE is the only token that can end with a newline, and\n        # `end` will point to the next line. For that case, don't increment lineno.\n        if value.endswith(\"\\n\") and type != token.FSTRING_MIDDLE:\n            lineno += 1\n            column = 0\n    else:\n        # We never broke out -- EOF is too soon (how can this happen???)\n        assert start is not None\n        raise parse.ParseError(\"incomplete input\", type, value, (prefix, start))\n    assert p.rootnode is not None\n    return p.rootnode", "loc": 67}
{"file": "black\\src\\blib2to3\\pgen2\\grammar.py", "class_name": "Grammar", "function_name": "dump", "parameters": ["self", "filename"], "param_types": {"filename": "Path"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "os.path.dirname", "os.replace", "pickle.dump", "self.__getstate__", "tempfile.NamedTemporaryFile"], "control_structures": ["If"], "behavior_type": ["file_io", "serialization"], "doc_summary": "Dump the grammar tables to a pickle file.", "source_code": "def dump(self, filename: Path) -> None:\n    \"\"\"Dump the grammar tables to a pickle file.\"\"\"\n\n    # mypyc generates objects that don't have a __dict__, but they\n    # do have __getstate__ methods that will return an equivalent\n    # dictionary\n    if hasattr(self, \"__dict__\"):\n        d = self.__dict__\n    else:\n        d = self.__getstate__()  # type: ignore\n\n    with tempfile.NamedTemporaryFile(\n        dir=os.path.dirname(filename), delete=False\n    ) as f:\n        pickle.dump(d, f, pickle.HIGHEST_PROTOCOL)\n    os.replace(f.name, filename)", "loc": 16}
{"file": "black\\src\\blib2to3\\pgen2\\grammar.py", "class_name": "Grammar", "function_name": "load", "parameters": ["self", "filename"], "param_types": {"filename": "Path"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["open", "pickle.load", "self._update"], "control_structures": [], "behavior_type": ["file_io", "serialization"], "doc_summary": "Load the grammar tables from a pickle file.", "source_code": "def load(self, filename: Path) -> None:\n    \"\"\"Load the grammar tables from a pickle file.\"\"\"\n    with open(filename, \"rb\") as f:\n        d = pickle.load(f)\n    self._update(d)", "loc": 5}
{"file": "black\\src\\blib2to3\\pgen2\\grammar.py", "class_name": "Grammar", "function_name": "copy", "parameters": ["self"], "param_types": {"self": "_P"}, "return_type": "_P", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "getattr(self, dict_attr).copy", "self.__class__", "setattr"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Copy the grammar.", "source_code": "def copy(self: _P) -> _P:\n    \"\"\"\n    Copy the grammar.\n    \"\"\"\n    new = self.__class__()\n    for dict_attr in (\n        \"symbol2number\",\n        \"number2symbol\",\n        \"dfas\",\n        \"keywords\",\n        \"soft_keywords\",\n        \"tokens\",\n        \"symbol2label\",\n    ):\n        setattr(new, dict_attr, getattr(self, dict_attr).copy())\n    new.labels = self.labels[:]\n    new.states = self.states[:]\n    new.start = self.start\n    new.version = self.version\n    new.async_keywords = self.async_keywords\n    return new", "loc": 21}
{"file": "black\\src\\blib2to3\\pgen2\\grammar.py", "class_name": "Grammar", "function_name": "report", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["pprint", "print"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Dump the grammar tables to standard output, for debugging.", "source_code": "def report(self) -> None:\n    \"\"\"Dump the grammar tables to standard output, for debugging.\"\"\"\n    from pprint import pprint\n\n    print(\"s2n\")\n    pprint(self.symbol2number)\n    print(\"n2s\")\n    pprint(self.number2symbol)\n    print(\"states\")\n    pprint(self.states)\n    print(\"dfas\")\n    pprint(self.dfas)\n    print(\"labels\")\n    pprint(self.labels)\n    print(\"start\", self.start)", "loc": 15}
{"file": "black\\src\\blib2to3\\pgen2\\literals.py", "class_name": null, "function_name": "escape", "parameters": ["m"], "param_types": {"m": "re.Match[str]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "all.startswith", "chr", "int", "len", "m.group", "simple_escapes.get", "tail.startswith"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def escape(m: re.Match[str]) -> str:\n    all, tail = m.group(0, 1)\n    assert all.startswith(\"\\\\\")\n    esc = simple_escapes.get(tail)\n    if esc is not None:\n        return esc\n    if tail.startswith(\"x\"):\n        hexes = tail[1:]\n        if len(hexes) < 2:\n            raise ValueError(f\"invalid hex string escape ('\\\\{tail}')\")\n        try:\n            i = int(hexes, 16)\n        except ValueError:\n            raise ValueError(f\"invalid hex string escape ('\\\\{tail}')\") from None\n    else:\n        try:\n            i = int(tail, 8)\n        except ValueError:\n            raise ValueError(f\"invalid octal string escape ('\\\\{tail}')\") from None\n    return chr(i)", "loc": 20}
{"file": "black\\src\\blib2to3\\pgen2\\literals.py", "class_name": null, "function_name": "evalString", "parameters": ["s"], "param_types": {"s": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "re.sub", "repr", "s.endswith", "s.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def evalString(s: str) -> str:\n    assert s.startswith(\"'\") or s.startswith('\"'), repr(s[:1])\n    q = s[0]\n    if s[:3] == q * 3:\n        q = q * 3\n    assert s.endswith(q), repr(s[-len(q) :])\n    assert len(s) >= 2 * len(q)\n    s = s[len(q) : -len(q)]\n    return re.sub(r\"\\\\(\\'|\\\"|\\\\|[abfnrtv]|x.{0,2}|[0-7]{1,3})\", escape, s)", "loc": 9}
{"file": "black\\src\\blib2to3\\pgen2\\literals.py", "class_name": null, "function_name": "test", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["chr", "evalString", "print", "range", "repr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def test() -> None:\n    for i in range(256):\n        c = chr(i)\n        s = repr(c)\n        e = evalString(s)\n        if e != c:\n            print(i, c, s, e)", "loc": 7}
{"file": "black\\src\\blib2to3\\pgen2\\parse.py", "class_name": "Recorder", "function_name": "switch_to", "parameters": ["self", "ilabel"], "param_types": {"ilabel": "int"}, "return_type": "Iterator[None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._dead_ilabels.add", "self.backtrack"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def switch_to(self, ilabel: int) -> Iterator[None]:\n    with self.backtrack():\n        self.parser.stack = self._points[ilabel]\n        try:\n            yield\n        except ParseError:\n            self._dead_ilabels.add(ilabel)\n        finally:\n            self.parser.stack = self._start_point", "loc": 9}
{"file": "black\\src\\blib2to3\\pgen2\\parse.py", "class_name": "Recorder", "function_name": "backtrack", "parameters": ["self"], "param_types": {}, "return_type": "Iterator[None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Use the node-level invariant ones for basic parsing operations (push/pop/shift). These still will operate on the stack; but they won't create any new nodes, or modify the contents of any other existing nodes.", "source_code": "def backtrack(self) -> Iterator[None]:\n    \"\"\"\n    Use the node-level invariant ones for basic parsing operations (push/pop/shift).\n    These still will operate on the stack; but they won't create any new nodes, or\n    modify the contents of any other existing nodes.\n\n    This saves us a ton of time when we are backtracking, since we\n    want to restore to the initial state as quick as possible, which\n    can only be done by having as little mutatations as possible.\n    \"\"\"\n    is_backtracking = self.parser.is_backtracking\n    try:\n        self.parser.is_backtracking = True\n        yield\n    finally:\n        self.parser.is_backtracking = is_backtracking", "loc": 16}
{"file": "black\\src\\blib2to3\\pgen2\\parse.py", "class_name": "Recorder", "function_name": "add_token", "parameters": ["self", "tok_type", "tok_val", "raw"], "param_types": {"tok_type": "int", "tok_val": "str", "raw": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.parser._addtoken", "self.parser.addtoken", "self.switch_to"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_token(self, tok_type: int, tok_val: str, raw: bool = False) -> None:\n    for ilabel in self.ilabels:\n        with self.switch_to(ilabel):\n            if raw:\n                self.parser._addtoken(ilabel, tok_type, tok_val, self.context)\n            else:\n                self.parser.addtoken(tok_type, tok_val, self.context)", "loc": 7}
{"file": "black\\src\\blib2to3\\pgen2\\parse.py", "class_name": "Recorder", "function_name": "determine_route", "parameters": ["self", "value", "force"], "param_types": {"value": "Optional[str]", "force": "bool"}, "return_type": "Optional[int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParseError", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def determine_route(\n    self, value: Optional[str] = None, force: bool = False\n) -> Optional[int]:\n    alive_ilabels = self.ilabels\n    if len(alive_ilabels) == 0:\n        *_, most_successful_ilabel = self._dead_ilabels\n        raise ParseError(\"bad input\", most_successful_ilabel, value, self.context)\n\n    ilabel, *rest = alive_ilabels\n    if force or not rest:\n        return ilabel\n    else:\n        return None", "loc": 13}
{"file": "black\\src\\blib2to3\\pgen2\\parse.py", "class_name": "Parser", "function_name": "setup", "parameters": ["self", "proxy", "start"], "param_types": {"proxy": "'TokenProxy'", "start": "Optional[int]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Prepare for parsing. This *must* be called before starting to parse. The optional argument is an alternative start symbol; it", "source_code": "def setup(self, proxy: \"TokenProxy\", start: Optional[int] = None) -> None:\n    \"\"\"Prepare for parsing.\n\n    This *must* be called before starting to parse.\n\n    The optional argument is an alternative start symbol; it\n    defaults to the grammar's start symbol.\n\n    You can use a Parser instance to parse any number of programs;\n    each time you call setup() the parser is reset to an initial\n    state determined by the (implicit or explicit) start symbol.\n\n    \"\"\"\n    if start is None:\n        start = self.grammar.start\n    # Each stack entry is a tuple: (dfa, state, node).\n    # A node is a tuple: (type, value, context, children),\n    # where children is a list of nodes or None, and context may be None.\n    newnode: RawNode = (start, None, None, [])\n    stackentry = (self.grammar.dfas[start], 0, newnode)\n    self.stack: list[tuple[DFAS, int, RawNode]] = [stackentry]\n    self.rootnode: Optional[NL] = None\n    self.used_names: set[str] = set()\n    self.proxy = proxy\n    self.last_token = None", "loc": 25}
{"file": "black\\src\\blib2to3\\pgen2\\parse.py", "class_name": "Parser", "function_name": "addtoken", "parameters": ["self", "type", "value", "context"], "param_types": {"type": "int", "value": "str", "context": "Context"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Recorder", "cast", "len", "proxy.can_advance", "proxy.eat", "recorder.add_token", "recorder.determine_route", "self._addtoken", "self.classify", "self.proxy.release"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Add a token; return True iff this is the end of the program.", "source_code": "def addtoken(self, type: int, value: str, context: Context) -> bool:\n    \"\"\"Add a token; return True iff this is the end of the program.\"\"\"\n    # Map from token to label\n    ilabels = self.classify(type, value, context)\n    assert len(ilabels) >= 1\n\n    # If we have only one state to advance, we'll directly\n    # take it as is.\n    if len(ilabels) == 1:\n        [ilabel] = ilabels\n        return self._addtoken(ilabel, type, value, context)\n\n    # If there are multiple states which we can advance (only\n    # happen under soft-keywords), then we will try all of them\n    # in parallel and as soon as one state can reach further than\n    # the rest, we'll choose that one. This is a pretty hacky\n    # and hopefully temporary algorithm.\n    #\n    # For a more detailed explanation, check out this post:\n    # https://tree.science/what-the-backtracking.html\n\n    with self.proxy.release() as proxy:\n        counter, force = 0, False\n        recorder = Recorder(self, ilabels, context)\n        recorder.add_token(type, value, raw=True)\n\n        next_token_value = value\n        while recorder.determine_route(next_token_value) is None:\n            if not proxy.can_advance(counter):\n                force = True\n                break\n\n            next_token_type, next_token_value, *_ = proxy.eat(counter)\n            if next_token_type in (tokenize.COMMENT, tokenize.NL):\n                counter += 1\n                continue\n\n            if next_token_type == tokenize.OP:\n                next_token_type = grammar.opmap[next_token_value]\n\n            recorder.add_token(next_token_type, next_token_value)\n            counter += 1\n\n        ilabel = cast(int, recorder.determine_route(next_token_value, force=force))\n        assert ilabel is not None\n\n    return self._addtoken(ilabel, type, value, context)", "loc": 47}
{"file": "black\\src\\blib2to3\\pgen2\\parse.py", "class_name": "Parser", "function_name": "classify", "parameters": ["self", "type", "value", "context"], "param_types": {"type": "int", "value": "str", "context": "Context"}, "return_type": "list[int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParseError", "self.grammar.tokens.get", "self.used_names.add"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Turn a token into a label.  (Internal) Depending on whether the value is a soft-keyword or not, this function may return multiple labels to choose from.", "source_code": "def classify(self, type: int, value: str, context: Context) -> list[int]:\n    \"\"\"Turn a token into a label.  (Internal)\n\n    Depending on whether the value is a soft-keyword or not,\n    this function may return multiple labels to choose from.\"\"\"\n    if type == token.NAME:\n        # Keep a listing of all used names\n        self.used_names.add(value)\n        # Check for reserved words\n        if value in self.grammar.keywords:\n            return [self.grammar.keywords[value]]\n        elif value in self.grammar.soft_keywords:\n            assert type in self.grammar.tokens\n            # Current soft keywords (match, case, type) can only appear at the\n            # beginning of a statement. So as a shortcut, don't try to treat them\n            # like keywords in any other context.\n            # ('_' is also a soft keyword in the real grammar, but for our grammar\n            # it's just an expression, so we don't need to treat it specially.)\n            if self.last_token not in (\n                None,\n                token.INDENT,\n                token.DEDENT,\n                token.NEWLINE,\n                token.SEMI,\n                token.COLON,\n            ):\n                return [self.grammar.tokens[type]]\n            return [\n                self.grammar.tokens[type],\n                self.grammar.soft_keywords[value],\n            ]\n\n    ilabel = self.grammar.tokens.get(type)\n    if ilabel is None:\n        raise ParseError(\"bad token\", type, value, context)\n    return [ilabel]", "loc": 36}
{"file": "black\\src\\blib2to3\\pgen2\\parse.py", "class_name": "Parser", "function_name": "shift", "parameters": ["self", "type", "value", "newstate", "context"], "param_types": {"type": "int", "value": "str", "newstate": "int", "context": "Context"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["convert", "node[-1].append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Shift a token.  (Internal)", "source_code": "def shift(self, type: int, value: str, newstate: int, context: Context) -> None:\n    \"\"\"Shift a token.  (Internal)\"\"\"\n    if self.is_backtracking:\n        dfa, state, _ = self.stack[-1]\n        self.stack[-1] = (dfa, newstate, DUMMY_NODE)\n    else:\n        dfa, state, node = self.stack[-1]\n        rawnode: RawNode = (type, value, context, None)\n        newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode)\n        self.stack[-1] = (dfa, newstate, node)", "loc": 12}
{"file": "black\\src\\blib2to3\\pgen2\\parse.py", "class_name": "Parser", "function_name": "push", "parameters": ["self", "type", "newdfa", "newstate", "context"], "param_types": {"type": "int", "newdfa": "DFAS", "newstate": "int", "context": "Context"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.stack.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Push a nonterminal.  (Internal)", "source_code": "def push(self, type: int, newdfa: DFAS, newstate: int, context: Context) -> None:\n    \"\"\"Push a nonterminal.  (Internal)\"\"\"\n    if self.is_backtracking:\n        dfa, state, _ = self.stack[-1]\n        self.stack[-1] = (dfa, newstate, DUMMY_NODE)\n        self.stack.append((newdfa, 0, DUMMY_NODE))\n    else:\n        dfa, state, node = self.stack[-1]\n        newnode: RawNode = (type, None, context, [])\n        self.stack[-1] = (dfa, newstate, node)\n        self.stack.append((newdfa, 0, newnode))", "loc": 11}
{"file": "black\\src\\blib2to3\\pgen2\\parse.py", "class_name": "Parser", "function_name": "pop", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["convert", "node[-1].append", "self.stack.pop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Pop a nonterminal.  (Internal)", "source_code": "def pop(self) -> None:\n    \"\"\"Pop a nonterminal.  (Internal)\"\"\"\n    if self.is_backtracking:\n        self.stack.pop()\n    else:\n        popdfa, popstate, popnode = self.stack.pop()\n        newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names", "loc": 14}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "make_grammar", "parameters": ["self"], "param_types": {}, "return_type": "PgenGrammar", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PgenGrammar", "arcs.append", "c.states.append", "dfa.index", "len", "list", "names.insert", "names.remove", "names.sort", "self.dfas.keys", "self.make_first", "self.make_label", "sorted", "state.arcs.items", "states.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_grammar(self) -> PgenGrammar:\n    c = PgenGrammar()\n    names = list(self.dfas.keys())\n    names.sort()\n    names.remove(self.startsymbol)\n    names.insert(0, self.startsymbol)\n    for name in names:\n        i = 256 + len(c.symbol2number)\n        c.symbol2number[name] = i\n        c.number2symbol[i] = name\n    for name in names:\n        dfa = self.dfas[name]\n        states = []\n        for state in dfa:\n            arcs = []\n            for label, next in sorted(state.arcs.items()):\n                arcs.append((self.make_label(c, label), dfa.index(next)))\n            if state.isfinal:\n                arcs.append((0, dfa.index(state)))\n            states.append(arcs)\n        c.states.append(states)\n        c.dfas[c.symbol2number[name]] = (states, self.make_first(c, name))\n    c.start = c.symbol2number[self.startsymbol]\n    return c", "loc": 24}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "make_first", "parameters": ["self", "c", "name"], "param_types": {"c": "PgenGrammar", "name": "str"}, "return_type": "dict[int, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.make_label", "sorted"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_first(self, c: PgenGrammar, name: str) -> dict[int, int]:\n    rawfirst = self.first[name]\n    assert rawfirst is not None\n    first = {}\n    for label in sorted(rawfirst):\n        ilabel = self.make_label(c, label)\n        ##assert ilabel not in first # XXX failed on <> ... !=\n        first[ilabel] = 1\n    return first", "loc": 9}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "make_label", "parameters": ["self", "c", "label"], "param_types": {"c": "PgenGrammar", "label": "str"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["c.labels.append", "eval", "getattr", "isinstance", "label[0].isalpha", "len", "value[0].isalpha"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_label(self, c: PgenGrammar, label: str) -> int:\n    # XXX Maybe this should be a method on a subclass of converter?\n    ilabel = len(c.labels)\n    if label[0].isalpha():\n        # Either a symbol name or a named token\n        if label in c.symbol2number:\n            # A symbol name (a non-terminal)\n            if label in c.symbol2label:\n                return c.symbol2label[label]\n            else:\n                c.labels.append((c.symbol2number[label], None))\n                c.symbol2label[label] = ilabel\n                return ilabel\n        else:\n            # A named token (NAME, NUMBER, STRING)\n            itoken = getattr(token, label, None)\n            assert isinstance(itoken, int), label\n            assert itoken in token.tok_name, label\n            if itoken in c.tokens:\n                return c.tokens[itoken]\n            else:\n                c.labels.append((itoken, None))\n                c.tokens[itoken] = ilabel\n                return ilabel\n    else:\n        # Either a keyword or an operator\n        assert label[0] in ('\"', \"'\"), label\n        value = eval(label)\n        if value[0].isalpha():\n            if label[0] == '\"':\n                keywords = c.soft_keywords\n            else:\n                keywords = c.keywords\n\n            # A keyword\n            if value in keywords:\n                return keywords[value]\n            else:\n                c.labels.append((token.NAME, value))\n                keywords[value] = ilabel\n                return ilabel\n        else:\n            # An operator (any non-numeric token)\n            itoken = grammar.opmap[value]  # Fails if unknown token\n            if itoken in c.tokens:\n                return c.tokens[itoken]\n            else:\n                c.labels.append((itoken, None))\n                c.tokens[itoken] = ilabel\n                return ilabel", "loc": 50}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "addfirstsets", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["list", "names.sort", "self.calcfirst", "self.dfas.keys"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def addfirstsets(self) -> None:\n    names = list(self.dfas.keys())\n    names.sort()\n    for name in names:\n        if name not in self.first:\n            self.calcfirst(name)", "loc": 6}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "calcfirst", "parameters": ["self", "name"], "param_types": {"name": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "overlapcheck.items", "self.calcfirst", "totalset.update"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def calcfirst(self, name: str) -> None:\n    dfa = self.dfas[name]\n    self.first[name] = None  # dummy to detect left recursion\n    state = dfa[0]\n    totalset: dict[str, int] = {}\n    overlapcheck = {}\n    for label in state.arcs:\n        if label in self.dfas:\n            if label in self.first:\n                fset = self.first[label]\n                if fset is None:\n                    raise ValueError(f\"recursion for rule {name!r}\")\n            else:\n                self.calcfirst(label)\n                fset = self.first[label]\n                assert fset is not None\n            totalset.update(fset)\n            overlapcheck[label] = fset\n        else:\n            totalset[label] = 1\n            overlapcheck[label] = {label: 1}\n    inverse: dict[str, str] = {}\n    for label, itsfirst in overlapcheck.items():\n        for symbol in itsfirst:\n            if symbol in inverse:\n                raise ValueError(\n                    f\"rule {name} is ambiguous; {symbol} is in the first sets of\"\n                    f\" {label} as well as {inverse[symbol]}\"\n                )\n            inverse[symbol] = label\n    self.first[name] = totalset", "loc": 31}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "parse", "parameters": ["self"], "param_types": {}, "return_type": "tuple[dict[str, list['DFAState']], str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.expect", "self.gettoken", "self.make_dfa", "self.parse_rhs", "self.simplify_dfa"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse(self) -> tuple[dict[str, list[\"DFAState\"]], str]:\n    dfas = {}\n    startsymbol: Optional[str] = None\n    # MSTART: (NEWLINE | RULE)* ENDMARKER\n    while self.type != token.ENDMARKER:\n        while self.type == token.NEWLINE:\n            self.gettoken()\n        # RULE: NAME ':' RHS NEWLINE\n        name = self.expect(token.NAME)\n        self.expect(token.OP, \":\")\n        a, z = self.parse_rhs()\n        self.expect(token.NEWLINE)\n        # self.dump_nfa(name, a, z)\n        dfa = self.make_dfa(a, z)\n        # self.dump_dfa(name, dfa)\n        # oldlen = len(dfa)\n        self.simplify_dfa(dfa)\n        # newlen = len(dfa)\n        dfas[name] = dfa\n        # print name, oldlen, newlen\n        if startsymbol is None:\n            startsymbol = name\n    assert startsymbol is not None\n    return dfas, startsymbol", "loc": 24}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "make_dfa", "parameters": ["self", "start", "finish"], "param_types": {"start": "'NFAState'", "finish": "'NFAState'"}, "return_type": "list['DFAState']", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DFAState", "addclosure", "arcs.items", "arcs.setdefault", "closure", "isinstance", "sorted", "state.addarc", "states.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_dfa(self, start: \"NFAState\", finish: \"NFAState\") -> list[\"DFAState\"]:\n    # To turn an NFA into a DFA, we define the states of the DFA\n    # to correspond to *sets* of states of the NFA.  Then do some\n    # state reduction.  Let's represent sets as dicts with 1 for\n    # values.\n    assert isinstance(start, NFAState)\n    assert isinstance(finish, NFAState)\n\n    def closure(state: NFAState) -> dict[NFAState, int]:\n        base: dict[NFAState, int] = {}\n        addclosure(state, base)\n        return base\n\n    def addclosure(state: NFAState, base: dict[NFAState, int]) -> None:\n        assert isinstance(state, NFAState)\n        if state in base:\n            return\n        base[state] = 1\n        for label, next in state.arcs:\n            if label is None:\n                addclosure(next, base)\n\n    states = [DFAState(closure(start), finish)]\n    for state in states:  # NB states grows while we're iterating\n        arcs: dict[str, dict[NFAState, int]] = {}\n        for nfastate in state.nfaset:\n            for label, next in nfastate.arcs:\n                if label is not None:\n                    addclosure(next, arcs.setdefault(label, {}))\n        for label, nfaset in sorted(arcs.items()):\n            for st in states:\n                if st.nfaset == nfaset:\n                    break\n            else:\n                st = DFAState(nfaset, finish)\n                states.append(st)\n            state.addarc(st, label)\n    return states  # List of DFAState instances; first one is start", "loc": 38}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "dump_nfa", "parameters": ["self", "name", "start", "finish"], "param_types": {"name": "str", "start": "'NFAState'", "finish": "'NFAState'"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "len", "print", "todo.append", "todo.index"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dump_nfa(self, name: str, start: \"NFAState\", finish: \"NFAState\") -> None:\n    print(\"Dump of NFA for\", name)\n    todo = [start]\n    for i, state in enumerate(todo):\n        print(\"  State\", i, state is finish and \"(final)\" or \"\")\n        for label, next in state.arcs:\n            if next in todo:\n                j = todo.index(next)\n            else:\n                j = len(todo)\n                todo.append(next)\n            if label is None:\n                print(f\"    -> {j}\")\n            else:\n                print(f\"    {label} -> {j}\")", "loc": 15}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "dump_dfa", "parameters": ["self", "name", "dfa"], "param_types": {"name": "str", "dfa": "Sequence['DFAState']"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dfa.index", "enumerate", "print", "sorted", "state.arcs.items"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dump_dfa(self, name: str, dfa: Sequence[\"DFAState\"]) -> None:\n    print(\"Dump of DFA for\", name)\n    for i, state in enumerate(dfa):\n        print(\"  State\", i, state.isfinal and \"(final)\" or \"\")\n        for label, next in sorted(state.arcs.items()):\n            print(f\"    {label} -> {dfa.index(next)}\")", "loc": 6}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "simplify_dfa", "parameters": ["self", "dfa"], "param_types": {"dfa": "list['DFAState']"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "len", "range", "state.unifystate"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def simplify_dfa(self, dfa: list[\"DFAState\"]) -> None:\n    # This is not theoretically optimal, but works well enough.\n    # Algorithm: repeatedly look for two states that have the same\n    # set of arcs (same labels pointing to the same nodes) and\n    # unify them, until things stop changing.\n\n    # dfa is a list of DFAState instances\n    changes = True\n    while changes:\n        changes = False\n        for i, state_i in enumerate(dfa):\n            for j in range(i + 1, len(dfa)):\n                state_j = dfa[j]\n                if state_i == state_j:\n                    # print \"  unify\", i, j\n                    del dfa[j]\n                    for state in dfa:\n                        state.unifystate(state_j, state_i)\n                    changes = True\n                    break", "loc": 20}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "parse_rhs", "parameters": ["self"], "param_types": {}, "return_type": "tuple['NFAState', 'NFAState']", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NFAState", "aa.addarc", "self.gettoken", "self.parse_alt", "z.addarc"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_rhs(self) -> tuple[\"NFAState\", \"NFAState\"]:\n    # RHS: ALT ('|' ALT)*\n    a, z = self.parse_alt()\n    if self.value != \"|\":\n        return a, z\n    else:\n        aa = NFAState()\n        zz = NFAState()\n        aa.addarc(a)\n        z.addarc(zz)\n        while self.value == \"|\":\n            self.gettoken()\n            a, z = self.parse_alt()\n            aa.addarc(a)\n            z.addarc(zz)\n        return aa, zz", "loc": 16}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "parse_alt", "parameters": ["self"], "param_types": {}, "return_type": "tuple['NFAState', 'NFAState']", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["b.addarc", "self.parse_item"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_alt(self) -> tuple[\"NFAState\", \"NFAState\"]:\n    # ALT: ITEM+\n    a, b = self.parse_item()\n    while self.value in (\"(\", \"[\") or self.type in (token.NAME, token.STRING):\n        c, d = self.parse_item()\n        b.addarc(c)\n        b = d\n    return a, b", "loc": 8}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "parse_item", "parameters": ["self"], "param_types": {}, "return_type": "tuple['NFAState', 'NFAState']", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["a.addarc", "self.expect", "self.gettoken", "self.parse_atom", "self.parse_rhs", "z.addarc"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_item(self) -> tuple[\"NFAState\", \"NFAState\"]:\n    # ITEM: '[' RHS ']' | ATOM ['+' | '*']\n    if self.value == \"[\":\n        self.gettoken()\n        a, z = self.parse_rhs()\n        self.expect(token.OP, \"]\")\n        a.addarc(z)\n        return a, z\n    else:\n        a, z = self.parse_atom()\n        value = self.value\n        if value not in (\"+\", \"*\"):\n            return a, z\n        self.gettoken()\n        z.addarc(a)\n        if value == \"+\":\n            return a, z\n        else:\n            return a, a", "loc": 19}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "parse_atom", "parameters": ["self"], "param_types": {}, "return_type": "tuple['NFAState', 'NFAState']", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NFAState", "a.addarc", "self.expect", "self.gettoken", "self.parse_rhs", "self.raise_error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_atom(self) -> tuple[\"NFAState\", \"NFAState\"]:\n    # ATOM: '(' RHS ')' | NAME | STRING\n    if self.value == \"(\":\n        self.gettoken()\n        a, z = self.parse_rhs()\n        self.expect(token.OP, \")\")\n        return a, z\n    elif self.type in (token.NAME, token.STRING):\n        a = NFAState()\n        z = NFAState()\n        a.addarc(z, self.value)\n        self.gettoken()\n        return a, z\n    else:\n        self.raise_error(\n            f\"expected (...) or NAME or STRING, got {self.type}/{self.value}\"\n        )", "loc": 17}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "expect", "parameters": ["self", "type", "value"], "param_types": {"type": "int", "value": "Optional[Any]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.gettoken", "self.raise_error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def expect(self, type: int, value: Optional[Any] = None) -> str:\n    if self.type != type or (value is not None and self.value != value):\n        self.raise_error(f\"expected {type}/{value}, got {self.type}/{self.value}\")\n    value = self.value\n    self.gettoken()\n    return value", "loc": 6}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": "ParserGenerator", "function_name": "gettoken", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["next"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def gettoken(self) -> None:\n    tup = next(self.generator)\n    while tup[0] in (tokenize.COMMENT, tokenize.NL):\n        tup = next(self.generator)\n    self.type, self.value, self.begin, self.end, self.line = tup", "loc": 5}
{"file": "black\\src\\blib2to3\\pgen2\\pgen.py", "class_name": null, "function_name": "addclosure", "parameters": ["state", "base"], "param_types": {"state": "NFAState", "base": "dict[NFAState, int]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["addclosure", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def addclosure(state: NFAState, base: dict[NFAState, int]) -> None:\n    assert isinstance(state, NFAState)\n    if state in base:\n        return\n    base[state] = 1\n    for label, next in state.arcs:\n        if label is None:\n            addclosure(next, base)", "loc": 8}
{"file": "black\\src\\blib2to3\\pgen2\\tokenize.py", "class_name": null, "function_name": "transform_whitespace", "parameters": ["token", "source", "prev_token"], "param_types": {"token": "pytokens.Token", "source": "str", "prev_token": "Optional[pytokens.Token]"}, "return_type": "pytokens.Token", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["pytokens.Token", "token_str.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Black treats `\\\\\\n` at the end of a line as a 'NL' token, while it is ignored as whitespace in the regular Python parser. But, only the first one. If there's a `\\\\\\n` following it", "source_code": "def transform_whitespace(\n    token: pytokens.Token, source: str, prev_token: Optional[pytokens.Token]\n) -> pytokens.Token:\n    r\"\"\"\n    Black treats `\\\\\\n` at the end of a line as a 'NL' token, while it\n    is ignored as whitespace in the regular Python parser.\n    But, only the first one. If there's a `\\\\\\n` following it\n    (as in, a \\ just by itself on a line), that is not made into NL.\n    \"\"\"\n    if (\n        token.type == TokenType.whitespace\n        and prev_token is not None\n        and prev_token.type not in (TokenType.nl, TokenType.newline)\n    ):\n        token_str = source[token.start_index : token.end_index]\n        if token_str.startswith(\"\\\\\\r\\n\"):\n            return pytokens.Token(\n                TokenType.nl,\n                token.start_index,\n                token.start_index + 3,\n                token.start_line,\n                token.start_col,\n                token.start_line,\n                token.start_col + 3,\n            )\n        elif token_str.startswith(\"\\\\\\n\") or token_str.startswith(\"\\\\\\r\"):\n            return pytokens.Token(\n                TokenType.nl,\n                token.start_index,\n                token.start_index + 2,\n                token.start_line,\n                token.start_col,\n                token.start_line,\n                token.start_col + 2,\n            )\n\n    return token", "loc": 37}
{"file": "black\\src\\blib2to3\\pgen2\\tokenize.py", "class_name": null, "function_name": "tokenize", "parameters": ["source", "grammar"], "param_types": {"source": "str", "grammar": "Optional[Grammar]"}, "return_type": "Iterator[TokenInfo]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TokenError", "pytokens.tokenize", "range", "source.split", "transform_whitespace", "type"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def tokenize(source: str, grammar: Optional[Grammar] = None) -> Iterator[TokenInfo]:\n    lines = source.split(\"\\n\")\n    lines += [\"\"]  # For newline tokens in files that don't end in a newline\n    line, column = 1, 0\n\n    prev_token: Optional[pytokens.Token] = None\n    try:\n        for token in pytokens.tokenize(source):\n            token = transform_whitespace(token, source, prev_token)\n\n            line, column = token.start_line, token.start_col\n            if token.type == TokenType.whitespace:\n                continue\n\n            token_str = source[token.start_index : token.end_index]\n\n            if token.type == TokenType.newline and token_str == \"\":\n                # Black doesn't yield empty newline tokens at the end of a file\n                # if there's no newline at the end of a file.\n                prev_token = token\n                continue\n\n            source_line = lines[token.start_line - 1]\n\n            if token.type == TokenType.identifier and token_str in (\"async\", \"await\"):\n                # Black uses `async` and `await` token types just for those two keywords\n                yield (\n                    ASYNC if token_str == \"async\" else AWAIT,\n                    token_str,\n                    (token.start_line, token.start_col),\n                    (token.end_line, token.end_col),\n                    source_line,\n                )\n            elif token.type == TokenType.op and token_str == \"...\":\n                # Black doesn't have an ellipsis token yet, yield 3 DOTs instead\n                assert token.start_line == token.end_line\n                assert token.end_col == token.start_col + 3\n\n                token_str = \".\"\n                for start_col in range(token.start_col, token.start_col + 3):\n                    end_col = start_col + 1\n                    yield (\n                        TOKEN_TYPE_MAP[token.type],\n                        token_str,\n                        (token.start_line, start_col),\n                        (token.end_line, end_col),\n                        source_line,\n                    )\n            else:\n                yield (\n                    TOKEN_TYPE_MAP[token.type],\n                    token_str,\n                    (token.start_line, token.start_col),\n                    (token.end_line, token.end_col),\n                    source_line,\n                )\n            prev_token = token\n\n    except pytokens.UnexpectedEOF:\n        raise TokenError(\"Unexpected EOF in multi-line statement\", (line, column))\n    except pytokens.TokenizeError as exc:\n        raise TokenError(f\"Failed to parse: {type(exc).__name__}\", (line, column))", "loc": 62}
{"file": "codetiming\\codetiming\\_timer.py", "class_name": "Timer", "function_name": "start", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Timer {name} started'.format", "TimerError", "isinstance", "self.initial_text.format", "self.logger", "time.perf_counter"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Start a new timer.", "source_code": "def start(self) -> None:\n    \"\"\"Start a new timer.\"\"\"\n    if self._start_time is not None:\n        raise TimerError(\"Timer is running. Use .stop() to stop it\")\n\n    # Log initial text when timer starts\n    if self.logger and self.initial_text:\n        if isinstance(self.initial_text, str):\n            initial_text = self.initial_text.format(name=self.name)\n        elif self.name:\n            initial_text = \"Timer {name} started\".format(name=self.name)\n        else:\n            initial_text = \"Timer started\"\n        self.logger(initial_text)\n\n    self._start_time = time.perf_counter()", "loc": 16}
{"file": "codetiming\\codetiming\\_timer.py", "class_name": "Timer", "function_name": "stop", "parameters": ["self"], "param_types": {}, "return_type": "float", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TimerError", "callable", "self.logger", "self.text", "self.text.format", "self.timers.add", "str", "time.perf_counter"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Stop the timer, and report the elapsed time.", "source_code": "def stop(self) -> float:\n    \"\"\"Stop the timer, and report the elapsed time.\"\"\"\n    if self._start_time is None:\n        raise TimerError(\"Timer is not running. Use .start() to start it\")\n\n    # Calculate elapsed time\n    self.last = time.perf_counter() - self._start_time\n    self._start_time = None\n\n    # Report elapsed time\n    if self.logger:\n        if callable(self.text):\n            text = self.text(self.last)\n        else:\n            attributes = {\n                \"name\": self.name,\n                \"milliseconds\": self.last * 1000,\n                \"seconds\": self.last,\n                \"minutes\": self.last / 60,\n            }\n            text = self.text.format(self.last, **attributes)\n        self.logger(str(text))\n    if self.name:\n        self.timers.add(self.name, self.last)\n\n    return self.last", "loc": 26}
{"file": "codetiming\\codetiming\\_timers.py", "class_name": "Timers", "function_name": "add", "parameters": ["self", "name", "value"], "param_types": {"name": "str", "value": "float"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._timings[name].append", "self.data.setdefault"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Add a timing value to the given timer.", "source_code": "def add(self, name: str, value: float) -> None:\n    \"\"\"Add a timing value to the given timer.\"\"\"\n    self._timings[name].append(value)\n    self.data.setdefault(name, 0)\n    self.data[name] += value", "loc": 5}
{"file": "codetiming\\codetiming\\_timers.py", "class_name": "Timers", "function_name": "apply", "parameters": ["self", "func", "name"], "param_types": {"func": "Callable[[List[float]], float]", "name": "str"}, "return_type": "float", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["KeyError", "func"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Apply a function to the results of one named timer.", "source_code": "def apply(self, func: Callable[[List[float]], float], name: str) -> float:\n    \"\"\"Apply a function to the results of one named timer.\"\"\"\n    if name in self._timings:\n        return func(self._timings[name])\n    raise KeyError(name)", "loc": 5}
{"file": "codetiming\\codetiming\\_timers.py", "class_name": "Timers", "function_name": "stdev", "parameters": ["self", "name"], "param_types": {"name": "str"}, "return_type": "float", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["KeyError", "len", "statistics.stdev"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Standard deviation of timings.", "source_code": "def stdev(self, name: str) -> float:\n    \"\"\"Standard deviation of timings.\"\"\"\n    if name in self._timings:\n        value = self._timings[name]\n        return statistics.stdev(value) if len(value) >= 2 else math.nan\n    raise KeyError(name)", "loc": 6}
{"file": "dataclasses-json\\dataclasses_json\\api.py", "class_name": null, "function_name": "dataclass_json", "parameters": ["_cls"], "param_types": {"_cls": "Optional[Type[T]]"}, "return_type": "Union[Callable[[Type[T]], Type[T]], Type[T]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_process_class", "wrap"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Based on the code in the `dataclasses` module to handle optional-parens decorators. See example below: @dataclass_json", "source_code": "def dataclass_json(_cls: Optional[Type[T]] = None, *, letter_case: Optional[LetterCase] = None,\n                   undefined: Optional[Union[str, Undefined]] = None) -> Union[Callable[[Type[T]], Type[T]], Type[T]]:\n    \"\"\"\n    Based on the code in the `dataclasses` module to handle optional-parens\n    decorators. See example below:\n\n    @dataclass_json\n    @dataclass_json(letter_case=LetterCase.CAMEL)\n    class Example:\n        ...\n    \"\"\"\n\n    def wrap(cls: Type[T]) -> Type[T]:\n        return _process_class(cls, letter_case, undefined)\n\n    if _cls is None:\n        return wrap\n    return wrap(_cls)", "loc": 18}
{"file": "dataclasses-json\\dataclasses_json\\api.py", "class_name": "DataClassJsonMixin", "function_name": "to_json", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["json.dumps", "self.to_dict"], "control_structures": [], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def to_json(self,\n            *,\n            skipkeys: bool = False,\n            ensure_ascii: bool = True,\n            check_circular: bool = True,\n            allow_nan: bool = True,\n            indent: Optional[Union[int, str]] = None,\n            separators: Optional[Tuple[str, str]] = None,\n            default: Optional[Callable] = None,\n            sort_keys: bool = False,\n            **kw) -> str:\n    return json.dumps(self.to_dict(encode_json=False),\n                      cls=_ExtendedEncoder,\n                      skipkeys=skipkeys,\n                      ensure_ascii=ensure_ascii,\n                      check_circular=check_circular,\n                      allow_nan=allow_nan,\n                      indent=indent,\n                      separators=separators,\n                      default=default,\n                      sort_keys=sort_keys,\n                      **kw)", "loc": 22}
{"file": "dataclasses-json\\dataclasses_json\\api.py", "class_name": "DataClassJsonMixin", "function_name": "from_json", "parameters": ["cls", "s"], "param_types": {"cls": "Type[A]", "s": "JsonData"}, "return_type": "A", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls.from_dict", "json.loads"], "control_structures": [], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def from_json(cls: Type[A],\n              s: JsonData,\n              *,\n              parse_float=None,\n              parse_int=None,\n              parse_constant=None,\n              infer_missing=False,\n              **kw) -> A:\n    kvs = json.loads(s,\n                     parse_float=parse_float,\n                     parse_int=parse_int,\n                     parse_constant=parse_constant,\n                     **kw)\n    return cls.from_dict(kvs, infer_missing=infer_missing)", "loc": 14}
{"file": "dataclasses-json\\dataclasses_json\\api.py", "class_name": "DataClassJsonMixin", "function_name": "schema", "parameters": ["cls"], "param_types": {"cls": "Type[A]"}, "return_type": "'SchemaType[A]'", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Schema", "_undefined_parameter_action_safe", "build_schema", "undefined_parameter_action.name.lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def schema(cls: Type[A],\n           *,\n           infer_missing: bool = False,\n           only=None,\n           exclude=(),\n           many: bool = False,\n           context=None,\n           load_only=(),\n           dump_only=(),\n           partial: bool = False,\n           unknown=None) -> \"SchemaType[A]\":\n    Schema = build_schema(cls, DataClassJsonMixin, infer_missing, partial)\n\n    if unknown is None:\n        undefined_parameter_action = _undefined_parameter_action_safe(cls)\n        if undefined_parameter_action is not None:\n            # We can just make use of the same-named mm keywords\n            unknown = undefined_parameter_action.name.lower()\n\n    return Schema(only=only,\n                  exclude=exclude,\n                  many=many,\n                  context=context,\n                  load_only=load_only,\n                  dump_only=dump_only,\n                  partial=partial,\n                  unknown=unknown)", "loc": 27}
{"file": "dataclasses-json\\dataclasses_json\\cfg.py", "class_name": null, "function_name": "config", "parameters": ["metadata"], "param_types": {"metadata": "Optional[dict]"}, "return_type": "Dict[str, dict]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["UndefinedParameterError", "_letter_case", "functools.wraps", "hasattr", "isinstance", "list", "metadata.setdefault", "undefined.upper"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def config(metadata: Optional[dict] = None, *,\n           # TODO: these can be typed more precisely\n           # Specifically, a Callable[A, B], where `B` is bound as a JSON type\n           encoder: Optional[Callable] = None,\n           decoder: Optional[Callable] = None,\n           mm_field: Optional[MarshmallowField] = None,\n           letter_case: Union[Callable[[str], str], LetterCase, None] = None,\n           undefined: Optional[Union[str, Undefined]] = None,\n           field_name: Optional[str] = None,\n           exclude: Optional[Callable[[T], bool]] = None,\n           ) -> Dict[str, dict]:\n    if metadata is None:\n        metadata = {}\n\n    lib_metadata = metadata.setdefault('dataclasses_json', {})\n\n    if encoder is not None:\n        lib_metadata['encoder'] = encoder\n\n    if decoder is not None:\n        lib_metadata['decoder'] = decoder\n\n    if mm_field is not None:\n        lib_metadata['mm_field'] = mm_field\n\n    if field_name is not None:\n        if letter_case is not None:\n            @functools.wraps(letter_case)  # type:ignore\n            def override(_, _letter_case=letter_case, _field_name=field_name):\n                return _letter_case(_field_name)\n        else:\n            def override(_, _field_name=field_name):  # type:ignore\n                return _field_name\n        letter_case = override\n\n    if letter_case is not None:\n        lib_metadata['letter_case'] = letter_case\n\n    if undefined is not None:\n        # Get the corresponding action for undefined parameters\n        if isinstance(undefined, str):\n            if not hasattr(Undefined, undefined.upper()):\n                valid_actions = list(action.name for action in Undefined)\n                raise UndefinedParameterError(\n                    f\"Invalid undefined parameter action, \"\n                    f\"must be one of {valid_actions}\")\n            undefined = Undefined[undefined.upper()]\n\n        lib_metadata['undefined'] = undefined\n\n    if exclude is not None:\n        lib_metadata['exclude'] = exclude\n\n    return metadata", "loc": 54}
{"file": "dataclasses-json\\dataclasses_json\\core.py", "class_name": "_ExtendedEncoder", "function_name": "default", "parameters": ["self", "o"], "param_types": {}, "return_type": "Json", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_isinstance_safe", "dict", "json.JSONEncoder.default", "list", "o.timestamp", "str"], "control_structures": ["If"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def default(self, o) -> Json:\n    result: Json\n    if _isinstance_safe(o, Collection):\n        if _isinstance_safe(o, Mapping):\n            result = dict(o)\n        else:\n            result = list(o)\n    elif _isinstance_safe(o, datetime):\n        result = o.timestamp()\n    elif _isinstance_safe(o, UUID):\n        result = str(o)\n    elif _isinstance_safe(o, Enum):\n        result = o.value\n    elif _isinstance_safe(o, Decimal):\n        result = str(o)\n    else:\n        result = json.JSONEncoder.default(self, o)\n    return result", "loc": 18}
{"file": "dataclasses-json\\dataclasses_json\\core.py", "class_name": null, "function_name": "handle_pep0673", "parameters": ["pre_0673_hint"], "param_types": {"pre_0673_hint": "str"}, "return_type": "Union[Type, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "hasattr", "sys.modules.values", "warnings.warn"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_pep0673(pre_0673_hint: str) -> Union[Type, str]:\n    for module in sys.modules.values():\n        if hasattr(module, type_args):\n            maybe_resolved = getattr(module, type_args)\n            warnings.warn(f\"Assuming hint {pre_0673_hint} resolves to {maybe_resolved} \"\n                          \"This is not necessarily the value that is in-scope.\")\n            return maybe_resolved\n\n    warnings.warn(f\"Could not resolve self-reference for type {pre_0673_hint}, \"\n                  f\"decoded type might be incorrect or decode might fail altogether.\")\n    return pre_0673_hint", "loc": 11}
{"file": "dataclasses-json\\dataclasses_json\\mm.py", "class_name": null, "function_name": "build_type", "parameters": ["type_", "options", "mixin", "field", "cls"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_TupleVarLen", "_UnionField", "_is_collection", "_is_new_type", "_is_optional", "_is_supported_generic", "_issubclass_safe", "bool", "dict", "fields.Enum", "fields.Field", "fields.Nested", "fields.Tuple", "getattr", "inner", "is_dataclass", "is_union_type", "len", "type", "type_.schema", "warnings.warn", "zip"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def build_type(type_, options, mixin, field, cls):\n    def inner(type_, options):\n        while True:\n            if not _is_new_type(type_):\n                break\n\n            type_ = type_.__supertype__\n\n        if is_dataclass(type_):\n            if _issubclass_safe(type_, mixin):\n                options['field_many'] = bool(\n                    _is_supported_generic(field.type) and _is_collection(\n                        field.type))\n                return fields.Nested(type_.schema(), **options)\n            else:\n                warnings.warn(f\"Nested dataclass field {field.name} of type \"\n                              f\"{field.type} detected in \"\n                              f\"{cls.__name__} that is not an instance of \"\n                              f\"dataclass_json. Did you mean to recursively \"\n                              f\"serialize this field? If so, make sure to \"\n                              f\"augment {type_} with either the \"\n                              f\"`dataclass_json` decorator or mixin.\")\n                return fields.Field(**options)\n\n        origin = getattr(type_, '__origin__', type_)\n        args = [inner(a, {}) for a in getattr(type_, '__args__', []) if\n                a is not type(None)]\n\n        if type_ == Ellipsis:\n            return type_\n\n        if _is_optional(type_):\n            options[\"allow_none\"] = True\n        if origin is tuple:\n            if len(args) == 2 and args[1] == Ellipsis:\n                return _TupleVarLen(args[0], **options)\n            else:\n                return fields.Tuple(args, **options)\n        if origin in TYPES:\n            return TYPES[origin](*args, **options)\n\n        if _issubclass_safe(origin, Enum):\n            return fields.Enum(enum=origin, by_value=True, *args, **options)\n\n        if is_union_type(type_):\n            union_types = [a for a in getattr(type_, '__args__', []) if\n                           a is not type(None)]\n            union_desc = dict(zip(union_types, args))\n            return _UnionField(union_desc, cls, field, **options)\n\n        warnings.warn(\n            f\"Unknown type {type_} at {cls.__name__}.{field.name}: {field.type} \"\n            f\"It's advised to pass the correct marshmallow type to `mm_field`.\")\n        return fields.Field(**options)\n\n    return inner(type_, options)", "loc": 56}
{"file": "dataclasses-json\\dataclasses_json\\mm.py", "class_name": null, "function_name": "schema", "parameters": ["cls", "mixin", "infer_missing"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_is_optional", "_user_overrides_or_exts", "build_type", "dc_fields", "field.default_factory", "field.metadata.get", "field.metadata.get('dataclasses_json', {}).get", "len", "metadata.letter_case", "options.get", "options.setdefault", "type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def schema(cls, mixin, infer_missing):\n    schema = {}\n    overrides = _user_overrides_or_exts(cls)\n    # TODO check the undefined parameters and add the proper schema action\n    #  https://marshmallow.readthedocs.io/en/stable/quickstart.html\n    for field in dc_fields(cls):\n        metadata = overrides[field.name]\n        if metadata.mm_field is not None:\n            schema[field.name] = metadata.mm_field\n        else:\n            type_ = field.type\n            options: typing.Dict[str, typing.Any] = {}\n            missing_key = 'missing' if infer_missing else 'default'\n            if field.default is not MISSING:\n                options[missing_key] = field.default\n            elif field.default_factory is not MISSING:\n                options[missing_key] = field.default_factory()\n            else:\n                options['required'] = True\n\n            if options.get(missing_key, ...) is None:\n                options['allow_none'] = True\n\n            if _is_optional(type_):\n                options.setdefault(missing_key, None)\n                options['allow_none'] = True\n                if len(type_.__args__) == 2:\n                    # Union[str, int, None] is optional too, but it has more than 1 typed field.\n                    type_ = [tp for tp in type_.__args__ if tp is not type(None)][0]\n\n            if metadata.letter_case is not None:\n                options['data_key'] = metadata.letter_case(field.name)\n\n            t = build_type(type_, options, mixin, field, cls)\n            if field.metadata.get('dataclasses_json', {}).get('decoder'):\n                # If the field defines a custom decoder, it should completely replace the Marshmallow field's conversion\n                # logic.\n                # From Marshmallow's documentation for the _deserialize method:\n                # \"Deserialize value. Concrete :class:`Field` classes should implement this method. \"\n                # This is the method that Field implementations override to perform the actual deserialization logic.\n                # In this case we specifically override this method instead of `deserialize` to minimize potential\n                # side effects, and only cancel the actual value deserialization.\n                t._deserialize = lambda v, *_a, **_kw: v\n\n            # if type(t) is not fields.Field:  # If we use `isinstance` we would return nothing.\n            if field.type != typing.Optional[CatchAllVar]:\n                schema[field.name] = t\n\n    return schema", "loc": 49}
{"file": "dataclasses-json\\dataclasses_json\\mm.py", "class_name": null, "function_name": "build_schema", "parameters": ["cls", "mixin", "infer_missing", "partial"], "param_types": {"cls": "typing.Type[A]"}, "return_type": "typing.Type['SchemaType[A]']", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Schema.dump", "Schema.dumps", "_decode_dataclass", "_handle_undefined_parameters_safe", "bool", "cls.__name__.capitalize", "cls.__name__.lower", "dc_fields", "dumped.update", "dumped[i].update", "enumerate", "schema", "tuple", "type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def build_schema(cls: typing.Type[A],\n                 mixin,\n                 infer_missing,\n                 partial) -> typing.Type[\"SchemaType[A]\"]:\n    Meta = type('Meta',\n                (),\n                {'fields': tuple(field.name for field in dc_fields(cls)  # type: ignore\n                                 if\n                                 field.name != 'dataclass_json_config' and field.type !=\n                                 typing.Optional[CatchAllVar]),\n                 # TODO #180\n                 # 'render_module': global_config.json_module\n                 })\n\n    @post_load\n    def make_instance(self, kvs, **kwargs):\n        return _decode_dataclass(cls, kvs, partial)\n\n    def dumps(self, *args, **kwargs):\n        if 'cls' not in kwargs:\n            kwargs['cls'] = _ExtendedEncoder\n\n        return Schema.dumps(self, *args, **kwargs)\n\n    def dump(self, obj, *, many=None):\n        many = self.many if many is None else bool(many)\n        dumped = Schema.dump(self, obj, many=many)\n        # TODO This is hacky, but the other option I can think of is to generate a different schema\n        #  depending on dump and load, which is even more hacky\n\n        # The only problem is the catch-all field, we can't statically create a schema for it,\n        # so we just update the dumped dict\n        if many:\n            for i, _obj in enumerate(obj):\n                dumped[i].update(\n                    _handle_undefined_parameters_safe(cls=_obj, kvs={},\n                                                      usage=\"dump\"))\n        else:\n            dumped.update(_handle_undefined_parameters_safe(cls=obj, kvs={},\n                                                            usage=\"dump\"))\n        return dumped\n\n    schema_ = schema(cls, mixin, infer_missing)\n    DataClassSchema: typing.Type[\"SchemaType[A]\"] = type(\n        f'{cls.__name__.capitalize()}Schema',\n        (Schema,),\n        {'Meta': Meta,\n         f'make_{cls.__name__.lower()}': make_instance,\n         'dumps': dumps,\n         'dump': dump,\n         **schema_})\n\n    return DataClassSchema", "loc": 53}
{"file": "dataclasses-json\\dataclasses_json\\mm.py", "class_name": null, "function_name": "inner", "parameters": ["type_", "options"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_TupleVarLen", "_UnionField", "_is_collection", "_is_new_type", "_is_optional", "_is_supported_generic", "_issubclass_safe", "bool", "dict", "fields.Enum", "fields.Field", "fields.Nested", "fields.Tuple", "getattr", "inner", "is_dataclass", "is_union_type", "len", "type", "type_.schema", "warnings.warn", "zip"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def inner(type_, options):\n    while True:\n        if not _is_new_type(type_):\n            break\n\n        type_ = type_.__supertype__\n\n    if is_dataclass(type_):\n        if _issubclass_safe(type_, mixin):\n            options['field_many'] = bool(\n                _is_supported_generic(field.type) and _is_collection(\n                    field.type))\n            return fields.Nested(type_.schema(), **options)\n        else:\n            warnings.warn(f\"Nested dataclass field {field.name} of type \"\n                          f\"{field.type} detected in \"\n                          f\"{cls.__name__} that is not an instance of \"\n                          f\"dataclass_json. Did you mean to recursively \"\n                          f\"serialize this field? If so, make sure to \"\n                          f\"augment {type_} with either the \"\n                          f\"`dataclass_json` decorator or mixin.\")\n            return fields.Field(**options)\n\n    origin = getattr(type_, '__origin__', type_)\n    args = [inner(a, {}) for a in getattr(type_, '__args__', []) if\n            a is not type(None)]\n\n    if type_ == Ellipsis:\n        return type_\n\n    if _is_optional(type_):\n        options[\"allow_none\"] = True\n    if origin is tuple:\n        if len(args) == 2 and args[1] == Ellipsis:\n            return _TupleVarLen(args[0], **options)\n        else:\n            return fields.Tuple(args, **options)\n    if origin in TYPES:\n        return TYPES[origin](*args, **options)\n\n    if _issubclass_safe(origin, Enum):\n        return fields.Enum(enum=origin, by_value=True, *args, **options)\n\n    if is_union_type(type_):\n        union_types = [a for a in getattr(type_, '__args__', []) if\n                       a is not type(None)]\n        union_desc = dict(zip(union_types, args))\n        return _UnionField(union_desc, cls, field, **options)\n\n    warnings.warn(\n        f\"Unknown type {type_} at {cls.__name__}.{field.name}: {field.type} \"\n        f\"It's advised to pass the correct marshmallow type to `mm_field`.\")\n    return fields.Field(**options)", "loc": 53}
{"file": "dataclasses-json\\dataclasses_json\\mm.py", "class_name": null, "function_name": "dumps", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Schema.dumps"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dumps(self, *args, **kwargs):\n    if 'cls' not in kwargs:\n        kwargs['cls'] = _ExtendedEncoder\n\n    return Schema.dumps(self, *args, **kwargs)", "loc": 5}
{"file": "dataclasses-json\\dataclasses_json\\mm.py", "class_name": null, "function_name": "dump", "parameters": ["self", "obj"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Schema.dump", "_handle_undefined_parameters_safe", "bool", "dumped.update", "dumped[i].update", "enumerate"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dump(self, obj, *, many=None):\n    many = self.many if many is None else bool(many)\n    dumped = Schema.dump(self, obj, many=many)\n    # TODO This is hacky, but the other option I can think of is to generate a different schema\n    #  depending on dump and load, which is even more hacky\n\n    # The only problem is the catch-all field, we can't statically create a schema for it,\n    # so we just update the dumped dict\n    if many:\n        for i, _obj in enumerate(obj):\n            dumped[i].update(\n                _handle_undefined_parameters_safe(cls=_obj, kvs={},\n                                                  usage=\"dump\"))\n    else:\n        dumped.update(_handle_undefined_parameters_safe(cls=obj, kvs={},\n                                                        usage=\"dump\"))\n    return dumped", "loc": 17}
{"file": "dataclasses-json\\dataclasses_json\\stringcase.py", "class_name": null, "function_name": "uplowcase", "parameters": ["string", "case"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["str", "str(string).lower", "str(string).upper"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convert string into upper or lower case.", "source_code": "def uplowcase(string, case):\n    \"\"\"Convert string into upper or lower case.\n\n    Args:\n        string: String to convert.\n\n    Returns:\n        string: Uppercase or lowercase case string.\n\n    \"\"\"\n    if case == 'up':\n        return str(string).upper()\n    elif case == 'low':\n        return str(string).lower()", "loc": 14}
{"file": "dataclasses-json\\dataclasses_json\\stringcase.py", "class_name": null, "function_name": "capitalcase", "parameters": ["string"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["str", "uplowcase"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convert string into capital case. First letters will be uppercase.", "source_code": "def capitalcase(string):\n    \"\"\"Convert string into capital case.\n    First letters will be uppercase.\n\n    Args:\n        string: String to convert.\n\n    Returns:\n        string: Capital case string.\n\n    \"\"\"\n\n    string = str(string)\n    if not string:\n        return string\n    return uplowcase(string[0], 'up') + string[1:]", "loc": 16}
{"file": "dataclasses-json\\dataclasses_json\\stringcase.py", "class_name": null, "function_name": "camelcase", "parameters": ["string"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["matched.group", "re.sub", "str", "uplowcase"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convert string into camel case.", "source_code": "def camelcase(string):\n    \"\"\" Convert string into camel case.\n\n    Args:\n        string: String to convert.\n\n    Returns:\n        string: Camel case string.\n\n    \"\"\"\n\n    string = re.sub(r\"^[\\-_\\.]\", '', str(string))\n    if not string:\n        return string\n    return (uplowcase(string[0], 'low')\n            + re.sub(r\"[\\-_\\.\\s]([a-z0-9])\",\n                     lambda matched: uplowcase(matched.group(1), 'up'),\n                     string[1:]))", "loc": 18}
{"file": "dataclasses-json\\dataclasses_json\\stringcase.py", "class_name": null, "function_name": "snakecase", "parameters": ["string"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["matched.group", "re.sub", "str", "uplowcase"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convert string into snake case. Join punctuation with underscore", "source_code": "def snakecase(string):\n    \"\"\"Convert string into snake case.\n    Join punctuation with underscore\n\n    Args:\n        string: String to convert.\n\n    Returns:\n        string: Snake cased string.\n\n    \"\"\"\n\n    string = re.sub(r\"[\\-\\.\\s]\", '_', str(string))\n    if not string:\n        return string\n    return (uplowcase(string[0], 'low')\n            + re.sub(r\"[A-Z0-9]\",\n                     lambda matched: '_' + uplowcase(matched.group(0), 'low'),\n                     string[1:]))", "loc": 19}
{"file": "dataclasses-json\\dataclasses_json\\stringcase.py", "class_name": null, "function_name": "spinalcase", "parameters": ["string"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["re.sub", "snakecase"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Convert string into spinal case. Join punctuation with hyphen.", "source_code": "def spinalcase(string):\n    \"\"\"Convert string into spinal case.\n    Join punctuation with hyphen.\n\n    Args:\n        string: String to convert.\n\n    Returns:\n        string: Spinal cased string.\n\n    \"\"\"\n\n    return re.sub(r\"_\", \"-\", snakecase(string))", "loc": 13}
{"file": "dataclasses-json\\dataclasses_json\\stringcase.py", "class_name": null, "function_name": "pascalcase", "parameters": ["string"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["camelcase", "capitalcase"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Convert string into pascal case.", "source_code": "def pascalcase(string):\n    \"\"\"Convert string into pascal case.\n\n    Args:\n        string: String to convert.\n\n    Returns:\n        string: Pascal case string.\n\n    \"\"\"\n\n    return capitalcase(camelcase(string))", "loc": 12}
{"file": "dataclasses-json\\dataclasses_json\\undefined.py", "class_name": "_RaiseUndefinedParameters", "function_name": "handle_from_dict", "parameters": ["cls", "kvs"], "param_types": {"kvs": "Dict"}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["UndefinedParameterError", "_UndefinedParameterAction._separate_defined_undefined_kvs", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_from_dict(cls, kvs: Dict) -> Dict[str, Any]:\n    known, unknown = \\\n        _UndefinedParameterAction._separate_defined_undefined_kvs(\n            cls=cls, kvs=kvs)\n    if len(unknown) > 0:\n        raise UndefinedParameterError(\n            f\"Received undefined initialization arguments {unknown}\")\n    return known", "loc": 8}
{"file": "dataclasses-json\\dataclasses_json\\undefined.py", "class_name": "_IgnoreUndefinedParameters", "function_name": "create_init", "parameters": ["obj"], "param_types": {}, "return_type": "Callable", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_CatchAllUndefinedParameters._separate_defined_undefined_kvs", "_IgnoreUndefinedParameters.handle_from_dict", "arguments.pop", "bound_parameters.apply_defaults", "functools.wraps", "init_signature.bind_partial", "inspect.signature", "len", "original_init"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_init(obj) -> Callable:\n    original_init = obj.__init__\n    init_signature = inspect.signature(original_init)\n\n    @functools.wraps(obj.__init__)\n    def _ignore_init(self, *args, **kwargs):\n        known_kwargs, _ = \\\n            _CatchAllUndefinedParameters._separate_defined_undefined_kvs(\n                obj, kwargs)\n        num_params_takeable = len(\n            init_signature.parameters) - 1  # don't count self\n        num_args_takeable = num_params_takeable - len(known_kwargs)\n\n        args = args[:num_args_takeable]\n        bound_parameters = init_signature.bind_partial(self, *args,\n                                                       **known_kwargs)\n        bound_parameters.apply_defaults()\n\n        arguments = bound_parameters.arguments\n        arguments.pop(\"self\", None)\n        final_parameters = \\\n            _IgnoreUndefinedParameters.handle_from_dict(obj, arguments)\n        original_init(self, **final_parameters)\n\n    return _ignore_init", "loc": 25}
{"file": "dataclasses-json\\dataclasses_json\\undefined.py", "class_name": "_CatchAllUndefinedParameters", "function_name": "handle_from_dict", "parameters": ["cls", "kvs"], "param_types": {"kvs": "Dict"}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["UndefinedParameterError", "_CatchAllUndefinedParameters._get_catch_all_field", "_CatchAllUndefinedParameters._get_default", "_UndefinedParameterAction._separate_defined_undefined_kvs", "isinstance", "len", "value_to_write.update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_from_dict(cls, kvs: Dict) -> Dict[str, Any]:\n    known, unknown = _UndefinedParameterAction \\\n        ._separate_defined_undefined_kvs(cls=cls, kvs=kvs)\n    catch_all_field = _CatchAllUndefinedParameters._get_catch_all_field(\n        cls=cls)\n\n    if catch_all_field.name in known:\n\n        already_parsed = isinstance(known[catch_all_field.name], dict)\n        default_value = _CatchAllUndefinedParameters._get_default(\n            catch_all_field=catch_all_field)\n        received_default = default_value == known[catch_all_field.name]\n\n        value_to_write: Any\n        if received_default and len(unknown) == 0:\n            value_to_write = default_value\n        elif received_default and len(unknown) > 0:\n            value_to_write = unknown\n        elif already_parsed:\n            # Did not receive default\n            value_to_write = known[catch_all_field.name]\n            if len(unknown) > 0:\n                value_to_write.update(unknown)\n        else:\n            error_message = f\"Received input field with \" \\\n                            f\"same name as catch-all field: \" \\\n                            f\"'{catch_all_field.name}': \" \\\n                            f\"'{known[catch_all_field.name]}'\"\n            raise UndefinedParameterError(error_message)\n    else:\n        value_to_write = unknown\n\n    known[catch_all_field.name] = value_to_write\n    return known", "loc": 34}
{"file": "dataclasses-json\\dataclasses_json\\undefined.py", "class_name": "_CatchAllUndefinedParameters", "function_name": "handle_to_dict", "parameters": ["obj", "kvs"], "param_types": {"kvs": "Dict[Any, Any]"}, "return_type": "Dict[Any, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_CatchAllUndefinedParameters._get_catch_all_field", "isinstance", "kvs.pop", "kvs.update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_to_dict(obj, kvs: Dict[Any, Any]) -> Dict[Any, Any]:\n    catch_all_field = \\\n        _CatchAllUndefinedParameters._get_catch_all_field(obj.__class__)\n    undefined_parameters = kvs.pop(catch_all_field.name)\n    if isinstance(undefined_parameters, dict):\n        kvs.update(\n            undefined_parameters)  # If desired handle letter case here\n    return kvs", "loc": 8}
{"file": "dataclasses-json\\dataclasses_json\\undefined.py", "class_name": "_CatchAllUndefinedParameters", "function_name": "create_init", "parameters": ["obj"], "param_types": {}, "return_type": "Callable", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_CatchAllUndefinedParameters._get_catch_all_field", "_CatchAllUndefinedParameters._separate_defined_undefined_kvs", "_CatchAllUndefinedParameters.handle_from_dict", "arguments.pop", "arguments.update", "enumerate", "functools.wraps", "init_signature.bind_partial", "inspect.signature", "len", "original_init"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_init(obj) -> Callable:\n    original_init = obj.__init__\n    init_signature = inspect.signature(original_init)\n\n    @functools.wraps(obj.__init__)\n    def _catch_all_init(self, *args, **kwargs):\n        known_kwargs, unknown_kwargs = \\\n            _CatchAllUndefinedParameters._separate_defined_undefined_kvs(\n                obj, kwargs)\n        num_params_takeable = len(\n            init_signature.parameters) - 1  # don't count self\n        if _CatchAllUndefinedParameters._get_catch_all_field(\n                obj).name not in known_kwargs:\n            num_params_takeable -= 1\n        num_args_takeable = num_params_takeable - len(known_kwargs)\n\n        args, unknown_args = args[:num_args_takeable], args[\n                                                       num_args_takeable:]\n        bound_parameters = init_signature.bind_partial(self, *args,\n                                                       **known_kwargs)\n\n        unknown_args = {f\"_UNKNOWN{i}\": v for i, v in\n                        enumerate(unknown_args)}\n        arguments = bound_parameters.arguments\n        arguments.update(unknown_args)\n        arguments.update(unknown_kwargs)\n        arguments.pop(\"self\", None)\n        final_parameters = _CatchAllUndefinedParameters.handle_from_dict(\n            obj, arguments)\n        original_init(self, **final_parameters)\n\n    return _catch_all_init", "loc": 32}
{"file": "docstring_parser\\docstring_parser\\attrdoc.py", "class_name": null, "function_name": "ast_unparse", "parameters": ["node"], "param_types": {"node": "ast.AST"}, "return_type": "T.Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.unparse", "ast_get_constant_value", "hasattr", "isinstance", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convert the AST node to source code as a string.", "source_code": "def ast_unparse(node: ast.AST) -> T.Optional[str]:\n    \"\"\"Convert the AST node to source code as a string.\"\"\"\n    if hasattr(ast, \"unparse\"):\n        return ast.unparse(node)\n    # Support simple cases in Python < 3.9\n    if isinstance(node, ast.Constant):\n        return str(ast_get_constant_value(node))\n    if isinstance(node, ast.Name):\n        return node.id\n    return None", "loc": 10}
{"file": "docstring_parser\\docstring_parser\\attrdoc.py", "class_name": null, "function_name": "ast_is_literal_str", "parameters": ["node"], "param_types": {"node": "ast.AST"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast_get_constant_value", "isinstance"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Return True if the given node is a literal string.", "source_code": "def ast_is_literal_str(node: ast.AST) -> bool:\n    \"\"\"Return True if the given node is a literal string.\"\"\"\n    return (\n        isinstance(node, ast.Expr)\n        and isinstance(node.value, ast.Constant)\n        and isinstance(ast_get_constant_value(node.value), str)\n    )", "loc": 7}
{"file": "docstring_parser\\docstring_parser\\attrdoc.py", "class_name": null, "function_name": "ast_get_attribute", "parameters": ["node"], "param_types": {"node": "ast.AST"}, "return_type": "T.Optional[T.Tuple[str, T.Optional[str], T.Optional[str]]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast_unparse", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return name, type and default if the given node is an attribute.", "source_code": "def ast_get_attribute(\n    node: ast.AST,\n) -> T.Optional[T.Tuple[str, T.Optional[str], T.Optional[str]]]:\n    \"\"\"Return name, type and default if the given node is an attribute.\"\"\"\n    if isinstance(node, (ast.Assign, ast.AnnAssign)):\n        target = (\n            node.targets[0] if isinstance(node, ast.Assign) else node.target\n        )\n        if isinstance(target, ast.Name):\n            type_str = None\n            if isinstance(node, ast.AnnAssign):\n                type_str = ast_unparse(node.annotation)\n            default = None\n            if node.value:\n                default = ast_unparse(node.value)\n            return target.id, type_str, default\n    return None", "loc": 17}
{"file": "docstring_parser\\docstring_parser\\attrdoc.py", "class_name": null, "function_name": "add_attribute_docstrings", "parameters": ["obj", "docstring"], "param_types": {"obj": "T.Union[type, ModuleType]", "docstring": "Docstring"}, "return_type": "None", "param_doc": {"obj": "object from which to parse attribute docstrings", "docstring": "Docstring object where found attributes are added"}, "return_doc": "list with names of added attributes", "raises_doc": [], "called_functions": ["AttributeDocstrings", "AttributeDocstrings().get_attr_docs", "AttributeDocstrings().get_attr_docs(obj).items", "DocstringParam", "docstring.meta.append", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Add attribute docstrings found in the object's source code.", "source_code": "def add_attribute_docstrings(\n    obj: T.Union[type, ModuleType], docstring: Docstring\n) -> None:\n    \"\"\"Add attribute docstrings found in the object's source code.\n\n    :param obj: object from which to parse attribute docstrings\n    :param docstring: Docstring object where found attributes are added\n    :returns: list with names of added attributes\n    \"\"\"\n    params = set(p.arg_name for p in docstring.params)\n    for arg_name, (description, type_name, default) in (\n        AttributeDocstrings().get_attr_docs(obj).items()\n    ):\n        if arg_name not in params:\n            param = DocstringParam(\n                args=[\"attribute\", arg_name],\n                description=description,\n                arg_name=arg_name,\n                type_name=type_name,\n                is_optional=default is not None,\n                default=default,\n            )\n            docstring.meta.append(param)", "loc": 23}
{"file": "docstring_parser\\docstring_parser\\attrdoc.py", "class_name": "AttributeDocstrings", "function_name": "visit", "parameters": ["self", "node"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast_get_attribute", "ast_get_constant_value", "ast_is_literal_str", "isinstance", "self.generic_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit(self, node):\n    if self.prev_attr and ast_is_literal_str(node):\n        attr_name, attr_type, attr_default = self.prev_attr\n        self.attr_docs[attr_name] = (\n            ast_get_constant_value(node.value),\n            attr_type,\n            attr_default,\n        )\n    self.prev_attr = ast_get_attribute(node)\n    if isinstance(node, (ast.ClassDef, ast.Module)):\n        self.generic_visit(node)", "loc": 11}
{"file": "docstring_parser\\docstring_parser\\attrdoc.py", "class_name": "AttributeDocstrings", "function_name": "get_attr_docs", "parameters": ["self", "component"], "param_types": {"component": "T.Any"}, "return_type": "T.Dict[str, T.Tuple[str, T.Optional[str], T.Optional[str]]]", "param_doc": {"component": "component to process (class or module)"}, "return_doc": "for each attribute docstring, a tuple with (description,", "raises_doc": [], "called_functions": ["ast.parse", "inspect.getsource", "inspect.ismodule", "isinstance", "self.visit", "textwrap.dedent"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Get attribute docstrings from the given component.", "source_code": "def get_attr_docs(\n    self, component: T.Any\n) -> T.Dict[str, T.Tuple[str, T.Optional[str], T.Optional[str]]]:\n    \"\"\"Get attribute docstrings from the given component.\n\n    :param component: component to process (class or module)\n    :returns: for each attribute docstring, a tuple with (description,\n        type, default)\n    \"\"\"\n    self.attr_docs = {}\n    self.prev_attr = None\n    try:\n        source = textwrap.dedent(inspect.getsource(component))\n    except OSError:\n        pass\n    else:\n        tree = ast.parse(source)\n        if inspect.ismodule(component):\n            self.visit(tree)\n        elif isinstance(tree, ast.Module) and isinstance(\n            tree.body[0], ast.ClassDef\n        ):\n            self.visit(tree.body[0])\n    return self.attr_docs", "loc": 24}
{"file": "docstring_parser\\docstring_parser\\common.py", "class_name": "Docstring", "function_name": "description", "parameters": ["self"], "param_types": {}, "return_type": "T.Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "ret.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the full description of the function", "source_code": "def description(self) -> T.Optional[str]:\n    \"\"\"Return the full description of the function\n\n    Returns None if the docstring did not include any description\n    \"\"\"\n    ret = []\n    if self.short_description:\n        ret.append(self.short_description)\n        if self.blank_after_short_description:\n            ret.append(\"\")\n    if self.long_description:\n        ret.append(self.long_description)\n\n    if not ret:\n        return None\n\n    return \"\\n\".join(ret)", "loc": 17}
{"file": "docstring_parser\\docstring_parser\\common.py", "class_name": "Docstring", "function_name": "returns", "parameters": ["self"], "param_types": {}, "return_type": "T.Optional[DocstringReturns]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return a single information on function return. Takes the first return information.", "source_code": "def returns(self) -> T.Optional[DocstringReturns]:\n    \"\"\"Return a single information on function return.\n\n    Takes the first return information.\n    \"\"\"\n    for item in self.meta:\n        if isinstance(item, DocstringReturns):\n            return item\n    return None", "loc": 9}
{"file": "docstring_parser\\docstring_parser\\common.py", "class_name": "Docstring", "function_name": "deprecation", "parameters": ["self"], "param_types": {}, "return_type": "T.Optional[DocstringDeprecated]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return a single information on function deprecation notes.", "source_code": "def deprecation(self) -> T.Optional[DocstringDeprecated]:\n    \"\"\"Return a single information on function deprecation notes.\"\"\"\n    for item in self.meta:\n        if isinstance(item, DocstringDeprecated):\n            return item\n    return None", "loc": 6}
{"file": "docstring_parser\\docstring_parser\\epydoc.py", "class_name": null, "function_name": "compose", "parameters": ["docstring", "rendering_style", "indent"], "param_types": {"docstring": "Docstring", "rendering_style": "RenderingStyle", "indent": "str"}, "return_type": "str", "param_doc": {"docstring": "parsed docstring representation", "rendering_style": "the style to render docstrings", "indent": "the characters used as indentation in the docstring string"}, "return_doc": "docstring text", "raises_doc": [], "called_functions": ["' '.join", "'\\n'.join", "desc.splitlines", "isinstance", "parts.append", "process_desc"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Render a parsed docstring into docstring text.", "source_code": "def compose(\n    docstring: Docstring,\n    rendering_style: RenderingStyle = RenderingStyle.COMPACT,\n    indent: str = \"    \",\n) -> str:\n    \"\"\"Render a parsed docstring into docstring text.\n\n    :param docstring: parsed docstring representation\n    :param rendering_style: the style to render docstrings\n    :param indent: the characters used as indentation in the docstring string\n    :returns: docstring text\n    \"\"\"\n\n    def process_desc(desc: T.Optional[str], is_type: bool) -> str:\n        if not desc:\n            return \"\"\n\n        if rendering_style == RenderingStyle.EXPANDED or (\n            rendering_style == RenderingStyle.CLEAN and not is_type\n        ):\n            (first, *rest) = desc.splitlines()\n            return \"\\n\".join(\n                [\"\\n\" + indent + first] + [indent + line for line in rest]\n            )\n\n        (first, *rest) = desc.splitlines()\n        return \"\\n\".join([\" \" + first] + [indent + line for line in rest])\n\n    parts: T.List[str] = []\n    if docstring.short_description:\n        parts.append(docstring.short_description)\n    if docstring.blank_after_short_description:\n        parts.append(\"\")\n    if docstring.long_description:\n        parts.append(docstring.long_description)\n    if docstring.blank_after_long_description:\n        parts.append(\"\")\n\n    for meta in docstring.meta:\n        if isinstance(meta, DocstringParam):\n            if meta.type_name:\n                type_name = (\n                    f\"{meta.type_name}?\"\n                    if meta.is_optional\n                    else meta.type_name\n                )\n                text = f\"@type {meta.arg_name}:\"\n                text += process_desc(type_name, True)\n                parts.append(text)\n            text = f\"@param {meta.arg_name}:\" + process_desc(\n                meta.description, False\n            )\n            parts.append(text)\n        elif isinstance(meta, DocstringReturns):\n            (arg_key, type_key) = (\n                (\"yield\", \"ytype\")\n                if meta.is_generator\n                else (\"return\", \"rtype\")\n            )\n            if meta.type_name:\n                text = f\"@{type_key}:\" + process_desc(meta.type_name, True)\n                parts.append(text)\n            if meta.description:\n                text = f\"@{arg_key}:\" + process_desc(meta.description, False)\n                parts.append(text)\n        elif isinstance(meta, DocstringRaises):\n            text = f\"@raise {meta.type_name}:\" if meta.type_name else \"@raise:\"\n            text += process_desc(meta.description, False)\n            parts.append(text)\n        else:\n            text = f'@{\" \".join(meta.args)}:'\n            text += process_desc(meta.description, False)\n            parts.append(text)\n    return \"\\n\".join(parts)", "loc": 74}
{"file": "docstring_parser\\docstring_parser\\epydoc.py", "class_name": null, "function_name": "process_desc", "parameters": ["desc", "is_type"], "param_types": {"desc": "T.Optional[str]", "is_type": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "desc.splitlines"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_desc(desc: T.Optional[str], is_type: bool) -> str:\n    if not desc:\n        return \"\"\n\n    if rendering_style == RenderingStyle.EXPANDED or (\n        rendering_style == RenderingStyle.CLEAN and not is_type\n    ):\n        (first, *rest) = desc.splitlines()\n        return \"\\n\".join(\n            [\"\\n\" + indent + first] + [indent + line for line in rest]\n        )\n\n    (first, *rest) = desc.splitlines()\n    return \"\\n\".join([\" \" + first] + [indent + line for line in rest])", "loc": 14}
{"file": "docstring_parser\\docstring_parser\\google.py", "class_name": null, "function_name": "parse", "parameters": ["text"], "param_types": {"text": "T.Optional[str]"}, "return_type": "Docstring", "param_doc": {}, "return_doc": "parsed docstring", "raises_doc": [], "called_functions": ["GoogleParser", "GoogleParser().parse"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Parse the Google-style docstring into its components.", "source_code": "def parse(text: T.Optional[str]) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    return GoogleParser().parse(text)", "loc": 6}
{"file": "docstring_parser\\docstring_parser\\google.py", "class_name": "GoogleParser", "function_name": "parse", "parameters": ["self", "text"], "param_types": {"text": "T.Optional[str]"}, "return_type": "Docstring", "param_doc": {}, "return_doc": "parsed docstring", "raises_doc": [], "called_functions": ["Docstring", "OrderedDict", "ParseError", "c_matches[-1].end", "c_matches[j + 1].start", "c_matches[j].end", "c_splits.append", "chunk[start:end].strip", "chunks.items", "desc_chunk.split", "enumerate", "indent_match.group", "inspect.cleandoc", "len", "list", "long_desc_chunk.endswith", "long_desc_chunk.startswith", "long_desc_chunk.strip", "match.start", "matches[-1].end", "matches[j + 1].start", "matches[j].end", "matches[j].group", "meta_details.strip", "range", "re.finditer", "re.search", "ret.meta.append", "self._build_meta", "self.titles_re.finditer", "self.titles_re.search", "splits.append", "unknown_meta.start"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Parse the Google-style docstring into its components.", "source_code": "def parse(self, text: T.Optional[str]) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    ret = Docstring(style=DocstringStyle.GOOGLE)\n    if not text:\n        return ret\n\n    # Clean according to PEP-0257\n    text = inspect.cleandoc(text)\n\n    # Find first title and split on its position\n    match = self.titles_re.search(text)\n    if match:\n        desc_chunk = text[: match.start()]\n        meta_chunk = text[match.start() :]\n    else:\n        desc_chunk = text\n        meta_chunk = \"\"\n\n    # Break description into short and long parts\n    parts = desc_chunk.split(\"\\n\", 1)\n    ret.short_description = parts[0] or None\n    if len(parts) > 1:\n        long_desc_chunk = parts[1] or \"\"\n        ret.blank_after_short_description = long_desc_chunk.startswith(\n            \"\\n\"\n        )\n        ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n        ret.long_description = long_desc_chunk.strip() or None\n\n    # Split by sections determined by titles\n    matches = list(self.titles_re.finditer(meta_chunk))\n    if not matches:\n        return ret\n    splits = []\n    for j in range(len(matches) - 1):\n        splits.append((matches[j].end(), matches[j + 1].start()))\n    splits.append((matches[-1].end(), len(meta_chunk)))\n\n    chunks = OrderedDict()  # type: T.Mapping[str,str]\n    for j, (start, end) in enumerate(splits):\n        title = matches[j].group(1)\n        if title not in self.sections:\n            continue\n\n        # Clear Any Unknown Meta\n        # Ref: https://github.com/rr-/docstring_parser/issues/29\n        meta_details = meta_chunk[start:end]\n        unknown_meta = re.search(r\"\\n\\S\", meta_details)\n        if unknown_meta is not None:\n            meta_details = meta_details[: unknown_meta.start()]\n\n        chunks[title] = meta_details.strip(\"\\n\")\n    if not chunks:\n        return ret\n\n    # Add elements from each chunk\n    for title, chunk in chunks.items():\n        # Determine indent\n        indent_match = re.search(r\"^\\s*\", chunk)\n        if not indent_match:\n            raise ParseError(f'Can\\'t infer indent from \"{chunk}\"')\n        indent = indent_match.group()\n\n        # Check for singular elements\n        if self.sections[title].type in [\n            SectionType.SINGULAR,\n            SectionType.SINGULAR_OR_MULTIPLE,\n        ]:\n            part = inspect.cleandoc(chunk)\n            ret.meta.append(self._build_meta(part, title))\n            continue\n\n        # Split based on lines which have exactly that indent\n        _re = \"^\" + indent + r\"(?=\\S)\"\n        c_matches = list(re.finditer(_re, chunk, flags=re.M))\n        if not c_matches:\n            raise ParseError(f'No specification for \"{title}\": \"{chunk}\"')\n        c_splits = []\n        for j in range(len(c_matches) - 1):\n            c_splits.append((c_matches[j].end(), c_matches[j + 1].start()))\n        c_splits.append((c_matches[-1].end(), len(chunk)))\n        for j, (start, end) in enumerate(c_splits):\n            part = chunk[start:end].strip(\"\\n\")\n            ret.meta.append(self._build_meta(part, title))\n\n    return ret", "loc": 89}
{"file": "docstring_parser\\docstring_parser\\google.py", "class_name": null, "function_name": "process_one", "parameters": ["one"], "param_types": {"one": "T.Union[DocstringParam, DocstringReturns, DocstringRaises]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["f'\\n{indent}{indent}'.join", "isinstance", "one.description.splitlines", "parts.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_one(\n    one: T.Union[DocstringParam, DocstringReturns, DocstringRaises],\n):\n    head = \"\"\n\n    if isinstance(one, DocstringParam):\n        head += one.arg_name or \"\"\n    elif isinstance(one, DocstringReturns):\n        head += one.return_name or \"\"\n\n    if isinstance(one, DocstringParam) and one.is_optional:\n        optional = (\n            \"?\"\n            if rendering_style == RenderingStyle.COMPACT\n            else \", optional\"\n        )\n    else:\n        optional = \"\"\n\n    if one.type_name and head:\n        head += f\" ({one.type_name}{optional}):\"\n    elif one.type_name:\n        head += f\"{one.type_name}{optional}:\"\n    else:\n        head += \":\"\n    head = indent + head\n\n    if one.description and rendering_style == RenderingStyle.EXPANDED:\n        body = f\"\\n{indent}{indent}\".join(\n            [head] + one.description.splitlines()\n        )\n        parts.append(body)\n    elif one.description:\n        (first, *rest) = one.description.splitlines()\n        body = f\"\\n{indent}{indent}\".join([head + \" \" + first] + rest)\n        parts.append(body)\n    else:\n        parts.append(head)", "loc": 38}
{"file": "docstring_parser\\docstring_parser\\google.py", "class_name": null, "function_name": "process_sect", "parameters": ["name", "args"], "param_types": {"name": "str", "args": "T.List[T.Any]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parts.append", "process_one"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_sect(name: str, args: T.List[T.Any]):\n    if args:\n        parts.append(name)\n        for arg in args:\n            process_one(arg)\n        parts.append(\"\")", "loc": 6}
{"file": "docstring_parser\\docstring_parser\\numpydoc.py", "class_name": null, "function_name": "parse", "parameters": ["text"], "param_types": {"text": "T.Optional[str]"}, "return_type": "Docstring", "param_doc": {}, "return_doc": "parsed docstring", "raises_doc": [], "called_functions": ["NumpydocParser", "NumpydocParser().parse"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Parse the numpy-style docstring into its components.", "source_code": "def parse(text: T.Optional[str]) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    return NumpydocParser().parse(text)", "loc": 6}
{"file": "docstring_parser\\docstring_parser\\numpydoc.py", "class_name": "Section", "function_name": "parse", "parameters": ["self", "text"], "param_types": {"text": "str"}, "return_type": "T.Iterable[DocstringMeta]", "param_doc": {"text": "section body text. Should be cleaned with"}, "return_doc": "", "raises_doc": [], "called_functions": ["DocstringMeta", "_clean_str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Parse ``DocstringMeta`` objects from the body of this section.", "source_code": "def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n    \"\"\"Parse ``DocstringMeta`` objects from the body of this section.\n\n    :param text: section body text. Should be cleaned with\n                 ``inspect.cleandoc`` before parsing.\n    \"\"\"\n    yield DocstringMeta([self.key], description=_clean_str(text))", "loc": 7}
{"file": "docstring_parser\\docstring_parser\\numpydoc.py", "class_name": "_KVSection", "function_name": "parse", "parameters": ["self", "text"], "param_types": {"text": "str"}, "return_type": "T.Iterable[DocstringMeta]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["KV_REGEX.finditer", "_pairwise", "inspect.cleandoc", "match.end", "match.group", "next_match.start", "self._parse_item"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n    for match, next_match in _pairwise(KV_REGEX.finditer(text)):\n        start = match.end()\n        end = next_match.start() if next_match is not None else None\n        value = text[start:end]\n        yield self._parse_item(\n            key=match.group(), value=inspect.cleandoc(value)\n        )", "loc": 8}
{"file": "docstring_parser\\docstring_parser\\numpydoc.py", "class_name": "DeprecationSection", "function_name": "parse", "parameters": ["self", "text"], "param_types": {"text": "str"}, "return_type": "T.Iterable[DocstringDeprecated]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DocstringDeprecated", "_clean_str", "inspect.cleandoc", "text.split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse(self, text: str) -> T.Iterable[DocstringDeprecated]:\n    version, desc, *_ = text.split(sep=\"\\n\", maxsplit=1) + [None, None]\n\n    if desc is not None:\n        desc = _clean_str(inspect.cleandoc(desc))\n\n    yield DocstringDeprecated(\n        args=[self.key], description=desc, version=_clean_str(version)\n    )", "loc": 9}
{"file": "docstring_parser\\docstring_parser\\numpydoc.py", "class_name": "ExamplesSection", "function_name": "parse", "parameters": ["self", "text"], "param_types": {"text": "str"}, "return_type": "T.Iterable[DocstringMeta]", "param_doc": {"text": "section body text. Should be cleaned with"}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "DocstringExample", "dedent", "dedent(text).strip", "dedent(text).strip().splitlines", "description_lines.append", "lines.pop", "lines[0].startswith", "snippet_lines.append"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Parse ``DocstringExample`` objects from the body of this section.", "source_code": "def parse(self, text: str) -> T.Iterable[DocstringMeta]:\n    \"\"\"Parse ``DocstringExample`` objects from the body of this section.\n\n    :param text: section body text. Should be cleaned with\n                 ``inspect.cleandoc`` before parsing.\n    \"\"\"\n    lines = dedent(text).strip().splitlines()\n    while lines:\n        snippet_lines = []\n        description_lines = []\n        while lines:\n            if not lines[0].startswith(\">>>\"):\n                break\n            snippet_lines.append(lines.pop(0))\n        while lines:\n            if lines[0].startswith(\">>>\"):\n                break\n            description_lines.append(lines.pop(0))\n        yield DocstringExample(\n            [self.key],\n            snippet=\"\\n\".join(snippet_lines) if snippet_lines else None,\n            description=\"\\n\".join(description_lines),\n        )", "loc": 23}
{"file": "docstring_parser\\docstring_parser\\numpydoc.py", "class_name": "NumpydocParser", "function_name": "parse", "parameters": ["self", "text"], "param_types": {"text": "T.Optional[str]"}, "return_type": "Docstring", "param_doc": {}, "return_doc": "parsed docstring", "raises_doc": [], "called_functions": ["Docstring", "_pairwise", "desc_chunk.split", "factory.parse", "inspect.cleandoc", "len", "long_desc_chunk.endswith", "long_desc_chunk.startswith", "long_desc_chunk.strip", "match.end", "match.groups", "match.start", "next", "nextmatch.start", "ret.meta.extend", "self.titles_re.finditer", "self.titles_re.search"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Parse the numpy-style docstring into its components.", "source_code": "def parse(self, text: T.Optional[str]) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    ret = Docstring(style=DocstringStyle.NUMPYDOC)\n    if not text:\n        return ret\n\n    # Clean according to PEP-0257\n    text = inspect.cleandoc(text)\n\n    # Find first title and split on its position\n    match = self.titles_re.search(text)\n    if match:\n        desc_chunk = text[: match.start()]\n        meta_chunk = text[match.start() :]\n    else:\n        desc_chunk = text\n        meta_chunk = \"\"\n\n    # Break description into short and long parts\n    parts = desc_chunk.split(\"\\n\", 1)\n    ret.short_description = parts[0] or None\n    if len(parts) > 1:\n        long_desc_chunk = parts[1] or \"\"\n        ret.blank_after_short_description = long_desc_chunk.startswith(\n            \"\\n\"\n        )\n        ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n        ret.long_description = long_desc_chunk.strip() or None\n\n    for match, nextmatch in _pairwise(self.titles_re.finditer(meta_chunk)):\n        title = next(g for g in match.groups() if g is not None)\n        factory = self.sections[title]\n\n        # section chunk starts after the header,\n        # ends at the start of the next header\n        start = match.end()\n        end = nextmatch.start() if nextmatch is not None else None\n        ret.meta.extend(factory.parse(meta_chunk[start:end]))\n\n    return ret", "loc": 43}
{"file": "docstring_parser\\docstring_parser\\numpydoc.py", "class_name": null, "function_name": "process_one", "parameters": ["one"], "param_types": {"one": "T.Union[DocstringParam, DocstringReturns, DocstringRaises]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["f'\\n{indent}'.join", "isinstance", "one.description.splitlines", "parts.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_one(\n    one: T.Union[DocstringParam, DocstringReturns, DocstringRaises],\n):\n    if isinstance(one, DocstringParam):\n        head = one.arg_name\n    elif isinstance(one, DocstringReturns):\n        head = one.return_name\n    else:\n        head = None\n\n    if one.type_name and head:\n        head += f\" : {one.type_name}\"\n    elif one.type_name:\n        head = one.type_name\n    elif not head:\n        head = \"\"\n\n    if isinstance(one, DocstringParam) and one.is_optional:\n        head += \", optional\"\n\n    if one.description:\n        body = f\"\\n{indent}\".join([head] + one.description.splitlines())\n        parts.append(body)\n    else:\n        parts.append(head)", "loc": 25}
{"file": "docstring_parser\\docstring_parser\\numpydoc.py", "class_name": null, "function_name": "process_sect", "parameters": ["name", "args"], "param_types": {"name": "str", "args": "T.List[T.Any]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "parts.append", "process_one"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_sect(name: str, args: T.List[T.Any]):\n    if args:\n        parts.append(\"\")\n        parts.append(name)\n        parts.append(\"-\" * len(parts[-1]))\n        for arg in args:\n            process_one(arg)", "loc": 7}
{"file": "docstring_parser\\docstring_parser\\parser.py", "class_name": null, "function_name": "parse", "parameters": ["text", "style"], "param_types": {"text": "T.Optional[str]", "style": "DocstringStyle"}, "return_type": "Docstring", "param_doc": {"text": "docstring text to parse", "style": "docstring style"}, "return_doc": "parsed docstring representation", "raises_doc": [], "called_functions": ["_STYLE_MAP.values", "_STYLE_MAP[style].parse", "len", "module.parse", "rets.append", "sorted"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Parse the docstring into its components.", "source_code": "def parse(\n    text: T.Optional[str], style: DocstringStyle = DocstringStyle.AUTO\n) -> Docstring:\n    \"\"\"Parse the docstring into its components.\n\n    :param text: docstring text to parse\n    :param style: docstring style\n    :returns: parsed docstring representation\n    \"\"\"\n    if style != DocstringStyle.AUTO:\n        return _STYLE_MAP[style].parse(text)\n\n    exc: T.Optional[Exception] = None\n    rets = []\n    for module in _STYLE_MAP.values():\n        try:\n            ret = module.parse(text)\n        except ParseError as ex:\n            exc = ex\n        else:\n            rets.append(ret)\n\n    if not rets:\n        raise exc\n\n    return sorted(rets, key=lambda d: len(d.meta), reverse=True)[0]", "loc": 26}
{"file": "docstring_parser\\docstring_parser\\parser.py", "class_name": null, "function_name": "parse_from_object", "parameters": ["obj", "style"], "param_types": {"obj": "T.Any", "style": "DocstringStyle"}, "return_type": "Docstring", "param_doc": {"obj": "object from which to parse the docstring(s)", "style": "docstring style"}, "return_doc": "parsed docstring representation", "raises_doc": [], "called_functions": ["add_attribute_docstrings", "inspect.isclass", "inspect.ismodule", "parse"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse the object's docstring(s) into its components. The object can be anything that has a ``__doc__`` attribute. In contrast to the ``parse`` function, ``parse_from_object`` is able to parse attribute docstrings which are defined in the source code instead of ``__doc__``. Currently only attribute docstrings defined at class and module levels are supported. Attribute docstrings defined in ``__init__`` methods are not supported. When given a class, only the attribute docstrings of that class are parsed, not its inherited classes. This is a design decision. Separate calls to this function should be performed to get attribute docstrings of parent classes.", "source_code": "def parse_from_object(\n    obj: T.Any,\n    style: DocstringStyle = DocstringStyle.AUTO,\n) -> Docstring:\n    \"\"\"Parse the object's docstring(s) into its components.\n\n    The object can be anything that has a ``__doc__`` attribute. In contrast to\n    the ``parse`` function, ``parse_from_object`` is able to parse attribute\n    docstrings which are defined in the source code instead of ``__doc__``.\n\n    Currently only attribute docstrings defined at class and module levels are\n    supported. Attribute docstrings defined in ``__init__`` methods are not\n    supported.\n\n    When given a class, only the attribute docstrings of that class are parsed,\n    not its inherited classes. This is a design decision. Separate calls to\n    this function should be performed to get attribute docstrings of parent\n    classes.\n\n    :param obj: object from which to parse the docstring(s)\n    :param style: docstring style\n    :returns: parsed docstring representation\n    \"\"\"\n    docstring = parse(obj.__doc__, style=style)\n\n    if inspect.isclass(obj) or inspect.ismodule(obj):\n        add_attribute_docstrings(obj, docstring)\n\n    return docstring", "loc": 29}
{"file": "docstring_parser\\docstring_parser\\rest.py", "class_name": null, "function_name": "parse", "parameters": ["text"], "param_types": {"text": "T.Optional[str]"}, "return_type": "Docstring", "param_doc": {}, "return_doc": "parsed docstring", "raises_doc": [], "called_functions": ["Docstring", "DocstringReturns", "ParseError", "_build_meta", "any", "args_chunk.split", "chunk.lstrip", "chunk.lstrip(':').split", "desc.split", "desc_chunk.split", "desc_chunk.strip", "inspect.cleandoc", "isinstance", "len", "long_desc_chunk.endswith", "long_desc_chunk.startswith", "long_desc_chunk.strip", "match.group", "match.start", "re.finditer", "re.search", "ret.meta.append", "rtypes.get", "rtypes.items", "types.get"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Parse the ReST-style docstring into its components.", "source_code": "def parse(text: T.Optional[str]) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n    ret = Docstring(style=DocstringStyle.REST)\n    if not text:\n        return ret\n\n    text = inspect.cleandoc(text)\n    match = re.search(\"^:\", text, flags=re.M)\n    if match:\n        desc_chunk = text[: match.start()]\n        meta_chunk = text[match.start() :]\n    else:\n        desc_chunk = text\n        meta_chunk = \"\"\n\n    parts = desc_chunk.split(\"\\n\", 1)\n    ret.short_description = parts[0] or None\n    if len(parts) > 1:\n        long_desc_chunk = parts[1] or \"\"\n        ret.blank_after_short_description = long_desc_chunk.startswith(\"\\n\")\n        ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n        ret.long_description = long_desc_chunk.strip() or None\n\n    types = {}\n    rtypes = {}\n    for match in re.finditer(\n        r\"(^:.*?)(?=^:|\\Z)\", meta_chunk, flags=re.S | re.M\n    ):\n        chunk = match.group(0)\n        if not chunk:\n            continue\n        try:\n            args_chunk, desc_chunk = chunk.lstrip(\":\").split(\":\", 1)\n        except ValueError as ex:\n            raise ParseError(\n                f'Error parsing meta information near \"{chunk}\".'\n            ) from ex\n        args = args_chunk.split()\n        desc = desc_chunk.strip()\n\n        if \"\\n\" in desc:\n            first_line, rest = desc.split(\"\\n\", 1)\n            desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n\n        # Add special handling for :type a: typename\n        if len(args) == 2 and args[0] == \"type\":\n            types[args[1]] = desc\n        elif len(args) in [1, 2] and args[0] == \"rtype\":\n            rtypes[None if len(args) == 1 else args[1]] = desc\n        else:\n            ret.meta.append(_build_meta(args, desc))\n\n    for meta in ret.meta:\n        if isinstance(meta, DocstringParam):\n            meta.type_name = meta.type_name or types.get(meta.arg_name)\n        elif isinstance(meta, DocstringReturns):\n            meta.type_name = meta.type_name or rtypes.get(meta.return_name)\n\n    if not any(isinstance(m, DocstringReturns) for m in ret.meta) and rtypes:\n        for return_name, type_name in rtypes.items():\n            ret.meta.append(\n                DocstringReturns(\n                    args=[],\n                    type_name=type_name,\n                    description=None,\n                    is_generator=False,\n                    return_name=return_name,\n                )\n            )\n\n    return ret", "loc": 74}
{"file": "docstring_parser\\docstring_parser\\rest.py", "class_name": null, "function_name": "compose", "parameters": ["docstring", "rendering_style", "indent"], "param_types": {"docstring": "Docstring", "rendering_style": "RenderingStyle", "indent": "str"}, "return_type": "str", "param_doc": {"docstring": "parsed docstring representation", "rendering_style": "the style to render docstrings", "indent": "the characters used as indentation in the docstring string"}, "return_doc": "docstring text", "raises_doc": [], "called_functions": ["' '.join", "'\\n'.join", "desc.splitlines", "isinstance", "parts.append", "process_desc"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Render a parsed docstring into docstring text.", "source_code": "def compose(\n    docstring: Docstring,\n    rendering_style: RenderingStyle = RenderingStyle.COMPACT,\n    indent: str = \"    \",\n) -> str:\n    \"\"\"Render a parsed docstring into docstring text.\n\n    :param docstring: parsed docstring representation\n    :param rendering_style: the style to render docstrings\n    :param indent: the characters used as indentation in the docstring string\n    :returns: docstring text\n    \"\"\"\n\n    def process_desc(desc: T.Optional[str]) -> str:\n        if not desc:\n            return \"\"\n\n        if rendering_style == RenderingStyle.CLEAN:\n            (first, *rest) = desc.splitlines()\n            return \"\\n\".join([\" \" + first] + [indent + line for line in rest])\n\n        if rendering_style == RenderingStyle.EXPANDED:\n            (first, *rest) = desc.splitlines()\n            return \"\\n\".join(\n                [\"\\n\" + indent + first] + [indent + line for line in rest]\n            )\n\n        return \" \" + desc\n\n    parts: T.List[str] = []\n    if docstring.short_description:\n        parts.append(docstring.short_description)\n    if docstring.blank_after_short_description:\n        parts.append(\"\")\n    if docstring.long_description:\n        parts.append(docstring.long_description)\n    if docstring.blank_after_long_description:\n        parts.append(\"\")\n\n    for meta in docstring.meta:\n        if isinstance(meta, DocstringParam):\n            if meta.type_name:\n                type_text = (\n                    f\" {meta.type_name}? \"\n                    if meta.is_optional\n                    else f\" {meta.type_name} \"\n                )\n            else:\n                type_text = \" \"\n            if rendering_style == RenderingStyle.EXPANDED:\n                text = f\":param {meta.arg_name}:\"\n                text += process_desc(meta.description)\n                parts.append(text)\n                if type_text[:-1]:\n                    parts.append(f\":type {meta.arg_name}:{type_text[:-1]}\")\n            else:\n                text = f\":param{type_text}{meta.arg_name}:\"\n                text += process_desc(meta.description)\n                parts.append(text)\n        elif isinstance(meta, DocstringReturns):\n            type_text = f\" {meta.type_name}\" if meta.type_name else \"\"\n            key = \"yields\" if meta.is_generator else \"returns\"\n\n            if rendering_style == RenderingStyle.EXPANDED:\n                if meta.description:\n                    text = f\":{key}:\"\n                    text += process_desc(meta.description)\n                    parts.append(text)\n                if type_text:\n                    parts.append(f\":rtype:{type_text}\")\n            else:\n                text = f\":{key}{type_text}:\"\n                text += process_desc(meta.description)\n                parts.append(text)\n        elif isinstance(meta, DocstringRaises):\n            type_text = f\" {meta.type_name} \" if meta.type_name else \"\"\n            text = f\":raises{type_text}:\" + process_desc(meta.description)\n            parts.append(text)\n        else:\n            text = f':{\" \".join(meta.args)}:' + process_desc(meta.description)\n            parts.append(text)\n    return \"\\n\".join(parts)", "loc": 82}
{"file": "docstring_parser\\docstring_parser\\rest.py", "class_name": null, "function_name": "process_desc", "parameters": ["desc"], "param_types": {"desc": "T.Optional[str]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "desc.splitlines"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_desc(desc: T.Optional[str]) -> str:\n    if not desc:\n        return \"\"\n\n    if rendering_style == RenderingStyle.CLEAN:\n        (first, *rest) = desc.splitlines()\n        return \"\\n\".join([\" \" + first] + [indent + line for line in rest])\n\n    if rendering_style == RenderingStyle.EXPANDED:\n        (first, *rest) = desc.splitlines()\n        return \"\\n\".join(\n            [\"\\n\" + indent + first] + [indent + line for line in rest]\n        )\n\n    return \" \" + desc", "loc": 15}
{"file": "docstring_parser\\docstring_parser\\util.py", "class_name": null, "function_name": "wrapper", "parameters": ["func"], "param_types": {"func": "_Func"}, "return_type": "_Func", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChainMap", "Signature.from_callable", "chain", "combined.values", "compose", "dict", "list", "metas.items", "metas.setdefault", "metas.setdefault(meta_type, []).append", "parse", "reversed", "type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wrapper(func: _Func) -> _Func:\n    sig = Signature.from_callable(func)\n\n    comb_doc = parse(func.__doc__ or \"\")\n    docs = [parse(other.__doc__ or \"\") for other in others] + [comb_doc]\n    params = dict(\n        ChainMap(\n            *(\n                {param.arg_name: param for param in doc.params}\n                for doc in docs\n            )\n        )\n    )\n\n    for doc in reversed(docs):\n        if not doc.short_description:\n            continue\n        comb_doc.short_description = doc.short_description\n        comb_doc.blank_after_short_description = (\n            doc.blank_after_short_description\n        )\n        break\n\n    for doc in reversed(docs):\n        if not doc.long_description:\n            continue\n        comb_doc.long_description = doc.long_description\n        comb_doc.blank_after_long_description = (\n            doc.blank_after_long_description\n        )\n        break\n\n    combined = {}\n    for doc in docs:\n        metas = {}\n        for meta in doc.meta:\n            meta_type = type(meta)\n            if meta_type in exclude:\n                continue\n            metas.setdefault(meta_type, []).append(meta)\n        for meta_type, meta in metas.items():\n            combined[meta_type] = meta\n\n    combined[DocstringParam] = [\n        params[name] for name in sig.parameters if name in params\n    ]\n    comb_doc.meta = list(chain(*combined.values()))\n    func.__doc__ = compose(\n        comb_doc, style=style, rendering_style=rendering_style\n    )\n    return func", "loc": 51}
{"file": "flutils\\flutils\\cmdutils.py", "class_name": null, "function_name": "prep_cmd", "parameters": ["cmd"], "param_types": {"cmd": "Sequence"}, "return_type": "Tuple[str, ...]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TypeError", "cast", "copy", "enumerate", "get_encoding", "hasattr", "isinstance", "out.decode", "shlex.split", "tuple", "type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Convert a given command into a tuple for use by :obj:`subprocess.Popen`.", "source_code": "def prep_cmd(cmd: Sequence) -> Tuple[str, ...]:\n    \"\"\"Convert a given command into a tuple for use by\n    :obj:`subprocess.Popen`.\n\n    Args:\n        cmd (:obj:`Sequence <typing.Sequence>`): The command to be converted.\n\n    This is for converting a command of type string or bytes to a tuple of\n    strings for use by :obj:`subprocess.Popen`.\n\n    Example:\n\n        >>> from flutils.cmdutils import prep_cmd\n        >>> prep_cmd('ls -Flap')\n        ('ls', '-Flap')\n    \"\"\"\n    if not hasattr(cmd, 'count') or not hasattr(cmd, 'index'):\n        raise TypeError(\n            \"The given 'cmd', %r, must be of type: str, bytes, list or \"\n            \"tuple.  Got: %r\" % (\n                cmd,\n                type(cmd).__name__\n            )\n        )\n    if hasattr(cmd, 'append'):\n        out = copy(cmd)\n    else:\n        out = cmd\n    if hasattr(out, 'decode'):\n        out = cast(bytes, out)\n        out = out.decode(get_encoding())\n    if hasattr(out, 'encode'):\n        out = cast(str, out)\n        out = shlex.split(out)\n    out = tuple(out)\n    out = cast(Tuple[str], out)\n    item: str\n    for x, item in enumerate(out):\n        if not isinstance(item, (str, UserString)):\n            raise TypeError(\n                \"Item %r of the given 'cmd' is not of type 'str'.  \"\n                \"Got: %r\" % (\n                    x,\n                    type(item).__name__\n                )\n            )\n    return out", "loc": 47}
{"file": "flutils\\flutils\\moduleutils.py", "class_name": "_CherryPickingLoader", "function_name": "exec_module", "parameters": ["self", "module"], "param_types": {"module": "ModuleType"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_all_.append", "_parse_attr_map", "iden_keys", "key.startswith", "list", "setattr", "sorted", "state_items"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Execute the given module in its own namespace.", "source_code": "def exec_module(  # pylint: disable=no-self-use\n        self,\n        module: ModuleType\n) -> None:\n    \"\"\"Execute the given module in its own namespace.\"\"\"\n    spec = module.__spec__\n\n    # add the parsed attr_map info to the module.\n    module.__cherry_pick_map__ = _parse_attr_map(  # type: ignore\n        # The attr_map must be in spec.loader_state.\n        # It's okay for it to error here.  If it does\n        # error then _CherryPickFinder.add was not called.\n        spec.loader_state['attr_map'],  # type: ignore\n        module.__name__\n    )\n    # add the un-parsed attr_map to the module\n    module.__attr_map__ = spec.loader_state['attr_map']  # type: ignore\n\n    # This variable is used to set module.__all__\n    _all_ = list()\n\n    # loop through each attribute name to set the module\n    # attribute (of the same name) to a sentinel.\n    iden_keys = module.__cherry_pick_map__.identifiers.keys  # type: ignore\n    for attr in iden_keys():\n        _all_.append(attr)\n        setattr(module, attr, _CHERRY_PICK)\n\n    # loop through the additional attributes (set in cherry_pick())\n    # and set the module attribute (of the same name) to the value.\n    state_items = spec.loader_state['addtl_attrs'].items  # type: ignore\n    for key, val in state_items():\n        if not key.startswith('_'):\n            _all_.append(key)\n        setattr(module, key, val)\n\n    module.__all__ = list(sorted(_all_))  # type: ignore\n\n    # Change the module class so that __getattribute__ can be overridden.\n    module.__class__ = _CherryPickingModule", "loc": 40}
{"file": "flutils\\flutils\\moduleutils.py", "class_name": "_CherryPickFinder", "function_name": "load", "parameters": ["cls"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls", "sys.meta_path.insert", "type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Make sure this finder is at the top of sys.meta_path.", "source_code": "def load(cls):\n    \"\"\"Make sure this finder is at the top of sys.meta_path.\"\"\"\n    for obj in sys.meta_path:\n        if type(obj).__name__ == cls.__name__:\n            return obj\n    obj = cls()\n    sys.meta_path.insert(0, obj)\n    return obj", "loc": 8}
{"file": "flutils\\flutils\\moduleutils.py", "class_name": "_CherryPickFinder", "function_name": "add", "parameters": ["cls", "fullname", "origin", "path", "attr_map"], "param_types": {"fullname": "str", "origin": "str", "path": "Union[str, List]", "attr_map": "Tuple[str, ...]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls.load", "dict"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Add cherry-picking-module data to the cache.", "source_code": "def add(\n        cls,\n        fullname: str,\n        origin: str,\n        path: Union[str, List],\n        attr_map: Tuple[str, ...],\n        **addtl_attrs: Any\n) -> None:\n    \"\"\"Add cherry-picking-module data to the cache.\"\"\"\n    obj = cls.load()\n    obj._cache[fullname] = dict(\n        fullname=fullname,\n        origin=origin,\n        path=path,\n        attr_map=attr_map,\n        addtl_attrs=addtl_attrs\n    )", "loc": 17}
{"file": "flutils\\flutils\\moduleutils.py", "class_name": "_CherryPickFinder", "function_name": "find_spec", "parameters": ["self", "fullname", "path", "target"], "param_types": {"fullname": "str", "path": "str", "target": "str"}, "return_type": "Union[ModuleSpec, None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ModuleSpec", "_CherryPickingLoader", "dict"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return a spec for a cherry-picking-module.", "source_code": "def find_spec(\n        self,\n        fullname: str,\n        path: str,  # pylint: disable=unused-argument\n        target: str = None  # pylint: disable=unused-argument\n) -> Union[ModuleSpec, None]:\n    \"\"\"Return a spec for a cherry-picking-module.\"\"\"\n    if fullname in self._cache:\n        loader_state = self._cache[fullname]\n        kwargs = dict(\n            origin=loader_state['origin'],\n            loader_state=loader_state,\n        )\n        loader = _CherryPickingLoader()\n        if loader_state['path']:\n            kwargs['is_package'] = True\n\n        # ModuleSpec docs: https://bit.ly/2Hlz1dv\n        return ModuleSpec(fullname, loader, **kwargs)\n    return None", "loc": 20}
{"file": "flutils\\flutils\\moduleutils.py", "class_name": "_LazyLoader", "function_name": "exec_module", "parameters": ["self", "module"], "param_types": {"module": "ModuleType"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dict", "module.__dict__.copy"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Make the module load lazily.", "source_code": "def exec_module(self, module: ModuleType):\n    \"\"\"Make the module load lazily.\"\"\"\n    module.__spec__.loader = self.loader  # type: ignore\n    module.__loader__ = self.loader\n\n    # Don't need to worry about deep-copying as trying to set an attribute\n    # on an object would have triggered the load,\n    # e.g. ``module.__spec__.loader = None`` would trigger a load from\n    # trying to access module.__spec__.\n    loader_state = dict()\n    loader_state['__dict__'] = module.__dict__.copy()\n    loader_state['__class__'] = module.__class__  # type: ignore\n    module.__spec__.loader_state = loader_state  # type: ignore\n    module.__class__ = _LazyModule", "loc": 14}
{"file": "flutils\\flutils\\objutils.py", "class_name": null, "function_name": "has_any_attrs", "parameters": ["obj"], "param_types": {"obj": "_Any"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Check if the given ``obj`` has **ANY** of the given ``*attrs``.", "source_code": "def has_any_attrs(obj: _Any, *attrs: str) -> bool:\n    \"\"\"Check if the given ``obj`` has **ANY** of the given ``*attrs``.\n\n    Args:\n        obj (:obj:`Any <typing.Any>`): The object to check.\n        *attrs (:obj:`str`): The names of the attributes to check.\n\n    :rtype:\n        :obj:`bool`\n\n        * :obj:`True` if any of the given ``*attrs`` exist on the given\n          ``obj``;\n        * :obj:`False` otherwise.\n\n    Example:\n        >>> from flutils.objutils import has_any_attrs\n        >>> has_any_attrs(dict(),'get','keys','items','values','something')\n        True\n    \"\"\"\n    for attr in attrs:\n        if hasattr(obj, attr) is True:\n            return True\n    return False", "loc": 23}
{"file": "flutils\\flutils\\objutils.py", "class_name": null, "function_name": "has_any_callables", "parameters": ["obj"], "param_types": {"obj": "_Any"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["callable", "getattr", "has_any_attrs"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Check if the given ``obj`` has **ANY** of the given ``attrs`` and are callable.", "source_code": "def has_any_callables(obj: _Any, *attrs: str) -> bool:\n    \"\"\"Check if the given ``obj`` has **ANY** of the given ``attrs`` and are\n    callable.\n\n    Args:\n        obj (:obj:`Any <typing.Any>`): The object to check.\n        *attrs (:obj:`str`): The names of the attributes to check.\n\n    :rtype:\n        :obj:`bool`\n\n        * :obj:`True` if ANY of the given ``*attrs`` exist on the given ``obj``\n          and ANY are callable;\n        * :obj:`False` otherwise.\n\n    Example:\n        >>> from flutils.objutils import has_any_callables\n        >>> has_any_callables(dict(),'get','keys','items','values','foo')\n        True\n    \"\"\"\n    if has_any_attrs(obj, *attrs) is True:\n        for attr in attrs:\n            if callable(getattr(obj, attr)) is True:\n                return True\n    return False", "loc": 25}
{"file": "flutils\\flutils\\objutils.py", "class_name": null, "function_name": "has_attrs", "parameters": ["obj"], "param_types": {"obj": "_Any"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Check if given ``obj`` has all the given ``*attrs``.", "source_code": "def has_attrs(\n        obj: _Any,\n        *attrs: str\n) -> bool:\n    \"\"\"Check if given ``obj`` has all the given ``*attrs``.\n\n    Args:\n        obj (:obj:`Any <typing.Any>`): The object to check.\n        *attrs (:obj:`str`): The names of the attributes to check.\n\n    :rtype:\n        :obj:`bool`\n\n        * :obj:`True` if all the given ``*attrs`` exist on the given ``obj``;\n        * :obj:`False` otherwise.\n\n    Example:\n        >>> from flutils.objutils import has_attrs\n        >>> has_attrs(dict(),'get','keys','items','values')\n        True\n    \"\"\"\n    for attr in attrs:\n        if hasattr(obj, attr) is False:\n            return False\n    return True", "loc": 25}
{"file": "flutils\\flutils\\objutils.py", "class_name": null, "function_name": "has_callables", "parameters": ["obj"], "param_types": {"obj": "_Any"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["callable", "getattr", "has_attrs"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Check if given ``obj`` has all the given ``attrs`` and are callable.", "source_code": "def has_callables(\n        obj: _Any,\n        *attrs: str\n) -> bool:\n    \"\"\"Check if given ``obj`` has all the given ``attrs`` and are callable.\n\n    Args:\n        obj (:obj:`Any <typing.Any>`): The object to check.\n        *attrs (:obj:`str`): The names of the attributes to check.\n\n    :rtype:\n        :obj:`bool`\n\n        * :obj:`True` if all the given ``*attrs`` exist on the given ``obj``\n          and all are callable;\n        * :obj:`False` otherwise.\n\n    Example:\n        >>> from flutils.objutils import has_callables\n        >>> has_callables(dict(),'get','keys','items','values')\n        True\n    \"\"\"\n    if has_attrs(obj, *attrs) is True:\n        for attr in attrs:\n            if callable(getattr(obj, attr)) is False:\n                return False\n        return True\n    return False", "loc": 28}
{"file": "flutils\\flutils\\objutils.py", "class_name": null, "function_name": "is_list_like", "parameters": ["obj"], "param_types": {"obj": "_Any"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_subclass_of_any"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Check that given ``obj`` acts like a list and is iterable. List-like objects are instances of: - :obj:`UserList <collections.UserList>` - :obj:`Iterator <collections.abc.Iterator>` - :obj:`KeysView <collections.abc.KeysView>` - :obj:`ValuesView <collections.abc.ValuesView>` - :obj:`deque <collections.deque>` - :obj:`frozenset` - :obj:`list` - :obj:`set` - :obj:`tuple` List-like objects are **NOT** instances of: - :obj:`None` - :obj:`bool` - :obj:`bytes` - :obj:`ChainMap <collections.ChainMap>` - :obj:`Counter <collections.Counter>` - :obj:`OrderedDict <collections.OrderedDict>` - :obj:`UserDict <collections.UserDict>` - :obj:`UserString <collections.UserString>` - :obj:`defaultdict <collections.defaultdict>` - :obj:`Decimal <decimal.Decimal>` - :obj:`dict` - :obj:`float` - :obj:`int` - :obj:`str` - etc...", "source_code": "def is_list_like(\n        obj: _Any\n) -> bool:\n    \"\"\"Check that given ``obj`` acts like a list and is iterable.\n\n    List-like objects are instances of:\n\n    - :obj:`UserList <collections.UserList>`\n    - :obj:`Iterator <collections.abc.Iterator>`\n    - :obj:`KeysView <collections.abc.KeysView>`\n    - :obj:`ValuesView <collections.abc.ValuesView>`\n    - :obj:`deque <collections.deque>`\n    - :obj:`frozenset`\n    - :obj:`list`\n    - :obj:`set`\n    - :obj:`tuple`\n\n    List-like objects are **NOT** instances of:\n\n    - :obj:`None`\n    - :obj:`bool`\n    - :obj:`bytes`\n    - :obj:`ChainMap <collections.ChainMap>`\n    - :obj:`Counter <collections.Counter>`\n    - :obj:`OrderedDict <collections.OrderedDict>`\n    - :obj:`UserDict <collections.UserDict>`\n    - :obj:`UserString <collections.UserString>`\n    - :obj:`defaultdict <collections.defaultdict>`\n    - :obj:`Decimal <decimal.Decimal>`\n    - :obj:`dict`\n    - :obj:`float`\n    - :obj:`int`\n    - :obj:`str`\n    - etc...\n\n    Args:\n        obj (:obj:`Any <typing.Any>`): The object to check.\n\n    :rtype:\n        :obj:`bool`\n\n        * :obj:`True` if the given ``obj`` is list-like; :\n        * :obj:`False` otherwise.\n\n    Examples:\n        >>> from flutils.objutils import is_list_like\n        >>> is_list_like([1, 2, 3])\n        True\n        >>> is_list_like(reversed([1, 2, 4]))\n        True\n        >>> is_list_like('hello')\n        False\n        >>> is_list_like(sorted('hello'))\n        True\n    \"\"\"\n    if is_subclass_of_any(obj, *_LIST_LIKE):\n        return True\n    return False", "loc": 58}
{"file": "flutils\\flutils\\objutils.py", "class_name": null, "function_name": "is_subclass_of_any", "parameters": ["obj"], "param_types": {"obj": "_Any"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["issubclass"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Check if the given ``obj`` is a subclass of any of the given ``*classes``.", "source_code": "def is_subclass_of_any(obj: _Any, *classes: _Any) -> bool:\n    \"\"\"Check if the given ``obj`` is a subclass of any of the given\n    ``*classes``.\n\n    Args:\n        obj (:obj:`Any <typing.Any>`): The object to check.\n        *classes (:obj:`Any <typing.Any>`): The classes to check against.\n\n    :rtype:\n        :obj:`bool`\n\n        * :obj:`True` if the given ``obj`` is an instance of ANY given\n          ``*classes``;\n        * :obj:`False` otherwise.\n\n    Example:\n        >>> from flutils.objutils import is_subclass_of_any\n        >>> from collections import ValuesView, KeysView, UserList\n        >>> obj = dict(a=1, b=2)\n        >>> is_subclass_of_any(obj.keys(),ValuesView,KeysView,UserList)\n        True\n    \"\"\"\n    for cls in classes:\n        if issubclass(obj.__class__, cls):\n            return True\n    return False", "loc": 26}
{"file": "flutils\\flutils\\pathutils.py", "class_name": null, "function_name": "chmod", "parameters": ["path", "mode_file", "mode_dir", "include_parent"], "param_types": {"path": "_PATH", "mode_file": "Optional[int]", "mode_dir": "Optional[int]", "include_parent": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "Path().glob", "normalize_path", "parent.chmod", "parent.is_dir", "path.as_posix", "path.chmod", "path.exists", "path.is_dir", "path.is_file", "sub_path.chmod", "sub_path.is_dir", "sub_path.is_file"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Change the mode of a path. This function processes the given ``path`` with :obj:`~flutils.normalize_path`. If the given ``path`` does NOT exist, nothing will be done. This function will **NOT** change the mode of: - symlinks (symlink targets that are files or directories will be changed) - sockets - fifo - block devices - char devices", "source_code": "def chmod(\n        path: _PATH,\n        mode_file: Optional[int] = None,\n        mode_dir: Optional[int] = None,\n        include_parent: bool = False\n) -> None:\n    \"\"\"Change the mode of a path.\n\n    This function processes the given ``path`` with\n    :obj:`~flutils.normalize_path`.\n\n    If the given ``path`` does NOT exist, nothing will be done.\n\n    This function will **NOT** change the mode of:\n\n    - symlinks (symlink targets that are files or directories will be changed)\n    - sockets\n    - fifo\n    - block devices\n    - char devices\n\n    Args:\n        path (:obj:`str`, :obj:`bytes` or :obj:`Path <pathlib.Path>`):\n            The path of the file or directory to have it's mode changed.  This\n            value can be a :term:`glob pattern`.\n        mode_file (:obj:`int`, optional): The mode applied to the given\n            ``path`` that is a file or a symlink target that is a file.\n            Defaults to ``0o600``.\n        mode_dir (:obj:`int`, optional): The mode applied to the given\n            ``path`` that is a directory or a symlink target that is a\n            directory. Defaults to ``0o700``.\n        include_parent (:obj:`bool`, optional): A value of :obj:`True`` will\n            chmod the parent directory of the given ``path`` that contains a\n            a :term:`glob pattern`.  Defaults to :obj:`False`.\n\n    :rtype: :obj:`None`\n\n    Examples:\n        >>> from flutils.pathutils import chmod\n        >>> chmod('~/tmp/flutils.tests.osutils.txt', 0o660)\n\n        Supports a :term:`glob pattern`.  So to recursively change the mode\n        of a directory just do:\n\n        >>> chmod('~/tmp/**', mode_file=0o644, mode_dir=0o770)\n\n        To change the mode of a directory's immediate contents:\n\n        >>> chmod('~/tmp/*')\n\n    \"\"\"\n\n    path = normalize_path(path)\n\n    if mode_file is None:\n        mode_file = 0o600\n\n    if mode_dir is None:\n        mode_dir = 0o700\n\n    if '*' in path.as_posix():\n        try:\n            for sub_path in Path().glob(path.as_posix()):\n                if sub_path.is_dir() is True:\n                    sub_path.chmod(mode_dir)\n                elif sub_path.is_file():\n                    sub_path.chmod(mode_file)\n\n        # Path().glob() returns an iterator that will\n        # raise NotImplementedError if there\n        # are no results from the glob pattern.\n        except NotImplementedError:\n            pass\n\n        else:\n            if include_parent is True:\n                parent = path.parent\n                if parent.is_dir():\n                    parent.chmod(mode_dir)\n    else:\n        if path.exists() is True:\n            if path.is_dir():\n                path.chmod(mode_dir)\n            elif path.is_file():\n                path.chmod(mode_file)", "loc": 85}
{"file": "flutils\\flutils\\pathutils.py", "class_name": null, "function_name": "chown", "parameters": ["path", "user", "group", "include_parent"], "param_types": {"path": "_PATH", "user": "Optional[str]", "group": "Optional[str]", "include_parent": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "Path().glob", "get_os_group", "get_os_user", "isinstance", "normalize_path", "os.chown", "path.as_posix", "path.exists", "path.is_dir", "sub_path.as_posix", "sub_path.is_dir", "sub_path.is_file"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Change ownership of a path. This function processes the given ``path`` with :obj:`~flutils.normalize_path`. If the given ``path`` does NOT exist, nothing will be done.", "source_code": "def chown(\n        path: _PATH,\n        user: Optional[str] = None,\n        group: Optional[str] = None,\n        include_parent: bool = False\n) -> None:\n    \"\"\"Change ownership of a path.\n\n    This function processes the given ``path`` with\n    :obj:`~flutils.normalize_path`.\n\n    If the given ``path`` does NOT exist, nothing will be done.\n\n    Args:\n        path (:obj:`str`, :obj:`bytes` or :obj:`Path <pathlib.Path>`):\n            The path of the file or directory that will have it's ownership\n            changed.  This value can be a :term:`glob pattern`.\n        user (:obj:`str` or :obj:`int`, optional): The \"login name\" used to set\n            the owner of ``path``.  A value of ``'-1'`` will leave the\n            owner unchanged.  Defaults to the \"login name\" of the current user.\n        group (:obj:`str` or :obj:`int`, optional): The group name used to set\n            the group of ``path``.  A value of ``'-1'`` will leave the\n            group unchanged.  Defaults to the current user's group.\n        include_parent (:obj:`bool`, optional): A value of :obj:`True` will\n            chown the parent directory of the given ``path`` that contains\n            a :term:`glob pattern`.  Defaults to :obj:`False`.\n\n    Raises:\n        OSError: If the given :obj:`user` does not exist as a \"login\n            name\" for this operating system.\n        OSError: If the given :obj:`group` does not exist as a \"group\n            name\" for this operating system.\n\n    :rtype: :obj:`None`\n\n    Examples:\n        >>> from flutils.pathutils import chown\n        >>> chown('~/tmp/flutils.tests.osutils.txt')\n\n        Supports a :term:`glob pattern`.  So to recursively change the\n        ownership of a directory just do:\n\n        >>> chown('~/tmp/**')\n\n\n        To change ownership of all the directory's immediate contents:\n\n        >>> chown('~/tmp/*', user='foo', group='bar')\n\n    \"\"\"\n    path = normalize_path(path)\n    if isinstance(user, str) and user == '-1':\n        uid = -1\n    else:\n        uid = get_os_user(user).pw_uid\n\n    if isinstance(user, str) and group == '-1':\n        gid = -1\n    else:\n        gid = get_os_group(group).gr_gid\n\n    if '*' in path.as_posix():\n        try:\n            for sub_path in Path().glob(path.as_posix()):\n                if sub_path.is_dir() or sub_path.is_file():\n                    os.chown(sub_path.as_posix(), uid, gid)\n        except NotImplementedError:\n            # Path().glob() returns an iterator that will\n            # raise NotImplementedError if there\n            # are no results from the glob pattern.\n            pass\n        else:\n            if include_parent is True:\n                path = path.parent\n                if path.is_dir() is True:\n                    os.chown(path.as_posix(), uid, gid)\n    else:\n        if path.exists() is True:\n            os.chown(path.as_posix(), uid, gid)", "loc": 79}
{"file": "flutils\\flutils\\pathutils.py", "class_name": null, "function_name": "exists_as", "parameters": ["path"], "param_types": {"path": "_PATH"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["normalize_path", "path.is_block_device", "path.is_char_device", "path.is_dir", "path.is_fifo", "path.is_file", "path.is_socket"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return a string describing the file type if it exists. This function processes the given ``path`` with :obj:`~flutils.normalize_path`.", "source_code": "def exists_as(path: _PATH) -> str:\n    \"\"\"Return a string describing the file type if it exists.\n\n    This function processes the given ``path`` with\n    :obj:`~flutils.normalize_path`.\n\n    Args:\n        path (:obj:`str`, :obj:`bytes` or :obj:`Path <pathlib.Path>`):\n            The path to check for existence.\n\n    :rtype:\n        :obj:`str`\n\n        * ``''`` (empty string): if the given ``path`` does NOT exist; or,\n          is a broken symbolic link; or, other errors (such as permission\n          errors) are propagated.\n        * ``'directory'``: if the given ``path`` points to a directory or\n          is a symbolic link pointing to a directory.\n        * ``'file'``: if the given ``path`` points to a regular file or is a\n          symbolic link pointing to a regular file.\n        * ``'block device'``: if the given ``path`` points to a block device or\n          is a symbolic link pointing to a block device.\n        * ``'char device'``: if the given ``path`` points to a character device\n          or is a symbolic link pointing to a character device.\n        * ``'FIFO'``: if the given ``path`` points to a FIFO or is a symbolic\n          link pointing to a FIFO.\n        * ``'socket'``: if the given ``path`` points to a Unix socket or is a\n          symbolic link pointing to a Unix socket.\n\n    Example:\n        >>> from flutils.pathutils import exists_as\n        >>> exists_as('~/tmp')\n        'directory'\n    \"\"\"\n    path = normalize_path(path)\n\n    if path.is_dir():\n        return 'directory'\n    if path.is_file():\n        return 'file'\n    if path.is_block_device():\n        return 'block device'\n    if path.is_char_device():\n        return 'char device'\n    if path.is_fifo():\n        return 'FIFO'\n    if path.is_socket():\n        return 'socket'\n    return ''", "loc": 49}
{"file": "flutils\\flutils\\pathutils.py", "class_name": null, "function_name": "find_paths", "parameters": ["pattern"], "param_types": {"pattern": "_PATH"}, "return_type": "Generator[Path, None, None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "Path(pattern.anchor).glob", "len", "normalize_path", "pattern.as_posix"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Find all paths that match the given :term:`glob pattern`. This function pre-processes the given ``pattern`` with :obj:`~flutils.normalize_path`.", "source_code": "def find_paths(\n        pattern: _PATH\n) -> Generator[Path, None, None]:\n    \"\"\"Find all paths that match the given :term:`glob pattern`.\n\n    This function pre-processes the given ``pattern`` with\n    :obj:`~flutils.normalize_path`.\n\n    Args:\n        pattern (:obj:`str`, :obj:`bytes` or :obj:`Path <pathlib.Path>`):\n            The path to find; which may contain a :term:`glob pattern`.\n\n    :rtype:\n        :obj:`Generator <typing.Generator>`\n\n    Yields:\n        :obj:`pathlib.PosixPath` or :obj:`pathlib.WindowsPath`\n\n    Example:\n        >>> from flutils.pathutils import find_paths\n        >>> list(find_paths('~/tmp/*'))\n        [PosixPath('/home/test_user/tmp/file_one'),\n        PosixPath('/home/test_user/tmp/dir_one')]\n\n    \"\"\"\n    pattern = normalize_path(pattern)\n    search = pattern.as_posix()[len(pattern.anchor):]\n    yield from Path(pattern.anchor).glob(search)", "loc": 28}
{"file": "flutils\\flutils\\pathutils.py", "class_name": null, "function_name": "get_os_group", "parameters": ["name"], "param_types": {"name": "_STR_OR_INT_OR_NONE"}, "return_type": "grp.struct_group", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["OSError", "cast", "get_os_user", "grp.getgrgid", "grp.getgrnam", "isinstance"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Get an operating system group object.", "source_code": "def get_os_group(name: _STR_OR_INT_OR_NONE = None) -> grp.struct_group:\n    \"\"\"Get an operating system group object.\n\n    Args:\n        name (:obj:`str` or :obj:`int`, optional): The \"group name\" or ``gid``.\n            Defaults to the current users's group.\n\n    Raises:\n        OSError: If the given ``name`` does not exist as a \"group\n            name\" for this operating system.\n        OSError: If the given ``name`` is a ``gid`` and it does not\n            exist.\n\n    :rtype:\n        :obj:`struct_group <grp>`\n\n        * A tuple like object.\n\n    Example:\n        >>> from flutils.pathutils import get_os_group\n        >>> get_os_group('bar')\n        grp.struct_group(gr_name='bar', gr_passwd='*', gr_gid=2001,\n        gr_mem=['foo'])\n    \"\"\"\n    if name is None:\n        name = get_os_user().pw_gid\n        name = cast(int, name)\n    if isinstance(name, int):\n        try:\n            return grp.getgrgid(name)\n        except KeyError:\n            raise OSError(\n                'The given gid: %r, is not a valid gid for this operating '\n                'system.' % name\n            )\n    try:\n        return grp.getgrnam(name)\n    except KeyError:\n        raise OSError(\n            'The given name: %r, is not a valid \"group name\" '\n            'for this operating system.' % name\n        )", "loc": 42}
{"file": "flutils\\flutils\\pathutils.py", "class_name": null, "function_name": "get_os_user", "parameters": ["name"], "param_types": {"name": "_STR_OR_INT_OR_NONE"}, "return_type": "pwd.struct_passwd", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["OSError", "getpass.getuser", "isinstance", "pwd.getpwnam", "pwd.getpwuid"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Return an user object representing an operating system user.", "source_code": "def get_os_user(name: _STR_OR_INT_OR_NONE = None) -> pwd.struct_passwd:\n    \"\"\"Return an user object representing an operating system user.\n\n    Args:\n        name (:obj:`str` or :obj:`int`, optional): The \"login name\" or\n            ``uid``.  Defaults to the current user's \"login name\".\n    Raises:\n        OSError: If the given ``name`` does not exist as a \"login\n            name\" for this operating system.\n        OSError: If the given ``name`` is an ``uid`` and it does not\n            exist.\n\n    :rtype:\n        :obj:`struct_passwd <pwd>`\n\n        * A tuple like object.\n\n    Example:\n        >>> from flutils.pathutils import get_os_user\n        >>> get_os_user('foo')\n        pwd.struct_passwd(pw_name='foo', pw_passwd='********', pw_uid=1001,\n        pw_gid=2001, pw_gecos='Foo Bar', pw_dir='/home/foo',\n        pw_shell='/usr/local/bin/bash')\n    \"\"\"\n    if isinstance(name, int):\n        try:\n            return pwd.getpwuid(name)\n        except KeyError:\n            raise OSError(\n                'The given uid: %r, is not a valid uid for this operating '\n                'system.' % name\n            )\n    if name is None:\n        name = getpass.getuser()\n    try:\n        return pwd.getpwnam(name)\n    except KeyError:\n        raise OSError(\n            'The given name: %r, is not a valid \"login name\" '\n            'for this operating system.' % name\n        )", "loc": 41}
{"file": "flutils\\flutils\\strutils.py", "class_name": null, "function_name": "as_escaped_unicode_literal", "parameters": ["text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\\\U{:0>8}'.format", "'\\\\u{:0>4}'.format", "'\\\\x{:0>2}'.format", "hex", "len", "ord"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Convert the given ``text``  into a string of escaped Unicode hexadecimal.", "source_code": "def as_escaped_unicode_literal(\n        text: str\n) -> str:\n    \"\"\"Convert the given ``text``  into a string of escaped Unicode\n    hexadecimal.\n\n    Args:\n         text (:obj:`str`): The string to convert.\n\n    :rtype:\n        :obj:`str`\n\n            A string with each character of the given ``text`` converted\n            into an escaped Python literal.\n\n    Example:\n        >>> from flutils.strutils import as_escaped_unicode_literal\n        >>> t = '1. '\n        >>> as_literal(t)\n        '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\u2605\\\\\\\\x20\\\\\\\\U0001f6d1'\n    \"\"\"\n    out = ''\n    for c in text:\n        c_hex = hex(ord(c))[2:]\n        c_len = len(c_hex)\n        if c_len in (1, 2):\n            out += '\\\\x{:0>2}'.format(c_hex)\n        elif c_len in (3, 4):\n            out += '\\\\u{:0>4}'.format(c_hex)\n        else:\n            out += '\\\\U{:0>8}'.format(c_hex)\n    return out", "loc": 32}
{"file": "flutils\\flutils\\strutils.py", "class_name": null, "function_name": "as_escaped_utf8_literal", "parameters": ["text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hex", "text.encode"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Convert the given ``text`` into a string of escaped UTF8 hexadecimal.", "source_code": "def as_escaped_utf8_literal(\n        text: str,\n) -> str:\n    \"\"\"Convert the given ``text`` into a string of escaped UTF8 hexadecimal.\n\n    Args:\n         text (:obj:`str`): The string to convert.\n\n    :rtype:\n        :obj:`str`\n\n            A string with each character of the given ``text`` converted\n            into an escaped UTF8 hexadecimal.\n\n    Example:\n        >>> from flutils.strutils import as_literal_utf8\n        >>> t = '1. '\n        >>> as_escaped_utf8_literal(t)\n        '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\xe2\\\\\\\\x98\\\\\\\\x85\\\\\\\\x20\\\\\\\\xf0\\\\\\\\x9f\\\\\\\\x9b\n        \\\\\\\\x91'\n    \"\"\"\n    out = ''\n    text_bytes = text.encode('utf8')\n    for c in text_bytes:\n        out += '\\\\%s' % hex(c)[1:]\n    return out", "loc": 26}
{"file": "flutils\\flutils\\strutils.py", "class_name": null, "function_name": "camel_to_underscore", "parameters": ["text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_CAMEL_TO_UNDERSCORE_RE.sub", "_CAMEL_TO_UNDERSCORE_RE.sub('_\\\\1', text).lower"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Convert a camel-cased string to a string containing words separated with underscores.", "source_code": "def camel_to_underscore(\n        text: str\n) -> str:\n    \"\"\"Convert a camel-cased string to a string containing words separated\n    with underscores.\n\n    Args:\n        text (str): The camel-cased string to convert.\n\n    :rtype: :obj:`str`\n\n    Example:\n        >>> from flutils.strutils import camel_to_underscore\n        >>> camel_to_underscore('FooBar')\n        'foo_bar'\n    \"\"\"\n    return _CAMEL_TO_UNDERSCORE_RE.sub(r'_\\1', text).lower()", "loc": 17}
{"file": "flutils\\flutils\\strutils.py", "class_name": null, "function_name": "convert_escaped_unicode_literal", "parameters": ["text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["text.encode", "text_bytes.decode"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Convert any escaped Unicode literal hexadecimal character(s) to the proper character(s). This function will convert a string, that may contain escaped Unicode literal hexadecimal characters, into a string with the proper characters.", "source_code": "def convert_escaped_unicode_literal(\n        text: str\n) -> str:\n    \"\"\"Convert any escaped Unicode literal hexadecimal character(s) to the\n    proper character(s).\n\n    This function will convert a string, that may contain escaped Unicode\n    literal hexadecimal characters, into a string with the proper characters.\n\n    Args:\n        text (:obj:`str`): The string that may have escaped Unicode\n            hexadecimal.\n\n    :rtype:\n        :obj:`str`\n\n            A string with each escaped Unicode hexadecimal character converted\n            into the proper character.\n\n\n    The following Unicode literal formats are supported::\n\n        \\\\x31\n        \\\\u0031\n        \\\\U00000031\n\n    Examples:\n\n        Basic usage::\n\n            >>> from flutils.strutils import convert_escaped_unicode_literal\n            >>> a = '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\u2605\\\\\\\\x20\\\\\\\\U0001f6d1'\n            >>> convert_escaped_unicode_literal(a)\n            '1. '\n\n        This function is intended for cases when the value of an environment\n        variable contains escaped Unicode literal characters that need to be\n        converted to proper characters::\n\n            $ export TEST='\\\\x31\\\\x2e\\\\u2605\\\\x20\\\\U0001f6d1'\n            $ python\n\n        ::\n\n            >>> import os\n            >>> from flutils.strutils import convert_escaped_unicode_literal\n            >>> a = os.getenv('TEST')\n            >>> a\n            '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\u2605\\\\\\\\x20\\\\\\\\U0001f6d1'\n            >>> convert_escaped_unicode_literal(a)\n            '1. '\n\n    \"\"\"\n    text_bytes = text.encode()\n    return text_bytes.decode('unicode_escape')", "loc": 55}
{"file": "flutils\\flutils\\strutils.py", "class_name": null, "function_name": "convert_escaped_utf8_literal", "parameters": ["text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["register_codecs", "text.encode", "text_bytes.decode"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Convert any escaped UTF-8 hexadecimal character bytes into the proper string characters(s). This function will convert a string, that may contain escaped UTF-8 literal hexadecimal bytes, into a string with the proper characters.", "source_code": "def convert_escaped_utf8_literal(\n        text: str\n) -> str:\n    \"\"\"Convert any escaped UTF-8 hexadecimal character bytes into the proper\n    string characters(s).\n\n    This function will convert a string, that may contain escaped UTF-8\n    literal hexadecimal bytes, into a string with the proper characters.\n\n    Args:\n        text (:obj:`str`): The string that may have escaped UTF8 hexadecimal.\n\n    Raises:\n         UnicodeDecodeError: if any of the escaped hexadecimal characters\n            are not proper UTF8 bytes.\n\n    :rtype:\n        :obj:`str`\n\n            A string with each escaped UTF8 hexadecimal character converted\n            into the proper character.\n\n    Examples:\n\n        Basic usage:\n\n            >>> from flutils.strutils import convert_raw_utf8_escape\n            >>> a = 'test\\\\\\\\xc2\\\\\\\\xa9'\n            >>> convert_escaped_utf8_literal(a)\n            'test'\n\n        This function is intended for cases when the value of an environment\n        variable contains escaped UTF-8 literal characters (bytes) that need\n        to be converted to proper characters::\n\n            $ export TEST='test\\\\\\\\xc2\\\\\\\\xa9'\n            $ python\n\n        ::\n\n            >>> import os\n            >>> from flutils.strutils import convert_raw_utf8_escape\n            >>> a = os.getenv('TEST')\n            >>> a\n            'test\\\\\\\\xc2\\\\\\\\xa9'\n            >>> convert_escaped_utf8_literal(a)\n            'test'\n    \"\"\"\n    from flutils.codecs import register_codecs  # pylint:disable=C0415\n    register_codecs()\n    text_bytes = text.encode('utf-8')\n    text = text_bytes.decode('raw_utf8_escape')\n    return text", "loc": 53}
{"file": "flutils\\flutils\\strutils.py", "class_name": null, "function_name": "underscore_to_camel", "parameters": ["text", "lower_first"], "param_types": {"text": "str", "lower_first": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "out[:1].lower", "text.split", "x.capitalize"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convert a string with words separated by underscores to a camel-cased string.", "source_code": "def underscore_to_camel(\n        text: str,\n        lower_first: bool = True\n) -> str:\n    \"\"\"Convert a string with words separated by underscores to a camel-cased\n    string.\n\n    Args:\n        text (:obj:`str`): The camel-cased string to convert.\n        lower_first (:obj:`bool`, optional): Lowercase the first character.\n            Defaults to :obj:`True`.\n\n    :rtype: :obj:`str`\n\n    Examples:\n        >>> from flutils.strutils import underscore_to_camel\n        >>> underscore_to_camel('foo_bar')\n        'fooBar'\n        >>> underscore_to_camel('_one__two___',lower_first=False)\n        'OneTwo'\n    \"\"\"\n    out = ''.join([x.capitalize() or '' for x in text.split('_')])\n    if lower_first is True:\n        return out[:1].lower() + out[1:]\n    return out", "loc": 25}
{"file": "flutils\\flutils\\txtutils.py", "class_name": null, "function_name": "len_without_ansi", "parameters": ["seq"], "param_types": {"seq": "Sequence"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_ANSI_RE.split", "cast", "chain", "hasattr", "len", "map", "text.endswith", "text.startswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return the character length of the given :obj:`Sequence <typing.Sequence>` without counting any ANSI codes. *New in version 0.6*", "source_code": "def len_without_ansi(seq: Sequence) -> int:\n    \"\"\"Return the character length of the given\n    :obj:`Sequence <typing.Sequence>` without counting any ANSI codes.\n\n    *New in version 0.6*\n\n    Args:\n         seq (:obj:`Sequence <typing.Sequence>`): A string or a list/tuple\n             of strings.\n\n    :rtype:\n        :obj:`int`\n\n    Example:\n        >>> from flutils.txtutils import len_without_ansi\n        >>> text = '\\\\x1b[38;5;209mfoobar\\\\x1b[0m'\n        >>> len_without_ansi(text)\n        6\n    \"\"\"\n    if hasattr(seq, 'capitalize'):\n        _text: str = cast(str, seq)\n        seq = [c for c in _ANSI_RE.split(_text) if c]\n    seq = [c for c in chain(*map(_ANSI_RE.split, seq)) if c]\n    seq = cast(Sequence[str], seq)\n    out = 0\n    for text in seq:\n        if hasattr(text, 'capitalize'):\n            if text.startswith('\\x1b[') and text.endswith('m'):\n                continue\n            else:\n                out += len(text)\n    return out", "loc": 32}
{"file": "flutils\\flutils\\txtutils.py", "class_name": "AnsiTextWrapper", "function_name": "wrap", "parameters": ["self", "text"], "param_types": {"text": "str"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["super", "super().wrap"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Wraps the single paragraph in the given ``text`` so every line is at most ``width`` characters long. All wrapping options are taken from instance attributes of the :obj:`~flutils.txtutils.AnsiTextWrapper` instance.", "source_code": "def wrap(self, text: str) -> List[str]:\n    \"\"\"Wraps the single paragraph in the given ``text`` so every line is\n    at most ``width`` characters long. All wrapping options are taken\n    from instance attributes of the\n    :obj:`~flutils.txtutils.AnsiTextWrapper` instance.\n\n    Args:\n        text (str): The text to be wrapped.\n\n    Returns:\n        A ``List[str]`` of output lines, without final newlines.\n        If the wrapped output has no content, the returned list is\n        empty.\n    \"\"\"\n    return super().wrap(text)", "loc": 15}
{"file": "flutils\\flutils\\txtutils.py", "class_name": "AnsiTextWrapper", "function_name": "fill", "parameters": ["self", "text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["super", "super().fill"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Wraps a single paragraph.", "source_code": "def fill(self, text: str) -> str:\n    \"\"\"Wraps a single paragraph.\n\n    Args:\n        text (str): The text to be wrapped.\n\n     Returns:\n          A single :obj:`str` containing the wrapped paragraph.\n    \"\"\"\n    return super().fill(text)", "loc": 10}
{"file": "flutils\\flutils\\validators.py", "class_name": null, "function_name": "validate_identifier", "parameters": ["identifier", "allow_underscore"], "param_types": {"identifier": "Union[str, UserString]", "allow_underscore": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SyntaxError", "TypeError", "identifier.isidentifier", "identifier.strip", "identifier[0:1].isdigit", "isinstance", "keyword.iskeyword", "str", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Validate the given string is a proper identifier. This validator will also raise an error if the given identifier is a keyword or a builtin identifier.", "source_code": "def validate_identifier(\n        identifier: Union[str, UserString],\n        allow_underscore: bool = True\n) -> None:\n    \"\"\"Validate the given string is a proper identifier.\n\n    This validator will also raise an error if the given identifier is a\n    keyword or a builtin identifier.\n\n    Args:\n        identifier (:obj:`str` or :obj:`UserString <collections.UserString>`):\n            The value to be tested.\n        allow_underscore (:obj:`bool`, optional): A value of :obj:`False`\n            will raise an error when the ``identifier`` has a value that starts\n            with an underscore ``_``. (Use :obj:`False` when validating\n            potential :obj:`namedtuple <collections.namedtuple>` keys)\n            Defaults to: :obj:`True`.\n\n    Raises:\n        SyntaxError: If the given identifier is invalid.\n        TypeError: If the given identifier is not a :obj:`str` or\n            :obj:`UserString <collections.UserString>`.\n\n    :rtype: :obj:`None`\n\n    Example:\n        >>> from flutils.validators import validate_identifier\n        >>> validate_identifier('123')\n        SyntaxError: The given 'identifier', '123', cannot start with a number\n    \"\"\"\n    if isinstance(identifier, UserString):\n        identifier = str(identifier)\n    if not isinstance(identifier, str):\n        raise TypeError(\n            \"The given 'identifier' must be a 'str'.  Got: %r\"\n            % type(identifier).__name__\n        )\n    identifier = identifier.strip()\n    if not identifier:\n        raise SyntaxError(\"The given 'identifier' cannot be empty\")\n\n    if allow_underscore is False and identifier[0:1] == '_':\n        raise SyntaxError(\n            f\"The given 'identifier', {identifier!r}, cannot start with an \"\n            \"underscore '_'\"\n        )\n\n    if identifier[0:1].isdigit():\n        raise SyntaxError(\n            f\"The given 'identifier', {identifier!r}, cannot start with a \"\n            \"number\"\n        )\n\n    if not identifier.isidentifier():\n        raise SyntaxError(\n            f\"The given 'identifier', {identifier!r}, is invalid.\"\n        )\n\n    if keyword.iskeyword(identifier):\n        raise SyntaxError(\n            f\"The given 'identifier', {identifier!r}, cannot be a keyword\"\n        )\n\n    if identifier in _BUILTIN_NAMES:\n        raise SyntaxError(\n            f\"The given 'identifier', {identifier!r}, cannot be a builtin name\"\n        )", "loc": 67}
{"file": "flutils\\flutils\\codecs\\b64.py", "class_name": null, "function_name": "encode", "parameters": ["text", "errors"], "param_types": {"text": "_STR", "errors": "_STR"}, "return_type": "Tuple[bytes, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "UnicodeEncodeError", "base64.decodebytes", "filter", "len", "map", "str", "text_input.strip", "text_str.encode", "text_str.strip", "text_str.strip().splitlines", "x.strip"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Convert the given ``text`` of base64 characters into the base64 decoded bytes.", "source_code": "def encode(\n        text: _STR,\n        errors: _STR = 'strict'\n) -> Tuple[bytes, int]:\n    \"\"\"Convert the given ``text`` of base64 characters into the base64\n    decoded bytes.\n\n    Args:\n        text (str): The string input.  The given string input can span\n            across many lines and be indented any number of spaces.\n        errors (str): Not used.  This argument exists to meet the\n            interface requirements.  Any value given to this argument\n            is ignored.\n\n    Returns:\n        bytes: The given ``text`` converted into base64 bytes.\n        int: The length of the returned bytes.\n    \"\"\"\n    # Convert the given 'text', that are of type UserString into a str.\n    text_input = str(text)\n\n    # Cleanup whitespace.\n    text_str = text_input.strip()\n    text_str = '\\n'.join(\n        filter(\n            lambda x: len(x) > 0,\n            map(lambda x: x.strip(), text_str.strip().splitlines())\n        )\n    )\n\n    # Convert the cleaned text into utf8 bytes\n    text_bytes = text_str.encode('utf-8')\n    try:\n        out = base64.decodebytes(text_bytes)\n    except Error as e:\n        raise UnicodeEncodeError(\n            'b64',\n            text_input,\n            0,\n            len(text),\n            (\n                f'{text_str!r} is not a proper bas64 character string: '\n                f'{e}'\n            )\n        )\n    return out, len(text)", "loc": 46}
{"file": "flutils\\flutils\\codecs\\b64.py", "class_name": null, "function_name": "decode", "parameters": ["data", "errors"], "param_types": {"data": "_ByteString", "errors": "_STR"}, "return_type": "Tuple[str, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["base64.b64encode", "bytes", "encoded_bytes.decode", "len"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Convert the given ``data`` into base64 Characters.", "source_code": "def decode(\n        data: _ByteString,\n        errors: _STR = 'strict'\n) -> Tuple[str, int]:\n    \"\"\"Convert the given ``data`` into base64 Characters.\n\n    Args:\n        data (bytes or bytearray or memoryview): Bytes to be converted\n            to a string of base64 characters.\n        errors (str or :obj:`~UserString`): Not used.  This argument exists\n            to meet the interface requirements.  Any value given to this\n            argument is ignored.\n\n    Returns:\n        str: of base64 Characters\n        int: the number of the given ``data`` bytes consumed.\n    \"\"\"\n    # Convert memoryview and bytearray objects to bytes.\n    data_bytes = bytes(data)\n\n    # Encode the 'data_bytes' into base64 bytes.\n    encoded_bytes = base64.b64encode(data_bytes)\n\n    # Decode the 'base64_bytes' as utf8 into a string.\n    encoded_str = encoded_bytes.decode('utf-8')\n\n    return encoded_str, len(data)", "loc": 27}
{"file": "flutils\\flutils\\codecs\\b64.py", "class_name": null, "function_name": "register", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["codecs.getdecoder", "codecs.register"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Register the ``b64`` codec with Python.", "source_code": "def register() -> None:\n    \"\"\"Register the ``b64`` codec with Python.\"\"\"\n    try:\n        codecs.getdecoder(NAME)\n    except LookupError:\n        codecs.register(_get_codec_info)   # type: ignore", "loc": 6}
{"file": "flutils\\flutils\\codecs\\raw_utf8_escape.py", "class_name": null, "function_name": "encode", "parameters": ["text", "errors"], "param_types": {"text": "_Str", "errors": "_Str"}, "return_type": "Tuple[bytes, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["UnicodeEncodeError", "_each_utf8_hex", "cast", "len", "out_str.encode", "reduce", "str", "text_bytes_utf8.decode", "text_input.encode", "text_str_latin1.encode"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Convert a :obj:`str`, that may contain escaped utf8 hexadecimal, to bytes of escaped utf8 hexadecimal.", "source_code": "def encode(\n        text: _Str,\n        errors: _Str = 'strict'\n) -> Tuple[bytes, int]:\n    \"\"\"Convert a :obj:`str`, that may contain escaped utf8 hexadecimal, to\n    bytes of escaped utf8 hexadecimal.\n\n    Args:\n        text (str or :obj:`~UserString`): The string input.\n        errors (str or :obj:`~UserString`): The error checking level.\n\n    Returns:\n        bytes: The given ``text`` converted into escaped utf8 bytes.\n        int: The number of given ``text`` characters consumed\n\n    Raises:\n         UnicodeEncodeError: if the given ``text`` contains escaped\n            utf8 hexadecimal that references invalid utf8 bytes.\n    \"\"\"\n\n    # Convert the given 'text', that are of type UserString into a str.\n    # if isinstance(text, UserString):\n    #     text_input = str(text)\n    # else:\n\n    text_input = str(text)\n\n    # Convert the given 'errors', that are of type UserString into a str.\n    errors_input = str(errors)\n\n    # Convert the string into utf-8 bytes\n    text_bytes_utf8 = text_input.encode('utf-8')\n    text_bytes_utf8 = cast(bytes, text_bytes_utf8)\n\n    # Convert the utf8 bytes into a string of latin-1 characters.\n    # This basically maps the exact utf8 bytes to the string. Also,\n    # this converts any escaped hexadecimal sequences \\\\xHH into\n    # \\xHH bytes.\n    text_str_latin1 = text_bytes_utf8.decode('unicode_escape')\n\n    # Convert the string of latin-1 characters (which are actually\n    # utf8 characters) into bytes.\n    text_bytes_utf8 = text_str_latin1.encode('latin1')\n\n    # Convert the utf8 bytes into a string.\n    try:\n        text_str = text_bytes_utf8.decode('utf-8', errors=errors_input)\n    except UnicodeDecodeError as e:\n        raise UnicodeEncodeError(\n            'eutf8h',\n            str(text_input),\n            e.start,\n            e.end,\n            e.reason,\n        )\n\n    # Convert each character into a string of escaped utf8 hexadecimal.\n    out_str: str = reduce(lambda a, b: f'{a}{b}', _each_utf8_hex(text_str))\n\n    out_bytes = out_str.encode('utf-8')\n\n    return out_bytes, len(text)", "loc": 62}
{"file": "flutils\\flutils\\codecs\\raw_utf8_escape.py", "class_name": null, "function_name": "decode", "parameters": ["data", "errors"], "param_types": {"data": "_ByteString", "errors": "_Str"}, "return_type": "Tuple[str, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["UnicodeDecodeError", "bytes", "data_bytes.decode", "len", "str", "text_bytes_utf8.decode", "text_str_latin1.encode"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Convert a bytes type of escaped utf8 hexadecimal to a string.", "source_code": "def decode(\n        data: _ByteString,\n        errors: _Str = 'strict'\n) -> Tuple[str, int]:\n    \"\"\"Convert a bytes type of escaped utf8 hexadecimal to a string.\n\n    Args:\n        data (bytes or bytearray or memoryview): The escaped utf8\n            hexadecimal bytes.\n        errors (str or :obj:`~UserString`): The error checking level.\n\n    Returns:\n        str: The given ``data`` (of escaped utf8 hexadecimal bytes)\n            converted into a :obj:`str`.\n        int: The number of the given ``data`` bytes consumed.\n\n    Raises:\n         UnicodeDecodeError: if the given ``data`` contains escaped\n            utf8 hexadecimal that references invalid utf8 bytes.\n\n\n    \"\"\"\n    # Convert memoryview and bytearray objects to bytes.\n    data_bytes = bytes(data)\n\n    # Convert the given 'errors', that are of type UserString into a str.\n    errors_input = str(errors)\n\n    # Convert the utf8 bytes into a string of latin-1 characters.\n    # This basically maps the exact utf8 bytes to the string. Also,\n    # this converts any escaped hexadecimal sequences \\\\xHH into\n    # \\xHH bytes.\n    text_str_latin1 = data_bytes.decode('unicode_escape')\n\n    # Convert the string of latin-1 characters (which are actually\n    # utf8 characters) into bytes.\n    text_bytes_utf8 = text_str_latin1.encode('latin1')\n\n    # Convert the utf8 bytes into a string.\n    try:\n        out = text_bytes_utf8.decode('utf-8', errors=errors_input)\n    except UnicodeDecodeError as e:\n        raise UnicodeDecodeError(\n            'eutf8h',\n            data_bytes,\n            e.start,\n            e.end,\n            e.reason\n        )\n    return out, len(data)", "loc": 50}
{"file": "flutils\\flutils\\codecs\\raw_utf8_escape.py", "class_name": null, "function_name": "register", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["codecs.getdecoder", "codecs.register"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def register() -> None:\n    try:\n        codecs.getdecoder(NAME)\n    except LookupError:\n        codecs.register(_get_codec_info)   # type: ignore", "loc": 5}
{"file": "flutils\\flutils\\codecs\\__init__.py", "class_name": null, "function_name": "register_codecs", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["b64.register", "raw_utf8_escape.register"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Register additional codecs. *New in version 0.4.* :rtype: :obj:`None`", "source_code": "def register_codecs() -> None:\n    \"\"\"Register additional codecs.\n\n    *New in version 0.4.*\n\n    :rtype: :obj:`None`\n\n    Examples:\n\n        >>> from flutils.codecs import register_codecs\n        >>> register_codecs()\n        >>> 'test'.encode('raw_utf8_escape')\n        b'test\\\\\\\\xc2\\\\\\\\xa9'\n        >>> b'test\\\\\\\\xc2\\\\\\\\xa9'.decode('raw_utf8_escape')\n        'test'\n        >>> 'dGVzdA=='.encode('b64')\n        b'test'\n        >>> b'test'.decode('b64')\n        'dGVzdA=='\n\n    \"\"\"\n    raw_utf8_escape.register()\n    b64.register()", "loc": 23}
{"file": "flutils\\flutils\\codecs\\__init__.py", "class_name": null, "function_name": "get_encoding", "parameters": ["name", "default"], "param_types": {"name": "Optional[str]", "default": "Optional[str]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["LookupError", "cast", "codecs.lookup", "default.strip", "hasattr", "name.strip"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Validate and return the given encoding codec name.", "source_code": "def get_encoding(\n        name: Optional[str] = None,\n        default: Optional[str] = SYSTEM_ENCODING\n) -> str:\n    \"\"\"Validate and return the given encoding codec name.\n\n    Args:\n        name (str): The name of the encoding to validate.\n            if empty or invalid then the value of the given ``default``\n            will be returned.\n        default (str, optional): If set, this encoding name will be returned\n            if the given ``name`` is invalid. Defaults to:\n            :obj:`~flutils.codecs.SYSTEM_ENCODING`.  If set to :obj:`None`\n            which will raise a :obj:`LookupError` if the given ``name``\n            is not valid.\n\n    Raises:\n        LookupError: If the given ``name`` is not a valid encoding codec name\n            and the given ``default`` is set to :obj:`None` or an empty string.\n        LookupError: If the given ``default`` is not a valid encoding codec\n            name.\n\n    Returns:\n        str: The encoding codec name.\n\n    Example:\n\n        >>> from flutils.codecs import get_encoding\n        >>> get_encoding()\n        'utf-8'\n    \"\"\"\n    if name is None:\n        name = ''\n    if hasattr(name, 'encode') is False:\n        name = ''\n    name = cast(str, name)\n    name = name.strip()\n\n    if default is None:\n        default = ''\n    if hasattr(default, 'encode') is False:\n        default = ''\n    default = cast(str, default)\n    default = default.strip()\n\n    if default:\n        try:\n            codec = codecs.lookup(default)\n        except LookupError:\n            raise LookupError(\n                f\"The given 'default' of {default!r} is an invalid encoding \"\n                f\"codec name.\"\n            )\n        else:\n            default = codec.name\n\n    try:\n        codec = codecs.lookup(name)\n    except LookupError:\n        if default:\n            return default\n        raise LookupError(\n            f\"The given 'name' of {name!r} is an invalid encoding \"\n            f\"codec name.\"\n        )\n    else:\n        return codec.name", "loc": 67}
{"file": "flutils\\flutils\\setuputils\\__init__.py", "class_name": null, "function_name": "add_setup_cfg_commands", "parameters": ["setup_kwargs", "setup_dir"], "param_types": {"setup_kwargs": "Dict[str, Any]", "setup_dir": "Optional[Union[PathLike, str]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["build_setup_cfg_command_class", "each_sub_command_config", "setup_kwargs.keys"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Add additional custom ``setup.py`` commands that are defined in ``setup.cfg``.", "source_code": "def add_setup_cfg_commands(\n        setup_kwargs: Dict[str, Any],\n        setup_dir: Optional[Union[PathLike, str]] = None\n) -> None:\n    \"\"\"Add additional custom ``setup.py`` commands that are defined in\n    ``setup.cfg``.\n\n    Args:\n        setup_kwargs (dict): A dictionary holding the\n            `setuptools.setup keyword arguments <https://bit.ly/2Ju4Zad>`_.\n            (see example below).\n        setup_dir (:obj:`str` or :obj:`Path <pathlib.Path>`, optional): The\n            root directory of the project. (e.g. the directory that contains\n            the ``setup.py`` file).  Defaults to: ``None`` which will try to\n            determine the directory using the call stack.\n\n    :rtype: :obj:`None`\n\n    Example:\n        Use in ``setup.py`` like the following::\n\n            #!/usr/bin/env python\n\n            import os\n\n            from setuptools import setup\n\n            from flutils.setuputils import add_setup_cfg_commands\n\n            setup_kwargs = {}\n            setup_dir = os.path.dirname(os.path.realpath(__file__))\n            add_setup_cfg_commands(setup_kwargs, setup_dir=setup_dir)\n            setup(**setup_kwargs)\n\n    \"\"\"\n    for sub_command_cfg in each_sub_command_config(setup_dir):\n        klass = build_setup_cfg_command_class(sub_command_cfg)\n        if 'cmdclass' not in setup_kwargs.keys():\n            setup_kwargs['cmdclass'] = {}\n        setup_kwargs['cmdclass'][sub_command_cfg.name] = klass", "loc": 40}
{"file": "httpie\\docs\\contributors\\fetch.py", "class_name": null, "function_name": "main", "parameters": ["previous_release", "current_release"], "param_types": {"previous_release": "str", "current_release": "str"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fetch_missing_users_details", "find_committers", "find_reporters", "load_awesome_people", "merge_all_the_people", "print", "release_date", "save_awesome_people"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main(previous_release: str, current_release: str) -> int:\n    since = release_date(previous_release)\n    until = release_date(current_release)\n\n    contributors = load_awesome_people()\n    try:\n        committers = find_committers(since, until)\n        reporters = find_reporters(since, until)\n    except Exception as exc:\n        # We want to save what we fetched so far. So pass.\n        print(' !! ', exc)\n\n    try:\n        merge_all_the_people(current_release, contributors, committers, reporters)\n        fetch_missing_users_details(contributors)\n    except FinishedForNow:\n        # We want to save what we fetched so far. So pass.\n        print(' !! Committers:', committers)\n        print(' !! Reporters:', reporters)\n        exit_status = 1\n    else:\n        exit_status = 0\n\n    save_awesome_people(contributors)\n    return exit_status", "loc": 25}
{"file": "httpie\\docs\\contributors\\fetch.py", "class_name": null, "function_name": "find_committers", "parameters": ["since", "until"], "param_types": {"since": "str", "until": "str"}, "return_type": "FullNames", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CO_AUTHORS", "co_author.group", "committers.add", "debug", "fetch", "len", "set"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_committers(since: str, until: str) -> FullNames:\n    url = f'{REPO_URL}/commits'\n    page = 1\n    per_page = 100\n    params = {\n        'since': since,\n        'until': until,\n        'per_page': per_page,\n    }\n    committers: FullNames = set()\n\n    while 'there are commits':\n        params['page'] = page\n        data = fetch(url, params=params)\n\n        for item in data:\n            commit = item['commit']\n            committers.add(commit['author']['name'])\n            debug(' >>> Commit', item['html_url'])\n            for co_author in CO_AUTHORS(commit['message']):\n                name = co_author.group(1)\n                committers.add(name)\n\n        if len(data) < per_page:\n            break\n        page += 1\n\n    return committers", "loc": 28}
{"file": "httpie\\docs\\contributors\\fetch.py", "class_name": null, "function_name": "find_reporters", "parameters": ["since", "until"], "param_types": {"since": "str", "until": "str"}, "return_type": "GitHubLogins", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "debug", "fetch", "len", "reporters.add", "set"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_reporters(since: str, until: str) -> GitHubLogins:\n    url = f'{API_URL}/search/issues'\n    page = 1\n    per_page = 100\n    params = {\n        'q': f'repo:{REPO}/{OWNER} is:issue closed:{since}..{until}',\n        'per_page': per_page,\n    }\n    reporters: GitHubLogins = set()\n\n    while 'there are issues':\n        params['page'] = page\n        data = fetch(url, params=params)\n\n        for item in data['items']:\n            # Filter out unwanted labels.\n            if any(label['name'] in SKIPPED_LABELS for label in item['labels']):\n                continue\n            debug(' >>> Issue', item['html_url'])\n            reporters.add(item['user']['login'])\n\n        if len(data['items']) < per_page:\n            break\n        page += 1\n\n    return reporters", "loc": 26}
{"file": "httpie\\docs\\contributors\\fetch.py", "class_name": null, "function_name": "merge_all_the_people", "parameters": ["release", "contributors", "committers", "reporters"], "param_types": {"release": "str", "contributors": "People", "committers": "FullNames", "reporters": "GitHubLogins"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["committers.remove", "contributors.items", "contributors[name]['reported'].append", "details['committed'].append", "details['reported'].append", "new_person", "reporters.remove", "user"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": ">>> contributors = {'Alice': new_person(github='alice', twitter='alice')} >>> merge_all_the_people('2.6.0', contributors, {}, {}) >>> contributors", "source_code": "def merge_all_the_people(release: str, contributors: People, committers: FullNames, reporters: GitHubLogins) -> None:\n    \"\"\"\n    >>> contributors = {'Alice': new_person(github='alice', twitter='alice')}\n    >>> merge_all_the_people('2.6.0', contributors, {}, {})\n    >>> contributors\n    {'Alice': {'committed': [], 'reported': [], 'github': 'alice', 'twitter': 'alice'}}\n\n    >>> contributors = {'Bob': new_person(github='bob', twitter='bob')}\n    >>> merge_all_the_people('2.6.0', contributors, {'Bob'}, {'bob'})\n    >>> contributors\n    {'Bob': {'committed': ['2.6.0'], 'reported': ['2.6.0'], 'github': 'bob', 'twitter': 'bob'}}\n\n    >>> contributors = {'Charlotte': new_person(github='charlotte', twitter='charlotte', committed=['2.5.0'], reported=['2.5.0'])}\n    >>> merge_all_the_people('2.6.0', contributors, {'Charlotte'}, {'charlotte'})\n    >>> contributors\n    {'Charlotte': {'committed': ['2.5.0', '2.6.0'], 'reported': ['2.5.0', '2.6.0'], 'github': 'charlotte', 'twitter': 'charlotte'}}\n\n    \"\"\"\n    # Update known contributors.\n    for name, details in contributors.items():\n        if name in committers:\n            if release not in details['committed']:\n                details['committed'].append(release)\n            committers.remove(name)\n        if details['github'] in reporters:\n            if release not in details['reported']:\n                details['reported'].append(release)\n            reporters.remove(details['github'])\n\n    # Add new committers.\n    for name in committers:\n        user_info = user(fullname=name)\n        contributors[name] = new_person(\n            github=user_info['login'],\n            twitter=user_info['twitter_username'],\n            committed=[release],\n        )\n        if user_info['login'] in reporters:\n            contributors[name]['reported'].append(release)\n            reporters.remove(user_info['login'])\n\n    # Add new reporters.\n    for github_username in reporters:\n        user_info = user(github_username=github_username)\n        contributors[user_info['name'] or user_info['login']] = new_person(\n            github=github_username,\n            twitter=user_info['twitter_username'],\n            reported=[release],\n        )", "loc": 49}
{"file": "httpie\\docs\\contributors\\fetch.py", "class_name": null, "function_name": "load_awesome_people", "parameters": [], "param_types": {}, "return_type": "People", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DB_FILE.open", "json.load"], "control_structures": ["Try"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def load_awesome_people() -> People:\n    try:\n        with DB_FILE.open(encoding='utf-8') as fh:\n            return json.load(fh)\n    except (FileNotFoundError, ValueError):\n        return {}", "loc": 6}
{"file": "httpie\\docs\\contributors\\fetch.py", "class_name": null, "function_name": "user", "parameters": ["fullname", "github_username"], "param_types": {"fullname": "Optional[str]", "github_username": "Optional[str]"}, "return_type": "UserInfo", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fetch"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def user(fullname: Optional[str] = '', github_username: Optional[str] = '') -> UserInfo:\n    if github_username:\n        url = f'{API_URL}/users/{github_username}'\n        return fetch(url)\n\n    url = f'{API_URL}/search/users'\n    for query in (f'fullname:{fullname}', f'user:{fullname}'):\n        params = {\n            'q': f'repo:{REPO}/{OWNER} {query}',\n            'per_page': 1,\n        }\n        user_info = fetch(url, params=params)\n        if user_info['items']:\n            user_url = user_info['items'][0]['url']\n            return fetch(user_url)", "loc": 15}
{"file": "httpie\\docs\\contributors\\fetch.py", "class_name": null, "function_name": "fetch_missing_users_details", "parameters": ["people"], "param_types": {"people": "People"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["people.items", "user"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fetch_missing_users_details(people: People) -> None:\n    for name, details in people.items():\n        if details['github'] and details['twitter']:\n            continue\n        user_info = user(github_username=details['github'], fullname=name)\n        if not details['github']:\n            details['github'] = user_info['login']\n        if not details['twitter']:\n            details['twitter'] = user_info['twitter_username']", "loc": 9}
{"file": "httpie\\docs\\contributors\\generate.py", "class_name": null, "function_name": "generate_snippets", "parameters": ["release"], "param_types": {"release": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TPL_FILE.read_text", "Template", "load_awesome_people", "people.items", "print", "template.render"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def generate_snippets(release: str) -> str:\n    people = load_awesome_people()\n    contributors = {\n        name: details\n        for name, details in people.items()\n        if details['github'] not in IGNORE_ACCOUNTS\n        and (release in details['committed'] or release in details['reported'])\n    }\n\n    template = Template(source=TPL_FILE.read_text(encoding='utf-8'))\n    output = template.render(contributors=contributors, release=release)\n    print(output)\n    return 0", "loc": 13}
{"file": "httpie\\docs\\installation\\generate.py", "class_name": null, "function_name": "generate_documentation", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TPL_FILE.read_text", "Template", "build_docs_structure", "clean_template_output", "load_database", "template.render"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def generate_documentation() -> str:\n    database = load_database()\n    structure = build_docs_structure(database)\n    template = Template(source=TPL_FILE.read_text(encoding='utf-8'))\n    output = template.render(structure=structure)\n    output = clean_template_output(output)\n    return output", "loc": 7}
{"file": "httpie\\docs\\installation\\generate.py", "class_name": null, "function_name": "save_doc_file", "parameters": ["content"], "param_types": {"content": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DOC_FILE.write_text", "current_doc.find", "len", "load_doc_file"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def save_doc_file(content: str) -> None:\n    current_doc = load_doc_file()\n    marker_start = current_doc.find(MARKER_START) + len(MARKER_START)\n    assert marker_start > 0, 'cannot find the start marker'\n    marker_end = current_doc.find(MARKER_END, marker_start)\n    assert marker_start < marker_end, f'{marker_end=} < {marker_start=}'\n    updated_doc = (\n        current_doc[:marker_start]\n        + '\\n\\n'\n        + content\n        + '\\n\\n'\n        + current_doc[marker_end:]\n    )\n    if current_doc != updated_doc:\n        DOC_FILE.write_text(updated_doc, encoding='utf-8')", "loc": 15}
{"file": "httpie\\docs\\installation\\generate.py", "class_name": null, "function_name": "build_docs_structure", "parameters": ["database"], "param_types": {"database": "Database"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "platform.isalnum", "structure.append", "tools.values", "tree.items"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def build_docs_structure(database: Database):\n    tools = database[KEY_TOOLS]\n    assert len(tools) == len({tool['title'] for tool in tools.values()}), 'tool titles need to be unique'\n    tree = database[KEY_DOC_STRUCTURE]\n    structure = []\n    for platform, tools_ids in tree.items():\n        assert platform.isalnum(), f'{platform=} must be alphanumeric for generated links to work'\n        platform_tools = [tools[tool_id] for tool_id in tools_ids]\n        structure.append((platform, platform_tools))\n    return structure", "loc": 10}
{"file": "httpie\\extras\\packaging\\linux\\build.py", "class_name": null, "function_name": "build_binaries", "parameters": [], "param_types": {}, "return_type": "Iterator[Tuple[str, Path]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DIST_DIR.iterdir", "TARGET_SCRIPTS.items", "executable_path.chmod", "executable_path.stat", "subprocess.check_call"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def build_binaries() -> Iterator[Tuple[str, Path]]:\n    for target_script, extra_args in TARGET_SCRIPTS.items():\n        subprocess.check_call(\n            [\n                'pyinstaller',\n                '--onefile',\n                '--noupx',\n                '-p',\n                HTTPIE_DIR,\n                '--additional-hooks-dir',\n                HOOKS_DIR,\n                *extra_args,\n                target_script,\n            ]\n        )\n\n    for executable_path in DIST_DIR.iterdir():\n        if executable_path.suffix:\n            continue\n        stat_r = executable_path.stat()\n        executable_path.chmod(stat_r.st_mode | stat.S_IEXEC)\n        yield executable_path.stem, executable_path", "loc": 22}
{"file": "httpie\\extras\\packaging\\linux\\scripts\\hooks\\hook-pip.py", "class_name": null, "function_name": "hook", "parameters": ["hook_api"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["collect_all", "hook_api.add_binaries", "hook_api.add_datas", "hook_api.add_imports"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def hook(hook_api):\n    for pkg in [\n        'pip',\n        'setuptools',\n        'distutils',\n        'pkg_resources'\n    ]:\n        datas, binaries, hiddenimports = collect_all(pkg)\n        hook_api.add_datas(datas)\n        hook_api.add_binaries(binaries)\n        hook_api.add_imports(*hiddenimports)", "loc": 11}
{"file": "httpie\\extras\\profiling\\benchmarks.py", "class_name": null, "function_name": "start_server", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'{}:{}'.format", "HTTPServer", "PREDEFINED_FILES.items", "TemporaryDirectory", "partial", "server.shutdown", "server.socket.getsockname", "subprocess.check_call", "thread.join", "thread.start", "threading.Thread"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Create a server to serve local files. It will create the PREDEFINED_FILES through dd.", "source_code": "def start_server():\n    \"\"\"Create a server to serve local files. It will create the\n    PREDEFINED_FILES through dd.\"\"\"\n    with TemporaryDirectory() as directory:\n        for file_name, (block_size, count) in PREDEFINED_FILES.items():\n            subprocess.check_call(\n                [\n                    'dd',\n                    'if=/dev/zero',\n                    f'of={file_name}',\n                    f'bs={block_size}',\n                    f'count={count}',\n                ],\n                cwd=directory,\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n            )\n\n        handler = partial(QuietSimpleHTTPServer, directory=directory)\n        server = HTTPServer(('localhost', 0), handler)\n\n        thread = threading.Thread(target=server.serve_forever)\n        thread.start()\n        yield '{}:{}'.format(*server.socket.getsockname())\n        server.shutdown()\n        thread.join(timeout=0.5)", "loc": 26}
{"file": "httpie\\extras\\profiling\\benchmarks.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Context", "context.run", "sys.argv.extend"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main() -> None:\n    # PyPerf will bring it's own argument parser, so configure the script.\n    # The somewhat fast and also precise enough configuration is this. We run\n    # benchmarks 3 times to warm up (e.g especially for download benchmark, this\n    # is important). And then 5 actual runs where we record.\n    sys.argv.extend(\n        ['--worker', '--loops=1', '--warmup=3', '--values=5', '--processes=2']\n    )\n\n    with Context() as context:\n        context.run()", "loc": 11}
{"file": "httpie\\extras\\profiling\\run.py", "class_name": null, "function_name": "dump_results", "parameters": ["results", "file", "min_speed"], "param_types": {"results": "List[str]", "file": "IO[str]", "min_speed": "Optional[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Some benchmarks were hidden from this list because their timings did not change in a significant way (change was within the error margin {margin}%).'.format", "'\\n'.join", "print", "result.strip", "result.strip().splitlines"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dump_results(\n    results: List[str],\n    file: IO[str],\n    min_speed: Optional[str] = None\n) -> None:\n    for result in results:\n        lines = result.strip().splitlines()\n        if min_speed is not None and \"hidden\" in lines[-1]:\n            lines[-1] = (\n                'Some benchmarks were hidden from this list '\n                'because their timings did not change in a '\n                'significant way (change was within the error '\n                'margin {margin}%).'\n            ).format(margin=min_speed)\n            result = '\\n'.join(lines)\n\n        print(result, file=file)\n        print(\"\\n---\\n\", file=file)", "loc": 18}
{"file": "httpie\\extras\\profiling\\run.py", "class_name": null, "function_name": "compare", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["compare_args.extend", "subprocess.check_output"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def compare(*args, directory: Path, min_speed: Optional[str] = None):\n    compare_args = ['pyperf', 'compare_to', '--table', '--table-format=md', *args]\n    if min_speed:\n        compare_args.extend(['--min-speed', min_speed])\n    return subprocess.check_output(\n        compare_args,\n        cwd=directory,\n        text=True,\n    )", "loc": 9}
{"file": "httpie\\extras\\profiling\\run.py", "class_name": null, "function_name": "run", "parameters": ["configs", "file", "debug", "min_speed"], "param_types": {"configs": "List[Dict[str, Environment]]", "file": "IO[str]", "debug": "bool", "min_speed": "Optional[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "args.append", "call", "compare", "config.items", "config.keys", "dump_results", "env.on_repo", "iterate", "print", "results.append", "sum", "tempfile.mkdtemp"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run(\n    configs: List[Dict[str, Environment]],\n    file: IO[str],\n    debug: bool = False,\n    min_speed: Optional[str] = None,\n) -> None:\n    result_directory = Path(tempfile.mkdtemp())\n    results = []\n\n    current = 1\n    total = sum(1 for config in configs for _ in config.items())\n\n    def iterate(env_name, status):\n        print(\n            f'Iteration: {env_name} ({current}/{total}) ({status})' + ' ' * 10,\n            end='\\r',\n            flush=True,\n        )\n\n    for config in configs:\n        for env_name, env in config.items():\n            iterate(env_name, 'setting up')\n            with env.on_repo() as (python, env_vars):\n                iterate(env_name, 'running benchmarks')\n                args = [python, BENCHMARK_SCRIPT, '-o', env_name]\n                if debug:\n                    args.append('--debug-single-value')\n                call(\n                    args,\n                    cwd=result_directory,\n                    env=env_vars,\n                )\n            current += 1\n\n        results.append(compare(\n            *config.keys(),\n            directory=result_directory,\n            min_speed=min_speed\n        ))\n\n    dump_results(results, file=file, min_speed=min_speed)\n    print('Results are available at:', result_directory)", "loc": 42}
{"file": "httpie\\extras\\profiling\\run.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ArgumentParser", "FileType", "HTTPieEnvironment", "LocalCommandEnvironment", "base_config.items", "configs.append", "dataclasses.replace", "parser.add_argument", "parser.parse_args", "run"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main() -> None:\n    parser = ArgumentParser()\n    parser.add_argument('--local-repo', default=CURRENT_REPO)\n    parser.add_argument('--local-branch', default=None)\n    parser.add_argument('--target-repo', default=CURRENT_REPO)\n    parser.add_argument('--target-branch', default=TARGET_BRANCH)\n    parser.add_argument(\n        '--fresh',\n        action='store_const',\n        const=GITHUB_URL,\n        dest='target_repo',\n        help='Clone the target repo from upstream GitHub URL',\n    )\n    parser.add_argument(\n        '--complex',\n        action='store_true',\n        help='Add a second run, with a complex python environment.',\n    )\n    parser.add_argument(\n        '--local-bin',\n        help='Run the suite with the given local binary in addition to'\n        ' existing runners. (E.g --local-bin $(command -v xh))',\n    )\n    parser.add_argument(\n        '--file',\n        type=FileType('w'),\n        default=sys.stdout,\n        help='File to print the actual results',\n    )\n    parser.add_argument(\n        '--min-speed',\n        help='Minimum of speed in percent to consider that a '\n             'benchmark is significant'\n    )\n    parser.add_argument(\n        '--debug',\n        action='store_true',\n    )\n\n    options = parser.parse_args()\n\n    configs = []\n\n    base_config = {\n        options.target_branch: HTTPieEnvironment(options.target_repo, options.target_branch),\n        'this_branch': HTTPieEnvironment(options.local_repo, options.local_branch),\n    }\n    configs.append(base_config)\n\n    if options.complex:\n        complex_config = {\n            env_name\n            + '-complex': dataclasses.replace(env, dependencies=ADDITIONAL_DEPS)\n            for env_name, env in base_config.items()\n        }\n        configs.append(complex_config)\n\n    if options.local_bin:\n        base_config['binary'] = LocalCommandEnvironment(options.local_bin)\n\n    run(configs, file=options.file, debug=options.debug, min_speed=options.min_speed)", "loc": 61}
{"file": "httpie\\extras\\profiling\\run.py", "class_name": "HTTPieEnvironment", "function_name": "on_repo", "parameters": ["self"], "param_types": {}, "return_type": "Generator[Path, None, None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "call", "next", "repo_path / 'dist'.iterdir", "shlex.join", "str", "tempfile.TemporaryDirectory", "venv.create"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_repo(self) -> Generator[Path, None, None]:\n    with tempfile.TemporaryDirectory() as directory_path:\n        directory = Path(directory_path)\n\n        # Clone the repo\n        repo_path = directory / 'httpie'\n        call(\n            ['git', 'clone', self.repo_url, repo_path],\n            stderr=subprocess.DEVNULL,\n        )\n\n        if self.branch is not None:\n            call(\n                ['git', 'checkout', self.branch],\n                cwd=repo_path,\n                stderr=subprocess.DEVNULL,\n            )\n\n        # Prepare the environment\n        venv_path = directory / '.venv'\n        venv.create(venv_path, with_pip=True)\n\n        # Install basic dependencies\n        python = venv_path / 'bin' / 'python'\n        call(\n            [\n                python,\n                '-m',\n                'pip',\n                'install',\n                'wheel',\n                'pyperf==2.3.0',\n                *self.dependencies,\n            ]\n        )\n\n        # Create a wheel distribution of HTTPie\n        call([python, 'setup.py', 'bdist_wheel'], cwd=repo_path)\n\n        # Install httpie\n        distribution_path = next((repo_path / 'dist').iterdir())\n        call(\n            [python, '-m', 'pip', 'install', distribution_path],\n            cwd=repo_path,\n        )\n\n        http = venv_path / 'bin' / 'http'\n        yield python, {'HTTPIE_COMMAND': shlex.join([str(python), str(http)])}", "loc": 48}
{"file": "httpie\\extras\\scripts\\generate_man_pages.py", "class_name": null, "function_name": "to_man_page", "parameters": ["program_name", "spec"], "param_types": {"program_name": "str", "spec": "ParserSpec"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ManPageBuilder", "Path", "Path(__file__).relative_to", "Path(spec.source_file).relative_to", "argument.serialize", "builder.add_comment", "builder.add_options", "builder.build", "builder.format_desc", "builder.section", "builder.separate", "builder.set_name", "builder.title_line", "builder.write", "enumerate", "raw_arg.get", "render_as_string", "to_usage"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def to_man_page(program_name: str, spec: ParserSpec, *, is_top_level_cmd: bool = False) -> str:\n    builder = ManPageBuilder()\n    builder.add_comment(\n        f\"This file is auto-generated from the parser declaration \"\n        + (f\"in {Path(spec.source_file).relative_to(PROJECT_ROOT)} \" if spec.source_file else \"\")\n        + f\"by {Path(__file__).relative_to(PROJECT_ROOT)}.\"\n    )\n\n    builder.title_line(\n        full_name='HTTPie',\n        program_name=program_name,\n        program_version=httpie.__version__,\n        last_edit_date=httpie.__date__,\n    )\n    builder.set_name(program_name)\n\n    with builder.section('SYNOPSIS'):\n        # `http` and `https` are commands that can be directly used, so they can have\n        # a valid usage. But `httpie` is a top-level command with multiple sub commands,\n        # so for the synopsis we'll only reference the `httpie` name.\n        if is_top_level_cmd:\n            synopsis = program_name\n        else:\n            synopsis = render_as_string(to_usage(spec, program_name=program_name))\n        builder.write(synopsis)\n\n    with builder.section('DESCRIPTION'):\n        builder.write(spec.description)\n        if spec.man_page_hint:\n            builder.write(spec.man_page_hint)\n\n    for index, group in enumerate(spec.groups, 1):\n        with builder.section(group.name):\n            if group.description:\n                builder.write(group.description)\n\n            for argument in group.arguments:\n                if argument.is_hidden:\n                    continue\n\n                raw_arg = argument.serialize(isolation_mode=True)\n\n                metavar = raw_arg.get('metavar')\n                if raw_arg.get('is_positional'):\n                    # In case of positional arguments, metavar is always equal\n                    # to the list of options (e.g `METHOD`).\n                    metavar = None\n                builder.add_options(raw_arg['options'], metavar=metavar)\n\n                desc = builder.format_desc(raw_arg.get('description', ''))\n                builder.write('\\n' + desc + '\\n')\n\n            builder.separate()\n\n    if spec.epilog:\n        with builder.section('SEE ALSO'):\n            builder.write(builder.format_desc(spec.epilog))\n\n    return builder.build()", "loc": 59}
{"file": "httpie\\extras\\scripts\\generate_man_pages.py", "class_name": "ManPageBuilder", "function_name": "format_desc", "parameters": ["self", "desc"], "param_types": {"desc": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["OPTION_HIGHLIGHT_RE.sub", "_escape_and_dedent", "self.boldify"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_desc(self, desc: str) -> str:\n    description = _escape_and_dedent(desc)\n    description = OPTION_HIGHLIGHT_RE.sub(\n        # Boldify the option part, but don't remove the prefix (start of the match).\n        lambda match: match[1] + self.boldify(match['option']),\n        description\n    )\n    return description", "loc": 8}
{"file": "httpie\\extras\\scripts\\generate_man_pages.py", "class_name": "ManPageBuilder", "function_name": "add_options", "parameters": ["self", "options"], "param_types": {"options": "Iterable[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "map", "self.underline", "self.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_options(self, options: Iterable[str], *, metavar: Optional[str] = None) -> None:\n    text = \", \".join(map(self.boldify, options))\n    if metavar:\n        text += f' {self.underline(metavar)}'\n    self.write(f'.IP \"{text}\"')", "loc": 5}
{"file": "httpie\\httpie\\adapters.py", "class_name": "HTTPieHTTPAdapter", "function_name": "build_response", "parameters": ["self", "req", "resp"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTTPHeadersDict", "getattr", "super", "super().build_response"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Wrap the original headers with the `HTTPHeadersDict` to preserve multiple headers that have the same name", "source_code": "def build_response(self, req, resp):\n    \"\"\"Wrap the original headers with the `HTTPHeadersDict`\n    to preserve multiple headers that have the same name\"\"\"\n\n    response = super().build_response(req, resp)\n    response.headers = HTTPHeadersDict(getattr(resp, 'headers', {}))\n    return response", "loc": 7}
{"file": "httpie\\httpie\\client.py", "class_name": null, "function_name": "max_headers", "parameters": ["limit"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["float"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def max_headers(limit):\n    # <https://github.com/httpie/cli/issues/802>\n    # noinspection PyUnresolvedReferences\n    orig = http.client._MAXHEADERS\n    http.client._MAXHEADERS = limit or float('Inf')\n    try:\n        yield\n    finally:\n        http.client._MAXHEADERS = orig", "loc": 9}
{"file": "httpie\\httpie\\client.py", "class_name": null, "function_name": "finalize_headers", "parameters": ["headers"], "param_types": {"headers": "HTTPHeadersDict"}, "return_type": "HTTPHeadersDict", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTTPHeadersDict", "final_headers.add", "headers.items", "isinstance", "name.lower", "value.encode", "value.strip"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def finalize_headers(headers: HTTPHeadersDict) -> HTTPHeadersDict:\n    final_headers = HTTPHeadersDict()\n    for name, value in headers.items():\n        if value is not None:\n            # leading or trailing LWS MAY be removed without\n            # changing the semantics of the field value\n            # <https://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html>\n            # Also, requests raises `InvalidHeader` for leading spaces.\n            value = value.strip()\n            if isinstance(value, str):\n                # See <https://github.com/httpie/cli/issues/212>\n                value = value.encode()\n        elif name.lower() in SKIPPABLE_HEADERS:\n            # Some headers get overwritten by urllib3 when set to `None`\n            # and should be replaced with the `SKIP_HEADER` constant.\n            value = SKIP_HEADER\n        final_headers.add(name, value)\n    return final_headers", "loc": 18}
{"file": "httpie\\httpie\\client.py", "class_name": null, "function_name": "transform_headers", "parameters": ["request", "prepared_request"], "param_types": {"request": "requests.Request", "prepared_request": "requests.PreparedRequest"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["apply_missing_repeated_headers", "prepared_request.headers.get", "prepared_request.headers.pop", "request.headers.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Apply various transformations on top of the `prepared_requests`'s headers to change the request prepreation behavior.", "source_code": "def transform_headers(\n    request: requests.Request,\n    prepared_request: requests.PreparedRequest\n) -> None:\n    \"\"\"Apply various transformations on top of the `prepared_requests`'s\n    headers to change the request prepreation behavior.\"\"\"\n\n    # Remove 'Content-Length' when it is misplaced by requests.\n    if (\n        prepared_request.method in IGNORE_CONTENT_LENGTH_METHODS\n        and prepared_request.headers.get('Content-Length') == '0'\n        and request.headers.get('Content-Length') != '0'\n    ):\n        prepared_request.headers.pop('Content-Length')\n\n    apply_missing_repeated_headers(\n        request.headers,\n        prepared_request\n    )", "loc": 19}
{"file": "httpie\\httpie\\client.py", "class_name": null, "function_name": "apply_missing_repeated_headers", "parameters": ["original_headers", "prepared_request"], "param_types": {"original_headers": "HTTPHeadersDict", "prepared_request": "requests.PreparedRequest"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTTPHeadersDict", "filter", "item[0].casefold", "new_headers.popone", "new_headers.update", "original_headers.items", "prepared_name.casefold", "prepared_request.headers.items", "zip"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Update the given `prepared_request`'s headers with the original ones. This allows the requests to be prepared as usual, and then later merged with headers that are specified multiple times.", "source_code": "def apply_missing_repeated_headers(\n    original_headers: HTTPHeadersDict,\n    prepared_request: requests.PreparedRequest\n) -> None:\n    \"\"\"Update the given `prepared_request`'s headers with the original\n    ones. This allows the requests to be prepared as usual, and then later\n    merged with headers that are specified multiple times.\"\"\"\n\n    new_headers = HTTPHeadersDict(prepared_request.headers)\n    for prepared_name, prepared_value in prepared_request.headers.items():\n        if prepared_name not in original_headers:\n            continue\n\n        original_keys, original_values = zip(*filter(\n            lambda item: item[0].casefold() == prepared_name.casefold(),\n            original_headers.items()\n        ))\n\n        if prepared_value not in original_values:\n            # If the current value is not among the initial values\n            # set for this field, then it means that this field got\n            # overridden on the way, and we should preserve it.\n            continue\n\n        new_headers.popone(prepared_name)\n        new_headers.update(zip(original_keys, original_values))\n\n    prepared_request.headers = new_headers", "loc": 28}
{"file": "httpie\\httpie\\client.py", "class_name": null, "function_name": "make_default_headers", "parameters": ["args"], "param_types": {"args": "argparse.Namespace"}, "return_type": "HTTPHeadersDict", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTTPHeadersDict"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_default_headers(args: argparse.Namespace) -> HTTPHeadersDict:\n    default_headers = HTTPHeadersDict({\n        'User-Agent': DEFAULT_UA\n    })\n\n    auto_json = args.data and not args.form\n    if args.json or auto_json:\n        default_headers['Accept'] = JSON_ACCEPT\n        if args.json or (auto_json and args.data):\n            default_headers['Content-Type'] = JSON_CONTENT_TYPE\n\n    elif args.form and not args.files:\n        # If sending files, `requests` will set\n        # the `Content-Type` for us.\n        default_headers['Content-Type'] = FORM_CONTENT_TYPE\n    return default_headers", "loc": 16}
{"file": "httpie\\httpie\\client.py", "class_name": null, "function_name": "make_send_kwargs_mergeable_from_env", "parameters": ["args"], "param_types": {"args": "argparse.Namespace"}, "return_type": "dict", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTTPieCertificate", "args.verify.lower", "{'yes': True, 'true': True, 'no': False, 'false': False}.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_send_kwargs_mergeable_from_env(args: argparse.Namespace) -> dict:\n    cert = None\n    if args.cert:\n        cert = args.cert\n        if args.cert_key:\n            # Having a client certificate key passphrase is not supported\n            # by requests. So we are using our own transportation structure\n            # which is compatible with their format (a tuple of minimum two\n            # items).\n            #\n            # See: https://github.com/psf/requests/issues/2519\n            cert = HTTPieCertificate(cert, args.cert_key, args.cert_key_pass.value)\n\n    return {\n        'proxies': {p.key: p.value for p in args.proxy},\n        'stream': True,\n        'verify': {\n            'yes': True,\n            'true': True,\n            'no': False,\n            'false': False,\n        }.get(args.verify.lower(), args.verify),\n        'cert': cert,\n    }", "loc": 24}
{"file": "httpie\\httpie\\client.py", "class_name": null, "function_name": "json_dict_to_request_body", "parameters": ["data"], "param_types": {"data": "Dict[str, Any]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["json.dumps", "unwrap_top_level_list_if_needed"], "control_structures": ["If"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def json_dict_to_request_body(data: Dict[str, Any]) -> str:\n    data = unwrap_top_level_list_if_needed(data)\n    if data:\n        data = json.dumps(data)\n    else:\n        # We need to set data to an empty string to prevent requests\n        # from assigning an empty list to `response.request.data`.\n        data = ''\n    return data", "loc": 9}
{"file": "httpie\\httpie\\client.py", "class_name": null, "function_name": "make_request_kwargs", "parameters": ["env", "args", "base_headers", "request_body_read_callback"], "param_types": {"env": "Environment", "args": "argparse.Namespace", "base_headers": "HTTPHeadersDict"}, "return_type": "dict", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["args.headers.get", "args.method.lower", "args.params.items", "finalize_headers", "get_multipart_data_and_content_type", "headers.get", "headers.update", "isinstance", "json_dict_to_request_body", "make_default_headers", "prepare_request_body"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Translate our `args` into `requests.Request` keyword arguments.", "source_code": "def make_request_kwargs(\n    env: Environment,\n    args: argparse.Namespace,\n    base_headers: HTTPHeadersDict = None,\n    request_body_read_callback=lambda chunk: chunk\n) -> dict:\n    \"\"\"\n    Translate our `args` into `requests.Request` keyword arguments.\n\n    \"\"\"\n    files = args.files\n    # Serialize JSON data, if needed.\n    data = args.data\n    auto_json = data and not args.form\n    if (args.json or auto_json) and isinstance(data, dict):\n        data = json_dict_to_request_body(data)\n\n    # Finalize headers.\n    headers = make_default_headers(args)\n    if base_headers:\n        headers.update(base_headers)\n    headers.update(args.headers)\n    if args.offline and args.chunked and 'Transfer-Encoding' not in headers:\n        # When online, we let requests set the header instead to be able more\n        # easily verify chunking is taking place.\n        headers['Transfer-Encoding'] = 'chunked'\n    headers = finalize_headers(headers)\n\n    if (args.form and files) or args.multipart:\n        data, headers['Content-Type'] = get_multipart_data_and_content_type(\n            data=args.multipart_data,\n            boundary=args.boundary,\n            content_type=args.headers.get('Content-Type'),\n        )\n\n    return {\n        'method': args.method.lower(),\n        'url': args.url,\n        'headers': headers,\n        'data': prepare_request_body(\n            env,\n            data,\n            body_read_callback=request_body_read_callback,\n            chunked=args.chunked,\n            offline=args.offline,\n            content_length_header_value=headers.get('Content-Length'),\n        ),\n        'auth': args.auth,\n        'params': args.params.items(),\n    }", "loc": 50}
{"file": "httpie\\httpie\\client.py", "class_name": null, "function_name": "ensure_path_as_is", "parameters": ["orig_url", "prepped_url"], "param_types": {"orig_url": "str", "prepped_url": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["final_dict.values", "parsed_prepped._asdict", "tuple", "urlparse", "urlunparse"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Handle `--path-as-is` by replacing the path component of the prepared URL with the path component from the original URL. Other parts stay untouched because other (welcome) processing on the URL might have", "source_code": "def ensure_path_as_is(orig_url: str, prepped_url: str) -> str:\n    \"\"\"\n    Handle `--path-as-is` by replacing the path component of the prepared\n    URL with the path component from the original URL. Other parts stay\n    untouched because other (welcome) processing on the URL might have\n    taken place.\n\n    <https://github.com/httpie/cli/issues/895>\n\n\n    <https://ec.haxx.se/http/http-basics#path-as-is>\n    <https://curl.haxx.se/libcurl/c/CURLOPT_PATH_AS_IS.html>\n\n    >>> ensure_path_as_is('http://foo/../', 'http://foo/?foo=bar')\n    'http://foo/../?foo=bar'\n\n    \"\"\"\n    parsed_orig, parsed_prepped = urlparse(orig_url), urlparse(prepped_url)\n    final_dict = {\n        # noinspection PyProtectedMember\n        **parsed_prepped._asdict(),\n        'path': parsed_orig.path,\n    }\n    return urlunparse(tuple(final_dict.values()))", "loc": 24}
{"file": "httpie\\httpie\\compat.py", "class_name": null, "function_name": "find_entry_points", "parameters": ["entry_points", "group"], "param_types": {"entry_points": "Any", "group": "str"}, "return_type": "Iterable[importlib_metadata.EntryPoint]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["entry_points.get", "entry_points.select", "hasattr", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_entry_points(entry_points: Any, group: str) -> Iterable[importlib_metadata.EntryPoint]:\n    if hasattr(entry_points, \"select\"):  # Python 3.10+ / importlib_metadata >= 3.9.0\n        return entry_points.select(group=group)\n    else:\n        return set(entry_points.get(group, ()))", "loc": 5}
{"file": "httpie\\httpie\\compat.py", "class_name": null, "function_name": "get_dist_name", "parameters": ["entry_point"], "param_types": {"entry_point": "importlib_metadata.EntryPoint"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["entry_point.pattern.match", "getattr", "importlib_metadata.metadata", "match.group", "match.group('module').split", "metadata.get"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_dist_name(entry_point: importlib_metadata.EntryPoint) -> Optional[str]:\n    dist = getattr(entry_point, \"dist\", None)\n    if dist is not None:  # Python 3.10+\n        return dist.name\n\n    match = entry_point.pattern.match(entry_point.value)\n    if not (match and match.group('module')):\n        return None\n\n    package = match.group('module').split('.')[0]\n    try:\n        metadata = importlib_metadata.metadata(package)\n    except importlib_metadata.PackageNotFoundError:\n        return None\n    else:\n        return metadata.get('name')", "loc": 16}
{"file": "httpie\\httpie\\compat.py", "class_name": null, "function_name": "ensure_default_certs_loaded", "parameters": ["ssl_context"], "param_types": {"ssl_context": "SSLContext"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "ssl_context.get_ca_certs", "ssl_context.load_default_certs"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Workaround for a bug in Requests 2.32.3 See <https://github.com/httpie/cli/issues/1583>", "source_code": "def ensure_default_certs_loaded(ssl_context: SSLContext) -> None:\n    \"\"\"\n    Workaround for a bug in Requests 2.32.3\n\n    See <https://github.com/httpie/cli/issues/1583>\n\n    \"\"\"\n    if hasattr(ssl_context, 'load_default_certs'):\n        if not ssl_context.get_ca_certs():\n            ssl_context.load_default_certs()", "loc": 10}
{"file": "httpie\\httpie\\config.py", "class_name": null, "function_name": "get_default_config_dir", "parameters": [], "param_types": {}, "return_type": "Path", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "Path.home", "legacy_config_dir.exists", "os.environ.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the path to the httpie configuration directory. This directory isn't guaranteed to exist, and nor are any of its ancestors (only the legacy ~/.httpie, if returned, is guaranteed to exist).", "source_code": "def get_default_config_dir() -> Path:\n    \"\"\"\n    Return the path to the httpie configuration directory.\n\n    This directory isn't guaranteed to exist, and nor are any of its\n    ancestors (only the legacy ~/.httpie, if returned, is guaranteed to exist).\n\n    XDG Base Directory Specification support:\n\n        <https://wiki.archlinux.org/index.php/XDG_Base_Directory>\n\n        $XDG_CONFIG_HOME is supported; $XDG_CONFIG_DIRS is not\n\n    \"\"\"\n    # 1. explicitly set through env\n    env_config_dir = os.environ.get(ENV_HTTPIE_CONFIG_DIR)\n    if env_config_dir:\n        return Path(env_config_dir)\n\n    # 2. Windows\n    if is_windows:\n        return DEFAULT_WINDOWS_CONFIG_DIR\n\n    home_dir = Path.home()\n\n    # 3. legacy ~/.httpie\n    legacy_config_dir = home_dir / DEFAULT_RELATIVE_LEGACY_CONFIG_DIR\n    if legacy_config_dir.exists():\n        return legacy_config_dir\n\n    # 4. XDG\n    xdg_config_home_dir = os.environ.get(\n        ENV_XDG_CONFIG_HOME,  # 4.1. explicit\n        home_dir / DEFAULT_RELATIVE_XDG_CONFIG_HOME  # 4.2. default\n    )\n    return Path(xdg_config_home_dir) / DEFAULT_CONFIG_DIRNAME", "loc": 36}
{"file": "httpie\\httpie\\config.py", "class_name": null, "function_name": "read_raw_config", "parameters": ["config_type", "path"], "param_types": {"config_type": "str", "path": "Path"}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ConfigFileError", "json.load", "path.open"], "control_structures": ["Try"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def read_raw_config(config_type: str, path: Path) -> Dict[str, Any]:\n    try:\n        with path.open(encoding=UTF8) as f:\n            try:\n                return json.load(f)\n            except ValueError as e:\n                raise ConfigFileError(\n                    f'invalid {config_type} file: {e} [{path}]'\n                )\n    except FileNotFoundError:\n        pass\n    except OSError as e:\n        raise ConfigFileError(f'cannot read {config_type} file: {e}')", "loc": 13}
{"file": "httpie\\httpie\\config.py", "class_name": "BaseConfigDict", "function_name": "load", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["read_raw_config", "self.pre_process_data", "self.update", "type", "type(self).__name__.lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load(self):\n    config_type = type(self).__name__.lower()\n    data = read_raw_config(config_type, self.path)\n    if data is not None:\n        data = self.pre_process_data(data)\n        self.update(data)", "loc": 6}
{"file": "httpie\\httpie\\config.py", "class_name": "BaseConfigDict", "function_name": "save", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["json.dumps", "self.ensure_directory", "self.path.write_text", "self.post_process_data", "self.setdefault"], "control_structures": ["If"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def save(self, *, bump_version: bool = False):\n    self.setdefault('__meta__', {})\n    if bump_version or 'httpie' not in self['__meta__']:\n        self['__meta__']['httpie'] = __version__\n    if self.helpurl:\n        self['__meta__']['help'] = self.helpurl\n\n    if self.about:\n        self['__meta__']['about'] = self.about\n\n    self.ensure_directory()\n\n    json_string = json.dumps(\n        obj=self.post_process_data(self),\n        indent=4,\n        sort_keys=True,\n        ensure_ascii=True,\n    )\n    self.path.write_text(json_string + '\\n', encoding=UTF8)", "loc": 19}
{"file": "httpie\\httpie\\context.py", "class_name": "Environment", "function_name": "config", "parameters": ["self"], "param_types": {}, "return_type": "Config", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Config", "config.is_new", "config.load", "self.log_error"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def config(self) -> Config:\n    config = self._config\n    if not config:\n        self._config = config = Config(directory=self.config_dir)\n        if not config.is_new():\n            try:\n                config.load()\n            except ConfigFileError as e:\n                self.log_error(e, level=LogLevel.WARNING)\n    return config", "loc": 10}
{"file": "httpie\\httpie\\context.py", "class_name": "Environment", "function_name": "as_silent", "parameters": ["self"], "param_types": {}, "return_type": "Iterator[None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def as_silent(self) -> Iterator[None]:\n    original_stdout = self.stdout\n    original_stderr = self.stderr\n\n    try:\n        self.stdout = self.devnull\n        self.stderr = self.devnull\n        yield\n    finally:\n        self.stdout = original_stdout\n        self.stderr = original_stderr", "loc": 11}
{"file": "httpie\\httpie\\context.py", "class_name": "Environment", "function_name": "log_error", "parameters": ["self", "msg", "level"], "param_types": {"msg": "str", "level": "LogLevel"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["rich_console.print", "self._make_rich_console", "stderr.isatty"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def log_error(self, msg: str, level: LogLevel = LogLevel.ERROR) -> None:\n    if self.stdout_isatty and self.quiet >= LOG_LEVEL_DISPLAY_THRESHOLDS[level]:\n        stderr = self.stderr  # Not directly /dev/null, since stderr might be mocked\n    else:\n        stderr = self._orig_stderr\n    rich_console = self._make_rich_console(file=stderr, force_terminal=stderr.isatty())\n    rich_console.print(\n        f'\\n{self.program_name}: {level.value}: {msg}\\n\\n',\n        style=LOG_LEVEL_COLORS[level],\n        markup=False,\n        highlight=False,\n        soft_wrap=True\n    )", "loc": 13}
{"file": "httpie\\httpie\\cookies.py", "class_name": "HTTPieCookiePolicy", "function_name": "return_ok_secure", "parameters": ["self", "cookie", "request"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cookiejar.request_host", "self._is_local_host", "super", "super().return_ok_secure"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Check whether the given cookie is sent to a secure host.", "source_code": "def return_ok_secure(self, cookie, request):\n    \"\"\"Check whether the given cookie is sent to a secure host.\"\"\"\n\n    is_secure_protocol = super().return_ok_secure(cookie, request)\n    if is_secure_protocol:\n        return True\n\n    # The original implementation of this method only takes secure protocols\n    # (e.g., https) into account, but the latest developments in modern browsers\n    # (chrome, firefox) assume 'localhost' is also a secure location. So we\n    # override it with our own strategy.\n    return self._is_local_host(cookiejar.request_host(request))", "loc": 12}
{"file": "httpie\\httpie\\core.py", "class_name": null, "function_name": "main", "parameters": ["args", "env"], "param_types": {"args": "List[Union[str, bytes]]", "env": "Environment"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Environment", "raw_main"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "The main function. Pre-process args, handle some special types of invocations, and run the main program with error handling.", "source_code": "def main(\n    args: List[Union[str, bytes]] = sys.argv,\n    env: Environment = Environment()\n) -> ExitStatus:\n    \"\"\"\n    The main function.\n\n    Pre-process args, handle some special types of invocations,\n    and run the main program with error handling.\n\n    Return exit status code.\n\n    \"\"\"\n\n    from .cli.definition import parser\n\n    return raw_main(\n        parser=parser,\n        main_program=program,\n        args=args,\n        env=env\n    )", "loc": 22}
{"file": "httpie\\httpie\\core.py", "class_name": null, "function_name": "print_debug_info", "parameters": ["env"], "param_types": {"env": "Environment"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["env.stderr.write", "env.stderr.writelines", "platform.release", "platform.system", "repr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def print_debug_info(env: Environment):\n    env.stderr.writelines([\n        f'HTTPie {httpie_version}\\n',\n        f'Requests {requests_version}\\n',\n        f'Pygments {pygments_version}\\n',\n        f'Python {sys.version}\\n{sys.executable}\\n',\n        f'{platform.system()} {platform.release()}',\n    ])\n    env.stderr.write('\\n\\n')\n    env.stderr.write(repr(env))\n    env.stderr.write('\\n\\n')\n    env.stderr.write(repr(plugin_manager))\n    env.stderr.write('\\n')", "loc": 13}
{"file": "httpie\\httpie\\core.py", "class_name": null, "function_name": "decode_raw_args", "parameters": ["args", "stdin_encoding"], "param_types": {"args": "List[Union[str, bytes]]", "stdin_encoding": "str"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["arg.decode", "type"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Convert all bytes args to str by decoding them using stdin encoding.", "source_code": "def decode_raw_args(\n    args: List[Union[str, bytes]],\n    stdin_encoding: str\n) -> List[str]:\n    \"\"\"\n    Convert all bytes args to str\n    by decoding them using stdin encoding.\n\n    \"\"\"\n    return [\n        arg.decode(stdin_encoding)\n        if type(arg) is bytes else arg\n        for arg in args\n    ]", "loc": 14}
{"file": "httpie\\httpie\\core.py", "class_name": null, "function_name": "handle_generic_error", "parameters": ["e", "annotation"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["env.log_error", "hasattr", "str", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_generic_error(e, annotation=None):\n    msg = str(e)\n    if hasattr(e, 'request'):\n        request = e.request\n        if hasattr(request, 'url'):\n            msg = (\n                f'{msg} while doing a {request.method}'\n                f' request to URL: {request.url}'\n            )\n    if annotation:\n        msg += annotation\n    env.log_error(f'{type(e).__name__}: {msg}')\n    if include_traceback:\n        raise", "loc": 14}
{"file": "httpie\\httpie\\core.py", "class_name": null, "function_name": "request_body_read_callback", "parameters": ["chunk"], "param_types": {"chunk": "bytes"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bool", "write_raw_data"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_body_read_callback(chunk: bytes):\n    should_pipe_to_stdout = bool(\n        # Request body output desired\n        OUT_REQ_BODY in args.output_options\n        # & not `.read()` already pre-request (e.g., for  compression)\n        and initial_request\n        # & non-EOF chunk\n        and chunk\n    )\n    if should_pipe_to_stdout:\n        return write_raw_data(\n            env,\n            chunk,\n            processing_options=processing_options,\n            headers=initial_request.headers\n        )", "loc": 16}
{"file": "httpie\\httpie\\downloads.py", "class_name": null, "function_name": "parse_content_range", "parameters": ["content_range", "resumed_from"], "param_types": {"content_range": "str", "resumed_from": "int"}, "return_type": "int", "param_doc": {"content_range": "the value of a Content-Range response header", "resumed_from": "first byte pos. from the Range request header"}, "return_doc": "total size of the response body when fully downloaded.", "raises_doc": [], "called_functions": ["ContentRangeError", "int", "match.groupdict", "re.match"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse and validate Content-Range header. <https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html>", "source_code": "def parse_content_range(content_range: str, resumed_from: int) -> int:\n    \"\"\"\n    Parse and validate Content-Range header.\n\n    <https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html>\n\n    :param content_range: the value of a Content-Range response header\n                          eg. \"bytes 21010-47021/47022\"\n    :param resumed_from: first byte pos. from the Range request header\n    :return: total size of the response body when fully downloaded.\n\n    \"\"\"\n    if content_range is None:\n        raise ContentRangeError('Missing Content-Range')\n\n    pattern = (\n        r'^bytes (?P<first_byte_pos>\\d+)-(?P<last_byte_pos>\\d+)'\n        r'/(\\*|(?P<instance_length>\\d+))$'\n    )\n    match = re.match(pattern, content_range)\n\n    if not match:\n        raise ContentRangeError(\n            f'Invalid Content-Range format {content_range!r}')\n\n    content_range_dict = match.groupdict()\n    first_byte_pos = int(content_range_dict['first_byte_pos'])\n    last_byte_pos = int(content_range_dict['last_byte_pos'])\n    instance_length = (\n        int(content_range_dict['instance_length'])\n        if content_range_dict['instance_length']\n        else None\n    )\n\n    # \"A byte-content-range-spec with a byte-range-resp-spec whose\n    # last- byte-pos value is less than its first-byte-pos value,\n    # or whose instance-length value is less than or equal to its\n    # last-byte-pos value, is invalid. The recipient of an invalid\n    # byte-content-range- spec MUST ignore it and any content\n    # transferred along with it.\"\n    if (first_byte_pos > last_byte_pos\n        or (instance_length is not None\n            and instance_length <= last_byte_pos)):\n        raise ContentRangeError(\n            f'Invalid Content-Range returned: {content_range!r}')\n\n    if (first_byte_pos != resumed_from\n        or (instance_length is not None\n            and last_byte_pos + 1 != instance_length)):\n        # Not what we asked for.\n        raise ContentRangeError(\n            f'Unexpected Content-Range returned ({content_range!r})'\n            f' for the requested Range (\"bytes={resumed_from}-\")'\n        )\n\n    return last_byte_pos + 1", "loc": 56}
{"file": "httpie\\httpie\\downloads.py", "class_name": null, "function_name": "trim_filename_if_needed", "parameters": ["filename", "directory", "extra"], "param_types": {"filename": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_filename_max_length", "len", "trim_filename"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def trim_filename_if_needed(filename: str, directory='.', extra=0) -> str:\n    max_len = get_filename_max_length(directory) - extra\n    if len(filename) > max_len:\n        filename = trim_filename(filename, max_len)\n    return filename", "loc": 5}
{"file": "httpie\\httpie\\downloads.py", "class_name": null, "function_name": "get_unique_filename", "parameters": ["filename", "exists"], "param_types": {"filename": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["exists", "len", "trim_filename_if_needed"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_unique_filename(filename: str, exists=os.path.exists) -> str:\n    attempt = 0\n    while True:\n        suffix = f'-{attempt}' if attempt > 0 else ''\n        try_filename = trim_filename_if_needed(filename, extra=len(suffix))\n        try_filename += suffix\n        if not exists(try_filename):\n            return try_filename\n        attempt += 1", "loc": 9}
{"file": "httpie\\httpie\\downloads.py", "class_name": "Downloader", "function_name": "start", "parameters": ["self", "initial_url", "final_response"], "param_types": {"initial_url": "str", "final_response": "requests.Response"}, "return_type": "Tuple[RawStream, IO]", "param_doc": {"initial_url": "The original requested URL", "final_response": "Initiated response object with headers already fetched"}, "return_doc": "RawStream, output_file", "raises_doc": [], "called_functions": ["HTTPResponse", "OutputOptions.from_message", "RawStream", "final_response.headers.get", "int", "parse_content_range", "self._get_output_file_from_response", "self._output_file.seek", "self._output_file.truncate", "self.status.started"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Initiate and return a stream for `response` body  with progress callback attached. Can be called only once.", "source_code": "def start(\n    self,\n    initial_url: str,\n    final_response: requests.Response\n) -> Tuple[RawStream, IO]:\n    \"\"\"\n    Initiate and return a stream for `response` body  with progress\n    callback attached. Can be called only once.\n\n    :param initial_url: The original requested URL\n    :param final_response: Initiated response object with headers already fetched\n\n    :return: RawStream, output_file\n\n    \"\"\"\n    assert not self.status.time_started\n\n    # FIXME: some servers still might sent Content-Encoding: gzip\n    # <https://github.com/httpie/cli/issues/423>\n    try:\n        total_size = int(final_response.headers['Content-Length'])\n    except (KeyError, ValueError, TypeError):\n        total_size = None\n\n    if not self._output_file:\n        self._output_file = self._get_output_file_from_response(\n            initial_url=initial_url,\n            final_response=final_response,\n        )\n    else:\n        # `--output, -o` provided\n        if self._resume and final_response.status_code == PARTIAL_CONTENT:\n            total_size = parse_content_range(\n                final_response.headers.get('Content-Range'),\n                self._resumed_from\n            )\n\n        else:\n            self._resumed_from = 0\n            try:\n                self._output_file.seek(0)\n                self._output_file.truncate()\n            except OSError:\n                pass  # stdout\n\n    output_options = OutputOptions.from_message(final_response, headers=False, body=True)\n    stream = RawStream(\n        msg=HTTPResponse(final_response),\n        output_options=output_options,\n        on_body_chunk_downloaded=self.chunk_downloaded,\n    )\n\n    self.status.started(\n        output_file=self._output_file,\n        resumed_from=self._resumed_from,\n        total_size=total_size\n    )\n\n    return stream, self._output_file", "loc": 59}
{"file": "httpie\\httpie\\downloads.py", "class_name": "Downloader", "function_name": "chunk_downloaded", "parameters": ["self", "chunk"], "param_types": {"chunk": "bytes"}, "return_type": null, "param_doc": {"chunk": "A chunk of response body data that has just"}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.status.chunk_downloaded"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "A download progress callback.", "source_code": "def chunk_downloaded(self, chunk: bytes):\n    \"\"\"\n    A download progress callback.\n\n    :param chunk: A chunk of response body data that has just\n                  been downloaded and written to the output.\n\n    \"\"\"\n    self.status.chunk_downloaded(len(chunk))", "loc": 9}
{"file": "httpie\\httpie\\downloads.py", "class_name": "DownloadStatus", "function_name": "started", "parameters": ["self", "output_file", "resumed_from", "total_size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["monotonic", "self.start_display"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def started(self, output_file, resumed_from=0, total_size=None):\n    assert self.time_started is None\n    self.total_size = total_size\n    self.downloaded = self.resumed_from = resumed_from\n    self.time_started = monotonic()\n    self.start_display(output_file=output_file)", "loc": 6}
{"file": "httpie\\httpie\\downloads.py", "class_name": "DownloadStatus", "function_name": "start_display", "parameters": ["self", "output_file"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DummyDisplay", "ProgressDisplay", "StatusDisplay", "self.display.start"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start_display(self, output_file):\n    from httpie.output.ui.rich_progress import (\n        DummyDisplay,\n        StatusDisplay,\n        ProgressDisplay\n    )\n\n    message = f'Downloading to {output_file.name}'\n    if self.env.show_displays:\n        if self.total_size is None:\n            # Rich does not support progress bars without a total\n            # size given. Instead we use status objects.\n            self.display = StatusDisplay(self.env)\n        else:\n            self.display = ProgressDisplay(self.env)\n    else:\n        self.display = DummyDisplay(self.env)\n\n    self.display.start(\n        total=self.total_size,\n        at=self.downloaded,\n        description=message\n    )", "loc": 23}
{"file": "httpie\\httpie\\downloads.py", "class_name": "DownloadStatus", "function_name": "time_spent", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def time_spent(self):\n    if (\n        self.time_started is not None\n        and self.time_finished is not None\n    ):\n        return self.time_finished - self.time_started\n    else:\n        return None", "loc": 8}
{"file": "httpie\\httpie\\downloads.py", "class_name": "DownloadStatus", "function_name": "finished", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "monotonic", "self.display.stop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def finished(self):\n    assert self.time_started is not None\n    assert self.time_finished is None\n    self.time_finished = monotonic()\n    if hasattr(self, 'display'):\n        self.display.stop(self.time_spent)", "loc": 6}
{"file": "httpie\\httpie\\encoding.py", "class_name": null, "function_name": "detect_encoding", "parameters": ["content"], "param_types": {"content": "ContentBytes"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytes", "from_bytes", "from_bytes(bytes(content)).best", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "We default to UTF-8 if text too short, because the detection can return a random encoding leading to confusing results given the `charset_normalizer` version (< 2.0.5).", "source_code": "def detect_encoding(content: ContentBytes) -> str:\n    \"\"\"\n    We default to UTF-8 if text too short, because the detection\n    can return a random encoding leading to confusing results\n    given the `charset_normalizer` version (< 2.0.5).\n\n    >>> too_short = ']\"foo\"'\n    >>> detected = from_bytes(too_short.encode()).best().encoding\n    >>> detected\n    'ascii'\n    >>> too_short.encode().decode(detected)\n    ']\"foo\"'\n    \"\"\"\n    encoding = UTF8\n    if len(content) > TOO_SMALL_SEQUENCE:\n        match = from_bytes(bytes(content)).best()\n        if match:\n            encoding = match.encoding\n    return encoding", "loc": 19}
{"file": "httpie\\httpie\\encoding.py", "class_name": null, "function_name": "smart_decode", "parameters": ["content", "encoding"], "param_types": {"content": "ContentBytes", "encoding": "str"}, "return_type": "Tuple[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["content.decode", "detect_encoding"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Decode `content` using the given `encoding`. If no `encoding` is provided, the best effort is to guess it from `content`. Unicode errors are replaced.", "source_code": "def smart_decode(content: ContentBytes, encoding: str) -> Tuple[str, str]:\n    \"\"\"Decode `content` using the given `encoding`.\n    If no `encoding` is provided, the best effort is to guess it from `content`.\n\n    Unicode errors are replaced.\n\n    \"\"\"\n    if not encoding:\n        encoding = detect_encoding(content)\n    return content.decode(encoding, 'replace'), encoding", "loc": 10}
{"file": "httpie\\httpie\\models.py", "class_name": null, "function_name": "infer_requests_message_kind", "parameters": ["message"], "param_types": {"message": "RequestsMessage"}, "return_type": "RequestsMessageKind", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TypeError", "isinstance", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def infer_requests_message_kind(message: RequestsMessage) -> RequestsMessageKind:\n    if isinstance(message, requests.PreparedRequest):\n        return RequestsMessageKind.REQUEST\n    elif isinstance(message, requests.Response):\n        return RequestsMessageKind.RESPONSE\n    else:\n        raise TypeError(f\"Unexpected message type: {type(message).__name__}\")", "loc": 7}
{"file": "httpie\\httpie\\models.py", "class_name": "HTTPMessage", "function_name": "content_type", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ct.decode", "isinstance", "self._orig.headers.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the message content type.", "source_code": "def content_type(self) -> str:\n    \"\"\"Return the message content type.\"\"\"\n    ct = self._orig.headers.get('Content-Type', '')\n    if not isinstance(ct, str):\n        ct = ct.decode()\n    return ct", "loc": 6}
{"file": "httpie\\httpie\\models.py", "class_name": "HTTPResponse", "function_name": "headers", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["': '.join", "'\\r\\n'.join", "headers.extend", "original.headers.items", "split_cookies"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def headers(self):\n    original = self._orig\n    status_line = f'HTTP/{self.version} {original.status_code} {original.reason}'\n    headers = [status_line]\n    headers.extend(\n        ': '.join(header)\n        for header in original.headers.items()\n        if header[0] != 'Set-Cookie'\n    )\n    headers.extend(\n        f'Set-Cookie: {cookie}'\n        for header, value in original.headers.items()\n        for cookie in split_cookies(value)\n        if header == 'Set-Cookie'\n    )\n    return '\\r\\n'.join(headers)", "loc": 16}
{"file": "httpie\\httpie\\models.py", "class_name": "HTTPResponse", "function_name": "metadata", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "data.items", "monotonic", "round", "self._orig.elapsed.total_seconds", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def metadata(self) -> str:\n    data = {}\n    time_to_parse_headers = self._orig.elapsed.total_seconds()\n    # noinspection PyProtectedMember\n    time_since_headers_parsed = monotonic() - self._orig._httpie_headers_parsed_at\n    time_elapsed = time_to_parse_headers + time_since_headers_parsed\n    # data['Headers time'] = str(round(time_to_parse_headers, 5)) + 's'\n    # data['Body time'] = str(round(time_since_headers_parsed, 5)) + 's'\n    data[ELAPSED_TIME_LABEL] = str(round(time_elapsed, 10)) + 's'\n    return '\\n'.join(\n        f'{key}: {value}'\n        for key, value in data.items()\n    )", "loc": 13}
{"file": "httpie\\httpie\\models.py", "class_name": "HTTPResponse", "function_name": "version", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Return the HTTP version used by the server, e.g. '1.1'. Assume HTTP/1.1 if version is not available.", "source_code": "def version(self) -> str:\n    \"\"\"\n    Return the HTTP version used by the server, e.g. '1.1'.\n\n    Assume HTTP/1.1 if version is not available.\n\n    \"\"\"\n    mapping = {\n        9: '0.9',\n        10: '1.0',\n        11: '1.1',\n        20: '2.0',\n    }\n    fallback = 11\n    version = None\n    try:\n        raw = self._orig.raw\n        if getattr(raw, '_original_response', None):\n            version = raw._original_response.version\n        else:\n            version = raw.version\n    except AttributeError:\n        pass\n    return mapping[version or fallback]", "loc": 24}
{"file": "httpie\\httpie\\models.py", "class_name": "HTTPRequest", "function_name": "headers", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\r\\n'.join", "'\\r\\n'.join(headers).strip", "'{method} {path}{query} HTTP/1.1'.format", "headers.insert", "headers.items", "isinstance", "name.lower", "self._orig.headers.copy", "url.netloc.split", "urlsplit", "value.decode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def headers(self):\n    url = urlsplit(self._orig.url)\n\n    request_line = '{method} {path}{query} HTTP/1.1'.format(\n        method=self._orig.method,\n        path=url.path or '/',\n        query=f'?{url.query}' if url.query else ''\n    )\n\n    headers = self._orig.headers.copy()\n    if 'Host' not in self._orig.headers:\n        headers['Host'] = url.netloc.split('@')[-1]\n\n    headers = [\n        f'{name}: {value if isinstance(value, str) else value.decode()}'\n        for name, value in headers.items()\n        if not (name.lower() in SKIPPABLE_HEADERS and value == SKIP_HEADER)\n    ]\n\n    headers.insert(0, request_line)\n    headers = '\\r\\n'.join(headers).strip()\n    return headers", "loc": 22}
{"file": "httpie\\httpie\\models.py", "class_name": "HTTPRequest", "function_name": "body", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["body.encode", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def body(self):\n    body = self._orig.body\n    if isinstance(body, str):\n        # Happens with JSON/form request data parsed from the command line.\n        body = body.encode()\n    return body or b''", "loc": 6}
{"file": "httpie\\httpie\\sessions.py", "class_name": null, "function_name": "materialize_cookie", "parameters": ["cookie"], "param_types": {"cookie": "Cookie"}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cookie._rest.get", "getattr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def materialize_cookie(cookie: Cookie) -> Dict[str, Any]:\n    materialized_cookie = {\n        option: getattr(cookie, option)\n        for option in KEPT_COOKIE_OPTIONS\n    }\n\n    if (\n        cookie._rest.get('is_explicit_none')\n        and materialized_cookie['domain'] == ''\n    ):\n        materialized_cookie['domain'] = None\n\n    return materialized_cookie", "loc": 13}
{"file": "httpie\\httpie\\sessions.py", "class_name": null, "function_name": "materialize_headers", "parameters": ["headers"], "param_types": {"headers": "Dict[str, str]"}, "return_type": "List[Dict[str, Any]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["headers.copy", "headers.copy().items"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def materialize_headers(headers: Dict[str, str]) -> List[Dict[str, Any]]:\n    return [\n        {\n            'name': name,\n            'value': value\n        }\n        for name, value in headers.copy().items()\n    ]", "loc": 8}
{"file": "httpie\\httpie\\sessions.py", "class_name": "Session", "function_name": "pre_process_data", "parameters": ["self", "data"], "param_types": {"data": "Dict[str, Any]"}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.get", "deserializer", "importer"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def pre_process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n    for key, deserializer, importer in [\n        ('cookies', legacy_cookies.pre_process, self._add_cookies),\n        ('headers', legacy_headers.pre_process, self._headers.update),\n    ]:\n        values = data.get(key)\n        if values:\n            normalized_values = deserializer(self, values)\n        else:\n            normalized_values = []\n\n        importer(normalized_values)\n\n    return data", "loc": 14}
{"file": "httpie\\httpie\\sessions.py", "class_name": "Session", "function_name": "post_process_data", "parameters": ["self", "data"], "param_types": {"data": "Dict[str, Any]"}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.get", "exporter", "serializer", "type"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def post_process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n    for key, store, serializer, exporter in [\n        ('cookies', self.cookie_jar, materialize_cookies, legacy_cookies.post_process),\n        ('headers', self._headers, materialize_headers, legacy_headers.post_process),\n    ]:\n        original_type = type(data.get(key))\n        values = serializer(store)\n\n        data[key] = exporter(\n            values,\n            original_type=original_type\n        )\n\n    return data", "loc": 14}
{"file": "httpie\\httpie\\sessions.py", "class_name": "Session", "function_name": "update_headers", "parameters": ["self", "request_headers"], "param_types": {"request_headers": "HTTPHeadersDict"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["new_headers.add", "new_headers.copy", "new_headers.copy().keys", "self._compute_new_headers", "self._headers.copy", "self._headers.copy().items"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Update the session headers with the request ones while ignoring certain name prefixes.", "source_code": "def update_headers(self, request_headers: HTTPHeadersDict):\n    \"\"\"\n    Update the session headers with the request ones while ignoring\n    certain name prefixes.\n\n    \"\"\"\n\n    new_headers = self._compute_new_headers(request_headers)\n    new_keys = new_headers.copy().keys()\n\n    # New headers will take priority over the existing ones, and override\n    # them directly instead of extending them.\n    for key, value in self._headers.copy().items():\n        if key in new_keys:\n            continue\n\n        new_headers.add(key, value)\n\n    self._headers = new_headers", "loc": 19}
{"file": "httpie\\httpie\\sessions.py", "class_name": "Session", "function_name": "remove_cookies", "parameters": ["self", "cookies"], "param_types": {"cookies": "List[Dict[str, str]]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cookie.get", "remove_cookie_by_name"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_cookies(self, cookies: List[Dict[str, str]]):\n    for cookie in cookies:\n        remove_cookie_by_name(\n            self.cookie_jar,\n            cookie['name'],\n            domain=cookie.get('domain', None),\n            path=cookie.get('path', None)\n        )", "loc": 8}
{"file": "httpie\\httpie\\sessions.py", "class_name": "Session", "function_name": "auth", "parameters": ["self"], "param_types": {}, "return_type": "Optional[AuthBase]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_auth", "plugin.get_auth", "plugin_manager.get_auth_plugin", "self.get"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def auth(self) -> Optional[AuthBase]:\n    auth = self.get('auth', None)\n    if not auth or not auth['type']:\n        return\n\n    plugin = plugin_manager.get_auth_plugin(auth['type'])()\n\n    credentials = {'username': None, 'password': None}\n    try:\n        # New style\n        plugin.raw_auth = auth['raw_auth']\n    except KeyError:\n        # Old style\n        credentials = {\n            'username': auth['username'],\n            'password': auth['password'],\n        }\n    else:\n        if plugin.auth_parse:\n            from .cli.argtypes import parse_auth\n            parsed = parse_auth(plugin.raw_auth)\n            credentials = {\n                'username': parsed.key,\n                'password': parsed.value,\n            }\n\n    return plugin.get_auth(**credentials)", "loc": 27}
{"file": "httpie\\httpie\\sessions.py", "class_name": "Session", "function_name": "warn_legacy_usage", "parameters": ["self", "warning"], "param_types": {"warning": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.env.log_error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def warn_legacy_usage(self, warning: str) -> None:\n    if self.suppress_legacy_warnings:\n        return None\n\n    self.env.log_error(\n        warning,\n        level=LogLevel.WARNING\n    )\n\n    # We don't want to spam multiple warnings on each usage,\n    # so if there is already a warning for the legacy usage\n    # we'll skip the next ones.\n    self.suppress_legacy_warnings = True", "loc": 13}
{"file": "httpie\\httpie\\ssl_.py", "class_name": "HTTPieHTTPSAdapter", "function_name": "cert_verify", "parameters": ["self", "conn", "url", "verify", "cert"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cert.to_raw_cert", "isinstance", "super", "super().cert_verify"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cert_verify(self, conn, url, verify, cert):\n    if isinstance(cert, HTTPieCertificate):\n        conn.key_password = cert.key_password\n        cert = cert.to_raw_cert()\n\n    return super().cert_verify(conn, url, verify, cert)", "loc": 6}
{"file": "httpie\\httpie\\status.py", "class_name": null, "function_name": "http_status_to_exit_status", "parameters": ["http_status", "follow"], "param_types": {"http_status": "int"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Translate HTTP status code to exit status code. (Relevant only when invoked with --check-status or --download.)", "source_code": "def http_status_to_exit_status(http_status: int, follow=False) -> ExitStatus:\n    \"\"\"\n    Translate HTTP status code to exit status code.\n\n    (Relevant only when invoked with --check-status or --download.)\n\n    \"\"\"\n    if 300 <= http_status <= 399 and not follow:\n        # Redirect\n        return ExitStatus.ERROR_HTTP_3XX\n    elif 400 <= http_status <= 499:\n        # Client Error\n        return ExitStatus.ERROR_HTTP_4XX\n    elif 500 <= http_status <= 599:\n        # Server Error\n        return ExitStatus.ERROR_HTTP_5XX\n    else:\n        return ExitStatus.SUCCESS", "loc": 18}
{"file": "httpie\\httpie\\uploads.py", "class_name": null, "function_name": "as_bytes", "parameters": ["data"], "param_types": {"data": "Union[str, bytes]"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.encode", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def as_bytes(data: Union[str, bytes]) -> bytes:\n    if isinstance(data, str):\n        return data.encode()\n    else:\n        return data", "loc": 5}
{"file": "httpie\\httpie\\uploads.py", "class_name": null, "function_name": "is_stdin", "parameters": ["file"], "param_types": {"file": "IO"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["file.fileno", "sys.stdin.fileno"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_stdin(file: IO) -> bool:\n    try:\n        file_no = file.fileno()\n    except Exception:\n        return False\n    else:\n        return file_no == sys.stdin.fileno()", "loc": 7}
{"file": "httpie\\httpie\\uploads.py", "class_name": null, "function_name": "observe_stdin_for_data_thread", "parameters": ["env", "file", "read_event"], "param_types": {"env": "Environment", "file": "IO", "read_event": "threading.Event"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["env.stderr.write", "event.wait", "thread.start", "threading.Thread"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def observe_stdin_for_data_thread(env: Environment, file: IO, read_event: threading.Event) -> None:\n    # Windows unfortunately does not support select() operation\n    # on regular files, like stdin in our use case.\n    # https://docs.python.org/3/library/select.html#select.select\n    if is_windows:\n        return None\n\n    # If the user configures READ_THRESHOLD to be 0, then\n    # disable this warning.\n    if READ_THRESHOLD == 0:\n        return None\n\n    def worker(event: threading.Event) -> None:\n        if not event.wait(timeout=READ_THRESHOLD):\n            env.stderr.write(\n                f'> warning: no stdin data read in {READ_THRESHOLD}s '\n                f'(perhaps you want to --ignore-stdin)\\n'\n                f'> See: https://httpie.io/docs/cli/best-practices\\n'\n            )\n\n    # Making it a daemon ensures that if the user exits from the main program\n    # (e.g. either regularly or with Ctrl-C), the thread will not\n    # block them.\n    thread = threading.Thread(\n        target=worker,\n        args=(read_event,),\n        daemon=True\n    )\n    thread.start()", "loc": 29}
{"file": "httpie\\httpie\\uploads.py", "class_name": null, "function_name": "prepare_request_body", "parameters": ["env", "raw_body", "body_read_callback", "offline", "chunked", "content_length_header_value"], "param_types": {"env": "Environment", "raw_body": "Union[str, bytes, IO, 'MultipartEncoder', RequestDataDict]", "body_read_callback": "CallbackT", "offline": "bool", "chunked": "bool", "content_length_header_value": "Optional[int]"}, "return_type": "Union[bytes, IO, 'MultipartEncoder', ChunkedStream]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChunkedUploadStream", "_prepare_file_for_upload", "as_bytes", "hasattr", "isinstance", "iter", "raw_body.read", "urlencode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def prepare_request_body(\n    env: Environment,\n    raw_body: Union[str, bytes, IO, 'MultipartEncoder', RequestDataDict],\n    body_read_callback: CallbackT,\n    offline: bool = False,\n    chunked: bool = False,\n    content_length_header_value: Optional[int] = None,\n) -> Union[bytes, IO, 'MultipartEncoder', ChunkedStream]:\n    is_file_like = hasattr(raw_body, 'read')\n    if isinstance(raw_body, (bytes, str)):\n        body = as_bytes(raw_body)\n    elif isinstance(raw_body, RequestDataDict):\n        body = as_bytes(urlencode(raw_body, doseq=True))\n    else:\n        body = raw_body\n\n    if offline:\n        if is_file_like:\n            return as_bytes(raw_body.read())\n        else:\n            return body\n\n    if is_file_like:\n        return _prepare_file_for_upload(\n            env,\n            body,\n            chunked=chunked,\n            callback=body_read_callback,\n            content_length_header_value=content_length_header_value\n        )\n    elif chunked:\n        return ChunkedUploadStream(\n            stream=iter([body]),\n            callback=body_read_callback\n        )\n    else:\n        return body", "loc": 37}
{"file": "httpie\\httpie\\uploads.py", "class_name": null, "function_name": "get_multipart_data_and_content_type", "parameters": ["data", "boundary", "content_type"], "param_types": {"data": "MultipartRequestDataDict", "boundary": "str", "content_type": "str"}, "return_type": "Tuple['MultipartEncoder', str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["MultipartEncoder", "content_type.strip", "data.items"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_multipart_data_and_content_type(\n    data: MultipartRequestDataDict,\n    boundary: str = None,\n    content_type: str = None,\n) -> Tuple['MultipartEncoder', str]:\n    from requests_toolbelt import MultipartEncoder\n\n    encoder = MultipartEncoder(\n        fields=data.items(),\n        boundary=boundary,\n    )\n    if content_type:\n        content_type = content_type.strip()\n        if 'boundary=' not in content_type:\n            content_type = f'{content_type}; boundary={encoder.boundary_value}'\n    else:\n        content_type = encoder.content_type\n\n    data = encoder\n    return data, content_type", "loc": 20}
{"file": "httpie\\httpie\\uploads.py", "class_name": null, "function_name": "compress_request", "parameters": ["request", "always"], "param_types": {"request": "requests.PreparedRequest", "always": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["deflater.compress", "deflater.flush", "hasattr", "isinstance", "len", "request.body.encode", "request.body.read", "str", "zlib.compressobj"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def compress_request(\n    request: requests.PreparedRequest,\n    always: bool,\n):\n    deflater = zlib.compressobj()\n    if isinstance(request.body, str):\n        body_bytes = request.body.encode()\n    elif hasattr(request.body, 'read'):\n        body_bytes = request.body.read()\n    else:\n        body_bytes = request.body\n    deflated_data = deflater.compress(body_bytes)\n    deflated_data += deflater.flush()\n    is_economical = len(deflated_data) < len(body_bytes)\n    if is_economical or always:\n        request.body = deflated_data\n        request.headers['Content-Encoding'] = 'deflate'\n        request.headers['Content-Length'] = str(len(deflated_data))", "loc": 18}
{"file": "httpie\\httpie\\uploads.py", "class_name": null, "function_name": "worker", "parameters": ["event"], "param_types": {"event": "threading.Event"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["env.stderr.write", "event.wait"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def worker(event: threading.Event) -> None:\n    if not event.wait(timeout=READ_THRESHOLD):\n        env.stderr.write(\n            f'> warning: no stdin data read in {READ_THRESHOLD}s '\n            f'(perhaps you want to --ignore-stdin)\\n'\n            f'> See: https://httpie.io/docs/cli/best-practices\\n'\n        )", "loc": 7}
{"file": "httpie\\httpie\\utils.py", "class_name": null, "function_name": "humanize_bytes", "parameters": ["n", "precision"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return a humanized string representation of a number of bytes. >>> humanize_bytes(1) '1 B'", "source_code": "def humanize_bytes(n, precision=2):\n    # Author: Doug Latornell\n    # Licence: MIT\n    # URL: https://code.activestate.com/recipes/577081/\n    \"\"\"Return a humanized string representation of a number of bytes.\n\n    >>> humanize_bytes(1)\n    '1 B'\n    >>> humanize_bytes(1024, precision=1)\n    '1.0 kB'\n    >>> humanize_bytes(1024 * 123, precision=1)\n    '123.0 kB'\n    >>> humanize_bytes(1024 * 12342, precision=1)\n    '12.1 MB'\n    >>> humanize_bytes(1024 * 12342, precision=2)\n    '12.05 MB'\n    >>> humanize_bytes(1024 * 1234, precision=2)\n    '1.21 MB'\n    >>> humanize_bytes(1024 * 1234 * 1111, precision=2)\n    '1.31 GB'\n    >>> humanize_bytes(1024 * 1234 * 1111, precision=1)\n    '1.3 GB'\n\n    \"\"\"\n    abbrevs = [\n        (1 << 50, 'PB'),\n        (1 << 40, 'TB'),\n        (1 << 30, 'GB'),\n        (1 << 20, 'MB'),\n        (1 << 10, 'kB'),\n        (1, 'B')\n    ]\n\n    if n == 1:\n        return '1 B'\n\n    for factor, suffix in abbrevs:\n        if n >= factor:\n            break\n\n    # noinspection PyUnboundLocalVariable\n    return f'{n / factor:.{precision}f} {suffix}'", "loc": 42}
{"file": "httpie\\httpie\\utils.py", "class_name": null, "function_name": "split_cookies", "parameters": ["cookies"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RE_COOKIE_SPLIT.split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "When ``requests`` stores cookies in ``response.headers['Set-Cookie']`` it concatenates all of them through ``, ``. This function splits cookies apart being careful to not to", "source_code": "def split_cookies(cookies):\n    \"\"\"\n    When ``requests`` stores cookies in ``response.headers['Set-Cookie']``\n    it concatenates all of them through ``, ``.\n\n    This function splits cookies apart being careful to not to\n    split on ``, `` which may be part of cookie value.\n    \"\"\"\n    if not cookies:\n        return []\n    return RE_COOKIE_SPLIT.split(cookies)", "loc": 11}
{"file": "httpie\\httpie\\utils.py", "class_name": null, "function_name": "get_expired_cookies", "parameters": ["cookies", "now"], "param_types": {"cookies": "str", "now": "float"}, "return_type": "List[dict]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_max_age_to_expires", "cookie.get", "dict", "is_expired", "parse_ns_headers", "split_cookies", "time.time"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_expired_cookies(\n    cookies: str,\n    now: float = None\n) -> List[dict]:\n\n    now = now or time.time()\n\n    def is_expired(expires: Optional[float]) -> bool:\n        return expires is not None and expires <= now\n\n    attr_sets: List[Tuple[str, str]] = parse_ns_headers(\n        split_cookies(cookies)\n    )\n\n    cookies = [\n        # The first attr name is the cookie name.\n        dict(attrs[1:], name=attrs[0][0])\n        for attrs in attr_sets\n    ]\n\n    _max_age_to_expires(cookies=cookies, now=now)\n\n    return [\n        {\n            'name': cookie['name'],\n            'path': cookie.get('path', '/')\n        }\n        for cookie in cookies\n        if is_expired(expires=cookie.get('expires'))\n    ]", "loc": 30}
{"file": "httpie\\httpie\\utils.py", "class_name": null, "function_name": "parse_content_type_header", "parameters": ["header"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["header.split", "key.lower", "param.find", "param.strip", "param[:index_of_equals].strip", "param[index_of_equals + 1:].strip", "tokens[0].strip"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Borrowed from requests.", "source_code": "def parse_content_type_header(header):\n    \"\"\"Borrowed from requests.\"\"\"\n    tokens = header.split(';')\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1:].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict", "loc": 16}
{"file": "httpie\\httpie\\utils.py", "class_name": null, "function_name": "as_site", "parameters": ["path"], "param_types": {"path": "Path"}, "return_type": "Path", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "str", "sysconfig.get_path"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def as_site(path: Path, **extra_vars) -> Path:\n    site_packages_path = sysconfig.get_path(\n        'purelib',\n        vars={'base': str(path), **extra_vars}\n    )\n    return Path(site_packages_path)", "loc": 6}
{"file": "httpie\\httpie\\utils.py", "class_name": null, "function_name": "get_site_paths", "parameters": ["path"], "param_types": {"path": "Path"}, "return_type": "Iterable[Path]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["as_site", "range"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_site_paths(path: Path) -> Iterable[Path]:\n    from httpie.compat import (\n        MIN_SUPPORTED_PY_VERSION,\n        MAX_SUPPORTED_PY_VERSION,\n        is_frozen\n    )\n\n    if is_frozen:\n        [major, min_minor] = MIN_SUPPORTED_PY_VERSION\n        [major, max_minor] = MAX_SUPPORTED_PY_VERSION\n        for minor in range(min_minor, max_minor + 1):\n            yield as_site(\n                path,\n                py_version_short=f'{major}.{minor}'\n            )\n    else:\n        yield as_site(path)", "loc": 17}
{"file": "httpie\\httpie\\utils.py", "class_name": null, "function_name": "split_iterable", "parameters": ["iterable", "key"], "param_types": {"iterable": "Iterable[T]", "key": "Callable[[T], bool]"}, "return_type": "Tuple[List[T], List[T]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["key", "left.append", "right.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def split_iterable(iterable: Iterable[T], key: Callable[[T], bool]) -> Tuple[List[T], List[T]]:\n    left, right = [], []\n    for item in iterable:\n        if key(item):\n            left.append(item)\n        else:\n            right.append(item)\n    return left, right", "loc": 8}
{"file": "httpie\\httpie\\utils.py", "class_name": null, "function_name": "unwrap_context", "parameters": ["exc"], "param_types": {"exc": "Exception"}, "return_type": "Optional[Exception]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "unwrap_context"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unwrap_context(exc: Exception) -> Optional[Exception]:\n    context = exc.__context__\n    if isinstance(context, Exception):\n        return unwrap_context(context)\n    else:\n        return exc", "loc": 6}
{"file": "httpie\\httpie\\utils.py", "class_name": null, "function_name": "is_version_greater", "parameters": ["version_1", "version_2"], "param_types": {"version_1": "str", "version_2": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "parts.append", "split_version", "tuple", "version.split"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_version_greater(version_1: str, version_2: str) -> bool:\n    # In an ideal scenario, we would depend on `packaging` in order\n    # to offer PEP 440 compatible parsing. But since it might not be\n    # commonly available for outside packages, and since we are only\n    # going to parse HTTPie's own version it should be fine to compare\n    # this in a SemVer subset fashion.\n\n    def split_version(version: str) -> Tuple[int, ...]:\n        parts = []\n        for part in version.split('.')[:3]:\n            try:\n                parts.append(int(part))\n            except ValueError:\n                break\n        return tuple(parts)\n\n    return split_version(version_1) > split_version(version_2)", "loc": 17}
{"file": "httpie\\httpie\\utils.py", "class_name": null, "function_name": "split_version", "parameters": ["version"], "param_types": {"version": "str"}, "return_type": "Tuple[int, ...]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "parts.append", "tuple", "version.split"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def split_version(version: str) -> Tuple[int, ...]:\n    parts = []\n    for part in version.split('.')[:3]:\n        try:\n            parts.append(int(part))\n        except ValueError:\n            break\n    return tuple(parts)", "loc": 8}
{"file": "httpie\\httpie\\__main__.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["main"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main():\n    try:\n        from httpie.core import main\n        exit_status = main()\n    except KeyboardInterrupt:\n        from httpie.status import ExitStatus\n        exit_status = ExitStatus.ERROR_CTRL_C\n\n    return exit_status.value", "loc": 9}
{"file": "httpie\\httpie\\cli\\argparser.py", "class_name": "HTTPieHelpFormatter", "function_name": "add_usage", "parameters": ["self", "usage", "actions", "groups", "prefix"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["displayed_actions.insert", "isinstance", "len", "super", "super().add_usage", "sys.exc_info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_usage(self, usage, actions, groups, prefix=None):\n    # Only display the positional arguments\n    displayed_actions = [\n        action\n        for action in actions\n        if not action.option_strings\n    ]\n\n    _, exception, _ = sys.exc_info()\n    if (\n        isinstance(exception, argparse.ArgumentError)\n        and len(exception.args) >= 1\n        and isinstance(exception.args[0], argparse.Action)\n    ):\n        # add_usage path is also taken when you pass an invalid option,\n        # e.g --style=invalid. If something like that happens, we want\n        # to include to action that caused to the invalid usage into\n        # the list of actions we are displaying.\n        displayed_actions.insert(0, exception.args[0])\n\n    super().add_usage(\n        usage,\n        displayed_actions,\n        groups,\n        prefix=\"usage:\\n    \"\n    )", "loc": 26}
{"file": "httpie\\httpie\\cli\\argparser.py", "class_name": "BaseHTTPieArgumentParser", "function_name": "parse_args", "parameters": ["self", "env", "args", "namespace"], "param_types": {"env": "Environment"}, "return_type": "argparse.Namespace", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "self.parse_known_args"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_args(\n    self,\n    env: Environment,\n    args=None,\n    namespace=None\n) -> argparse.Namespace:\n    self.env = env\n    self.args, no_options = self.parse_known_args(args, namespace)\n    if self.args.debug:\n        self.args.traceback = True\n    self.has_stdin_data = (\n        self.env.stdin\n        and not getattr(self.args, 'ignore_stdin', False)\n        and not self.env.stdin_isatty\n    )\n    self.has_input_data = self.has_stdin_data or getattr(self.args, 'raw', None) is not None\n    return self.args", "loc": 17}
{"file": "httpie\\httpie\\cli\\argparser.py", "class_name": "HTTPieManagerArgumentParser", "function_name": "parse_known_args", "parameters": ["self", "args", "namespace"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["argparse.ArgumentError", "hasattr", "super", "super().parse_known_args"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_known_args(self, args=None, namespace=None):\n    try:\n        return super().parse_known_args(args, namespace)\n    except SystemExit as exc:\n        if not hasattr(self, 'root') and exc.code == 2:  # Argument Parser Error\n            raise argparse.ArgumentError(None, None)\n        raise", "loc": 7}
{"file": "httpie\\httpie\\cli\\argparser.py", "class_name": "HTTPieArgumentParser", "function_name": "parse_args", "parameters": ["self", "env", "args", "namespace"], "param_types": {"env": "Environment"}, "return_type": "argparse.Namespace", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["argparse.Namespace", "self._apply_no_options", "self._body_from_file", "self._body_from_input", "self._guess_method", "self._parse_items", "self._process_auth", "self._process_download_options", "self._process_format_options", "self._process_output_options", "self._process_pretty_options", "self._process_request_type", "self._process_ssl_cert", "self._process_url", "self._setup_standard_streams", "self.error", "super", "super().parse_known_args"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_args(\n    self,\n    env: Environment,\n    args=None,\n    namespace=None\n) -> argparse.Namespace:\n    self.env = env\n    self.env.args = namespace = namespace or argparse.Namespace()\n    self.args, no_options = super().parse_known_args(args, namespace)\n    if self.args.debug:\n        self.args.traceback = True\n    self.has_stdin_data = (\n        self.env.stdin\n        and not self.args.ignore_stdin\n        and not self.env.stdin_isatty\n    )\n    self.has_input_data = self.has_stdin_data or self.args.raw is not None\n    # Arguments processing and environment setup.\n    self._apply_no_options(no_options)\n    self._process_request_type()\n    self._process_download_options()\n    self._setup_standard_streams()\n    self._process_output_options()\n    self._process_pretty_options()\n    self._process_format_options()\n    self._guess_method()\n    self._parse_items()\n    self._process_url()\n    self._process_auth()\n    self._process_ssl_cert()\n\n    if self.args.raw is not None:\n        self._body_from_input(self.args.raw)\n    elif self.has_stdin_data:\n        self._body_from_file(self.env.stdin)\n\n    if self.args.compress:\n        # TODO: allow --compress with --chunked / --multipart\n        if self.args.chunked:\n            self.error('cannot combine --compress and --chunked')\n        if self.args.multipart:\n            self.error('cannot combine --compress and --multipart')\n\n    return self.args", "loc": 44}
{"file": "httpie\\httpie\\cli\\argparser.py", "class_name": "HTTPieArgumentParser", "function_name": "print_manual", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["man_pages.display_for", "man_pages.is_available", "self.env.rich_console.pager", "self.env.rich_console.print", "self.format_help"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def print_manual(self):\n    from httpie.output.ui import man_pages\n\n    if man_pages.is_available(self.env.program_name):\n        man_pages.display_for(self.env, self.env.program_name)\n        return None\n\n    text = self.format_help()\n    with self.env.rich_console.pager():\n        self.env.rich_console.print(\n            text,\n            highlight=False\n        )", "loc": 13}
{"file": "httpie\\httpie\\cli\\argparser.py", "class_name": "HTTPieArgumentParser", "function_name": "print_usage", "parameters": ["self", "file"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Text", "isinstance", "len", "rich_help.to_usage", "self.env.rich_error_console.print", "set", "sys.exc_info", "usage_text.append", "whitelist.add"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def print_usage(self, file):\n    from rich.text import Text\n    from httpie.output.ui import rich_help\n\n    whitelist = set()\n    _, exception, _ = sys.exc_info()\n    if (\n        isinstance(exception, argparse.ArgumentError)\n        and len(exception.args) >= 1\n        and isinstance(exception.args[0], argparse.Action)\n        and exception.args[0].option_strings\n    ):\n        # add_usage path is also taken when you pass an invalid option,\n        # e.g --style=invalid. If something like that happens, we want\n        # to include to action that caused to the invalid usage into\n        # the list of actions we are displaying.\n        whitelist.add(exception.args[0].option_strings[0])\n\n    usage_text = Text('usage', style='bold')\n    usage_text.append(':\\n    ')\n    usage_text.append(rich_help.to_usage(self.spec, whitelist=whitelist))\n    self.env.rich_error_console.print(usage_text)", "loc": 22}
{"file": "httpie\\httpie\\cli\\argtypes.py", "class_name": null, "function_name": "parse_format_options", "parameters": ["s", "defaults"], "param_types": {"s": "str", "defaults": "Optional[dict]"}, "return_type": "dict", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["argparse.ArgumentTypeError", "deepcopy", "int", "option.lower", "option.lower().split", "options.setdefault", "path.split", "s.split", "type", "value.isnumeric"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Parse `s` and update `defaults` with the parsed values. >>> parse_format_options( ... defaults={'json': {'indent': 4, 'sort_keys': True}},", "source_code": "def parse_format_options(s: str, defaults: Optional[dict]) -> dict:\n    \"\"\"\n    Parse `s` and update `defaults` with the parsed values.\n\n    >>> parse_format_options(\n    ... defaults={'json': {'indent': 4, 'sort_keys': True}},\n    ... s='json.indent:2,json.sort_keys:False',\n    ... )\n    {'json': {'indent': 2, 'sort_keys': False}}\n\n    \"\"\"\n    value_map = {\n        'true': True,\n        'false': False,\n    }\n    options = deepcopy(defaults or {})\n    for option in s.split(','):\n        try:\n            path, value = option.lower().split(':')\n            section, key = path.split('.')\n        except ValueError:\n            raise argparse.ArgumentTypeError(f'invalid option {option!r}')\n\n        if value in value_map:\n            parsed_value = value_map[value]\n        else:\n            if value.isnumeric():\n                parsed_value = int(value)\n            else:\n                parsed_value = value\n\n        if defaults is None:\n            options.setdefault(section, {})\n        else:\n            try:\n                default_value = defaults[section][key]\n            except KeyError:\n                raise argparse.ArgumentTypeError(\n                    f'invalid key {path!r}')\n\n            default_type, parsed_type = type(default_value), type(parsed_value)\n            if parsed_type is not default_type:\n                raise argparse.ArgumentTypeError(\n                    'invalid value'\n                    f' {value!r} in {option!r}'\n                    f' (expected {default_type.__name__}'\n                    f' got {parsed_type.__name__})'\n                )\n\n        options[section][key] = parsed_value\n\n    return options", "loc": 52}
{"file": "httpie\\httpie\\cli\\argtypes.py", "class_name": null, "function_name": "response_charset_type", "parameters": ["encoding"], "param_types": {"encoding": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.encode", "argparse.ArgumentTypeError"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def response_charset_type(encoding: str) -> str:\n    try:\n        ''.encode(encoding)\n    except LookupError:\n        raise argparse.ArgumentTypeError(\n            f'{encoding!r} is not a supported encoding')\n    return encoding", "loc": 7}
{"file": "httpie\\httpie\\cli\\argtypes.py", "class_name": null, "function_name": "response_mime_type", "parameters": ["mime_type"], "param_types": {"mime_type": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["argparse.ArgumentTypeError", "mime_type.count"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def response_mime_type(mime_type: str) -> str:\n    if mime_type.count('/') != 1:\n        raise argparse.ArgumentTypeError(\n            f'{mime_type!r} doesnt look like a mime type; use type/subtype')\n    return mime_type", "loc": 5}
{"file": "httpie\\httpie\\cli\\argtypes.py", "class_name": "KeyValueArgType", "function_name": "tokenize", "parameters": ["self", "s"], "param_types": {"s": "str"}, "return_type": "List[Union[str, Escaped]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Escaped", "iter", "next", "tokens.extend"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Tokenize the raw arg string There are only two token types - strings and escaped characters: >>> KeyValueArgType('=').tokenize(r'foo\\=bar\\\\baz')", "source_code": "def tokenize(self, s: str) -> List[Union[str, Escaped]]:\n    r\"\"\"Tokenize the raw arg string\n\n    There are only two token types - strings and escaped characters:\n\n    >>> KeyValueArgType('=').tokenize(r'foo\\=bar\\\\baz')\n    ['foo', Escaped('='), 'bar\\\\\\\\baz']\n\n    \"\"\"\n    tokens = ['']\n    characters = iter(s)\n    for char in characters:\n        if char == '\\\\':\n            char = next(characters, '')\n            if char not in self.special_characters:\n                tokens[-1] += '\\\\' + char\n            else:\n                tokens.extend([Escaped(char), ''])\n        else:\n            tokens[-1] += char\n    return tokens", "loc": 21}
{"file": "httpie\\httpie\\cli\\definition.py", "class_name": null, "function_name": "format_style_help", "parameters": ["available_styles"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "'\\n'.join", "'\\n'.join((f'    {line.strip()}' for line in textwrap.wrap(', '.join(available_styles), 60))).strip", "line.strip", "sorted", "text.format", "textwrap.dedent", "textwrap.wrap"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_style_help(available_styles, *, isolation_mode: bool = False):\n    text = \"\"\"\n    Output coloring style (default is \"{default}\"). It can be one of:\n\n        {available_styles}\n    \"\"\"\n    if isolation_mode:\n        text += '\\n\\n'\n        text += 'For finding out all available styles in your system, try:\\n\\n'\n        text += '    $ http --style\\n'\n    text += textwrap.dedent(\"\"\"\n        The \"{auto_style}\" style follows your terminal's ANSI color styles.\n        For non-{auto_style} styles to work properly, please make sure that the\n        $TERM environment variable is set to \"xterm-256color\" or similar\n        (e.g., via `export TERM=xterm-256color' in your ~/.bashrc).\n    \"\"\")\n\n    if isolation_mode:\n        available_styles = sorted(BUNDLED_STYLES)\n\n    available_styles_text = '\\n'.join(\n        f'    {line.strip()}'\n        for line in textwrap.wrap(', '.join(available_styles), 60)\n    ).strip()\n    return text.format(\n        default=DEFAULT_STYLE,\n        available_styles=available_styles_text,\n        auto_style=AUTO_STYLE,\n    )", "loc": 29}
{"file": "httpie\\httpie\\cli\\definition.py", "class_name": null, "function_name": "format_auth_help", "parameters": ["auth_plugins_mapping"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\"{type}\": {name}{package}{description}'.format", "'\\n      '.join", "'\\n\\n    '.join", "auth_plugins_mapping.values", "issubclass", "list", "text.format", "textwrap.wrap"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_auth_help(auth_plugins_mapping, *, isolation_mode: bool = False):\n    text = \"\"\"\n    The authentication mechanism to be used. Defaults to \"{default}\".\n\n    {auth_types}\n    \"\"\"\n\n    auth_plugins = list(auth_plugins_mapping.values())\n    if isolation_mode:\n        auth_plugins = [\n            auth_plugin\n            for auth_plugin in auth_plugins\n            if issubclass(auth_plugin, BuiltinAuthPlugin)\n        ]\n        text += '\\n'\n        text += 'To see all available auth types on your system, including ones installed via plugins, run:\\n\\n'\n        text += '    $ http --auth-type'\n\n    auth_types = '\\n\\n    '.join(\n        '\"{type}\": {name}{package}{description}'.format(\n            type=plugin.auth_type,\n            name=plugin.name,\n            package=(\n                ''\n                if issubclass(plugin, BuiltinAuthPlugin)\n                else f' (provided by {plugin.package_name})'\n            ),\n            description=(\n                ''\n                if not plugin.description\n                else '\\n      '\n                     + ('\\n      '.join(textwrap.wrap(plugin.description)))\n            ),\n        )\n        for plugin in auth_plugins\n    )\n\n    return text.format(\n        default=auth_plugins[0].auth_type,\n        auth_types=auth_types,\n    )", "loc": 41}
{"file": "httpie\\httpie\\cli\\dicts.py", "class_name": "HTTPHeadersDict", "function_name": "add", "parameters": ["self", "key", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.getone", "self.popone", "super", "super().add"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Add or update a new header. If the given `value` is `None`, then all the previous values will be overwritten and the value will be set", "source_code": "def add(self, key, value):\n    \"\"\"\n    Add or update a new header.\n\n    If the given `value` is `None`, then all the previous\n    values will be overwritten and the value will be set\n    to `None`.\n    \"\"\"\n    if value is None:\n        self[key] = value\n        return None\n\n    # If the previous value for the given header is `None`\n    # then discard it since we are explicitly giving a new\n    # value for it.\n    if key in self and self.getone(key) is None:\n        self.popone(key)\n\n    super().add(key, value)", "loc": 19}
{"file": "httpie\\httpie\\cli\\dicts.py", "class_name": "HTTPHeadersDict", "function_name": "remove_item", "parameters": ["self", "key", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["existing_values.remove", "self.add", "self.popall"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Remove a (key, value) pair from the dict.", "source_code": "def remove_item(self, key, value):\n    \"\"\"\n    Remove a (key, value) pair from the dict.\n    \"\"\"\n    existing_values = self.popall(key)\n    existing_values.remove(value)\n\n    for value in existing_values:\n        self.add(key, value)", "loc": 9}
{"file": "httpie\\httpie\\cli\\dicts.py", "class_name": "MultiValueOrderedDict", "function_name": "items", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "super", "super().items"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def items(self):\n    for key, values in super().items():\n        if not isinstance(values, list):\n            values = [values]\n        for value in values:\n            yield key, value", "loc": 6}
{"file": "httpie\\httpie\\cli\\options.py", "class_name": null, "function_name": "map_qualifiers", "parameters": ["configuration", "qualifier_map"], "param_types": {"configuration": "Dict[str, Any]", "qualifier_map": "Dict[Qualifiers, Any]"}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["configuration.items", "isinstance"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def map_qualifiers(\n    configuration: Dict[str, Any], qualifier_map: Dict[Qualifiers, Any]\n) -> Dict[str, Any]:\n    return {\n        key: qualifier_map[value] if isinstance(value, Qualifiers) else value\n        for key, value in configuration.items()\n    }", "loc": 7}
{"file": "httpie\\httpie\\cli\\options.py", "class_name": null, "function_name": "to_argparse", "parameters": ["abstract_options", "parser_type"], "param_types": {"abstract_options": "ParserSpec", "parser_type": "ParserType"}, "return_type": "ParserType", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["concrete_group.add_argument", "concrete_group.add_mutually_exclusive_group", "concrete_parser.add_argument_group", "concrete_parser.register", "drop_keys", "map_qualifiers", "parser_type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def to_argparse(\n    abstract_options: ParserSpec,\n    parser_type: ParserType = HTTPieArgumentParser,\n) -> ParserType:\n    concrete_parser = parser_type(\n        prog=abstract_options.program,\n        description=abstract_options.description,\n        epilog=abstract_options.epilog,\n    )\n    concrete_parser.spec = abstract_options\n    concrete_parser.register('action', 'lazy_choices', LazyChoices)\n    concrete_parser.register('action', 'manual', Manual)\n\n    for abstract_group in abstract_options.groups:\n        concrete_group = concrete_parser.add_argument_group(\n            title=abstract_group.name, description=abstract_group.description\n        )\n        if abstract_group.is_mutually_exclusive:\n            concrete_group = concrete_group.add_mutually_exclusive_group(required=False)\n\n        for abstract_argument in abstract_group.arguments:\n            concrete_group.add_argument(\n                *abstract_argument.aliases,\n                **drop_keys(map_qualifiers(\n                    abstract_argument.configuration, ARGPARSE_QUALIFIER_MAP\n                ), ARGPARSE_IGNORE_KEYS)\n            )\n\n    return concrete_parser", "loc": 29}
{"file": "httpie\\httpie\\cli\\options.py", "class_name": "ParserSpec", "function_name": "finalize", "parameters": ["self"], "param_types": {}, "return_type": "'ParserSpec'", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["group.finalize", "textwrap.dedent"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def finalize(self) -> 'ParserSpec':\n    if self.description:\n        self.description = textwrap.dedent(self.description)\n    if self.epilog:\n        self.epilog = textwrap.dedent(self.epilog)\n    for group in self.groups:\n        group.finalize()\n    return self", "loc": 8}
{"file": "httpie\\httpie\\cli\\options.py", "class_name": "Group", "function_name": "add_argument", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Argument", "argument.post_init", "kwargs.copy", "list", "self.arguments.append"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_argument(self, *args, **kwargs):\n    argument = Argument(list(args), kwargs.copy())\n    argument.post_init()\n    self.arguments.append(argument)\n    return argument", "loc": 5}
{"file": "httpie\\httpie\\cli\\options.py", "class_name": "Argument", "function_name": "post_init", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.configuration.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Run a bunch of post-init hooks.", "source_code": "def post_init(self):\n    \"\"\"Run a bunch of post-init hooks.\"\"\"\n    # If there is a short help, then create the longer version from it.\n    short_help = self.configuration.get('short_help')\n    if (\n        short_help\n        and 'help' not in self.configuration\n        and self.configuration.get('action') != 'lazy_choices'\n    ):\n        self.configuration['help'] = f'\\n{short_help}\\n\\n'", "loc": 10}
{"file": "httpie\\httpie\\cli\\options.py", "class_name": "Argument", "function_name": "serialize", "parameters": ["self"], "param_types": {}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["LazyChoices", "choices.load", "configuration.get", "configuration.items", "configuration.pop", "hasattr", "list", "result.update", "self.aliases.copy", "self.configuration.copy", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize(self, *, isolation_mode: bool = False) -> Dict[str, Any]:\n    configuration = self.configuration.copy()\n\n    # Unpack the dynamically computed choices, since we\n    # will need to store the actual values somewhere.\n    action = configuration.pop('action', None)\n    short_help = configuration.pop('short_help', None)\n    nested_options = configuration.pop('nested_options', None)\n\n    if action == 'lazy_choices':\n        choices = LazyChoices(\n            self.aliases,\n            **{'dest': None, **configuration},\n            isolation_mode=isolation_mode\n        )\n        configuration['choices'] = list(choices.load())\n        configuration['help'] = choices.help\n\n    result = {}\n    if self.aliases:\n        result['options'] = self.aliases.copy()\n    else:\n        result['options'] = [configuration['metavar']]\n        result['is_positional'] = True\n\n    qualifiers = JSON_QUALIFIER_TO_OPTIONS[configuration.get('nargs', Qualifiers.SUPPRESS)]\n    result.update(qualifiers)\n\n    description = configuration.get('help')\n    if description and description is not Qualifiers.SUPPRESS:\n        result['short_description'] = short_help\n        result['description'] = description\n\n    if nested_options:\n        result['nested_options'] = nested_options\n\n    python_type = configuration.get('type')\n    if python_type is not None:\n        if hasattr(python_type, '__name__'):\n            type_name = python_type.__name__\n        else:\n            type_name = type(python_type).__name__\n\n        result['python_type_name'] = type_name\n\n    result.update({\n        key: value\n        for key, value in configuration.items()\n        if key in JSON_DIRECT_MIRROR_OPTIONS\n        if value is not Qualifiers.SUPPRESS\n    })\n\n    return result", "loc": 53}
{"file": "httpie\\httpie\\cli\\requestitems.py", "class_name": null, "function_name": "process_empty_header_arg", "parameters": ["arg"], "param_types": {"arg": "KeyValueArg"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParseError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_empty_header_arg(arg: KeyValueArg) -> str:\n    if not arg.value:\n        return arg.value\n    raise ParseError(\n        f'Invalid item {arg.orig!r} (to specify an empty header use `Header;`)'\n    )", "loc": 6}
{"file": "httpie\\httpie\\cli\\requestitems.py", "class_name": null, "function_name": "convert_json_value_to_form_if_needed", "parameters": ["in_json_mode", "processor"], "param_types": {"in_json_mode": "bool", "processor": "Callable[[KeyValueArg], JSONType]"}, "return_type": "Callable[[], str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParseError", "functools.wraps", "isinstance", "processor", "str"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "We allow primitive values to be passed to forms via JSON key/value syntax. But complex values lead to an error because theres no clear way to serialize them.", "source_code": "def convert_json_value_to_form_if_needed(in_json_mode: bool, processor: Callable[[KeyValueArg], JSONType]) -> Callable[[], str]:\n    \"\"\"\n    We allow primitive values to be passed to forms via JSON key/value syntax.\n\n    But complex values lead to an error because theres no clear way to serialize them.\n\n    \"\"\"\n    if in_json_mode:\n        return processor\n\n    @functools.wraps(processor)\n    def wrapper(*args, **kwargs) -> str:\n        try:\n            output = processor(*args, **kwargs)\n        except ParseError:\n            output = None\n        if isinstance(output, (str, int, float)):\n            return str(output)\n        else:\n            raise ParseError('Cannot use complex JSON value types with --form/--multipart.')\n\n    return wrapper", "loc": 22}
{"file": "httpie\\httpie\\cli\\requestitems.py", "class_name": null, "function_name": "load_json", "parameters": ["arg", "contents"], "param_types": {"arg": "KeyValueArg", "contents": "str"}, "return_type": "JSONType", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParseError", "load_json_preserve_order_and_dupe_keys"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_json(arg: KeyValueArg, contents: str) -> JSONType:\n    try:\n        return load_json_preserve_order_and_dupe_keys(contents)\n    except ValueError as e:\n        raise ParseError(f'{arg.orig!r}: {e}')", "loc": 5}
{"file": "httpie\\httpie\\cli\\requestitems.py", "class_name": "RequestItems", "function_name": "from_args", "parameters": ["cls", "request_item_args", "request_type"], "param_types": {"request_item_args": "List[KeyValueArg]", "request_type": "Optional[RequestType]"}, "return_type": "'RequestItems'", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls", "convert_json_value_to_form_if_needed", "isinstance", "processor_func", "split_iterable", "target_dict.add", "target_dict.update"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def from_args(\n    cls,\n    request_item_args: List[KeyValueArg],\n    request_type: Optional[RequestType] = None,\n) -> 'RequestItems':\n    instance = cls(request_type=request_type)\n    rules: Dict[str, Tuple[Callable, dict]] = {\n        SEPARATOR_HEADER: (\n            process_header_arg,\n            instance.headers,\n        ),\n        SEPARATOR_HEADER_EMPTY: (\n            process_empty_header_arg,\n            instance.headers,\n        ),\n        SEPARATOR_HEADER_EMBED: (\n            process_embed_header_arg,\n            instance.headers,\n        ),\n        SEPARATOR_QUERY_PARAM: (\n            process_query_param_arg,\n            instance.params,\n        ),\n        SEPARATOR_QUERY_EMBED_FILE: (\n            process_embed_query_param_arg,\n            instance.params,\n        ),\n        SEPARATOR_FILE_UPLOAD: (\n            process_file_upload_arg,\n            instance.files,\n        ),\n        SEPARATOR_DATA_STRING: (\n            process_data_item_arg,\n            instance.data,\n        ),\n        SEPARATOR_DATA_EMBED_FILE_CONTENTS: (\n            process_data_embed_file_contents_arg,\n            instance.data,\n        ),\n        SEPARATOR_GROUP_NESTED_JSON_ITEMS: (\n            process_data_nested_json_embed_args,\n            instance.data,\n        ),\n        SEPARATOR_DATA_RAW_JSON: (\n            convert_json_value_to_form_if_needed(\n                in_json_mode=instance.is_json,\n                processor=process_data_raw_json_embed_arg\n            ),\n            instance.data,\n        ),\n        SEPARATOR_DATA_EMBED_RAW_JSON_FILE: (\n            convert_json_value_to_form_if_needed(\n                in_json_mode=instance.is_json,\n                processor=process_data_embed_raw_json_file_arg,\n            ),\n            instance.data,\n        ),\n    }\n\n    if instance.is_json:\n        json_item_args, request_item_args = split_iterable(\n            iterable=request_item_args,\n            key=lambda arg: arg.sep in SEPARATOR_GROUP_NESTED_JSON_ITEMS\n        )\n        if json_item_args:\n            pairs = [(arg.key, rules[arg.sep][0](arg)) for arg in json_item_args]\n            processor_func, target_dict = rules[SEPARATOR_GROUP_NESTED_JSON_ITEMS]\n            value = processor_func(pairs)\n            target_dict.update(value)\n\n    # Then handle all other items.\n    for arg in request_item_args:\n        processor_func, target_dict = rules[arg.sep]\n        value = processor_func(arg)\n\n        if arg.sep in SEPARATORS_GROUP_MULTIPART:\n            instance.multipart_data[arg.key] = value\n\n        if isinstance(target_dict, BaseMultiDict):\n            target_dict.add(arg.key, value)\n        else:\n            target_dict[arg.key] = value\n\n    return instance", "loc": 84}
{"file": "httpie\\httpie\\cli\\requestitems.py", "class_name": null, "function_name": "wrapper", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParseError", "functools.wraps", "isinstance", "processor", "str"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wrapper(*args, **kwargs) -> str:\n    try:\n        output = processor(*args, **kwargs)\n    except ParseError:\n        output = None\n    if isinstance(output, (str, int, float)):\n        return str(output)\n    else:\n        raise ParseError('Cannot use complex JSON value types with --form/--multipart.')", "loc": 9}
{"file": "httpie\\httpie\\cli\\utils.py", "class_name": "LazyChoices", "function_name": "load", "parameters": ["self"], "param_types": {}, "return_type": "T", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.getter"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load(self) -> T:\n    if self._obj is None or not self.cache:\n        self._obj = self.getter()\n\n    assert self._obj is not None\n    return self._obj", "loc": 6}
{"file": "httpie\\httpie\\cli\\utils.py", "class_name": "LazyChoices", "function_name": "help", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.help_formatter", "self.load"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def help(self) -> str:\n    if self._help is None and self.help_formatter is not None:\n        self._help = self.help_formatter(\n            self.load(),\n            isolation_mode=self.isolation_mode\n        )\n    return self._help", "loc": 7}
{"file": "httpie\\httpie\\cli\\nested_json\\interpret.py", "class_name": null, "function_name": "interpret_nested_json", "parameters": ["pairs"], "param_types": {"pairs": "Iterable[Tuple[str, str]]"}, "return_type": "dict", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["interpret", "wrap_with_dict"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def interpret_nested_json(pairs: Iterable[Tuple[str, str]]) -> dict:\n    context = None\n    for key, value in pairs:\n        context = interpret(context, key, value)\n    return wrap_with_dict(context)", "loc": 5}
{"file": "httpie\\httpie\\cli\\nested_json\\interpret.py", "class_name": null, "function_name": "interpret", "parameters": ["context", "key", "value"], "param_types": {"context": "Any", "key": "str", "value": "Any"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "JSON_TYPE_MAPPING.get", "NestedJSONSyntaxError", "Path", "Token", "assert_cant_happen", "cursor.append", "cursor.extend", "cursor.setdefault", "enumerate", "isinstance", "len", "list", "object_for", "parse", "path.kind.to_string", "path.reconstruct", "paths.append", "repr", "type", "type_check", "zip"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def interpret(context: Any, key: str, value: Any) -> Any:\n    cursor = context\n    paths = list(parse(key))\n    paths.append(Path(PathAction.SET, value))\n\n    # noinspection PyShadowingNames\n    def type_check(index: int, path: Path, expected_type: JSONType):\n        if not isinstance(cursor, expected_type):\n            if path.tokens:\n                pseudo_token = Token(\n                    kind=TokenKind.PSEUDO,\n                    value='',\n                    start=path.tokens[0].start,\n                    end=path.tokens[-1].end,\n                )\n            else:\n                pseudo_token = None\n            cursor_type = JSON_TYPE_MAPPING.get(type(cursor), type(cursor).__name__)\n            required_type = JSON_TYPE_MAPPING[expected_type]\n            message = f'Cannot perform {path.kind.to_string()!r} based access on '\n            message += repr(''.join(path.reconstruct() for path in paths[:index]))\n            message += f' which has a type of {cursor_type!r} but this operation'\n            message += f' requires a type of {required_type!r}.'\n            raise NestedJSONSyntaxError(\n                source=key,\n                token=pseudo_token,\n                message=message,\n                message_kind='Type',\n            )\n\n    def object_for(kind: PathAction) -> Any:\n        if kind is PathAction.KEY:\n            return {}\n        elif kind in {PathAction.INDEX, PathAction.APPEND}:\n            return []\n        else:\n            assert_cant_happen()\n\n    for index, (path, next_path) in enumerate(zip(paths, paths[1:])):\n        # If there is no context yet, set it.\n        if cursor is None:\n            context = cursor = object_for(path.kind)\n        if path.kind is PathAction.KEY:\n            type_check(index, path, dict)\n            if next_path.kind is PathAction.SET:\n                cursor[path.accessor] = next_path.accessor\n                break\n            cursor = cursor.setdefault(path.accessor, object_for(next_path.kind))\n        elif path.kind is PathAction.INDEX:\n            type_check(index, path, list)\n            if path.accessor < 0:\n                raise NestedJSONSyntaxError(\n                    source=key,\n                    token=path.tokens[1],\n                    message='Negative indexes are not supported.',\n                    message_kind='Value',\n                )\n            cursor.extend([None] * (path.accessor - len(cursor) + 1))\n            if next_path.kind is PathAction.SET:\n                cursor[path.accessor] = next_path.accessor\n                break\n            if cursor[path.accessor] is None:\n                cursor[path.accessor] = object_for(next_path.kind)\n            cursor = cursor[path.accessor]\n        elif path.kind is PathAction.APPEND:\n            type_check(index, path, list)\n            if next_path.kind is PathAction.SET:\n                cursor.append(next_path.accessor)\n                break\n            cursor.append(object_for(next_path.kind))\n            cursor = cursor[-1]\n        else:\n            assert_cant_happen()\n\n    return context", "loc": 75}
{"file": "httpie\\httpie\\cli\\nested_json\\interpret.py", "class_name": null, "function_name": "wrap_with_dict", "parameters": ["context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NestedJSONArray", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wrap_with_dict(context):\n    if context is None:\n        return {}\n    elif isinstance(context, list):\n        return {\n            EMPTY_STRING: NestedJSONArray(context),\n        }\n    else:\n        assert isinstance(context, dict)\n        return context", "loc": 10}
{"file": "httpie\\httpie\\cli\\nested_json\\interpret.py", "class_name": null, "function_name": "unwrap_top_level_list_if_needed", "parameters": ["data"], "param_types": {"data": "dict"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.items", "isinstance", "len", "list"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Propagate the top-level list, if thats what we got.", "source_code": "def unwrap_top_level_list_if_needed(data: dict):\n    \"\"\"\n    Propagate the top-level list, if thats what we got.\n\n    \"\"\"\n    if len(data) == 1:\n        key, value = list(data.items())[0]\n        if isinstance(value, NestedJSONArray):\n            assert key == EMPTY_STRING\n            return value\n    return data", "loc": 11}
{"file": "httpie\\httpie\\cli\\nested_json\\interpret.py", "class_name": null, "function_name": "type_check", "parameters": ["index", "path", "expected_type"], "param_types": {"index": "int", "path": "Path", "expected_type": "JSONType"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "JSON_TYPE_MAPPING.get", "NestedJSONSyntaxError", "Token", "isinstance", "path.kind.to_string", "path.reconstruct", "repr", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def type_check(index: int, path: Path, expected_type: JSONType):\n    if not isinstance(cursor, expected_type):\n        if path.tokens:\n            pseudo_token = Token(\n                kind=TokenKind.PSEUDO,\n                value='',\n                start=path.tokens[0].start,\n                end=path.tokens[-1].end,\n            )\n        else:\n            pseudo_token = None\n        cursor_type = JSON_TYPE_MAPPING.get(type(cursor), type(cursor).__name__)\n        required_type = JSON_TYPE_MAPPING[expected_type]\n        message = f'Cannot perform {path.kind.to_string()!r} based access on '\n        message += repr(''.join(path.reconstruct() for path in paths[:index]))\n        message += f' which has a type of {cursor_type!r} but this operation'\n        message += f' requires a type of {required_type!r}.'\n        raise NestedJSONSyntaxError(\n            source=key,\n            token=pseudo_token,\n            message=message,\n            message_kind='Type',\n        )", "loc": 23}
{"file": "httpie\\httpie\\cli\\nested_json\\interpret.py", "class_name": null, "function_name": "object_for", "parameters": ["kind"], "param_types": {"kind": "PathAction"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["assert_cant_happen"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def object_for(kind: PathAction) -> Any:\n    if kind is PathAction.KEY:\n        return {}\n    elif kind in {PathAction.INDEX, PathAction.APPEND}:\n        return []\n    else:\n        assert_cant_happen()", "loc": 7}
{"file": "httpie\\httpie\\cli\\nested_json\\parse.py", "class_name": null, "function_name": "tokenize", "parameters": ["source"], "param_types": {"source": "str"}, "return_type": "Iterator[Token]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "Token", "buffer.append", "buffer.clear", "can_advance", "len", "send_buffer", "variation"], "control_structures": ["For", "If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def tokenize(source: str) -> Iterator[Token]:\n    cursor = 0\n    backslashes = 0\n    buffer = []\n\n    def send_buffer() -> Iterator[Token]:\n        nonlocal backslashes\n        if not buffer:\n            return None\n\n        value = ''.join(buffer)\n        kind = TokenKind.TEXT\n        if not backslashes:\n            for variation, kind in [\n                (int, TokenKind.NUMBER),\n                (check_escaped_int, TokenKind.TEXT),\n            ]:\n                try:\n                    value = variation(value)\n                except ValueError:\n                    continue\n                else:\n                    break\n        yield Token(\n            kind=kind,\n            value=value,\n            start=cursor - (len(buffer) + backslashes),\n            end=cursor,\n        )\n        buffer.clear()\n        backslashes = 0\n\n    def can_advance() -> bool:\n        return cursor < len(source)\n\n    while can_advance():\n        index = source[cursor]\n        if index in OPERATORS:\n            yield from send_buffer()\n            yield Token(OPERATORS[index], index, cursor, cursor + 1)\n        elif index == BACKSLASH and can_advance():\n            if source[cursor + 1] in SPECIAL_CHARS:\n                backslashes += 1\n            else:\n                buffer.append(index)\n            buffer.append(source[cursor + 1])\n            cursor += 1\n        else:\n            buffer.append(index)\n        cursor += 1\n\n    yield from send_buffer()", "loc": 52}
{"file": "httpie\\httpie\\cli\\nested_json\\parse.py", "class_name": null, "function_name": "check_escaped_int", "parameters": ["value"], "param_types": {"value": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "int", "value.startswith"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_escaped_int(value: str) -> str:\n    if not value.startswith(BACKSLASH):\n        raise ValueError('Not an escaped int')\n    try:\n        int(value[1:])\n    except ValueError as exc:\n        raise ValueError('Not an escaped int') from exc\n    else:\n        return value[1:]", "loc": 9}
{"file": "httpie\\httpie\\cli\\nested_json\\parse.py", "class_name": null, "function_name": "expect", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "NestedJSONSyntaxError", "can_advance", "kind.to_name", "kinds[-1].to_name", "kinds[0].to_name", "len", "tokens[-1]._replace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def expect(*kinds):\n    nonlocal cursor\n    assert kinds\n    if can_advance():\n        token = tokens[cursor]\n        cursor += 1\n        if token.kind in kinds:\n            return token\n    elif tokens:\n        token = tokens[-1]._replace(\n            start=tokens[-1].end + 0,\n            end=tokens[-1].end + 1,\n        )\n    else:\n        token = None\n    if len(kinds) == 1:\n        suffix = kinds[0].to_name()\n    else:\n        suffix = ', '.join(kind.to_name() for kind in kinds[:-1])\n        suffix += ' or ' + kinds[-1].to_name()\n    message = f'Expecting {suffix}'\n    raise NestedJSONSyntaxError(source, token, message)", "loc": 22}
{"file": "httpie\\httpie\\cli\\nested_json\\parse.py", "class_name": null, "function_name": "parse_root", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "assert_cant_happen", "can_advance", "expect", "str", "tokens.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_root():\n    tokens = []\n    if not can_advance():\n        return Path(\n            kind=PathAction.KEY,\n            accessor=EMPTY_STRING,\n            is_root=True\n        )\n    # (literal | index_path | append_path)?\n    token = expect(*LITERAL_TOKENS, TokenKind.LEFT_BRACKET)\n    tokens.append(token)\n    if token.kind in LITERAL_TOKENS:\n        action = PathAction.KEY\n        value = str(token.value)\n    elif token.kind is TokenKind.LEFT_BRACKET:\n        token = expect(TokenKind.NUMBER, TokenKind.RIGHT_BRACKET)\n        tokens.append(token)\n        if token.kind is TokenKind.NUMBER:\n            action = PathAction.INDEX\n            value = token.value\n            tokens.append(expect(TokenKind.RIGHT_BRACKET))\n        elif token.kind is TokenKind.RIGHT_BRACKET:\n            action = PathAction.APPEND\n            value = None\n        else:\n            assert_cant_happen()\n    else:\n        assert_cant_happen()\n    # noinspection PyUnboundLocalVariable\n    return Path(\n        kind=action,\n        accessor=value,\n        tokens=tokens,\n        is_root=True\n    )", "loc": 35}
{"file": "httpie\\httpie\\cli\\nested_json\\parse.py", "class_name": null, "function_name": "send_buffer", "parameters": [], "param_types": {}, "return_type": "Iterator[Token]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "Token", "buffer.clear", "len", "variation"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def send_buffer() -> Iterator[Token]:\n    nonlocal backslashes\n    if not buffer:\n        return None\n\n    value = ''.join(buffer)\n    kind = TokenKind.TEXT\n    if not backslashes:\n        for variation, kind in [\n            (int, TokenKind.NUMBER),\n            (check_escaped_int, TokenKind.TEXT),\n        ]:\n            try:\n                value = variation(value)\n            except ValueError:\n                continue\n            else:\n                break\n    yield Token(\n        kind=kind,\n        value=value,\n        start=cursor - (len(buffer) + backslashes),\n        end=cursor,\n    )\n    buffer.clear()\n    backslashes = 0", "loc": 26}
{"file": "httpie\\httpie\\cli\\nested_json\\tokens.py", "class_name": "TokenKind", "function_name": "to_name", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["OPERATORS.items", "repr", "self.name.lower"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def to_name(self) -> str:\n    for key, value in OPERATORS.items():\n        if value is self:\n            return repr(key)\n    else:\n        return 'a ' + self.name.lower()", "loc": 6}
{"file": "httpie\\httpie\\cli\\nested_json\\tokens.py", "class_name": "Path", "function_name": "reconstruct", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def reconstruct(self) -> str:\n    if self.kind is PathAction.KEY:\n        if self.is_root:\n            return str(self.accessor)\n        return OPEN_BRACKET + self.accessor + CLOSE_BRACKET\n    elif self.kind is PathAction.INDEX:\n        return OPEN_BRACKET + str(self.accessor) + CLOSE_BRACKET\n    elif self.kind is PathAction.APPEND:\n        return OPEN_BRACKET + CLOSE_BRACKET", "loc": 9}
{"file": "httpie\\httpie\\internal\\daemon_runner.py", "class_name": null, "function_name": "run_daemon_task", "parameters": ["env", "args"], "param_types": {"env": "Environment", "args": "List[str]"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_get_suppress_context", "_parse_options", "redirect_stderr", "redirect_stdout"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run_daemon_task(env: Environment, args: List[str]) -> ExitStatus:\n    options = _parse_options(args)\n\n    assert options.daemon\n    assert options.task_id in DAEMONIZED_TASKS\n    with redirect_stdout(env.devnull), redirect_stderr(env.devnull):\n        with _get_suppress_context(env):\n            DAEMONIZED_TASKS[options.task_id](env)\n\n    return ExitStatus.SUCCESS", "loc": 10}
{"file": "httpie\\httpie\\internal\\update_warnings.py", "class_name": null, "function_name": "fetch_updates", "parameters": ["env", "lazy"], "param_types": {"env": "Environment", "lazy": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_fetch_updates", "spawn_daemon"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fetch_updates(env: Environment, lazy: bool = True):\n    if lazy:\n        spawn_daemon('fetch_updates')\n    else:\n        _fetch_updates(env)", "loc": 5}
{"file": "httpie\\httpie\\internal\\update_warnings.py", "class_name": null, "function_name": "maybe_fetch_updates", "parameters": ["env"], "param_types": {"env": "Environment"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_read_data_error_free", "datetime.fromisoformat", "datetime.now", "env.config.get", "fetch_updates"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def maybe_fetch_updates(env: Environment) -> None:\n    if env.config.get('disable_update_warnings'):\n        return None\n\n    data = _read_data_error_free(env.config.version_info_file)\n\n    if data:\n        current_date = datetime.now()\n        last_fetched_date = datetime.fromisoformat(data['last_fetched_date'])\n        earliest_fetch_date = last_fetched_date + FETCH_INTERVAL\n        if current_date < earliest_fetch_date:\n            return None\n\n    fetch_updates(env)", "loc": 14}
{"file": "httpie\\httpie\\internal\\update_warnings.py", "class_name": null, "function_name": "check_updates", "parameters": ["env"], "param_types": {"env": "Environment"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_get_update_status", "current_date.isoformat", "datetime.fromisoformat", "datetime.now", "env.config.get", "env.log_error", "json.dump", "json.load", "open_with_lockfile"], "control_structures": ["If"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def check_updates(env: Environment) -> None:\n    if env.config.get('disable_update_warnings'):\n        return None\n\n    file = env.config.version_info_file\n    update_status = _get_update_status(env)\n\n    if not update_status:\n        return None\n\n    # If the user quickly spawns multiple httpie processes\n    # we don't want to end in a race.\n    with open_with_lockfile(file) as stream:\n        version_info = json.load(stream)\n\n    # We don't want to spam the user with too many warnings,\n    # so we'll only warn every once a while (WARN_INTERNAL).\n    current_date = datetime.now()\n    last_warned_date = version_info['last_warned_date']\n    if last_warned_date is not None:\n        earliest_warn_date = (\n            datetime.fromisoformat(last_warned_date) + WARN_INTERVAL\n        )\n        if current_date < earliest_warn_date:\n            return None\n\n    env.log_error(update_status, level=LogLevel.INFO)\n    version_info['last_warned_date'] = current_date.isoformat()\n\n    with open_with_lockfile(file, 'w') as stream:\n        json.dump(version_info, stream)", "loc": 31}
{"file": "httpie\\httpie\\internal\\update_warnings.py", "class_name": null, "function_name": "wrapper", "parameters": ["env"], "param_types": {"env": "Environment"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_get_suppress_context", "func", "maybe_fetch_updates"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wrapper(env: Environment) -> None:\n    with _get_suppress_context(env):\n        func(env)\n\n    with _get_suppress_context(env):\n        maybe_fetch_updates(env)", "loc": 6}
{"file": "httpie\\httpie\\legacy\\v3_1_0_session_cookie_format.py", "class_name": null, "function_name": "pre_process", "parameters": ["session", "cookies"], "param_types": {"session": "'Session'", "cookies": "Any"}, "return_type": "List[Dict[str, Any]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["INSECURE_COOKIE_JAR_WARNING.format", "any", "cookie.get", "cookies.items", "isinstance", "session.warn_legacy_usage"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Load the given cookies to the cookie jar while maintaining support for the old cookie layout.", "source_code": "def pre_process(session: 'Session', cookies: Any) -> List[Dict[str, Any]]:\n    \"\"\"Load the given cookies to the cookie jar while maintaining\n    support for the old cookie layout.\"\"\"\n\n    is_old_style = isinstance(cookies, dict)\n    if is_old_style:\n        normalized_cookies = [\n            {\n                'name': key,\n                **value\n            }\n            for key, value in cookies.items()\n        ]\n    else:\n        normalized_cookies = cookies\n\n    should_issue_warning = is_old_style and any(\n        cookie.get('domain', '') == ''\n        for cookie in normalized_cookies\n    )\n\n    if should_issue_warning:\n        warning = INSECURE_COOKIE_JAR_WARNING.format(hostname=session.bound_host, session_id=session.session_id)\n        if not session.is_anonymous:\n            warning += INSECURE_COOKIE_JAR_WARNING_FOR_NAMED_SESSIONS\n        warning += INSECURE_COOKIE_SECURITY_LINK\n        session.warn_legacy_usage(warning)\n\n    return normalized_cookies", "loc": 29}
{"file": "httpie\\httpie\\legacy\\v3_1_0_session_cookie_format.py", "class_name": null, "function_name": "post_process", "parameters": ["normalized_cookies"], "param_types": {"normalized_cookies": "List[Dict[str, Any]]"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cookie.pop", "issubclass"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convert the cookies to their original format for maximum compatibility.", "source_code": "def post_process(\n    normalized_cookies: List[Dict[str, Any]],\n    *,\n    original_type: Type[Any]\n) -> Any:\n    \"\"\"Convert the cookies to their original format for\n    maximum compatibility.\"\"\"\n\n    if issubclass(original_type, dict):\n        return {\n            cookie.pop('name'): cookie\n            for cookie in normalized_cookies\n        }\n    else:\n        return normalized_cookies", "loc": 15}
{"file": "httpie\\httpie\\legacy\\v3_1_0_session_cookie_format.py", "class_name": null, "function_name": "fix_layout", "parameters": ["session", "hostname", "args"], "param_types": {"session": "'Session'", "hostname": "str", "args": "argparse.Namespace"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "session['cookies'].items"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fix_layout(session: 'Session', hostname: str, args: argparse.Namespace) -> None:\n    if not isinstance(session['cookies'], dict):\n        return None\n\n    session['cookies'] = [\n        {\n            'name': key,\n            **value\n        }\n        for key, value in session['cookies'].items()\n    ]\n    for cookie in session.cookies:\n        if cookie.domain == '':\n            if args.bind_cookies:\n                cookie.domain = hostname\n            else:\n                cookie._rest['is_explicit_none'] = True", "loc": 17}
{"file": "httpie\\httpie\\legacy\\v3_2_0_session_header_format.py", "class_name": null, "function_name": "pre_process", "parameters": ["session", "headers"], "param_types": {"session": "'Session'", "headers": "Any"}, "return_type": "List[Dict[str, Any]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["OLD_HEADER_STORE_WARNING.format", "headers.items", "isinstance", "list", "session.warn_legacy_usage"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Serialize the headers into a unified form and issue a warning if the session file is using the old layout.", "source_code": "def pre_process(session: 'Session', headers: Any) -> List[Dict[str, Any]]:\n    \"\"\"Serialize the headers into a unified form and issue a warning if\n    the session file is using the old layout.\"\"\"\n\n    is_old_style = isinstance(headers, dict)\n    if is_old_style:\n        normalized_headers = list(headers.items())\n    else:\n        normalized_headers = [\n            (item['name'], item['value'])\n            for item in headers\n        ]\n\n    if is_old_style:\n        warning = OLD_HEADER_STORE_WARNING.format(hostname=session.bound_host, session_id=session.session_id)\n        if not session.is_anonymous:\n            warning += OLD_HEADER_STORE_WARNING_FOR_NAMED_SESSIONS\n        warning += OLD_HEADER_STORE_LINK\n        session.warn_legacy_usage(warning)\n\n    return normalized_headers", "loc": 21}
{"file": "httpie\\httpie\\legacy\\v3_2_0_session_header_format.py", "class_name": null, "function_name": "post_process", "parameters": ["normalized_headers"], "param_types": {"normalized_headers": "List[Dict[str, Any]]"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["issubclass"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Deserialize given header store into the original form it was used in.", "source_code": "def post_process(\n    normalized_headers: List[Dict[str, Any]],\n    *,\n    original_type: Type[Any]\n) -> Any:\n    \"\"\"Deserialize given header store into the original form it was\n    used in.\"\"\"\n\n    if issubclass(original_type, dict):\n        # For the legacy behavior, preserve the last value.\n        return {\n            item['name']: item['value']\n            for item in normalized_headers\n        }\n    else:\n        return normalized_headers", "loc": 16}
{"file": "httpie\\httpie\\legacy\\v3_2_0_session_header_format.py", "class_name": null, "function_name": "fix_layout", "parameters": ["session"], "param_types": {"session": "'Session'"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "materialize_headers"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fix_layout(session: 'Session', *args, **kwargs) -> None:\n    from httpie.sessions import materialize_headers\n\n    if not isinstance(session['headers'], dict):\n        return None\n\n    session['headers'] = materialize_headers(session['headers'])", "loc": 7}
{"file": "httpie\\httpie\\manager\\cli.py", "class_name": null, "function_name": "missing_subcommand", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "base.keys", "isinstance", "map"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def missing_subcommand(*args) -> str:\n    base = COMMANDS\n    for arg in args:\n        base = base[arg]\n\n    assert isinstance(base, dict)\n    subcommands = ', '.join(map(repr, base.keys()))\n    return f'Please specify one of these: {subcommands}'", "loc": 8}
{"file": "httpie\\httpie\\manager\\cli.py", "class_name": null, "function_name": "generate_subparsers", "parameters": ["root", "parent_parser", "definitions", "spec"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'_'.join", "actions.add_parser", "argument.copy", "argument.pop", "command_parser.add_argument", "definitions.items", "generate_subparsers", "group.add_argument", "isinstance", "map_qualifiers", "parent_parser.add_subparsers", "parent_parser.prog.split", "properties.copy", "properties.pop", "spec.add_group"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def generate_subparsers(root, parent_parser, definitions, spec):\n    action_dest = '_'.join(parent_parser.prog.split()[1:] + ['action'])\n    actions = parent_parser.add_subparsers(\n        dest=action_dest\n    )\n    for command, properties in definitions.items():\n        is_subparser = isinstance(properties, dict)\n        properties = properties.copy()\n\n        descr = properties.pop('help', None) if is_subparser else properties.pop(0)\n        command_parser = actions.add_parser(command, description=descr)\n        command_parser.root = root\n        if is_subparser:\n            generate_subparsers(root, command_parser, properties, spec)\n            continue\n\n        group = spec.add_group(parent_parser.prog + ' ' + command, description=descr)\n        for argument in properties:\n            argument = argument.copy()\n            flags = argument.pop('flags', [])\n            command_parser.add_argument(*flags, **map_qualifiers(argument, ARGPARSE_QUALIFIER_MAP))\n            group.add_argument(*flags, **argument)", "loc": 22}
{"file": "httpie\\httpie\\manager\\compat.py", "class_name": null, "function_name": "run_pip", "parameters": ["args"], "param_types": {"args": "List[str]"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_discover_system_pip", "_run_pip_subprocess"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run_pip(args: List[str]) -> bytes:\n    if is_frozen:\n        pip_executable = [_discover_system_pip()]\n    else:\n        pip_executable = [sys.executable, '-m', 'pip']\n\n    return _run_pip_subprocess(pip_executable, args)", "loc": 7}
{"file": "httpie\\httpie\\manager\\core.py", "class_name": null, "function_name": "dispatch_cli_task", "parameters": ["env", "action", "args"], "param_types": {"env": "Environment", "action": "Optional[str]", "args": "argparse.Namespace"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["missing_subcommand", "parser.error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dispatch_cli_task(env: Environment, action: Optional[str], args: argparse.Namespace) -> ExitStatus:\n    if action is None:\n        parser.error(missing_subcommand('cli'))\n\n    return CLI_TASKS[action](env, args)", "loc": 5}
{"file": "httpie\\httpie\\manager\\core.py", "class_name": null, "function_name": "program", "parameters": ["args", "env"], "param_types": {"args": "argparse.Namespace", "env": "Environment"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dispatch_cli_task", "parser.error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def program(args: argparse.Namespace, env: Environment) -> ExitStatus:\n    if args.action is None:\n        parser.error(MSG_NAKED_INVOCATION)\n\n    if args.action == 'plugins':\n        return dispatch_cli_task(env, args.action, args)\n    elif args.action == 'cli':\n        return dispatch_cli_task(env, args.cli_action, args)\n\n    return ExitStatus.SUCCESS", "loc": 10}
{"file": "httpie\\httpie\\manager\\__main__.py", "class_name": null, "function_name": "program", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["main"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def program():\n    try:\n        exit_status = main()\n    except KeyboardInterrupt:\n        exit_status = ExitStatus.ERROR_CTRL_C\n\n    return exit_status", "loc": 7}
{"file": "httpie\\httpie\\manager\\tasks\\export_args.py", "class_name": null, "function_name": "cli_export_args", "parameters": ["env", "args"], "param_types": {"env": "Environment", "args": "argparse.Namespace"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "json.dumps", "to_data", "write_raw_data"], "control_structures": ["If"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def cli_export_args(env: Environment, args: argparse.Namespace) -> ExitStatus:\n    if args.format == 'json':\n        data = json.dumps(to_data(options))\n    else:\n        raise NotImplementedError(f'Unexpected format value: {args.format}')\n\n    write_raw_data(\n        env,\n        data,\n        stream_kwargs={'mime_overwrite': FORMAT_TO_CONTENT_TYPE[args.format]},\n    )\n    return ExitStatus.SUCCESS", "loc": 12}
{"file": "httpie\\httpie\\manager\\tasks\\plugins.py", "class_name": null, "function_name": "cli_plugins", "parameters": ["env", "args"], "param_types": {"env": "Environment", "args": "argparse.Namespace"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PluginInstaller", "plugins.run"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cli_plugins(env: Environment, args: argparse.Namespace) -> ExitStatus:\n    plugins = PluginInstaller(env, debug=args.debug)\n\n    try:\n        action = args.cli_plugins_action\n    except AttributeError:\n        action = args.plugins_action\n\n    return plugins.run(action, args)", "loc": 9}
{"file": "httpie\\httpie\\manager\\tasks\\plugins.py", "class_name": "PluginInstaller", "function_name": "setup_plugins_dir", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.dir.mkdir", "self.env.stderr.write"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def setup_plugins_dir(self) -> None:\n    try:\n        self.dir.mkdir(\n            exist_ok=True,\n            parents=True\n        )\n    except OSError:\n        self.env.stderr.write(\n            f'Couldn\\'t create \"{self.dir!s}\"'\n            ' directory for plugin installation.'\n            ' Please re-check the permissions for that directory,'\n            ' and if needed, allow write-access.'\n        )\n        raise", "loc": 14}
{"file": "httpie\\httpie\\manager\\tasks\\plugins.py", "class_name": "PluginInstaller", "function_name": "fail", "parameters": ["self", "command", "target", "reason"], "param_types": {"command": "str", "target": "Optional[str]", "reason": "Optional[str]"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.env.stderr.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fail(\n    self,\n    command: str,\n    target: Optional[str] = None,\n    reason: Optional[str] = None\n) -> ExitStatus:\n    message = f'Can\\'t {command}'\n    if target:\n        message += f' {target!r}'\n    if reason:\n        message += f': {reason}'\n\n    self.env.stderr.write(message + '\\n')\n    return ExitStatus.ERROR", "loc": 14}
{"file": "httpie\\httpie\\manager\\tasks\\plugins.py", "class_name": "PluginInstaller", "function_name": "install", "parameters": ["self", "targets"], "param_types": {"targets": "List[str]"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "self._install", "self.env.stdout.flush", "self.env.stdout.write"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def install(self, targets: List[str]) -> ExitStatus:\n    self.env.stdout.write(f\"Installing {', '.join(targets)}...\\n\")\n    self.env.stdout.flush()\n    _, exit_status = self._install(targets)\n    return exit_status", "loc": 5}
{"file": "httpie\\httpie\\manager\\tasks\\plugins.py", "class_name": "PluginInstaller", "function_name": "upgrade", "parameters": ["self", "targets"], "param_types": {"targets": "List[str]"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "installation_line.split", "installation_line.startswith", "raw_stdout.decode", "self._clear_metadata", "self._install", "self.env.stdout.flush", "self.env.stdout.write", "stdout.splitlines"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def upgrade(self, targets: List[str]) -> ExitStatus:\n    self.env.stdout.write(f\"Upgrading {', '.join(targets)}...\\n\")\n    self.env.stdout.flush()\n\n    raw_stdout, exit_status = self._install(\n        targets,\n        mode='upgrade'\n    )\n    if not raw_stdout:\n        return exit_status\n\n    stdout = raw_stdout.decode()\n    installation_line = stdout.splitlines()[-1]\n    if installation_line.startswith('Successfully installed'):\n        self._clear_metadata(installation_line.split()[2:])", "loc": 15}
{"file": "httpie\\httpie\\manager\\tasks\\plugins.py", "class_name": "PluginInstaller", "function_name": "uninstall", "parameters": ["self", "targets"], "param_types": {"targets": "List[str]"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ExitStatus", "self._uninstall"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def uninstall(self, targets: List[str]) -> ExitStatus:\n    # Unfortunately uninstall doesn't work with custom pip schemes. See:\n    # - https://github.com/pypa/pip/issues/5595\n    # - https://github.com/pypa/pip/issues/4575\n    # so we have to implement our own uninstalling logic. Which works\n    # on top of the importlib_metadata.\n\n    exit_code = ExitStatus.SUCCESS\n    for target in targets:\n        exit_code |= self._uninstall(target) or ExitStatus.SUCCESS\n    return ExitStatus(exit_code)", "loc": 11}
{"file": "httpie\\httpie\\manager\\tasks\\plugins.py", "class_name": "PluginInstaller", "function_name": "list", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["defaultdict", "get_dist_name", "importlib_metadata.version", "known_plugins.items", "known_plugins[ep_name].append", "plugin_manager.iter_entry_points", "self.env.stdout.write", "sorted"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def list(self) -> None:\n    from httpie.plugins.registry import plugin_manager\n\n    known_plugins = defaultdict(list)\n\n    for entry_point in plugin_manager.iter_entry_points(self.dir):\n        ep_info = (entry_point.group, entry_point.name)\n        ep_name = get_dist_name(entry_point) or entry_point.module\n        known_plugins[ep_name].append(ep_info)\n\n    for plugin, entry_points in known_plugins.items():\n        self.env.stdout.write(plugin)\n\n        version = importlib_metadata.version(plugin)\n        if version is not None:\n            self.env.stdout.write(f' ({version})')\n        self.env.stdout.write('\\n')\n\n        for group, entry_point in sorted(entry_points):\n            self.env.stdout.write(f'  {entry_point} ({group})\\n')", "loc": 20}
{"file": "httpie\\httpie\\manager\\tasks\\plugins.py", "class_name": "PluginInstaller", "function_name": "run", "parameters": ["self", "action", "args"], "param_types": {"action": "Optional[str]", "args": "argparse.Namespace"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enable_plugins", "missing_subcommand", "parser.error", "self.install", "self.list", "self.uninstall", "self.upgrade"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run(\n    self,\n    action: Optional[str],\n    args: argparse.Namespace,\n) -> ExitStatus:\n    from httpie.plugins.manager import enable_plugins\n\n    if action is None:\n        parser.error(missing_subcommand('plugins'))\n\n    with enable_plugins(self.dir):\n        if action == 'install':\n            status = self.install(args.targets)\n        elif action == 'upgrade':\n            status = self.upgrade(args.targets)\n        elif action == 'uninstall':\n            status = self.uninstall(args.targets)\n        elif action == 'list':\n            status = self.list()\n\n    return status or ExitStatus.SUCCESS", "loc": 21}
{"file": "httpie\\httpie\\manager\\tasks\\sessions.py", "class_name": null, "function_name": "cli_sessions", "parameters": ["env", "args"], "param_types": {"env": "Environment", "args": "argparse.Namespace"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "cli_upgrade_all_sessions", "cli_upgrade_session", "missing_subcommand", "parser.error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cli_sessions(env: Environment, args: argparse.Namespace) -> ExitStatus:\n    action = args.cli_sessions_action\n    if action is None:\n        parser.error(missing_subcommand('cli', 'sessions'))\n\n    if action == 'upgrade':\n        return cli_upgrade_session(env, args)\n    elif action == 'upgrade-all':\n        return cli_upgrade_all_sessions(env, args)\n    else:\n        raise ValueError(f'Unexpected action: {action}')", "loc": 11}
{"file": "httpie\\httpie\\manager\\tasks\\sessions.py", "class_name": null, "function_name": "cli_upgrade_all_sessions", "parameters": ["env", "args"], "param_types": {"env": "Environment", "args": "argparse.Namespace"}, "return_type": "ExitStatus", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["host_path.glob", "session_dir_path.iterdir", "upgrade_session"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cli_upgrade_all_sessions(env: Environment, args: argparse.Namespace) -> ExitStatus:\n    session_dir_path = env.config_dir / SESSIONS_DIR_NAME\n\n    status = ExitStatus.SUCCESS\n    for host_path in session_dir_path.iterdir():\n        hostname = host_path.name\n        for session_path in host_path.glob(\"*.json\"):\n            session_name = session_path.stem\n            status |= upgrade_session(\n                env,\n                args=args,\n                hostname=hostname,\n                session_name=session_name\n            )\n    return status", "loc": 15}
{"file": "httpie\\httpie\\output\\models.py", "class_name": "ProcessingOptions", "function_name": "get_prettify", "parameters": ["self", "env"], "param_types": {"env": "Environment"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_prettify(self, env: Environment) -> List[str]:\n    if self.prettify is PRETTY_STDOUT_TTY_ONLY:\n        return PRETTY_MAP['all' if env.stdout_isatty else 'none']\n    else:\n        return self.prettify", "loc": 5}
{"file": "httpie\\httpie\\output\\models.py", "class_name": "ProcessingOptions", "function_name": "from_raw_args", "parameters": ["cls", "options"], "param_types": {"options": "argparse.Namespace"}, "return_type": "'ProcessingOptions'", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls", "getattr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def from_raw_args(cls, options: argparse.Namespace) -> 'ProcessingOptions':\n    fetched_options = {\n        option: getattr(options, option)\n        for option in cls._fields\n    }\n    return cls(**fetched_options)", "loc": 6}
{"file": "httpie\\httpie\\output\\processing.py", "class_name": "Conversion", "function_name": "get_converter", "parameters": ["mime"], "param_types": {"mime": "str"}, "return_type": "Optional[ConverterPlugin]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["converter_class", "converter_class.supports", "is_valid_mime", "plugin_manager.get_converters"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_converter(mime: str) -> Optional[ConverterPlugin]:\n    if is_valid_mime(mime):\n        for converter_class in plugin_manager.get_converters():\n            if converter_class.supports(mime):\n                return converter_class(mime)", "loc": 5}
{"file": "httpie\\httpie\\output\\processing.py", "class_name": "Formatting", "function_name": "format_body", "parameters": ["self", "content", "mime"], "param_types": {"content": "str", "mime": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_valid_mime", "p.format_body"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_body(self, content: str, mime: str) -> str:\n    if is_valid_mime(mime):\n        for p in self.enabled_plugins:\n            content = p.format_body(content, mime)\n    return content", "loc": 5}
{"file": "httpie\\httpie\\output\\streams.py", "class_name": "EncodedStream", "function_name": "iter_body", "parameters": ["self"], "param_types": {}, "return_type": "Iterable[bytes]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BinarySuppressedError", "self.decode_chunk", "self.msg.iter_lines", "smart_encode"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def iter_body(self) -> Iterable[bytes]:\n    for line, lf in self.msg.iter_lines(self.CHUNK_SIZE):\n        if b'\\0' in line:\n            raise BinarySuppressedError()\n        line = self.decode_chunk(line)\n        yield smart_encode(line, self.output_encoding) + lf", "loc": 6}
{"file": "httpie\\httpie\\output\\streams.py", "class_name": "EncodedStream", "function_name": "encoding", "parameters": ["self"], "param_types": {}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def encoding(self) -> Optional[str]:\n    if self._encoding:\n        return self._encoding\n\n    # If we find a reliable (used consecutively) encoding, than\n    # use it for the next iterations.\n    if len(self._encoding_guesses) < ENCODING_GUESS_THRESHOLD:\n        return None\n\n    guess_1, guess_2 = self._encoding_guesses[-2:]\n    if guess_1 == guess_2:\n        self._encoding = guess_1\n        return guess_1", "loc": 13}
{"file": "httpie\\httpie\\output\\streams.py", "class_name": "PrettyStream", "function_name": "iter_body", "parameters": ["self"], "param_types": {}, "return_type": "Iterable[bytes]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BinarySuppressedError", "body.extend", "bytearray", "chain", "converter.convert", "isinstance", "self.conversion.get_converter", "self.msg.iter_lines", "self.process_body"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def iter_body(self) -> Iterable[bytes]:\n    first_chunk = True\n    iter_lines = self.msg.iter_lines(self.CHUNK_SIZE)\n    for line, lf in iter_lines:\n        if b'\\0' in line:\n            if first_chunk:\n                converter = self.conversion.get_converter(self.mime)\n                if converter:\n                    body = bytearray()\n                    # noinspection PyAssignmentToLoopOrWithParameter\n                    for line, lf in chain([(line, lf)], iter_lines):\n                        body.extend(line)\n                        body.extend(lf)\n                    self.mime, body = converter.convert(body)\n                    assert isinstance(body, str)\n                    yield self.process_body(body)\n                    return\n            raise BinarySuppressedError()\n        yield self.process_body(line) + lf\n        first_chunk = False", "loc": 20}
{"file": "httpie\\httpie\\output\\streams.py", "class_name": "PrettyStream", "function_name": "process_body", "parameters": ["self", "chunk"], "param_types": {"chunk": "Union[str, bytes]"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self.decode_chunk", "self.formatting.format_body", "smart_encode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_body(self, chunk: Union[str, bytes]) -> bytes:\n    if not isinstance(chunk, str):\n        # Text when a converter has been used,\n        # otherwise it will always be bytes.\n        chunk = self.decode_chunk(chunk)\n    chunk = self.formatting.format_body(content=chunk, mime=self.mime)\n    return smart_encode(chunk, self.output_encoding)", "loc": 7}
{"file": "httpie\\httpie\\output\\streams.py", "class_name": "BufferedPrettyStream", "function_name": "iter_body", "parameters": ["self"], "param_types": {}, "return_type": "Iterable[bytes]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BinarySuppressedError", "body.extend", "bytearray", "converter.convert", "self.conversion.get_converter", "self.msg.iter_body", "self.process_body"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def iter_body(self) -> Iterable[bytes]:\n    # Read the whole body before prettifying it,\n    # but bail out immediately if the body is binary.\n    converter = None\n    body = bytearray()\n\n    for chunk in self.msg.iter_body(self.CHUNK_SIZE):\n        if not converter and b'\\0' in chunk:\n            converter = self.conversion.get_converter(self.mime)\n            if not converter:\n                raise BinarySuppressedError()\n        body.extend(chunk)\n\n    if converter:\n        self.mime, body = converter.convert(body)\n\n    yield self.process_body(body)", "loc": 17}
{"file": "httpie\\httpie\\output\\utils.py", "class_name": null, "function_name": "load_prefixed_json", "parameters": ["data"], "param_types": {"data": "str"}, "return_type": "Tuple[str, json.JSONDecoder]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "load_json_preserve_order_and_dupe_keys", "parse_prefixed_json"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Simple JSON loading from `data`.", "source_code": "def load_prefixed_json(data: str) -> Tuple[str, json.JSONDecoder]:\n    \"\"\"Simple JSON loading from `data`.\n\n    \"\"\"\n    # First, the full data.\n    try:\n        return '', load_json_preserve_order_and_dupe_keys(data)\n    except ValueError:\n        pass\n\n    # Then, try to find the start of the actual body.\n    data_prefix, body = parse_prefixed_json(data)\n    try:\n        return data_prefix, load_json_preserve_order_and_dupe_keys(body)\n    except ValueError:\n        raise ValueError('Invalid JSON')", "loc": 16}
{"file": "httpie\\httpie\\output\\utils.py", "class_name": null, "function_name": "parse_prefixed_json", "parameters": ["data"], "param_types": {"data": "str"}, "return_type": "Tuple[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "re.findall"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Find the potential JSON body from `data`. Sometimes the JSON body is prefixed with a XSSI magic string, specific to the server. Return a tuple (data prefix, actual JSON body).", "source_code": "def parse_prefixed_json(data: str) -> Tuple[str, str]:\n    \"\"\"Find the potential JSON body from `data`.\n\n    Sometimes the JSON body is prefixed with a XSSI magic string, specific to the server.\n    Return a tuple (data prefix, actual JSON body).\n\n    \"\"\"\n    matches = re.findall(PREFIX_REGEX, data)\n    data_prefix = matches[0] if matches else ''\n    body = data[len(data_prefix):]\n    return data_prefix, body", "loc": 11}
{"file": "httpie\\httpie\\output\\writer.py", "class_name": null, "function_name": "write_message", "parameters": ["requests_message", "env", "output_options", "processing_options", "extra_stream_kwargs"], "param_types": {"requests_message": "RequestsMessage", "env": "Environment", "output_options": "OutputOptions", "processing_options": "ProcessingOptions", "extra_stream_kwargs": "Optional[Dict[str, Any]]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["build_output_stream_for_message", "env.stderr.write", "output_options.any", "processing_options.get_prettify", "write_stream", "write_stream_with_colors_win"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write_message(\n    requests_message: RequestsMessage,\n    env: Environment,\n    output_options: OutputOptions,\n    processing_options: ProcessingOptions,\n    extra_stream_kwargs: Optional[Dict[str, Any]] = None\n):\n    if not output_options.any():\n        return\n    write_stream_kwargs = {\n        'stream': build_output_stream_for_message(\n            env=env,\n            requests_message=requests_message,\n            output_options=output_options,\n            processing_options=processing_options,\n            extra_stream_kwargs=extra_stream_kwargs\n        ),\n        # NOTE: `env.stdout` will in fact be `stderr` with `--download`\n        'outfile': env.stdout,\n        'flush': env.stdout_isatty or processing_options.stream\n    }\n    try:\n        if env.is_windows and 'colors' in processing_options.get_prettify(env):\n            write_stream_with_colors_win(**write_stream_kwargs)\n        else:\n            write_stream(**write_stream_kwargs)\n    except OSError as e:\n        if processing_options.show_traceback and e.errno == errno.EPIPE:\n            # Ignore broken pipes unless --traceback.\n            env.stderr.write('\\n')\n        else:\n            raise", "loc": 32}
{"file": "httpie\\httpie\\output\\writer.py", "class_name": null, "function_name": "write_stream", "parameters": ["stream", "outfile", "flush"], "param_types": {"stream": "BaseStream", "outfile": "Union[IO, TextIO]", "flush": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["buf.write", "outfile.flush"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Write the output stream.", "source_code": "def write_stream(\n    stream: BaseStream,\n    outfile: Union[IO, TextIO],\n    flush: bool\n):\n    \"\"\"Write the output stream.\"\"\"\n    try:\n        # Writing bytes so we use the buffer interface.\n        buf = outfile.buffer\n    except AttributeError:\n        buf = outfile\n\n    for chunk in stream:\n        buf.write(chunk)\n        if flush:\n            outfile.flush()", "loc": 16}
{"file": "httpie\\httpie\\output\\writer.py", "class_name": null, "function_name": "write_stream_with_colors_win", "parameters": ["stream", "outfile", "flush"], "param_types": {"stream": "'BaseStream'", "outfile": "TextIO", "flush": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["chunk.decode", "outfile.buffer.write", "outfile.flush", "outfile.write"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Like `write`, but colorized chunks are written as text directly to `outfile` to ensure it gets processed by colorama. Applies only to Windows and colorized terminal output.", "source_code": "def write_stream_with_colors_win(\n    stream: 'BaseStream',\n    outfile: TextIO,\n    flush: bool\n):\n    \"\"\"Like `write`, but colorized chunks are written as text\n    directly to `outfile` to ensure it gets processed by colorama.\n    Applies only to Windows and colorized terminal output.\n\n    \"\"\"\n    color = b'\\x1b['\n    encoding = outfile.encoding\n    for chunk in stream:\n        if color in chunk:\n            outfile.write(chunk.decode(encoding))\n        else:\n            outfile.buffer.write(chunk)\n        if flush:\n            outfile.flush()", "loc": 19}
{"file": "httpie\\httpie\\output\\writer.py", "class_name": null, "function_name": "build_output_stream_for_message", "parameters": ["env", "requests_message", "output_options", "processing_options", "extra_stream_kwargs"], "param_types": {"env": "Environment", "requests_message": "RequestsMessage", "output_options": "OutputOptions", "processing_options": "ProcessingOptions", "extra_stream_kwargs": "Optional[Dict[str, Any]]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_stream_type_and_kwargs", "getattr", "message_type", "stream_class", "stream_kwargs.update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def build_output_stream_for_message(\n    env: Environment,\n    requests_message: RequestsMessage,\n    output_options: OutputOptions,\n    processing_options: ProcessingOptions,\n    extra_stream_kwargs: Optional[Dict[str, Any]] = None\n):\n    message_type = {\n        RequestsMessageKind.REQUEST: HTTPRequest,\n        RequestsMessageKind.RESPONSE: HTTPResponse,\n    }[output_options.kind]\n    stream_class, stream_kwargs = get_stream_type_and_kwargs(\n        env=env,\n        processing_options=processing_options,\n        message_type=message_type,\n        headers=requests_message.headers\n    )\n    if extra_stream_kwargs:\n        stream_kwargs.update(extra_stream_kwargs)\n    yield from stream_class(\n        msg=message_type(requests_message),\n        output_options=output_options,\n        **stream_kwargs,\n    )\n    if (env.stdout_isatty and output_options.body and not output_options.meta\n            and not getattr(requests_message, 'is_body_upload_chunk', False)):\n        # Ensure a blank line after the response body.\n        # For terminal output only.\n        yield MESSAGE_SEPARATOR_BYTES", "loc": 29}
{"file": "httpie\\httpie\\output\\writer.py", "class_name": null, "function_name": "get_stream_type_and_kwargs", "parameters": ["env", "processing_options", "message_type", "headers"], "param_types": {"env": "Environment", "processing_options": "ProcessingOptions", "message_type": "Type[HTTPMessage]", "headers": "HTTPHeadersDict"}, "return_type": "Tuple[Type['BaseStream'], dict]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Conversion", "Formatting", "headers.get", "parse_content_type_header", "processing_options.get_prettify", "stream_kwargs.update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Pick the right stream type and kwargs for it based on `env` and `args`.", "source_code": "def get_stream_type_and_kwargs(\n    env: Environment,\n    processing_options: ProcessingOptions,\n    message_type: Type[HTTPMessage],\n    headers: HTTPHeadersDict,\n) -> Tuple[Type['BaseStream'], dict]:\n    \"\"\"Pick the right stream type and kwargs for it based on `env` and `args`.\n\n    \"\"\"\n    is_stream = processing_options.stream\n    prettify_groups = processing_options.get_prettify(env)\n    if not is_stream and message_type is HTTPResponse:\n        # If this is a response, then check the headers for determining\n        # auto-streaming.\n        raw_content_type_header = headers.get('Content-Type', None)\n        if raw_content_type_header:\n            content_type_header, _ = parse_content_type_header(raw_content_type_header)\n            is_stream = (content_type_header == 'text/event-stream')\n\n    if not env.stdout_isatty and not prettify_groups:\n        stream_class = RawStream\n        stream_kwargs = {\n            'chunk_size': (\n                RawStream.CHUNK_SIZE_BY_LINE\n                if is_stream\n                else RawStream.CHUNK_SIZE\n            )\n        }\n    else:\n        stream_class = EncodedStream\n        stream_kwargs = {\n            'env': env,\n        }\n        if message_type is HTTPResponse:\n            stream_kwargs.update({\n                'mime_overwrite': processing_options.response_mime,\n                'encoding_overwrite': processing_options.response_charset,\n            })\n        if prettify_groups:\n            stream_class = PrettyStream if is_stream else BufferedPrettyStream\n            stream_kwargs.update({\n                'conversion': Conversion(),\n                'formatting': Formatting(\n                    env=env,\n                    groups=prettify_groups,\n                    color_scheme=processing_options.style,\n                    explicit_json=processing_options.json,\n                    format_options=processing_options.format_options,\n                )\n            })\n\n    return stream_class, stream_kwargs", "loc": 52}
{"file": "httpie\\httpie\\output\\formatters\\colors.py", "class_name": null, "function_name": "get_lexer", "parameters": ["mime", "explicit_json", "body"], "param_types": {"mime": "str"}, "return_type": "Optional[Type[Lexer]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EnhancedJsonLexer", "isinstance", "json.loads", "lexer_names.append", "lexer_names.extend", "mime.split", "mime_types.extend", "pygments.lexers.get_lexer_by_name", "pygments.lexers.get_lexer_for_mimetype", "subtype.split"], "control_structures": ["For", "If", "Try"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def get_lexer(\n    mime: str,\n    explicit_json=False,\n    body=''\n) -> Optional[Type[Lexer]]:\n    # Build candidate mime type and lexer names.\n    mime_types, lexer_names = [mime], []\n    type_, subtype = mime.split('/', 1)\n    if '+' not in subtype:\n        lexer_names.append(subtype)\n    else:\n        subtype_name, subtype_suffix = subtype.split('+', 1)\n        lexer_names.extend([subtype_name, subtype_suffix])\n        mime_types.extend([\n            f'{type_}/{subtype_name}',\n            f'{type_}/{subtype_suffix}',\n        ])\n\n    # As a last resort, if no lexer feels responsible, and\n    # the subtype contains 'json', take the JSON lexer\n    if 'json' in subtype:\n        lexer_names.append('json')\n\n    # Try to resolve the right lexer.\n    lexer = None\n    for mime_type in mime_types:\n        try:\n            lexer = pygments.lexers.get_lexer_for_mimetype(mime_type)\n            break\n        except ClassNotFound:\n            pass\n    else:\n        for name in lexer_names:\n            try:\n                lexer = pygments.lexers.get_lexer_by_name(name)\n            except ClassNotFound:\n                pass\n\n    if explicit_json and body and (not lexer or isinstance(lexer, TextLexer)):\n        # JSON response with an incorrect Content-Type?\n        try:\n            json.loads(body)  # FIXME: the body also gets parsed in json.py\n        except ValueError:\n            pass  # Nope\n        else:\n            lexer = pygments.lexers.get_lexer_by_name('json')\n\n    # Use our own JSON lexer: it supports JSON bodies preceded by non-JSON data\n    # as well as legit JSON bodies.\n    if isinstance(lexer, JsonLexer):\n        lexer = EnhancedJsonLexer()\n\n    return lexer", "loc": 53}
{"file": "httpie\\httpie\\output\\formatters\\colors.py", "class_name": null, "function_name": "make_style", "parameters": ["name", "raw_styles", "shade"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "format_value", "get_color", "raw_styles.items", "type", "value.split"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_style(name, raw_styles, shade):\n    def format_value(value):\n        return ' '.join(\n            get_color(part, shade) or part\n            for part in value.split()\n        )\n\n    bases = (pygments.style.Style,)\n    data = {\n        'styles': {\n            key: format_value(value)\n            for key, value in raw_styles.items()\n        }\n    }\n    return type(name, bases, data)", "loc": 15}
{"file": "httpie\\httpie\\output\\formatters\\colors.py", "class_name": null, "function_name": "make_styles", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SHADE_TO_PIE_STYLE.items", "make_style"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_styles():\n    styles = {}\n\n    for shade, name in SHADE_TO_PIE_STYLE.items():\n        styles[name] = [\n            make_style(name, style_map, shade)\n            for style_name, style_map in [\n                (f'Pie{name}HeaderStyle', PIE_HEADER_STYLE),\n                (f'Pie{name}BodyStyle', PIE_BODY_STYLE),\n            ]\n        ]\n\n    return styles", "loc": 13}
{"file": "httpie\\httpie\\output\\formatters\\colors.py", "class_name": "ColorFormatter", "function_name": "format_body", "parameters": ["self", "body", "mime"], "param_types": {"body": "str", "mime": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["pygments.highlight", "self.get_lexer_for_body"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_body(self, body: str, mime: str) -> str:\n    lexer = self.get_lexer_for_body(mime, body)\n    if lexer:\n        body = pygments.highlight(\n            code=body,\n            lexer=lexer,\n            formatter=self.body_formatter,\n        )\n    return body", "loc": 9}
{"file": "httpie\\httpie\\output\\formatters\\colors.py", "class_name": "ColorFormatter", "function_name": "format_metadata", "parameters": ["self", "metadata"], "param_types": {"metadata": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["pygments.highlight", "pygments.highlight(code=metadata, lexer=self.metadata_lexer, formatter=self.header_formatter).strip"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_metadata(self, metadata: str) -> str:\n    return pygments.highlight(\n        code=metadata,\n        lexer=self.metadata_lexer,\n        formatter=self.header_formatter,\n    ).strip()", "loc": 6}
{"file": "httpie\\httpie\\output\\formatters\\colors.py", "class_name": "ColorFormatter", "function_name": "get_formatters", "parameters": ["self", "color_scheme"], "param_types": {"color_scheme": "str"}, "return_type": "Tuple[pygments.formatter.Formatter, pygments.formatter.Formatter, bool]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Terminal256Formatter", "self.get_style_class"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_formatters(self, color_scheme: str) -> Tuple[\n    pygments.formatter.Formatter,\n    pygments.formatter.Formatter,\n    bool\n]:\n    if color_scheme in PIE_STYLES:\n        header_style, body_style = PIE_STYLES[color_scheme]\n        precise = True\n    else:\n        header_style = self.get_style_class(color_scheme)\n        body_style = header_style\n        precise = False\n\n    return (\n        Terminal256Formatter(style=header_style),\n        Terminal256Formatter(style=body_style),\n        precise\n    )", "loc": 18}
{"file": "httpie\\httpie\\output\\formatters\\colors.py", "class_name": "ColorFormatter", "function_name": "get_style_class", "parameters": ["color_scheme"], "param_types": {"color_scheme": "str"}, "return_type": "Type[pygments.style.Style]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["pygments.styles.get_style_by_name"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_style_class(color_scheme: str) -> Type[pygments.style.Style]:\n    try:\n        return pygments.styles.get_style_by_name(color_scheme)\n    except ClassNotFound:\n        return Solarized256Style", "loc": 5}
{"file": "httpie\\httpie\\output\\formatters\\colors.py", "class_name": null, "function_name": "format_value", "parameters": ["value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "get_color", "value.split"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_value(value):\n    return ' '.join(\n        get_color(part, shade) or part\n        for part in value.split()\n    )", "loc": 5}
{"file": "httpie\\httpie\\output\\formatters\\headers.py", "class_name": "HeadersFormatter", "function_name": "format_headers", "parameters": ["self", "headers"], "param_types": {"headers": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\r\\n'.join", "h.split", "headers.splitlines", "sorted"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Sorts headers by name while retaining relative order of multiple headers with the same name.", "source_code": "def format_headers(self, headers: str) -> str:\n    \"\"\"\n    Sorts headers by name while retaining relative\n    order of multiple headers with the same name.\n\n    \"\"\"\n    lines = headers.splitlines()\n    headers = sorted(lines[1:], key=lambda h: h.split(':')[0])\n    return '\\r\\n'.join(lines[:1] + headers)", "loc": 9}
{"file": "httpie\\httpie\\output\\formatters\\json.py", "class_name": "JSONFormatter", "function_name": "format_body", "parameters": ["self", "body", "mime"], "param_types": {"body": "str", "mime": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "json.dumps", "load_prefixed_json"], "control_structures": ["If", "Try"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def format_body(self, body: str, mime: str) -> str:\n    maybe_json = [\n        'json',\n        'javascript',\n        'text',\n    ]\n    if (self.kwargs['explicit_json']\n            or any(token in mime for token in maybe_json)):\n        from ..utils import load_prefixed_json\n        try:\n            data_prefix, json_obj = load_prefixed_json(body)\n        except ValueError:\n            pass  # Invalid JSON, ignore.\n        else:\n            # Indent, sort keys by name, and avoid\n            # unicode escapes to improve readability.\n            body = data_prefix + json.dumps(\n                obj=json_obj,\n                sort_keys=self.format_options['json']['sort_keys'],\n                ensure_ascii=False,\n                indent=self.format_options['json']['indent']\n            )\n    return body", "loc": 23}
{"file": "httpie\\httpie\\output\\formatters\\xml.py", "class_name": null, "function_name": "parse_declaration", "parameters": ["raw_body"], "param_types": {"raw_body": "str"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["body.find", "body.startswith", "len", "raw_body.strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_declaration(raw_body: str) -> Optional[str]:\n    body = raw_body.strip()\n    # XMLDecl ::= '<?xml' DECL_CONTENT '?>'\n    if body.startswith(XML_DECLARATION_OPEN):\n        end = body.find(XML_DECLARATION_CLOSE)\n        if end != -1:\n            return body[:end + len(XML_DECLARATION_CLOSE)]", "loc": 7}
{"file": "httpie\\httpie\\output\\formatters\\xml.py", "class_name": null, "function_name": "pretty_xml", "parameters": ["document", "declaration", "encoding", "indent"], "param_types": {"document": "'Document'", "declaration": "Optional[str]", "encoding": "Optional[str]", "indent": "int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "body.splitlines", "document.toprettyxml", "document.toprettyxml(**kwargs).decode", "len", "line.strip", "lines.insert", "lines.pop", "parse_declaration"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Render the given :class:`~xml.dom.minidom.Document` `document` into a prettified string.", "source_code": "def pretty_xml(document: 'Document',\n               declaration: Optional[str] = None,\n               encoding: Optional[str] = UTF8,\n               indent: int = 2) -> str:\n    \"\"\"Render the given :class:`~xml.dom.minidom.Document` `document` into a prettified string.\"\"\"\n    kwargs = {\n        'encoding': encoding or UTF8,\n        'indent': ' ' * indent,\n    }\n    body = document.toprettyxml(**kwargs).decode(kwargs['encoding'])\n\n    # Remove blank lines automatically added by `toprettyxml()`.\n    lines = [line for line in body.splitlines() if line.strip()]\n\n    # xml.dom automatically adds the declaration, even if\n    # it is not present in the actual body. Remove it.\n    if len(lines) >= 1 and parse_declaration(lines[0]):\n        lines.pop(0)\n        if declaration:\n            lines.insert(0, declaration)\n\n    return '\\n'.join(lines)", "loc": 22}
{"file": "httpie\\httpie\\output\\formatters\\xml.py", "class_name": "XMLFormatter", "function_name": "format_body", "parameters": ["self", "body", "mime"], "param_types": {"body": "str", "mime": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_declaration", "parse_xml", "pretty_xml"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_body(self, body: str, mime: str):\n    if 'xml' not in mime:\n        return body\n\n    from xml.parsers.expat import ExpatError\n    from defusedxml.common import DefusedXmlException\n\n    declaration = parse_declaration(body)\n    try:\n        parsed_body = parse_xml(body)\n    except ExpatError:\n        pass  # Invalid XML, ignore.\n    except DefusedXmlException:\n        pass  # Unsafe XML, ignore.\n    else:\n        body = pretty_xml(parsed_body,\n                          encoding=parsed_body.encoding,\n                          indent=self.format_options['xml']['indent'],\n                          declaration=declaration)\n\n    return body", "loc": 21}
{"file": "httpie\\httpie\\output\\lexers\\common.py", "class_name": null, "function_name": "precise", "parameters": ["lexer", "precise_token", "parent_token"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["lexer.options.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def precise(lexer, precise_token, parent_token):\n    # Due to a pygments bug*, custom tokens will look bad\n    # on outside styles. Until it is fixed on upstream, we'll\n    # convey whether the client is using pie style or not\n    # through precise option and return more precise tokens\n    # depending on it's value.\n    #\n    # [0]: https://github.com/pygments/pygments/issues/1986\n    if precise_token is None or not lexer.options.get(\"precise\"):\n        return parent_token\n    else:\n        return precise_token", "loc": 12}
{"file": "httpie\\httpie\\output\\lexers\\http.py", "class_name": null, "function_name": "http_response_type", "parameters": ["lexer", "match", "ctx"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RE_STATUS_LINE.match", "STATUS_TYPES.get", "groups", "match.group", "precise", "pygments.lexer.bygroups", "status_match.groups"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def http_response_type(lexer, match, ctx):\n    status_match = RE_STATUS_LINE.match(match.group())\n    if status_match is None:\n        return None\n\n    status_code, text, reason = status_match.groups()\n    status_type = precise(\n        lexer,\n        STATUS_TYPES.get(status_code[0]),\n        pygments.token.Number\n    )\n\n    groups = pygments.lexer.bygroups(\n        status_type,\n        pygments.token.Text,\n        status_type\n    )\n    yield from groups(lexer, status_match, ctx)", "loc": 18}
{"file": "httpie\\httpie\\output\\lexers\\http.py", "class_name": null, "function_name": "request_method", "parameters": ["lexer", "match", "ctx"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RESPONSE_TYPES.get", "match.group", "match.start", "precise"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_method(lexer, match, ctx):\n    response_type = precise(\n        lexer,\n        RESPONSE_TYPES.get(match.group()),\n        pygments.token.Name.Function\n    )\n    yield match.start(), response_type, match.group()", "loc": 7}
{"file": "httpie\\httpie\\output\\lexers\\metadata.py", "class_name": null, "function_name": "speed_based_token", "parameters": ["lexer", "match", "ctx"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SPEED_TOKENS.items", "float", "match.group", "match.start", "precise"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def speed_based_token(lexer, match, ctx):\n    try:\n        value = float(match.group())\n    except ValueError:\n        return pygments.token.Number\n\n    for limit, token in SPEED_TOKENS.items():\n        if value <= limit:\n            break\n    else:\n        token = pygments.token.Number.SPEED.VERY_SLOW\n\n    response_type = precise(\n        lexer,\n        token,\n        pygments.token.Number\n    )\n    yield match.start(), response_type, match.group()", "loc": 18}
{"file": "httpie\\httpie\\output\\ui\\man_pages.py", "class_name": null, "function_name": "is_available", "parameters": ["program"], "param_types": {"program": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["subprocess.run"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Check whether `program`'s man pages are available on this system.", "source_code": "def is_available(program: str) -> bool:\n    \"\"\"\n    Check whether `program`'s man pages are available on this system.\n\n    \"\"\"\n    if NO_MAN_PAGES or os.system == 'nt':\n        return False\n    try:\n        process = subprocess.run(\n            [MAN_COMMAND, MAN_PAGE_SECTION, program],\n            shell=False,\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL\n        )\n    except Exception:\n        # There might be some errors outside the process, e.g\n        # a permission error to execute something that is not an\n        # executable.\n        return False\n    else:\n        return process.returncode == 0", "loc": 21}
{"file": "httpie\\httpie\\output\\ui\\palette.py", "class_name": null, "function_name": "get_color", "parameters": ["color", "shade"], "param_types": {"color": "PieColor", "shade": "str"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_color(\n    color: PieColor, shade: str, *, palette=COLOR_PALETTE\n) -> Optional[str]:\n    if color not in palette:\n        return None\n    color_code = palette[color]\n    if isinstance(color_code, dict) and shade in color_code:\n        return color_code[shade]\n    else:\n        return color_code", "loc": 10}
{"file": "httpie\\httpie\\output\\ui\\palette.py", "class_name": "GenericColor", "function_name": "apply_style", "parameters": ["self", "style"], "param_types": {"style": "Styles"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PieStyle", "get_color"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Apply the given style to a particular value.", "source_code": "def apply_style(\n    self, style: Styles, *, style_name: Optional[str] = None\n) -> str:\n    \"\"\"Apply the given style to a particular value.\"\"\"\n    exposed_color = self.value[style]\n    if style is Styles.PIE:\n        assert style_name is not None\n        shade = PIE_STYLE_TO_SHADE[PieStyle(style_name)]\n        return get_color(exposed_color, shade)\n    else:\n        return exposed_color", "loc": 11}
{"file": "httpie\\httpie\\output\\ui\\rich_help.py", "class_name": null, "function_name": "unpack_argument", "parameters": ["argument"], "param_types": {"argument": "Argument"}, "return_type": "Tuple[Text, Text]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Text", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unpack_argument(\n    argument: Argument,\n) -> Tuple[Text, Text]:\n    opt1 = opt2 = ''\n\n    style = None\n    if argument.aliases:\n        if len(argument.aliases) >= 2:\n            opt2, opt1 = argument.aliases\n        else:\n            (opt1,) = argument.aliases\n    else:\n        opt1 = argument.metavar\n        style = STYLE_USAGE_REGULAR\n\n    return Text(opt1, style=style), Text(opt2)", "loc": 16}
{"file": "httpie\\httpie\\output\\ui\\rich_help.py", "class_name": null, "function_name": "to_usage", "parameters": ["spec"], "param_types": {"spec": "ParserSpec"}, "return_type": "RenderableType", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "'/'.join", "Text", "argument.configuration.get", "argument.serialize", "frozenset", "raw_form.get", "shown_arguments.sort", "sorted", "text.append", "whitelist.intersection"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def to_usage(\n    spec: ParserSpec,\n    *,\n    program_name: Optional[str] = None,\n    whitelist: AbstractSet[str] = frozenset()\n) -> RenderableType:\n    shown_arguments = [\n        argument\n        for group in spec.groups\n        for argument in group.arguments\n        if (not argument.aliases or whitelist.intersection(argument.aliases))\n    ]\n\n    # Sort the shown_arguments so that --dash options are\n    # shown first\n    shown_arguments.sort(key=lambda argument: argument.aliases, reverse=True)\n\n    text = Text(program_name or spec.program, style=STYLE_BOLD)\n    for argument in shown_arguments:\n        text.append(' ')\n\n        is_whitelisted = whitelist.intersection(argument.aliases)\n        if argument.aliases:\n            name = '/'.join(sorted(argument.aliases, key=len))\n        else:\n            name = argument.metavar\n\n        nargs = argument.configuration.get('nargs')\n        if nargs is Qualifiers.OPTIONAL:\n            text.append('[' + name + ']', style=STYLE_USAGE_OPTIONAL)\n        elif nargs is Qualifiers.ZERO_OR_MORE:\n            text.append(\n                '[' + name + ' ...]',\n                style=STYLE_USAGE_OPTIONAL,\n            )\n        else:\n            text.append(\n                name,\n                style=STYLE_USAGE_ERROR\n                if is_whitelisted\n                else STYLE_USAGE_REGULAR,\n            )\n\n        raw_form = argument.serialize()\n        if raw_form.get('choices'):\n            text.append(' ')\n            text.append(\n                '{' + ', '.join(raw_form['choices']) + '}',\n                style=STYLE_USAGE_MISSING,\n            )\n\n    return text", "loc": 52}
{"file": "httpie\\httpie\\output\\ui\\rich_progress.py", "class_name": "StatusDisplay", "function_name": "start", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.console.status", "self.status.start"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start(\n    self, *, total: Optional[float], at: float, description: str\n) -> None:\n    self.observed = at\n    self.description = (\n        f'[progress.description]{description}[/progress.description]'\n    )\n\n    self.status = self.console.status(self.description, spinner='line')\n    self.status.start()", "loc": 10}
{"file": "httpie\\httpie\\output\\ui\\rich_progress.py", "class_name": "StatusDisplay", "function_name": "update", "parameters": ["self", "steps"], "param_types": {"steps": "float"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["filesize.decimal", "filesize.decimal(self.observed).split", "self.status.update"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update(self, steps: float) -> None:\n    from rich import filesize\n\n    self.observed += steps\n\n    observed_amount, observed_unit = filesize.decimal(\n        self.observed\n    ).split()\n    self.status.update(\n        status=f'{self.description} [progress.download]{observed_amount}/? {observed_unit}[/progress.download]'\n    )", "loc": 11}
{"file": "httpie\\httpie\\output\\ui\\rich_progress.py", "class_name": "StatusDisplay", "function_name": "stop", "parameters": ["self", "time_spent"], "param_types": {"time_spent": "float"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._print_summary", "self.console.print", "self.status.stop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def stop(self, time_spent: float) -> None:\n    self.status.stop()\n    self.console.print(self.description)\n    if time_spent:\n        self._print_summary(\n            is_finished=True,\n            observed_steps=self.observed,\n            time_spent=time_spent,\n        )", "loc": 9}
{"file": "httpie\\httpie\\output\\ui\\rich_progress.py", "class_name": "ProgressDisplay", "function_name": "start", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BarColumn", "DownloadColumn", "Progress", "TimeRemainingColumn", "TransferSpeedColumn", "self.console.print", "self.progress_bar.add_task", "self.progress_bar.start"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start(\n    self, *, total: Optional[float], at: float, description: str\n) -> None:\n    from rich.progress import (\n        Progress,\n        BarColumn,\n        DownloadColumn,\n        TimeRemainingColumn,\n        TransferSpeedColumn,\n    )\n\n    assert total is not None\n    self.console.print(f'[progress.description]{description}')\n    self.progress_bar = Progress(\n        '[',\n        BarColumn(),\n        ']',\n        '[progress.percentage]{task.percentage:>3.0f}%',\n        '(',\n        DownloadColumn(),\n        ')',\n        TimeRemainingColumn(),\n        TransferSpeedColumn(),\n        console=self.console,\n        transient=True,\n    )\n    self.progress_bar.start()\n    self.transfer_task = self.progress_bar.add_task(\n        description, completed=at, total=total\n    )", "loc": 30}
{"file": "httpie\\httpie\\output\\ui\\rich_progress.py", "class_name": "ProgressDisplay", "function_name": "stop", "parameters": ["self", "time_spent"], "param_types": {"time_spent": "Optional[float]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._print_summary", "self.progress_bar.stop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def stop(self, time_spent: Optional[float]) -> None:\n    self.progress_bar.stop()\n\n    if time_spent:\n        [task] = self.progress_bar.tasks\n        self._print_summary(\n            is_finished=task.finished,\n            observed_steps=task.completed,\n            time_spent=time_spent,\n        )", "loc": 10}
{"file": "httpie\\httpie\\output\\ui\\rich_utils.py", "class_name": null, "function_name": "enable_highlighter", "parameters": ["console", "highlighter"], "param_types": {"console": "Console", "highlighter": "Highlighter"}, "return_type": "Iterator[Console]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Enable a highlighter temporarily.", "source_code": "def enable_highlighter(\n    console: Console,\n    highlighter: Highlighter,\n) -> Iterator[Console]:\n    \"\"\"Enable a highlighter temporarily.\"\"\"\n\n    original_highlighter = console.highlighter\n    try:\n        console.highlighter = highlighter\n        yield console\n    finally:\n        console.highlighter = original_highlighter", "loc": 12}
{"file": "httpie\\httpie\\plugins\\manager.py", "class_name": null, "function_name": "enable_plugins", "parameters": ["plugins_dir"], "param_types": {"plugins_dir": "Optional[Path]"}, "return_type": "ContextManager[None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_load_directories", "get_site_paths", "nullcontext"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def enable_plugins(plugins_dir: Optional[Path]) -> ContextManager[None]:\n    if plugins_dir is None:\n        return nullcontext()\n    else:\n        return _load_directories(get_site_paths(plugins_dir))", "loc": 5}
{"file": "httpie\\httpie\\plugins\\manager.py", "class_name": "PluginManager", "function_name": "iter_entry_points", "parameters": ["self", "directory"], "param_types": {"directory": "Optional[Path]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enable_plugins", "find_entry_points", "importlib_metadata.entry_points"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def iter_entry_points(self, directory: Optional[Path] = None):\n    with enable_plugins(directory):\n        eps = importlib_metadata.entry_points()\n\n        for entry_point_name in ENTRY_POINT_NAMES:\n            yield from find_entry_points(eps, group=entry_point_name)", "loc": 6}
{"file": "httpie\\httpie\\plugins\\manager.py", "class_name": "PluginManager", "function_name": "load_installed_plugins", "parameters": ["self", "directory"], "param_types": {"directory": "Optional[Path]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["entry_point.load", "get_dist_name", "self.iter_entry_points", "self.register", "warnings.warn"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_installed_plugins(self, directory: Optional[Path] = None):\n    for entry_point in self.iter_entry_points(directory):\n        plugin_name = get_dist_name(entry_point)\n        try:\n            plugin = entry_point.load()\n        except BaseException as exc:\n            warnings.warn(\n                f'While loading \"{plugin_name}\", an error occurred: {exc}\\n'\n                f'For uninstallations, please use either \"httpie plugins uninstall {plugin_name}\" '\n                f'or \"pip uninstall {plugin_name}\" (depending on how you installed it in the first '\n                'place).'\n            )\n            continue\n        plugin.package_name = plugin_name\n        self.register(plugin)", "loc": 15}
{"file": "httpie\\httpie\\plugins\\manager.py", "class_name": "PluginManager", "function_name": "get_formatters_grouped", "parameters": ["self"], "param_types": {}, "return_type": "Dict[str, List[Type[FormatterPlugin]]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["attrgetter", "groupby", "list", "self.get_formatters"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_formatters_grouped(self) -> Dict[str, List[Type[FormatterPlugin]]]:\n    return {\n        group_name: list(group)\n        for group_name, group\n        in groupby(self.get_formatters(), key=attrgetter('group_name'))\n    }", "loc": 6}
{"file": "isort\\example_isort_formatting_plugin\\example_isort_formatting_plugin.py", "class_name": null, "function_name": "black_format_import_section", "parameters": ["contents", "extension", "config"], "param_types": {"contents": "str", "extension": "str", "config": "isort.settings.Config"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["black.FileMode", "black.format_file_contents", "extension.lower"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Formats the given import section using black.", "source_code": "def black_format_import_section(\n    contents: str, extension: str, config: isort.settings.Config\n) -> str:\n    \"\"\"Formats the given import section using black.\"\"\"\n    if extension.lower() not in (\"pyi\", \"py\"):\n        return contents\n\n    try:\n        return black.format_file_contents(\n            contents,\n            fast=True,\n            mode=black.FileMode(\n                is_pyi=extension.lower() == \"pyi\",\n                line_length=config.line_length,\n            ),\n        )\n    except black.NothingChanged:\n        return contents", "loc": 18}
{"file": "isort\\isort\\api.py", "class_name": null, "function_name": "sort_code_string", "parameters": ["code", "extension", "config", "file_path", "disregard_skip", "show_diff"], "param_types": {"code": "str", "extension": "str | None", "config": "Config", "file_path": "Path | None", "disregard_skip": "bool", "show_diff": "bool | TextIO"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["StringIO", "_config", "output_stream.read", "output_stream.seek", "sort_stream"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Sorts any imports within the provided code string, returning a new string with them sorted. - **code**: The string of code with imports that need to be sorted. - **extension**: The file extension that contains imports. Defaults to filename extension or py.", "source_code": "def sort_code_string(\n    code: str,\n    extension: str | None = None,\n    config: Config = DEFAULT_CONFIG,\n    file_path: Path | None = None,\n    disregard_skip: bool = False,\n    show_diff: bool | TextIO = False,\n    **config_kwargs: Any,\n) -> str:\n    \"\"\"Sorts any imports within the provided code string, returning a new string with them sorted.\n\n    - **code**: The string of code with imports that need to be sorted.\n    - **extension**: The file extension that contains imports. Defaults to filename extension or py.\n    - **config**: The config object to use when sorting imports.\n    - **file_path**: The disk location where the code string was pulled from.\n    - **disregard_skip**: set to `True` if you want to ignore a skip set in config for this file.\n    - **show_diff**: If `True` the changes that need to be done will be printed to stdout, if a\n    TextIO stream is provided results will be written to it, otherwise no diff will be computed.\n    - ****config_kwargs**: Any config modifications.\n    \"\"\"\n    input_stream = StringIO(code)\n    output_stream = StringIO()\n    config = _config(path=file_path, config=config, **config_kwargs)\n    sort_stream(\n        input_stream,\n        output_stream,\n        extension=extension,\n        config=config,\n        file_path=file_path,\n        disregard_skip=disregard_skip,\n        show_diff=show_diff,\n    )\n    output_stream.seek(0)\n    return output_stream.read()", "loc": 34}
{"file": "isort\\isort\\api.py", "class_name": null, "function_name": "check_code_string", "parameters": ["code", "show_diff", "extension", "config", "file_path", "disregard_skip"], "param_types": {"code": "str", "show_diff": "bool | TextIO", "extension": "str | None", "config": "Config", "file_path": "Path | None", "disregard_skip": "bool"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["StringIO", "_config", "check_stream"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Checks the order, format, and categorization of imports within the provided code string.", "source_code": "def check_code_string(\n    code: str,\n    show_diff: bool | TextIO = False,\n    extension: str | None = None,\n    config: Config = DEFAULT_CONFIG,\n    file_path: Path | None = None,\n    disregard_skip: bool = False,\n    **config_kwargs: Any,\n) -> bool:\n    \"\"\"Checks the order, format, and categorization of imports within the provided code string.\n    Returns `True` if everything is correct, otherwise `False`.\n\n    - **code**: The string of code with imports that need to be sorted.\n    - **show_diff**: If `True` the changes that need to be done will be printed to stdout, if a\n    TextIO stream is provided results will be written to it, otherwise no diff will be computed.\n    - **extension**: The file extension that contains imports. Defaults to filename extension or py.\n    - **config**: The config object to use when sorting imports.\n    - **file_path**: The disk location where the code string was pulled from.\n    - **disregard_skip**: set to `True` if you want to ignore a skip set in config for this file.\n    - ****config_kwargs**: Any config modifications.\n    \"\"\"\n    config = _config(path=file_path, config=config, **config_kwargs)\n    return check_stream(\n        StringIO(code),\n        show_diff=show_diff,\n        extension=extension,\n        config=config,\n        file_path=file_path,\n        disregard_skip=disregard_skip,\n    )", "loc": 30}
{"file": "isort\\isort\\api.py", "class_name": null, "function_name": "check_stream", "parameters": ["input_stream", "show_diff", "extension", "config", "file_path", "disregard_skip"], "param_types": {"input_stream": "TextIO", "show_diff": "bool | TextIO", "extension": "str | None", "config": "Config", "file_path": "Path | None", "disregard_skip": "bool"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["StringIO", "_config", "create_terminal_printer", "input_stream.read", "input_stream.seek", "output_stream.read", "output_stream.seek", "printer.error", "printer.success", "show_unified_diff", "sort_stream"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Checks any imports within the provided code stream, returning `False` if any unsorted or incorrectly imports are found or `True` if no problems are identified. - **input_stream**: The stream of code with imports that need to be sorted.", "source_code": "def check_stream(\n    input_stream: TextIO,\n    show_diff: bool | TextIO = False,\n    extension: str | None = None,\n    config: Config = DEFAULT_CONFIG,\n    file_path: Path | None = None,\n    disregard_skip: bool = False,\n    **config_kwargs: Any,\n) -> bool:\n    \"\"\"Checks any imports within the provided code stream, returning `False` if any unsorted or\n    incorrectly imports are found or `True` if no problems are identified.\n\n    - **input_stream**: The stream of code with imports that need to be sorted.\n    - **show_diff**: If `True` the changes that need to be done will be printed to stdout, if a\n    TextIO stream is provided results will be written to it, otherwise no diff will be computed.\n    - **extension**: The file extension that contains imports. Defaults to filename extension or py.\n    - **config**: The config object to use when sorting imports.\n    - **file_path**: The disk location where the code string was pulled from.\n    - **disregard_skip**: set to `True` if you want to ignore a skip set in config for this file.\n    - ****config_kwargs**: Any config modifications.\n    \"\"\"\n    config = _config(path=file_path, config=config, **config_kwargs)\n\n    if show_diff:\n        input_stream = StringIO(input_stream.read())\n\n    changed: bool = sort_stream(\n        input_stream=input_stream,\n        output_stream=Empty,\n        extension=extension,\n        config=config,\n        file_path=file_path,\n        disregard_skip=disregard_skip,\n    )\n    printer = create_terminal_printer(\n        color=config.color_output, error=config.format_error, success=config.format_success\n    )\n    if not changed:\n        if config.verbose and not config.only_modified:\n            printer.success(f\"{file_path or ''} Everything Looks Good!\")\n        return True\n\n    printer.error(f\"{file_path or ''} Imports are incorrectly sorted and/or formatted.\")\n    if show_diff:\n        output_stream = StringIO()\n        input_stream.seek(0)\n        file_contents = input_stream.read()\n        sort_stream(\n            input_stream=StringIO(file_contents),\n            output_stream=output_stream,\n            extension=extension,\n            config=config,\n            file_path=file_path,\n            disregard_skip=disregard_skip,\n        )\n        output_stream.seek(0)\n\n        show_unified_diff(\n            file_input=file_contents,\n            file_output=output_stream.read(),\n            file_path=file_path,\n            output=None if show_diff is True else show_diff,\n            color_output=config.color_output,\n        )\n    return False", "loc": 65}
{"file": "isort\\isort\\api.py", "class_name": null, "function_name": "check_file", "parameters": ["filename", "show_diff", "config", "file_path", "disregard_skip", "extension"], "param_types": {"filename": "str | Path", "show_diff": "bool | TextIO", "config": "Config", "file_path": "Path | None", "disregard_skip": "bool", "extension": "str | None"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Config", "check_stream", "config_kwargs.pop", "config_trie.search", "io.File.read", "print"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Checks any imports within the provided file, returning `False` if any unsorted or incorrectly imports are found or `True` if no problems are identified. - **filename**: The name or Path of the file to check.", "source_code": "def check_file(\n    filename: str | Path,\n    show_diff: bool | TextIO = False,\n    config: Config = DEFAULT_CONFIG,\n    file_path: Path | None = None,\n    disregard_skip: bool = True,\n    extension: str | None = None,\n    **config_kwargs: Any,\n) -> bool:\n    \"\"\"Checks any imports within the provided file, returning `False` if any unsorted or\n    incorrectly imports are found or `True` if no problems are identified.\n\n    - **filename**: The name or Path of the file to check.\n    - **show_diff**: If `True` the changes that need to be done will be printed to stdout, if a\n    TextIO stream is provided results will be written to it, otherwise no diff will be computed.\n    - **config**: The config object to use when sorting imports.\n    - **file_path**: The disk location where the code string was pulled from.\n    - **disregard_skip**: set to `True` if you want to ignore a skip set in config for this file.\n    - **extension**: The file extension that contains imports. Defaults to filename extension or py.\n    - ****config_kwargs**: Any config modifications.\n    \"\"\"\n    file_config: Config = config\n\n    if \"config_trie\" in config_kwargs:\n        config_trie = config_kwargs.pop(\"config_trie\", None)\n        if config_trie:\n            config_info = config_trie.search(filename)\n            if config.verbose:\n                print(f\"{config_info[0]} used for file {filename}\")\n\n            file_config = Config(**config_info[1])\n\n    with io.File.read(filename) as source_file:\n        return check_stream(\n            source_file.stream,\n            show_diff=show_diff,\n            extension=extension,\n            config=file_config,\n            file_path=file_path or source_file.path,\n            disregard_skip=disregard_skip,\n            **config_kwargs,\n        )", "loc": 42}
{"file": "isort\\isort\\api.py", "class_name": null, "function_name": "find_imports_in_code", "parameters": ["code", "config", "file_path", "unique", "top_only"], "param_types": {"code": "str", "config": "Config", "file_path": "Path | None", "unique": "bool | ImportKey", "top_only": "bool"}, "return_type": "Iterator[identify.Import]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["StringIO", "find_imports_in_stream"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Finds and returns all imports within the provided code string. - **code**: The string of code with imports that need to be sorted. - **config**: The config object to use when sorting imports.", "source_code": "def find_imports_in_code(\n    code: str,\n    config: Config = DEFAULT_CONFIG,\n    file_path: Path | None = None,\n    unique: bool | ImportKey = False,\n    top_only: bool = False,\n    **config_kwargs: Any,\n) -> Iterator[identify.Import]:\n    \"\"\"Finds and returns all imports within the provided code string.\n\n    - **code**: The string of code with imports that need to be sorted.\n    - **config**: The config object to use when sorting imports.\n    - **file_path**: The disk location where the code string was pulled from.\n    - **unique**: If True, only the first instance of an import is returned.\n    - **top_only**: If True, only return imports that occur before the first function or class.\n    - ****config_kwargs**: Any config modifications.\n    \"\"\"\n    yield from find_imports_in_stream(\n        input_stream=StringIO(code),\n        config=config,\n        file_path=file_path,\n        unique=unique,\n        top_only=top_only,\n        **config_kwargs,\n    )", "loc": 25}
{"file": "isort\\isort\\api.py", "class_name": null, "function_name": "find_imports_in_stream", "parameters": ["input_stream", "config", "file_path", "unique", "top_only", "_seen"], "param_types": {"input_stream": "TextIO", "config": "Config", "file_path": "Path | None", "unique": "bool | ImportKey", "top_only": "bool", "_seen": "set[str] | None"}, "return_type": "Iterator[identify.Import]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_config", "identified_import.module.split", "identified_import.statement", "identify.imports", "seen.add", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Finds and returns all imports within the provided code stream. - **input_stream**: The stream of code with imports that need to be sorted. - **config**: The config object to use when sorting imports.", "source_code": "def find_imports_in_stream(\n    input_stream: TextIO,\n    config: Config = DEFAULT_CONFIG,\n    file_path: Path | None = None,\n    unique: bool | ImportKey = False,\n    top_only: bool = False,\n    _seen: set[str] | None = None,\n    **config_kwargs: Any,\n) -> Iterator[identify.Import]:\n    \"\"\"Finds and returns all imports within the provided code stream.\n\n    - **input_stream**: The stream of code with imports that need to be sorted.\n    - **config**: The config object to use when sorting imports.\n    - **file_path**: The disk location where the code string was pulled from.\n    - **unique**: If True, only the first instance of an import is returned.\n    - **top_only**: If True, only return imports that occur before the first function or class.\n    - **_seen**: An optional set of imports already seen. Generally meant only for internal use.\n    - ****config_kwargs**: Any config modifications.\n    \"\"\"\n    config = _config(config=config, **config_kwargs)\n    identified_imports = identify.imports(\n        input_stream, config=config, file_path=file_path, top_only=top_only\n    )\n    if not unique:\n        yield from identified_imports\n\n    seen: set[str] = set() if _seen is None else _seen\n    for identified_import in identified_imports:\n        if unique in (True, ImportKey.ALIAS):\n            key = identified_import.statement()\n        elif unique == ImportKey.ATTRIBUTE:\n            key = f\"{identified_import.module}.{identified_import.attribute}\"\n        elif unique == ImportKey.MODULE:\n            key = identified_import.module\n        elif unique == ImportKey.PACKAGE:  # pragma: no branch # type checking ensures this\n            key = identified_import.module.split(\".\")[0]\n\n        if key and key not in seen:\n            seen.add(key)\n            yield identified_import", "loc": 40}
{"file": "isort\\isort\\api.py", "class_name": null, "function_name": "find_imports_in_file", "parameters": ["filename", "config", "file_path", "unique", "top_only"], "param_types": {"filename": "str | Path", "config": "Config", "file_path": "Path | None", "unique": "bool | ImportKey", "top_only": "bool"}, "return_type": "Iterator[identify.Import]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["find_imports_in_stream", "io.File.read", "warn"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Finds and returns all imports within the provided source file. - **filename**: The name or Path of the file to look for imports in. - **extension**: The file extension that contains imports. Defaults to filename extension or py.", "source_code": "def find_imports_in_file(\n    filename: str | Path,\n    config: Config = DEFAULT_CONFIG,\n    file_path: Path | None = None,\n    unique: bool | ImportKey = False,\n    top_only: bool = False,\n    **config_kwargs: Any,\n) -> Iterator[identify.Import]:\n    \"\"\"Finds and returns all imports within the provided source file.\n\n    - **filename**: The name or Path of the file to look for imports in.\n    - **extension**: The file extension that contains imports. Defaults to filename extension or py.\n    - **config**: The config object to use when sorting imports.\n    - **file_path**: The disk location where the code string was pulled from.\n    - **unique**: If True, only the first instance of an import is returned.\n    - **top_only**: If True, only return imports that occur before the first function or class.\n    - ****config_kwargs**: Any config modifications.\n    \"\"\"\n    try:\n        with io.File.read(filename) as source_file:\n            yield from find_imports_in_stream(\n                input_stream=source_file.stream,\n                config=config,\n                file_path=file_path or source_file.path,\n                unique=unique,\n                top_only=top_only,\n                **config_kwargs,\n            )\n    except OSError as error:\n        warn(f\"Unable to parse file {filename} due to {error}\", stacklevel=2)", "loc": 30}
{"file": "isort\\isort\\api.py", "class_name": null, "function_name": "find_imports_in_paths", "parameters": ["paths", "config", "file_path", "unique", "top_only"], "param_types": {"paths": "Iterator[str | Path]", "config": "Config", "file_path": "Path | None", "unique": "bool | ImportKey", "top_only": "bool"}, "return_type": "Iterator[identify.Import]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_config", "chain", "files.find", "find_imports_in_file", "map", "set"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Finds and returns all imports within the provided source paths. - **paths**: A collection of paths to recursively look for imports within. - **extension**: The file extension that contains imports. Defaults to filename extension or py.", "source_code": "def find_imports_in_paths(\n    paths: Iterator[str | Path],\n    config: Config = DEFAULT_CONFIG,\n    file_path: Path | None = None,\n    unique: bool | ImportKey = False,\n    top_only: bool = False,\n    **config_kwargs: Any,\n) -> Iterator[identify.Import]:\n    \"\"\"Finds and returns all imports within the provided source paths.\n\n    - **paths**: A collection of paths to recursively look for imports within.\n    - **extension**: The file extension that contains imports. Defaults to filename extension or py.\n    - **config**: The config object to use when sorting imports.\n    - **file_path**: The disk location where the code string was pulled from.\n    - **unique**: If True, only the first instance of an import is returned.\n    - **top_only**: If True, only return imports that occur before the first function or class.\n    - ****config_kwargs**: Any config modifications.\n    \"\"\"\n    config = _config(config=config, **config_kwargs)\n    seen: set[str] | None = set() if unique else None\n    yield from chain(\n        *(\n            find_imports_in_file(\n                file_name, unique=unique, config=config, top_only=top_only, _seen=seen\n            )\n            for file_name in files.find(map(str, paths), config, [], [])\n        )\n    )", "loc": 28}
{"file": "isort\\isort\\comments.py", "class_name": null, "function_name": "parse", "parameters": ["line"], "param_types": {"line": "str"}, "return_type": "tuple[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["line.find", "line[comment_start + 1:].strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parses import lines for comments and returns back the import statement and the associated comment.", "source_code": "def parse(line: str) -> tuple[str, str]:\n    \"\"\"Parses import lines for comments and returns back the\n    import statement and the associated comment.\n    \"\"\"\n    comment_start = line.find(\"#\")\n    if comment_start != -1:\n        return (line[:comment_start], line[comment_start + 1 :].strip())\n\n    return (line, \"\")", "loc": 9}
{"file": "isort\\isort\\comments.py", "class_name": null, "function_name": "add_to_line", "parameters": ["comments", "original_string", "removed", "comment_prefix"], "param_types": {"comments": "list[str] | None", "original_string": "str", "removed": "bool", "comment_prefix": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'; '.join", "parse", "unique_comments.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_to_line(\n    comments: list[str] | None,\n    original_string: str = \"\",\n    removed: bool = False,\n    comment_prefix: str = \"\",\n) -> str:\n    \"\"\"Returns a string with comments added if removed is not set.\"\"\"\n    if removed:\n        return parse(original_string)[0]\n\n    if not comments:\n        return original_string\n\n    unique_comments: list[str] = []\n    for comment in comments:\n        if comment not in unique_comments:\n            unique_comments.append(comment)\n    return f\"{parse(original_string)[0]}{comment_prefix} {'; '.join(unique_comments)}\"", "loc": 18}
{"file": "isort\\isort\\format.py", "class_name": null, "function_name": "format_simplified", "parameters": ["import_line"], "param_types": {"import_line": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["import_line.replace", "import_line.startswith", "import_line.strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_simplified(import_line: str) -> str:\n    import_line = import_line.strip()\n    if import_line.startswith(\"from \"):\n        import_line = import_line.replace(\"from \", \"\")\n        import_line = import_line.replace(\" import \", \".\")\n    elif import_line.startswith(\"import \"):\n        import_line = import_line.replace(\"import \", \"\")\n\n    return import_line", "loc": 9}
{"file": "isort\\isort\\format.py", "class_name": null, "function_name": "format_natural", "parameters": ["import_line"], "param_types": {"import_line": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'.'.join", "import_line.split", "import_line.startswith", "import_line.strip", "parts.pop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_natural(import_line: str) -> str:\n    import_line = import_line.strip()\n    if not import_line.startswith(\"from \") and not import_line.startswith(\"import \"):\n        if \".\" not in import_line:\n            return f\"import {import_line}\"\n        parts = import_line.split(\".\")\n        end = parts.pop(-1)\n        return f\"from {'.'.join(parts)} import {end}\"\n\n    return import_line", "loc": 10}
{"file": "isort\\isort\\format.py", "class_name": null, "function_name": "show_unified_diff", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["create_terminal_printer", "datetime.fromtimestamp", "datetime.now", "file_input.splitlines", "file_output.splitlines", "file_path.stat", "printer.diff_line", "str", "unified_diff"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Shows a unified_diff for the provided input and output against the provided file path. - **file_input**: A string that represents the contents of a file before changes. - **file_output**: A string that represents the contents of a file after changes.", "source_code": "def show_unified_diff(\n    *,\n    file_input: str,\n    file_output: str,\n    file_path: Path | None,\n    output: TextIO | None = None,\n    color_output: bool = False,\n) -> None:\n    \"\"\"Shows a unified_diff for the provided input and output against the provided file path.\n\n    - **file_input**: A string that represents the contents of a file before changes.\n    - **file_output**: A string that represents the contents of a file after changes.\n    - **file_path**: A Path object that represents the file path of the file being changed.\n    - **output**: A stream to output the diff to. If non is provided uses sys.stdout.\n    - **color_output**: Use color in output if True.\n    \"\"\"\n    printer = create_terminal_printer(color_output, output)\n    file_name = \"\" if file_path is None else str(file_path)\n    file_mtime = str(\n        datetime.now() if file_path is None else datetime.fromtimestamp(file_path.stat().st_mtime)\n    )\n    unified_diff_lines = unified_diff(\n        file_input.splitlines(keepends=True),\n        file_output.splitlines(keepends=True),\n        fromfile=file_name + \":before\",\n        tofile=file_name + \":after\",\n        fromfiledate=file_mtime,\n        tofiledate=str(datetime.now()),\n    )\n    for line in unified_diff_lines:\n        printer.diff_line(line)", "loc": 31}
{"file": "isort\\isort\\format.py", "class_name": null, "function_name": "ask_whether_to_apply_changes_to_file", "parameters": ["file_path"], "param_types": {"file_path": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["answer.lower", "input", "sys.exit"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ask_whether_to_apply_changes_to_file(file_path: str) -> bool:\n    answer = None\n    while answer not in (\"yes\", \"y\", \"no\", \"n\", \"quit\", \"q\"):\n        answer = input(f\"Apply suggested changes to '{file_path}' [y/n/q]? \")  # nosec\n        answer = answer.lower()\n        if answer in (\"no\", \"n\"):\n            return False\n        if answer in (\"quit\", \"q\"):\n            sys.exit(1)\n    return True", "loc": 10}
{"file": "isort\\isort\\format.py", "class_name": null, "function_name": "create_terminal_printer", "parameters": ["color", "output", "error", "success"], "param_types": {"color": "bool", "output": "TextIO | None", "error": "str", "success": "str"}, "return_type": "BasicPrinter", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BasicPrinter", "ColoramaPrinter", "colorama.init", "print", "sys.exit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_terminal_printer(\n    color: bool, output: TextIO | None = None, error: str = \"\", success: str = \"\"\n) -> BasicPrinter:\n    if color and colorama_unavailable:\n        no_colorama_message = (\n            \"\\n\"\n            \"Sorry, but to use --color (color_output) the colorama python package is required.\\n\\n\"\n            \"Reference: https://pypi.org/project/colorama/\\n\\n\"\n            \"You can either install it separately on your system or as the colors extra \"\n            \"for isort. Ex: \\n\\n\"\n            \"$ pip install isort[colors]\\n\"\n        )\n        print(no_colorama_message, file=sys.stderr)\n        sys.exit(1)\n\n    if not colorama_unavailable:\n        colorama.init(strip=False)\n    return (\n        ColoramaPrinter(error, success, output) if color else BasicPrinter(error, success, output)\n    )", "loc": 20}
{"file": "isort\\isort\\format.py", "class_name": "ColoramaPrinter", "function_name": "diff_line", "parameters": ["self", "line"], "param_types": {"line": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["re.match", "self.output.write", "self.style_text"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def diff_line(self, line: str) -> None:\n    style = None\n    if re.match(ADDED_LINE_PATTERN, line):\n        style = self.ADDED_LINE\n    elif re.match(REMOVED_LINE_PATTERN, line):\n        style = self.REMOVED_LINE\n    self.output.write(self.style_text(line, style))", "loc": 7}
{"file": "isort\\isort\\hooks.py", "class_name": null, "function_name": "get_output", "parameters": ["command"], "param_types": {"command": "list[str]"}, "return_type": "str", "param_doc": {}, "return_doc": "the stdout output of the command", "raises_doc": [], "called_functions": ["result.stdout.decode", "subprocess.run"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Run a command and return raw output", "source_code": "def get_output(command: list[str]) -> str:\n    \"\"\"Run a command and return raw output\n\n    :param str command: the command to run\n    :returns: the stdout output of the command\n    \"\"\"\n    result = subprocess.run(command, stdout=subprocess.PIPE, check=True)  # nosec\n    return result.stdout.decode()", "loc": 8}
{"file": "isort\\isort\\hooks.py", "class_name": null, "function_name": "get_lines", "parameters": ["command"], "param_types": {"command": "list[str]"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "list of whitespace-stripped lines output by command", "raises_doc": [], "called_functions": ["get_output", "line.strip", "stdout.splitlines"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Run a command and return lines of output", "source_code": "def get_lines(command: list[str]) -> list[str]:\n    \"\"\"Run a command and return lines of output\n\n    :param str command: the command to run\n    :returns: list of whitespace-stripped lines output by command\n    \"\"\"\n    stdout = get_output(command)\n    return [line.strip() for line in stdout.splitlines()]", "loc": 8}
{"file": "isort\\isort\\identify.py", "class_name": "Import", "function_name": "statement", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def statement(self) -> str:\n    import_cmd = \"cimport\" if self.cimport else \"import\"\n    if self.attribute:\n        import_string = f\"from {self.module} {import_cmd} {self.attribute}\"\n    else:\n        import_string = f\"{import_cmd} {self.module}\"\n    if self.alias:\n        import_string += f\" as {self.alias}\"\n    return import_string", "loc": 9}
{"file": "isort\\isort\\io.py", "class_name": "File", "function_name": "detect_encoding", "parameters": ["filename", "readline"], "param_types": {"filename": "str | Path", "readline": "Callable[[], bytes]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["UnsupportedEncoding", "tokenize.detect_encoding"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def detect_encoding(filename: str | Path, readline: Callable[[], bytes]) -> str:\n    try:\n        return tokenize.detect_encoding(readline)[0]\n    except Exception:\n        raise UnsupportedEncoding(filename)", "loc": 5}
{"file": "isort\\isort\\literal.py", "class_name": null, "function_name": "assignments", "parameters": ["code"], "param_types": {"code": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "AssignmentsFormatMismatch", "code.splitlines", "line.split", "line.strip", "sorted", "values.keys"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def assignments(code: str) -> str:\n    values = {}\n    for line in code.splitlines(keepends=True):\n        if not line.strip():\n            continue\n        if \" = \" not in line:\n            raise AssignmentsFormatMismatch(code)\n        variable_name, value = line.split(\" = \", 1)\n        values[variable_name] = value\n\n    return \"\".join(\n        f\"{variable_name} = {values[variable_name]}\" for variable_name in sorted(values.keys())\n    )", "loc": 13}
{"file": "isort\\isort\\literal.py", "class_name": null, "function_name": "assignment", "parameters": ["code", "sort_type", "extension", "config"], "param_types": {"code": "str", "sort_type": "str", "extension": "str", "config": "Config"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "ISortPrettyPrinter", "LiteralParsingFailure", "LiteralSortTypeMismatch", "ValueError", "assignments", "ast.literal_eval", "code.rstrip", "code.split", "config.formatting_function", "config.formatting_function(sorted_value_code, extension, config).rstrip", "len", "literal.lstrip", "sort_function", "type", "type_mapping.keys", "variable_name.strip"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Sorts the literal present within the provided code against the provided sort type, returning the sorted representation of the source code.", "source_code": "def assignment(code: str, sort_type: str, extension: str, config: Config = DEFAULT_CONFIG) -> str:\n    \"\"\"Sorts the literal present within the provided code against the provided sort type,\n    returning the sorted representation of the source code.\n    \"\"\"\n    if sort_type == \"assignments\":\n        return assignments(code)\n    if sort_type not in type_mapping:\n        raise ValueError(\n            \"Trying to sort using an undefined sort_type. \"\n            f\"Defined sort types are {', '.join(type_mapping.keys())}.\"\n        )\n\n    variable_name, literal = code.split(\"=\")\n    variable_name = variable_name.strip()\n    literal = literal.lstrip()\n    try:\n        value = ast.literal_eval(literal)\n    except Exception as error:\n        raise LiteralParsingFailure(code, error)\n\n    expected_type, sort_function = type_mapping[sort_type]\n    if type(value) is not expected_type:\n        raise LiteralSortTypeMismatch(type(value), expected_type)\n\n    printer = ISortPrettyPrinter(config)\n    sorted_value_code = f\"{variable_name} = {sort_function(value, printer)}\"\n    if config.formatting_function:\n        sorted_value_code = config.formatting_function(\n            sorted_value_code, extension, config\n        ).rstrip()\n\n    sorted_value_code += code[len(code.rstrip()) :]\n    return sorted_value_code", "loc": 33}
{"file": "isort\\isort\\main.py", "class_name": null, "function_name": "sort_imports", "parameters": ["file_name", "config", "check", "ask_to_apply", "write_to_stdout"], "param_types": {"file_name": "str", "config": "Config", "check": "bool", "ask_to_apply": "bool", "write_to_stdout": "bool"}, "return_type": "SortAttempt | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SortAttempt", "_print_hard_fail", "api.check_file", "api.sort_file", "str", "sys.exit", "warn"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def sort_imports(\n    file_name: str,\n    config: Config,\n    check: bool = False,\n    ask_to_apply: bool = False,\n    write_to_stdout: bool = False,\n    **kwargs: Any,\n) -> SortAttempt | None:\n    incorrectly_sorted: bool = False\n    skipped: bool = False\n    try:\n        if check:\n            try:\n                incorrectly_sorted = not api.check_file(file_name, config=config, **kwargs)\n            except FileSkipped:\n                skipped = True\n            return SortAttempt(incorrectly_sorted, skipped, True)\n\n        try:\n            incorrectly_sorted = not api.sort_file(\n                file_name,\n                config=config,\n                ask_to_apply=ask_to_apply,\n                write_to_stdout=write_to_stdout,\n                **kwargs,\n            )\n        except FileSkipped:\n            skipped = True\n        return SortAttempt(incorrectly_sorted, skipped, True)\n    except (OSError, ValueError) as error:\n        warn(f\"Unable to parse file {file_name} due to {error}\", stacklevel=2)\n        return None\n    except UnsupportedEncoding:\n        if config.verbose:\n            warn(f\"Encoding not supported for {file_name}\", stacklevel=2)\n        return SortAttempt(incorrectly_sorted, skipped, False)\n    except ISortError as error:\n        _print_hard_fail(config, message=str(error))\n        sys.exit(1)\n    except Exception:\n        _print_hard_fail(config, offending_file=file_name)\n        raise", "loc": 42}
{"file": "isort\\isort\\main.py", "class_name": null, "function_name": "parse_args", "parameters": ["argv"], "param_types": {"argv": "Sequence[str] | None"}, "return_type": "dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["WrapModes", "_build_arg_parser", "arguments.get", "enumerate", "int", "list", "multi_line_output.isdigit", "parser.parse_args", "remapped_deprecated_args.append", "sys.exit", "vars", "vars(parser.parse_args(argv)).items"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_args(argv: Sequence[str] | None = None) -> dict[str, Any]:\n    argv = sys.argv[1:] if argv is None else list(argv)\n    remapped_deprecated_args = []\n    for index, arg in enumerate(argv):\n        if arg in DEPRECATED_SINGLE_DASH_ARGS:\n            remapped_deprecated_args.append(arg)\n            argv[index] = f\"-{arg}\"\n\n    parser = _build_arg_parser()\n    arguments = {key: value for key, value in vars(parser.parse_args(argv)).items() if value}\n    if remapped_deprecated_args:\n        arguments[\"remapped_deprecated_args\"] = remapped_deprecated_args\n    if \"dont_order_by_type\" in arguments:\n        arguments[\"order_by_type\"] = False\n        del arguments[\"dont_order_by_type\"]\n    if \"dont_follow_links\" in arguments:\n        arguments[\"follow_links\"] = False\n        del arguments[\"dont_follow_links\"]\n    if \"dont_float_to_top\" in arguments:\n        del arguments[\"dont_float_to_top\"]\n        if arguments.get(\"float_to_top\", False):\n            sys.exit(\"Can't set both --float-to-top and --dont-float-to-top.\")\n        else:\n            arguments[\"float_to_top\"] = False\n    multi_line_output = arguments.get(\"multi_line_output\", None)\n    if multi_line_output:\n        if multi_line_output.isdigit():\n            arguments[\"multi_line_output\"] = WrapModes(int(multi_line_output))\n        else:\n            arguments[\"multi_line_output\"] = WrapModes[multi_line_output]\n\n    return arguments", "loc": 32}
{"file": "isort\\isort\\main.py", "class_name": null, "function_name": "identify_imports_main", "parameters": ["argv", "stdin"], "param_types": {"argv": "Sequence[str] | None", "stdin": "TextIOWrapper | None"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["api.find_imports_in_paths", "api.find_imports_in_stream", "argparse.ArgumentParser", "identified_import.module.split", "parser.add_argument", "parser.add_argument_group", "parser.add_mutually_exclusive_group", "parser.parse_args", "print", "str", "target_group.add_argument", "uniqueness.add_argument"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def identify_imports_main(\n    argv: Sequence[str] | None = None, stdin: TextIOWrapper | None = None\n) -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Get all import definitions from a given file.\"\n        \"Use `-` as the first argument to represent stdin.\"\n    )\n    parser.add_argument(\n        \"files\", nargs=\"+\", help=\"One or more Python source files that need their imports sorted.\"\n    )\n    parser.add_argument(\n        \"--top-only\",\n        action=\"store_true\",\n        default=False,\n        help=\"Only identify imports that occur in before functions or classes.\",\n    )\n\n    target_group = parser.add_argument_group(\"target options\")\n    target_group.add_argument(\n        \"--follow-links\",\n        action=\"store_true\",\n        default=False,\n        help=\"Tells isort to follow symlinks that are encountered when running recursively.\",\n    )\n\n    uniqueness = parser.add_mutually_exclusive_group()\n    uniqueness.add_argument(\n        \"--unique\",\n        action=\"store_true\",\n        default=False,\n        help=\"If true, isort will only identify unique imports.\",\n    )\n    uniqueness.add_argument(\n        \"--packages\",\n        dest=\"unique\",\n        action=\"store_const\",\n        const=api.ImportKey.PACKAGE,\n        default=False,\n        help=\"If true, isort will only identify the unique top level modules imported.\",\n    )\n    uniqueness.add_argument(\n        \"--modules\",\n        dest=\"unique\",\n        action=\"store_const\",\n        const=api.ImportKey.MODULE,\n        default=False,\n        help=\"If true, isort will only identify the unique modules imported.\",\n    )\n    uniqueness.add_argument(\n        \"--attributes\",\n        dest=\"unique\",\n        action=\"store_const\",\n        const=api.ImportKey.ATTRIBUTE,\n        default=False,\n        help=\"If true, isort will only identify the unique attributes imported.\",\n    )\n\n    arguments = parser.parse_args(argv)\n\n    file_names = arguments.files\n    if file_names == [\"-\"]:\n        identified_imports = api.find_imports_in_stream(\n            sys.stdin if stdin is None else stdin,\n            unique=arguments.unique,\n            top_only=arguments.top_only,\n            follow_links=arguments.follow_links,\n        )\n    else:\n        identified_imports = api.find_imports_in_paths(\n            file_names,\n            unique=arguments.unique,\n            top_only=arguments.top_only,\n            follow_links=arguments.follow_links,\n        )\n\n    for identified_import in identified_imports:\n        if arguments.unique == api.ImportKey.PACKAGE:\n            print(identified_import.module.split(\".\")[0])\n        elif arguments.unique == api.ImportKey.MODULE:\n            print(identified_import.module)\n        elif arguments.unique == api.ImportKey.ATTRIBUTE:\n            print(f\"{identified_import.module}.{identified_import.attribute}\")\n        else:\n            print(str(identified_import))", "loc": 84}
{"file": "isort\\isort\\parse.py", "class_name": null, "function_name": "normalize_line", "parameters": ["raw_line"], "param_types": {"raw_line": "str"}, "return_type": "tuple[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["line.replace", "re.sub"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Normalizes import related statements in the provided line.", "source_code": "def normalize_line(raw_line: str) -> tuple[str, str]:\n    \"\"\"Normalizes import related statements in the provided line.\n\n    Returns (normalized_line: str, raw_line: str)\n    \"\"\"\n    line = re.sub(r\"from(\\.+)cimport \", r\"from \\g<1> cimport \", raw_line)\n    line = re.sub(r\"from(\\.+)import \", r\"from \\g<1> import \", line)\n    line = line.replace(\"import*\", \"import *\")\n    line = re.sub(r\" (\\.+)import \", r\" \\g<1> import \", line)\n    line = re.sub(r\" (\\.+)cimport \", r\" \\g<1> cimport \", line)\n    line = line.replace(\"\\t\", \" \")\n    return line, raw_line", "loc": 12}
{"file": "isort\\isort\\parse.py", "class_name": null, "function_name": "import_type", "parameters": ["line", "config"], "param_types": {"line": "str", "config": "Config"}, "return_type": "str | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["line.lower", "line.lower().rstrip", "line.lower().rstrip().endswith", "line.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "If the current line is an import line it will return its type (from or straight)", "source_code": "def import_type(line: str, config: Config = DEFAULT_CONFIG) -> str | None:\n    \"\"\"If the current line is an import line it will return its type (from or straight)\"\"\"\n    if config.honor_noqa and line.lower().rstrip().endswith(\"noqa\"):\n        return None\n    if \"isort:skip\" in line or \"isort: skip\" in line or \"isort: split\" in line:\n        return None\n    if line.startswith((\"import \", \"cimport \")):\n        return \"straight\"\n    if line.startswith(\"from \"):\n        return \"from\"\n    return None", "loc": 11}
{"file": "isort\\isort\\parse.py", "class_name": null, "function_name": "strip_syntax", "parameters": ["import_string"], "param_types": {"import_string": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "import_list.remove", "import_string.replace", "import_string.replace('{ ', '{|').replace", "import_string.split"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def strip_syntax(import_string: str) -> str:\n    import_string = import_string.replace(\"_import\", \"[[i]]\")\n    import_string = import_string.replace(\"_cimport\", \"[[ci]]\")\n    for remove_syntax in [\"\\\\\", \"(\", \")\", \",\"]:\n        import_string = import_string.replace(remove_syntax, \" \")\n    import_list = import_string.split()\n    for key in (\"from\", \"import\", \"cimport\"):\n        if key in import_list:\n            import_list.remove(key)\n    import_string = \" \".join(import_list)\n    import_string = import_string.replace(\"[[i]]\", \"_import\")\n    import_string = import_string.replace(\"[[ci]]\", \"_cimport\")\n    return import_string.replace(\"{ \", \"{|\").replace(\" }\", \"|}\")", "loc": 13}
{"file": "isort\\isort\\parse.py", "class_name": null, "function_name": "skip_line", "parameters": ["line", "in_quote", "index", "section_comments", "needs_import"], "param_types": {"line": "str", "in_quote": "str", "index": "int", "section_comments": "tuple[str, ...]", "needs_import": "bool"}, "return_type": "tuple[bool, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bool", "len", "line.split", "part.startswith", "part.strip"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "Determine if a given line should be skipped.", "source_code": "def skip_line(\n    line: str,\n    in_quote: str,\n    index: int,\n    section_comments: tuple[str, ...],\n    needs_import: bool = True,\n) -> tuple[bool, str]:\n    \"\"\"Determine if a given line should be skipped.\n\n    Returns back a tuple containing:\n\n    (skip_line: bool,\n     in_quote: str,)\n    \"\"\"\n    should_skip = bool(in_quote)\n    if '\"' in line or \"'\" in line:\n        char_index = 0\n        while char_index < len(line):\n            if line[char_index] == \"\\\\\":\n                char_index += 1\n            elif in_quote:\n                if line[char_index : char_index + len(in_quote)] == in_quote:\n                    in_quote = \"\"\n            elif line[char_index] in (\"'\", '\"'):\n                long_quote = line[char_index : char_index + 3]\n                if long_quote in ('\"\"\"', \"'''\"):\n                    in_quote = long_quote\n                    char_index += 2\n                else:\n                    in_quote = line[char_index]\n            elif line[char_index] == \"#\":\n                break\n            char_index += 1\n\n    if \";\" in line.split(\"#\")[0] and needs_import:\n        for part in (part.strip() for part in line.split(\";\")):\n            if (\n                part\n                and not part.startswith(\"from \")\n                and not part.startswith((\"import \", \"cimport \"))\n            ):\n                should_skip = True\n\n    return (bool(should_skip or in_quote), in_quote)", "loc": 44}
{"file": "isort\\isort\\place.py", "class_name": null, "function_name": "module_with_reason", "parameters": ["name", "config"], "param_types": {"name": "str", "config": "Config"}, "return_type": "tuple[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_forced_separate", "_known_pattern", "_local", "_src_path", "lru_cache"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def module_with_reason(name: str, config: Config = DEFAULT_CONFIG) -> tuple[str, str]:\n    \"\"\"Returns the section placement for the given module name alongside the reasoning.\"\"\"\n    return (\n        _forced_separate(name, config)\n        or _local(name, config)\n        or _known_pattern(name, config)\n        or _src_path(name, config)\n        or (config.default_section, \"Default option in Config or universal default.\")\n    )", "loc": 9}
{"file": "isort\\isort\\settings.py", "class_name": "Config", "function_name": "known_patterns", "parameters": ["self"], "param_types": {}, "return_type": "list[tuple[Pattern[str], str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["KNOWN_SECTION_MAPPING.get", "KNOWN_SECTION_MAPPING.get(placement, placement).lower", "getattr", "known_pattern.replace", "known_pattern.replace('*', '.*').replace", "re.compile", "reversed", "self._known_patterns.append", "self._parse_known_pattern", "self.known_other.get", "set", "set(extra_modules).union"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def known_patterns(self) -> list[tuple[Pattern[str], str]]:\n    if self._known_patterns is not None:\n        return self._known_patterns\n\n    self._known_patterns = []\n    pattern_sections = [STDLIB] + [section for section in self.sections if section != STDLIB]\n    for placement in reversed(pattern_sections):\n        known_placement = KNOWN_SECTION_MAPPING.get(placement, placement).lower()\n        config_key = f\"{KNOWN_PREFIX}{known_placement}\"\n        known_modules = getattr(self, config_key, self.known_other.get(known_placement, ()))\n        extra_modules = getattr(self, f\"extra_{known_placement}\", ())\n        all_modules = set(extra_modules).union(known_modules)\n        known_patterns = [\n            pattern\n            for known_pattern in all_modules\n            for pattern in self._parse_known_pattern(known_pattern)\n        ]\n        for known_pattern in known_patterns:\n            regexp = \"^\" + known_pattern.replace(\"*\", \".*\").replace(\"?\", \".?\") + \"$\"\n            self._known_patterns.append((re.compile(regexp), placement))\n\n    return self._known_patterns", "loc": 22}
{"file": "isort\\isort\\settings.py", "class_name": "Config", "function_name": "section_comments", "parameters": ["self"], "param_types": {}, "return_type": "tuple[str, ...]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.import_headings.values", "tuple"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def section_comments(self) -> tuple[str, ...]:\n    if self._section_comments is not None:\n        return self._section_comments\n\n    self._section_comments = tuple(f\"# {heading}\" for heading in self.import_headings.values())\n    return self._section_comments", "loc": 6}
{"file": "isort\\isort\\settings.py", "class_name": "Config", "function_name": "section_comments_end", "parameters": ["self"], "param_types": {}, "return_type": "tuple[str, ...]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.import_footers.values", "tuple"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def section_comments_end(self) -> tuple[str, ...]:\n    if self._section_comments_end is not None:\n        return self._section_comments_end\n\n    self._section_comments_end = tuple(f\"# {footer}\" for footer in self.import_footers.values())\n    return self._section_comments_end", "loc": 6}
{"file": "isort\\isort\\settings.py", "class_name": "Config", "function_name": "skips", "parameters": ["self"], "param_types": {}, "return_type": "frozenset[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.skip.union"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def skips(self) -> frozenset[str]:\n    if self._skips is not None:\n        return self._skips\n\n    self._skips = self.skip.union(self.extend_skip)\n    return self._skips", "loc": 6}
{"file": "isort\\isort\\settings.py", "class_name": "Config", "function_name": "skip_globs", "parameters": ["self"], "param_types": {}, "return_type": "frozenset[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.skip_glob.union"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def skip_globs(self) -> frozenset[str]:\n    if self._skip_globs is not None:\n        return self._skip_globs\n\n    self._skip_globs = self.skip_glob.union(self.extend_skip_glob)\n    return self._skip_globs", "loc": 6}
{"file": "isort\\isort\\settings.py", "class_name": "Config", "function_name": "sorting_function", "parameters": ["self"], "param_types": {}, "return_type": "Callable[..., list[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SortingFunctionDoesNotExist", "available_sort_orders.append", "entry_points", "sort_plugin.load"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def sorting_function(self) -> Callable[..., list[str]]:\n    if self._sorting_function is not None:\n        return self._sorting_function\n\n    if self.sort_order == \"natural\":\n        self._sorting_function = sorting.naturally\n    elif self.sort_order == \"native\":\n        self._sorting_function = sorted\n    else:\n        available_sort_orders = [\"natural\", \"native\"]\n        for sort_plugin in entry_points(group=\"isort.sort_function\"):\n            available_sort_orders.append(sort_plugin.name)\n            if sort_plugin.name == self.sort_order:\n                self._sorting_function = sort_plugin.load()\n                break\n        else:\n            raise SortingFunctionDoesNotExist(self.sort_order, available_sort_orders)\n\n    return self._sorting_function", "loc": 19}
{"file": "isort\\isort\\setuptools_commands.py", "class_name": "ISortCommand", "function_name": "distribution_files", "parameters": ["self"], "param_types": {}, "return_type": "Iterator[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["pkg_dir.replace"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Find distribution packages.", "source_code": "def distribution_files(self) -> Iterator[str]:\n    \"\"\"Find distribution packages.\"\"\"\n    # This is verbatim from flake8\n    if self.distribution.packages:  # pragma: no cover\n        package_dirs = self.distribution.package_dir or {}\n        for package in self.distribution.packages:\n            pkg_dir = package\n            if package in package_dirs:\n                pkg_dir = package_dirs[package]\n            elif \"\" in package_dirs:  # pragma: no cover\n                pkg_dir = package_dirs[\"\"] + os.path.sep + pkg_dir\n            yield pkg_dir.replace(\".\", os.path.sep)\n\n    if self.distribution.py_modules:\n        for filename in self.distribution.py_modules:\n            yield f\"{filename}.py\"\n    # Don't miss the setup.py file itself\n    yield \"setup.py\"", "loc": 18}
{"file": "isort\\isort\\sorting.py", "class_name": null, "function_name": "module_key", "parameters": ["module_name", "config", "sub_imports", "ignore_case", "section_name", "straight_import"], "param_types": {"module_name": "str", "config": "Config", "sub_imports": "bool", "ignore_case": "bool", "section_name": "Any | None", "straight_import": "bool | None"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "match.groups", "module_name.isupper", "module_name.lower", "module_name[0:1].isupper", "re.match", "sep.join", "str", "str(module_name).lower", "str(section_name).lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def module_key(\n    module_name: str,\n    config: Config,\n    sub_imports: bool = False,\n    ignore_case: bool = False,\n    section_name: Any | None = None,\n    straight_import: bool | None = False,\n) -> str:\n    match = re.match(r\"^(\\.+)\\s*(.*)\", module_name)\n    if match:\n        sep = \" \" if config.reverse_relative else \"_\"\n        module_name = sep.join(match.groups())\n\n    prefix = \"\"\n    if ignore_case:\n        module_name = str(module_name).lower()\n    else:\n        module_name = str(module_name)\n\n    if sub_imports and config.order_by_type:\n        if module_name in config.constants:\n            prefix = \"A\"\n        elif module_name in config.classes:\n            prefix = \"B\"\n        elif module_name in config.variables:\n            prefix = \"C\"\n        elif module_name.isupper() and len(module_name) > 1:  # see issue #376\n            prefix = \"A\"\n        elif module_name in config.classes or module_name[0:1].isupper():\n            prefix = \"B\"\n        else:\n            prefix = \"C\"\n    if not config.case_sensitive:\n        module_name = module_name.lower()\n\n    length_sort = (\n        config.length_sort\n        or (config.length_sort_straight and straight_import)\n        or str(section_name).lower() in config.length_sort_sections\n    )\n    _length_sort_maybe = (str(len(module_name)) + \":\" + module_name) if length_sort else module_name\n    return f\"{(module_name in config.force_to_top and 'A') or 'B'}{prefix}{_length_sort_maybe}\"", "loc": 42}
{"file": "isort\\isort\\sorting.py", "class_name": null, "function_name": "section_key", "parameters": ["line", "config"], "param_types": {"line": "str", "config": "Config"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "_import_line_intro_re.sub", "_import_line_midline_import_re.sub", "len", "line.lower", "line.split", "line.startswith", "line.strip", "line.strip().startswith", "match.groups", "module_name.lower", "names.lower", "re.match", "re.sub"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def section_key(line: str, config: Config) -> str:\n    section = \"B\"\n\n    if (\n        not config.sort_relative_in_force_sorted_sections\n        and config.reverse_relative\n        and line.startswith(\"from .\")\n    ):\n        match = re.match(r\"^from (\\.+)\\s*(.*)\", line)\n        if match:  # pragma: no cover - regex always matches if line starts with \"from .\"\n            line = f\"from {' '.join(match.groups())}\"\n    if config.group_by_package and line.strip().startswith(\"from\"):\n        line = line.split(\" import \", 1)[0]\n\n    if config.lexicographical:\n        line = _import_line_intro_re.sub(\"\", _import_line_midline_import_re.sub(\".\", line))\n    else:\n        line = re.sub(\"^from \", \"\", line)\n        line = re.sub(\"^import \", \"\", line)\n    if config.sort_relative_in_force_sorted_sections:\n        sep = \" \" if config.reverse_relative else \"_\"\n        line = re.sub(r\"^(\\.+)\", rf\"\\1{sep}\", line)\n    if line.split(\" \")[0] in config.force_to_top:\n        section = \"A\"\n    # * If honor_case_in_force_sorted_sections is true, and case_sensitive and\n    #   order_by_type are different, only ignore case in part of the line.\n    # * Otherwise, let order_by_type decide the sorting of the whole line. This\n    #   is only \"correct\" if case_sensitive and order_by_type have the same value.\n    if config.honor_case_in_force_sorted_sections and config.case_sensitive != config.order_by_type:\n        split_module = line.split(\" import \", 1)\n        if len(split_module) > 1:\n            module_name, names = split_module\n            if not config.case_sensitive:\n                module_name = module_name.lower()\n            if not config.order_by_type:\n                names = names.lower()\n            line = f\"{module_name} import {names}\"\n        elif not config.case_sensitive:\n            line = line.lower()\n    elif not config.order_by_type:\n        line = line.lower()\n\n    return f\"{section}{len(line) if config.length_sort else ''}{line}\"", "loc": 43}
{"file": "isort\\isort\\sorting.py", "class_name": null, "function_name": "naturally", "parameters": ["to_sort", "key", "reverse"], "param_types": {"to_sort": "Iterable[str]", "key": "Callable[[str], Any] | None", "reverse": "bool"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_natural_keys", "key", "sorted"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def naturally(\n    to_sort: Iterable[str], key: Callable[[str], Any] | None = None, reverse: bool = False\n) -> list[str]:\n    \"\"\"Returns a naturally sorted list\"\"\"\n    if key is None:\n        key_callback = _natural_keys\n    else:\n\n        def key_callback(text: str) -> list[Any]:\n            return _natural_keys(key(text))\n\n    return sorted(to_sort, key=key_callback, reverse=reverse)", "loc": 12}
{"file": "isort\\isort\\utils.py", "class_name": "Trie", "function_name": "insert", "parameters": ["self", "config_file", "config_data"], "param_types": {"config_file": "str", "config_data": "dict[str, Any]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "Path(config_file).parent.resolve", "TrieNode"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def insert(self, config_file: str, config_data: dict[str, Any]) -> None:\n    resolved_config_path_as_tuple = Path(config_file).parent.resolve().parts\n\n    temp = self.root\n\n    for path in resolved_config_path_as_tuple:\n        if path not in temp.nodes:\n            temp.nodes[path] = TrieNode()\n\n        temp = temp.nodes[path]\n\n    temp.config_info = (config_file, config_data)", "loc": 12}
{"file": "isort\\isort\\utils.py", "class_name": "Trie", "function_name": "search", "parameters": ["self", "filename"], "param_types": {"filename": "str"}, "return_type": "tuple[str, dict[str, Any]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "Path(filename).resolve"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def search(self, filename: str) -> tuple[str, dict[str, Any]]:\n    \"\"\"\n    Returns the closest config relative to filename by doing a depth\n    first search on the prefix tree.\n    \"\"\"\n    resolved_file_path_as_tuple = Path(filename).resolve().parts\n\n    temp = self.root\n\n    last_stored_config: tuple[str, dict[str, Any]] = (\"\", {})\n\n    for path in resolved_file_path_as_tuple:\n        if temp.config_info[0]:\n            last_stored_config = temp.config_info\n\n        if path not in temp.nodes:\n            break\n\n        temp = temp.nodes[path]\n\n    return last_stored_config", "loc": 21}
{"file": "isort\\isort\\wrap.py", "class_name": null, "function_name": "import_statement", "parameters": ["import_start", "from_imports", "comments", "line_separator", "config", "multi_line_output", "explode"], "param_types": {"import_start": "str", "from_imports": "list[str]", "comments": "Sequence[str]", "line_separator": "str", "config": "Config", "multi_line_output": "Modes | None", "explode": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_wrap_line", "copy.copy", "formatter", "formatter_from_string", "len", "min", "new_import_statement.split", "statement.count", "statement.split"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def import_statement(\n    import_start: str,\n    from_imports: list[str],\n    comments: Sequence[str] = (),\n    line_separator: str = \"\\n\",\n    config: Config = DEFAULT_CONFIG,\n    multi_line_output: Modes | None = None,\n    explode: bool = False,\n) -> str:\n    \"\"\"Returns a multi-line wrapped form of the provided from import statement.\"\"\"\n    if explode:\n        formatter = vertical_hanging_indent\n        line_length = 1\n        include_trailing_comma = True\n    else:\n        formatter = formatter_from_string((multi_line_output or config.multi_line_output).name)\n        line_length = config.wrap_length or config.line_length\n        include_trailing_comma = config.include_trailing_comma\n    dynamic_indent = \" \" * (len(import_start) + 1)\n    indent = config.indent\n    statement = formatter(\n        statement=import_start,\n        imports=copy.copy(from_imports),\n        white_space=dynamic_indent,\n        indent=indent,\n        line_length=line_length,\n        comments=comments,\n        line_separator=line_separator,\n        comment_prefix=config.comment_prefix,\n        include_trailing_comma=include_trailing_comma,\n        remove_comments=config.ignore_comments,\n    )\n    if config.balanced_wrapping:\n        lines = statement.split(line_separator)\n        line_count = len(lines)\n        if len(lines) > 1:\n            minimum_length = min(len(line) for line in lines[:-1])\n        else:\n            minimum_length = 0\n        new_import_statement = statement\n        while len(lines[-1]) < minimum_length and len(lines) == line_count and line_length > 10:\n            statement = new_import_statement\n            line_length -= 1\n            new_import_statement = formatter(\n                statement=import_start,\n                imports=copy.copy(from_imports),\n                white_space=dynamic_indent,\n                indent=indent,\n                line_length=line_length,\n                comments=comments,\n                line_separator=line_separator,\n                comment_prefix=config.comment_prefix,\n                include_trailing_comma=include_trailing_comma,\n                remove_comments=config.ignore_comments,\n            )\n            lines = new_import_statement.split(line_separator)\n    if statement.count(line_separator) == 0:\n        return _wrap_line(statement, line_separator, config)\n    return statement", "loc": 59}
{"file": "isort\\isort\\wrap.py", "class_name": null, "function_name": "line", "parameters": ["content", "line_separator", "config"], "param_types": {"content": "str", "line_separator": "str", "config": "Config"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_wrap_line", "cont_line.lstrip", "cont_line.rstrip", "content.split", "len", "line_parts.pop", "line_parts[-1].strip", "line_separator.join", "line_without_comment.rstrip", "line_without_comment.rstrip().endswith", "line_without_comment.strip", "line_without_comment.strip().startswith", "lines[-1].endswith", "lines[-1].split", "next_line.append", "next_line.pop", "output.split", "re.escape", "re.search", "re.split", "splitter.join", "splitter.join(next_line).lstrip"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def line(content: str, line_separator: str, config: Config = DEFAULT_CONFIG) -> str:\n    \"\"\"Returns a line wrapped to the specified line-length, if possible.\"\"\"\n    wrap_mode = config.multi_line_output\n    if len(content) > config.line_length and wrap_mode != Modes.NOQA:  # type: ignore\n        line_without_comment = content\n        comment = None\n        if \"#\" in content:\n            line_without_comment, comment = content.split(\"#\", 1)\n        for splitter in (\"import \", \"cimport \", \".\", \"as \"):\n            exp = r\"\\b\" + re.escape(splitter) + r\"\\b\"\n            if re.search(exp, line_without_comment) and not line_without_comment.strip().startswith(\n                splitter\n            ):\n                line_parts = re.split(exp, line_without_comment)\n                if comment and not (config.use_parentheses and \"noqa\" in comment):\n                    _comma_maybe = (\n                        \",\"\n                        if (\n                            config.include_trailing_comma\n                            and config.use_parentheses\n                            and not line_without_comment.rstrip().endswith(\",\")\n                        )\n                        else \"\"\n                    )\n                    line_parts[-1] = (\n                        f\"{line_parts[-1].strip()}{_comma_maybe}{config.comment_prefix}{comment}\"\n                    )\n                next_line = []\n                while (len(content) + 2) > (\n                    config.wrap_length or config.line_length\n                ) and line_parts:\n                    next_line.append(line_parts.pop())\n                    content = splitter.join(line_parts)\n                if not content:\n                    content = next_line.pop()\n\n                cont_line = _wrap_line(\n                    config.indent + splitter.join(next_line).lstrip(),\n                    line_separator,\n                    config,\n                )\n                if config.use_parentheses:\n                    if splitter == \"as \":\n                        output = f\"{content}{splitter}{cont_line.lstrip()}\"\n                    else:\n                        _comma = \",\" if config.include_trailing_comma and not comment else \"\"\n\n                        if wrap_mode in (\n                            Modes.VERTICAL_HANGING_INDENT,  # type: ignore\n                            Modes.VERTICAL_GRID_GROUPED,  # type: ignore\n                        ):\n                            _separator = line_separator\n                        else:\n                            _separator = \"\"\n                        noqa_comment = \"\"\n                        if comment and \"noqa\" in comment:\n                            noqa_comment = f\"{config.comment_prefix}{comment}\"\n                            cont_line = cont_line.rstrip()\n                            _comma = \",\" if config.include_trailing_comma else \"\"\n                        output = (\n                            f\"{content}{splitter}({noqa_comment}\"\n                            f\"{line_separator}{cont_line}{_comma}{_separator})\"\n                        )\n                        lines = output.split(line_separator)\n                        if config.comment_prefix in lines[-1] and lines[-1].endswith(\")\"):\n                            content, comment = lines[-1].split(config.comment_prefix, 1)\n                            lines[-1] = content + \")\" + config.comment_prefix + comment[:-1]\n                        output = line_separator.join(lines)\n                    return output\n                return f\"{content}{splitter}\\\\{line_separator}{cont_line}\"\n    elif len(content) > config.line_length and wrap_mode == Modes.NOQA and \"# NOQA\" not in content:  # type: ignore\n        return f\"{content}{config.comment_prefix} NOQA\"\n\n    return content", "loc": 74}
{"file": "isort\\isort\\wrap_modes.py", "class_name": null, "function_name": "grid", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["interface['imports'].pop", "interface['line_separator'].join", "isort.comments.add_to_line", "len", "lines.append", "next_import.split", "next_statement.split"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def grid(**interface: Any) -> str:\n    if not interface[\"imports\"]:\n        return \"\"\n\n    interface[\"statement\"] += \"(\" + interface[\"imports\"].pop(0)\n    while interface[\"imports\"]:\n        next_import = interface[\"imports\"].pop(0)\n        next_statement = isort.comments.add_to_line(\n            interface[\"comments\"],\n            interface[\"statement\"] + \", \" + next_import,\n            removed=interface[\"remove_comments\"],\n            comment_prefix=interface[\"comment_prefix\"],\n        )\n        if (\n            len(next_statement.split(interface[\"line_separator\"])[-1]) + 1\n            > interface[\"line_length\"]\n        ):\n            lines = [f\"{interface['white_space']}{next_import.split(' ')[0]}\"]\n            for part in next_import.split(\" \")[1:]:\n                new_line = f\"{lines[-1]} {part}\"\n                if len(new_line) + 1 > interface[\"line_length\"]:\n                    lines.append(f\"{interface['white_space']}{part}\")\n                else:\n                    lines[-1] = new_line\n            next_import = interface[\"line_separator\"].join(lines)\n            interface[\"statement\"] = (\n                isort.comments.add_to_line(\n                    interface[\"comments\"],\n                    f\"{interface['statement']},\",\n                    removed=interface[\"remove_comments\"],\n                    comment_prefix=interface[\"comment_prefix\"],\n                )\n                + f\"{interface['line_separator']}{next_import}\"\n            )\n            interface[\"comments\"] = []\n        else:\n            interface[\"statement\"] += \", \" + next_import\n    return f\"{interface['statement']}{',' if interface['include_trailing_comma'] else ''})\"", "loc": 38}
{"file": "isort\\isort\\wrap_modes.py", "class_name": null, "function_name": "vertical", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["',' + interface['line_separator'] + interface['white_space'].join", "interface['imports'].pop", "isort.comments.add_to_line"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def vertical(**interface: Any) -> str:\n    if not interface[\"imports\"]:\n        return \"\"\n\n    first_import = (\n        isort.comments.add_to_line(\n            interface[\"comments\"],\n            interface[\"imports\"].pop(0) + \",\",\n            removed=interface[\"remove_comments\"],\n            comment_prefix=interface[\"comment_prefix\"],\n        )\n        + interface[\"line_separator\"]\n        + interface[\"white_space\"]\n    )\n\n    _imports = (\",\" + interface[\"line_separator\"] + interface[\"white_space\"]).join(\n        interface[\"imports\"]\n    )\n    _comma_maybe = \",\" if interface[\"include_trailing_comma\"] else \"\"\n    return f\"{interface['statement']}({first_import}{_imports}{_comma_maybe})\"", "loc": 20}
{"file": "isort\\isort\\wrap_modes.py", "class_name": null, "function_name": "hanging_indent", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_hanging_indent_end_line", "interface['comment_prefix'].lstrip", "interface['imports'].pop", "isort.comments.add_to_line", "len", "next_statement.split", "statement_with_comments.split", "str"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def hanging_indent(**interface: Any) -> str:\n    if not interface[\"imports\"]:\n        return \"\"\n\n    line_length_limit = interface[\"line_length\"] - 3\n\n    next_import = interface[\"imports\"].pop(0)\n    next_statement = interface[\"statement\"] + next_import\n    # Check for first import\n    if len(next_statement) > line_length_limit:\n        next_statement = (\n            _hanging_indent_end_line(interface[\"statement\"])\n            + interface[\"line_separator\"]\n            + interface[\"indent\"]\n            + next_import\n        )\n\n    interface[\"statement\"] = next_statement\n    while interface[\"imports\"]:\n        next_import = interface[\"imports\"].pop(0)\n        next_statement = interface[\"statement\"] + \", \" + next_import\n        if len(next_statement.split(interface[\"line_separator\"])[-1]) > line_length_limit:\n            next_statement = (\n                _hanging_indent_end_line(interface[\"statement\"] + \",\")\n                + f\"{interface['line_separator']}{interface['indent']}{next_import}\"\n            )\n        interface[\"statement\"] = next_statement\n\n    if interface[\"comments\"]:\n        statement_with_comments = isort.comments.add_to_line(\n            interface[\"comments\"],\n            interface[\"statement\"],\n            removed=interface[\"remove_comments\"],\n            comment_prefix=interface[\"comment_prefix\"],\n        )\n        if len(statement_with_comments.split(interface[\"line_separator\"])[-1]) <= (\n            line_length_limit + 2\n        ):\n            return statement_with_comments\n        return (\n            _hanging_indent_end_line(interface[\"statement\"])\n            + str(interface[\"line_separator\"])\n            + isort.comments.add_to_line(\n                interface[\"comments\"],\n                interface[\"indent\"],\n                removed=interface[\"remove_comments\"],\n                comment_prefix=interface[\"comment_prefix\"].lstrip(),\n            )\n        )\n    return str(interface[\"statement\"])", "loc": 50}
{"file": "isort\\isort\\wrap_modes.py", "class_name": null, "function_name": "vertical_hanging_indent", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["',' + interface['line_separator'] + interface['indent'].join", "isort.comments.add_to_line"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def vertical_hanging_indent(**interface: Any) -> str:\n    _line_with_comments = isort.comments.add_to_line(\n        interface[\"comments\"],\n        \"\",\n        removed=interface[\"remove_comments\"],\n        comment_prefix=interface[\"comment_prefix\"],\n    )\n    _imports = (\",\" + interface[\"line_separator\"] + interface[\"indent\"]).join(interface[\"imports\"])\n    _comma_maybe = \",\" if interface[\"include_trailing_comma\"] else \"\"\n    return (\n        f\"{interface['statement']}({_line_with_comments}{interface['line_separator']}\"\n        f\"{interface['indent']}{_imports}{_comma_maybe}{interface['line_separator']})\"\n    )", "loc": 13}
{"file": "isort\\isort\\wrap_modes.py", "class_name": null, "function_name": "vertical_grid_grouped", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_vertical_grid_common", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def vertical_grid_grouped(**interface: Any) -> str:\n    return (\n        _vertical_grid_common(need_trailing_char=False, **interface)\n        + str(interface[\"line_separator\"])\n        + \")\"\n    )", "loc": 6}
{"file": "isort\\isort\\wrap_modes.py", "class_name": null, "function_name": "noqa", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "', '.join", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def noqa(**interface: Any) -> str:\n    _imports = \", \".join(interface[\"imports\"])\n    retval = f\"{interface['statement']}{_imports}\"\n    comment_str = \" \".join(interface[\"comments\"])\n    if interface[\"comments\"]:\n        if (\n            len(retval) + len(interface[\"comment_prefix\"]) + 1 + len(comment_str)\n            <= interface[\"line_length\"]\n        ):\n            return f\"{retval}{interface['comment_prefix']} {comment_str}\"\n        if \"NOQA\" in interface[\"comments\"]:\n            return f\"{retval}{interface['comment_prefix']} {comment_str}\"\n        return f\"{retval}{interface['comment_prefix']} NOQA {comment_str}\"\n\n    if len(retval) <= interface[\"line_length\"]:\n        return retval\n    return f\"{retval}{interface['comment_prefix']} NOQA\"", "loc": 17}
{"file": "isort\\isort\\wrap_modes.py", "class_name": null, "function_name": "vertical_hanging_indent_bracket", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["vertical_hanging_indent"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def vertical_hanging_indent_bracket(**interface: Any) -> str:\n    if not interface[\"imports\"]:\n        return \"\"\n    statement = vertical_hanging_indent(**interface)\n    return f\"{statement[:-1]}{interface['indent']})\"", "loc": 5}
{"file": "isort\\isort\\wrap_modes.py", "class_name": null, "function_name": "vertical_prefix_from_module_import", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["interface['imports'].pop", "isort.comments.add_to_line", "len", "statement_with_comments.split", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def vertical_prefix_from_module_import(**interface: Any) -> str:\n    if not interface[\"imports\"]:\n        return \"\"\n\n    prefix_statement = interface[\"statement\"]\n    output_statement = prefix_statement + interface[\"imports\"].pop(0)\n    comments = interface[\"comments\"]\n\n    statement = output_statement\n    statement_with_comments = \"\"\n    for next_import in interface[\"imports\"]:\n        statement = statement + \", \" + next_import\n        statement_with_comments = isort.comments.add_to_line(\n            comments,\n            statement,\n            removed=interface[\"remove_comments\"],\n            comment_prefix=interface[\"comment_prefix\"],\n        )\n        if (\n            len(statement_with_comments.split(interface[\"line_separator\"])[-1]) + 1\n            > interface[\"line_length\"]\n        ):\n            statement = (\n                isort.comments.add_to_line(\n                    comments,\n                    output_statement,\n                    removed=interface[\"remove_comments\"],\n                    comment_prefix=interface[\"comment_prefix\"],\n                )\n                + f\"{interface['line_separator']}{prefix_statement}{next_import}\"\n            )\n            comments = []\n        output_statement = statement\n\n    if comments and statement_with_comments:\n        output_statement = statement_with_comments\n    return str(output_statement)", "loc": 37}
{"file": "isort\\isort\\wrap_modes.py", "class_name": null, "function_name": "hanging_indent_with_parentheses", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["interface['imports'].pop", "interface['statement'].split", "isort.comments.add_to_line", "len", "line.rstrip", "next_statement.split"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def hanging_indent_with_parentheses(**interface: Any) -> str:\n    if not interface[\"imports\"]:\n        return \"\"\n\n    line_length_limit = interface[\"line_length\"] - 1\n\n    interface[\"statement\"] += \"(\"\n    next_import = interface[\"imports\"].pop(0)\n    next_statement = interface[\"statement\"] + next_import\n    # Check for first import\n    if len(next_statement) > line_length_limit:\n        next_statement = (\n            isort.comments.add_to_line(\n                interface[\"comments\"],\n                interface[\"statement\"],\n                removed=interface[\"remove_comments\"],\n                comment_prefix=interface[\"comment_prefix\"],\n            )\n            + f\"{interface['line_separator']}{interface['indent']}{next_import}\"\n        )\n        interface[\"comments\"] = []\n    interface[\"statement\"] = next_statement\n    while interface[\"imports\"]:\n        next_import = interface[\"imports\"].pop(0)\n        if (\n            interface[\"line_separator\"] not in interface[\"statement\"]\n            and \"#\" in interface[\"statement\"]\n        ):  # pragma: no cover # TODO: fix, this is because of test run inconsistency.\n            line, comments = interface[\"statement\"].split(\"#\", 1)\n            next_statement = (\n                f\"{line.rstrip()}, {next_import}{interface['comment_prefix']}{comments}\"\n            )\n        else:\n            next_statement = isort.comments.add_to_line(\n                interface[\"comments\"],\n                interface[\"statement\"] + \", \" + next_import,\n                removed=interface[\"remove_comments\"],\n                comment_prefix=interface[\"comment_prefix\"],\n            )\n        current_line = next_statement.split(interface[\"line_separator\"])[-1]\n        if len(current_line) > line_length_limit:\n            next_statement = (\n                isort.comments.add_to_line(\n                    interface[\"comments\"],\n                    interface[\"statement\"] + \",\",\n                    removed=interface[\"remove_comments\"],\n                    comment_prefix=interface[\"comment_prefix\"],\n                )\n                + f\"{interface['line_separator']}{interface['indent']}{next_import}\"\n            )\n            interface[\"comments\"] = []\n        interface[\"statement\"] = next_statement\n    return f\"{interface['statement']}{',' if interface['include_trailing_comma'] else ''})\"", "loc": 53}
{"file": "isort\\isort\\deprecated\\finders.py", "class_name": null, "function_name": "chdir", "parameters": ["path"], "param_types": {"path": "str"}, "return_type": "Iterator[None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["os.chdir", "os.getcwd"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Context manager for changing dir and restoring previous workdir after exit.", "source_code": "def chdir(path: str) -> Iterator[None]:\n    \"\"\"Context manager for changing dir and restoring previous workdir after exit.\"\"\"\n    curdir = os.getcwd()\n    os.chdir(path)\n    try:\n        yield\n    finally:\n        os.chdir(curdir)", "loc": 8}
{"file": "isort\\isort\\deprecated\\finders.py", "class_name": "ForcedSeparateFinder", "function_name": "find", "parameters": ["self", "module_name"], "param_types": {"module_name": "str"}, "return_type": "str | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fnmatch", "forced_separate.endswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find(self, module_name: str) -> str | None:\n    for forced_separate in self.config.forced_separate:\n        # Ensure all forced_separate patterns will match to end of string\n        path_glob = forced_separate\n        if not forced_separate.endswith(\"*\"):\n            path_glob = f\"{forced_separate}*\"\n\n        if fnmatch(module_name, path_glob) or fnmatch(module_name, \".\" + path_glob):\n            return forced_separate\n    return None", "loc": 10}
{"file": "isort\\isort\\deprecated\\finders.py", "class_name": "KnownPatternFinder", "function_name": "find", "parameters": ["self", "module_name"], "param_types": {"module_name": "str"}, "return_type": "str | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'.'.join", "len", "module_name.split", "pattern.match", "range"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find(self, module_name: str) -> str | None:\n    # Try to find most specific placement instruction match (if any)\n    parts = module_name.split(\".\")\n    module_names_to_check = (\".\".join(parts[:first_k]) for first_k in range(len(parts), 0, -1))\n    for module_name_to_check in module_names_to_check:\n        for pattern, placement in self.known_patterns:\n            if pattern.match(module_name_to_check):\n                return placement\n    return None", "loc": 9}
{"file": "isort\\isort\\deprecated\\finders.py", "class_name": "ReqsBaseFinder", "function_name": "find", "parameters": ["self", "module_name"], "param_types": {"module_name": "str"}, "return_type": "str | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["module_name.lower", "module_name.partition"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find(self, module_name: str) -> str | None:\n    # required lib not installed yet\n    if not self.enabled:\n        return None\n\n    module_name, _sep, _submodules = module_name.partition(\".\")\n    module_name = module_name.lower()\n    if not module_name:\n        return None\n\n    for name in self.names:\n        if module_name == name:\n            return sections.THIRDPARTY\n    return None", "loc": 14}
{"file": "isort\\isort\\deprecated\\finders.py", "class_name": "FindersManager", "function_name": "find", "parameters": ["self", "module_name"], "param_types": {"module_name": "str"}, "return_type": "str | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["finder.find", "print"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find(self, module_name: str) -> str | None:\n    for finder in self.finders:\n        try:\n            section = finder.find(module_name)\n            if section is not None:\n                return section\n        except Exception as exception:\n            # isort has to be able to keep trying to identify the correct\n            # import section even if one approach fails\n            if self.verbose:\n                print(\n                    f\"{finder.__class__.__name__} encountered an error ({exception}) while \"\n                    f\"trying to identify the {module_name} module\"\n                )\n    return None", "loc": 15}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "load", "parameters": ["fp"], "param_types": {"fp": "IO"}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fp.read", "isinstance", "loads", "s.decode", "warnings.warn"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse TOML from a file object.", "source_code": "def load(fp: IO, *, parse_float: ParseFloat = float) -> Dict[str, Any]:\n    \"\"\"Parse TOML from a file object.\"\"\"\n    s = fp.read()\n    if isinstance(s, bytes):\n        s = s.decode()\n    else:\n        warnings.warn(\n            \"Text file object support is deprecated in favor of binary file objects.\"\n            ' Use `open(\"foo.toml\", \"rb\")` to open the file in binary mode.',\n            DeprecationWarning,\n        )\n    return loads(s, parse_float=parse_float)", "loc": 12}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "loads", "parameters": ["s"], "param_types": {"s": "str"}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Flags", "NestedDict", "Output", "create_dict_rule", "create_list_rule", "key_value_rule", "s.replace", "skip_chars", "skip_comment", "suffixed_err"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Parse TOML from a string.", "source_code": "def loads(s: str, *, parse_float: ParseFloat = float) -> Dict[str, Any]:  # noqa: C901\n    \"\"\"Parse TOML from a string.\"\"\"\n\n    # The spec allows converting \"\\r\\n\" to \"\\n\", even in string\n    # literals. Let's do so to simplify parsing.\n    src = s.replace(\"\\r\\n\", \"\\n\")\n    pos = 0\n    out = Output(NestedDict(), Flags())\n    header: Key = ()\n\n    # Parse one statement at a time\n    # (typically means one line in TOML source)\n    while True:\n        # 1. Skip line leading whitespace\n        pos = skip_chars(src, pos, TOML_WS)\n\n        # 2. Parse rules. Expect one of the following:\n        #    - end of file\n        #    - end of line\n        #    - comment\n        #    - key/value pair\n        #    - append dict to list (and move to its namespace)\n        #    - create dict (and move to its namespace)\n        # Skip trailing whitespace when applicable.\n        try:\n            char = src[pos]\n        except IndexError:\n            break\n        if char == \"\\n\":\n            pos += 1\n            continue\n        if char in KEY_INITIAL_CHARS:\n            pos = key_value_rule(src, pos, out, header, parse_float)\n            pos = skip_chars(src, pos, TOML_WS)\n        elif char == \"[\":\n            try:\n                second_char: Optional[str] = src[pos + 1]\n            except IndexError:\n                second_char = None\n            if second_char == \"[\":\n                pos, header = create_list_rule(src, pos, out)\n            else:\n                pos, header = create_dict_rule(src, pos, out)\n            pos = skip_chars(src, pos, TOML_WS)\n        elif char != \"#\":\n            raise suffixed_err(src, pos, \"Invalid statement\")\n\n        # 3. Skip comment\n        pos = skip_comment(src, pos)\n\n        # 4. Expect end of line or end of file\n        try:\n            char = src[pos]\n        except IndexError:\n            break\n        if char != \"\\n\":\n            raise suffixed_err(src, pos, \"Expected newline or end of document after a statement\")\n        pos += 1\n\n    return out.data.dict", "loc": 60}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "skip_chars", "parameters": ["src", "pos", "chars"], "param_types": {"src": "str", "pos": "Pos", "chars": "Iterable[str]"}, "return_type": "Pos", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def skip_chars(src: str, pos: Pos, chars: Iterable[str]) -> Pos:\n    try:\n        while src[pos] in chars:\n            pos += 1\n    except IndexError:\n        pass\n    return pos", "loc": 7}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "skip_until", "parameters": ["src", "pos", "expect"], "param_types": {"src": "str", "pos": "Pos", "expect": "str"}, "return_type": "Pos", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["error_on.isdisjoint", "len", "src.index", "suffixed_err"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def skip_until(\n    src: str,\n    pos: Pos,\n    expect: str,\n    *,\n    error_on: FrozenSet[str],\n    error_on_eof: bool,\n) -> Pos:\n    try:\n        new_pos = src.index(expect, pos)\n    except ValueError:\n        new_pos = len(src)\n        if error_on_eof:\n            raise suffixed_err(src, new_pos, f'Expected \"{expect!r}\"')\n\n    if not error_on.isdisjoint(src[pos:new_pos]):\n        while src[pos] not in error_on:\n            pos += 1\n        raise suffixed_err(src, pos, f'Found invalid character \"{src[pos]!r}\"')\n    return new_pos", "loc": 20}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "skip_comment", "parameters": ["src", "pos"], "param_types": {"src": "str", "pos": "Pos"}, "return_type": "Pos", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["skip_until"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def skip_comment(src: str, pos: Pos) -> Pos:\n    try:\n        char: Optional[str] = src[pos]\n    except IndexError:\n        char = None\n    if char == \"#\":\n        return skip_until(src, pos + 1, \"\\n\", error_on=ILLEGAL_COMMENT_CHARS, error_on_eof=False)\n    return pos", "loc": 8}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "skip_comments_and_array_ws", "parameters": ["src", "pos"], "param_types": {"src": "str", "pos": "Pos"}, "return_type": "Pos", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["skip_chars", "skip_comment"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def skip_comments_and_array_ws(src: str, pos: Pos) -> Pos:\n    while True:\n        pos_before_skip = pos\n        pos = skip_chars(src, pos, TOML_WS_AND_NEWLINE)\n        pos = skip_comment(src, pos)\n        if pos == pos_before_skip:\n            return pos", "loc": 7}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "create_dict_rule", "parameters": ["src", "pos", "out"], "param_types": {"src": "str", "pos": "Pos", "out": "Output"}, "return_type": "Tuple[Pos, Key]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["out.data.get_or_create_nest", "out.flags.is_", "out.flags.set", "parse_key", "skip_chars", "src.startswith", "suffixed_err"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_dict_rule(src: str, pos: Pos, out: Output) -> Tuple[Pos, Key]:\n    pos += 1  # Skip \"[\"\n    pos = skip_chars(src, pos, TOML_WS)\n    pos, key = parse_key(src, pos)\n\n    if out.flags.is_(key, Flags.EXPLICIT_NEST) or out.flags.is_(key, Flags.FROZEN):\n        raise suffixed_err(src, pos, f\"Can not declare {key} twice\")\n    out.flags.set(key, Flags.EXPLICIT_NEST, recursive=False)\n    try:\n        out.data.get_or_create_nest(key)\n    except KeyError:\n        raise suffixed_err(src, pos, \"Can not overwrite a value\")\n\n    if not src.startswith(\"]\", pos):\n        raise suffixed_err(src, pos, 'Expected \"]\" at the end of a table declaration')\n    return pos + 1, key", "loc": 16}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "create_list_rule", "parameters": ["src", "pos", "out"], "param_types": {"src": "str", "pos": "Pos", "out": "Output"}, "return_type": "Tuple[Pos, Key]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["out.data.append_nest_to_list", "out.flags.is_", "out.flags.set", "out.flags.unset_all", "parse_key", "skip_chars", "src.startswith", "suffixed_err"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_list_rule(src: str, pos: Pos, out: Output) -> Tuple[Pos, Key]:\n    pos += 2  # Skip \"[[\"\n    pos = skip_chars(src, pos, TOML_WS)\n    pos, key = parse_key(src, pos)\n\n    if out.flags.is_(key, Flags.FROZEN):\n        raise suffixed_err(src, pos, f\"Can not mutate immutable namespace {key}\")\n    # Free the namespace now that it points to another empty list item...\n    out.flags.unset_all(key)\n    # ...but this key precisely is still prohibited from table declaration\n    out.flags.set(key, Flags.EXPLICIT_NEST, recursive=False)\n    try:\n        out.data.append_nest_to_list(key)\n    except KeyError:\n        raise suffixed_err(src, pos, \"Can not overwrite a value\")\n\n    if not src.startswith(\"]]\", pos):\n        raise suffixed_err(src, pos, 'Expected \"]]\" at the end of an array declaration')\n    return pos + 2, key", "loc": 19}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "key_value_rule", "parameters": ["src", "pos", "out", "header", "parse_float"], "param_types": {"src": "str", "pos": "Pos", "out": "Output", "header": "Key", "parse_float": "ParseFloat"}, "return_type": "Pos", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "out.data.get_or_create_nest", "out.flags.is_", "out.flags.set", "out.flags.set_for_relative_key", "parse_key_value_pair", "suffixed_err"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def key_value_rule(src: str, pos: Pos, out: Output, header: Key, parse_float: ParseFloat) -> Pos:\n    pos, key, value = parse_key_value_pair(src, pos, parse_float)\n    key_parent, key_stem = key[:-1], key[-1]\n    abs_key_parent = header + key_parent\n\n    if out.flags.is_(abs_key_parent, Flags.FROZEN):\n        raise suffixed_err(src, pos, f\"Can not mutate immutable namespace {abs_key_parent}\")\n    # Containers in the relative path can't be opened with the table syntax after this\n    out.flags.set_for_relative_key(header, key, Flags.EXPLICIT_NEST)\n    try:\n        nest = out.data.get_or_create_nest(abs_key_parent)\n    except KeyError:\n        raise suffixed_err(src, pos, \"Can not overwrite a value\")\n    if key_stem in nest:\n        raise suffixed_err(src, pos, \"Can not overwrite a value\")\n    # Mark inline table and array namespaces recursively immutable\n    if isinstance(value, (dict, list)):\n        out.flags.set(header + key, Flags.FROZEN, recursive=True)\n    nest[key_stem] = value\n    return pos", "loc": 20}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "parse_key_value_pair", "parameters": ["src", "pos", "parse_float"], "param_types": {"src": "str", "pos": "Pos", "parse_float": "ParseFloat"}, "return_type": "Tuple[Pos, Key, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_key", "parse_value", "skip_chars", "suffixed_err"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_key_value_pair(src: str, pos: Pos, parse_float: ParseFloat) -> Tuple[Pos, Key, Any]:\n    pos, key = parse_key(src, pos)\n    try:\n        char: Optional[str] = src[pos]\n    except IndexError:\n        char = None\n    if char != \"=\":\n        raise suffixed_err(src, pos, 'Expected \"=\" after a key in a key/value pair')\n    pos += 1\n    pos = skip_chars(src, pos, TOML_WS)\n    pos, value = parse_value(src, pos, parse_float)\n    return pos, key, value", "loc": 12}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "parse_key", "parameters": ["src", "pos"], "param_types": {"src": "str", "pos": "Pos"}, "return_type": "Tuple[Pos, Key]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_key_part", "skip_chars"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_key(src: str, pos: Pos) -> Tuple[Pos, Key]:\n    pos, key_part = parse_key_part(src, pos)\n    key: Key = (key_part,)\n    pos = skip_chars(src, pos, TOML_WS)\n    while True:\n        try:\n            char: Optional[str] = src[pos]\n        except IndexError:\n            char = None\n        if char != \".\":\n            return pos, key\n        pos += 1\n        pos = skip_chars(src, pos, TOML_WS)\n        pos, key_part = parse_key_part(src, pos)\n        key += (key_part,)\n        pos = skip_chars(src, pos, TOML_WS)", "loc": 16}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "parse_key_part", "parameters": ["src", "pos"], "param_types": {"src": "str", "pos": "Pos"}, "return_type": "Tuple[Pos, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_literal_str", "parse_one_line_basic_str", "skip_chars", "suffixed_err"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_key_part(src: str, pos: Pos) -> Tuple[Pos, str]:\n    try:\n        char: Optional[str] = src[pos]\n    except IndexError:\n        char = None\n    if char in BARE_KEY_CHARS:\n        start_pos = pos\n        pos = skip_chars(src, pos, BARE_KEY_CHARS)\n        return pos, src[start_pos:pos]\n    if char == \"'\":\n        return parse_literal_str(src, pos)\n    if char == '\"':\n        return parse_one_line_basic_str(src, pos)\n    raise suffixed_err(src, pos, \"Invalid initial character for a key part\")", "loc": 14}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "parse_array", "parameters": ["src", "pos", "parse_float"], "param_types": {"src": "str", "pos": "Pos", "parse_float": "ParseFloat"}, "return_type": "Tuple[Pos, list]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["array.append", "parse_value", "skip_comments_and_array_ws", "src.startswith", "suffixed_err"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_array(src: str, pos: Pos, parse_float: ParseFloat) -> Tuple[Pos, list]:\n    pos += 1\n    array: list = []\n\n    pos = skip_comments_and_array_ws(src, pos)\n    if src.startswith(\"]\", pos):\n        return pos + 1, array\n    while True:\n        pos, val = parse_value(src, pos, parse_float)\n        array.append(val)\n        pos = skip_comments_and_array_ws(src, pos)\n\n        c = src[pos : pos + 1]\n        if c == \"]\":\n            return pos + 1, array\n        if c != \",\":\n            raise suffixed_err(src, pos, \"Unclosed array\")\n        pos += 1\n\n        pos = skip_comments_and_array_ws(src, pos)\n        if src.startswith(\"]\", pos):\n            return pos + 1, array", "loc": 22}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "parse_inline_table", "parameters": ["src", "pos", "parse_float"], "param_types": {"src": "str", "pos": "Pos", "parse_float": "ParseFloat"}, "return_type": "Tuple[Pos, dict]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Flags", "NestedDict", "flags.is_", "flags.set", "isinstance", "nested_dict.get_or_create_nest", "parse_key_value_pair", "skip_chars", "src.startswith", "suffixed_err"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_inline_table(src: str, pos: Pos, parse_float: ParseFloat) -> Tuple[Pos, dict]:\n    pos += 1\n    nested_dict = NestedDict()\n    flags = Flags()\n\n    pos = skip_chars(src, pos, TOML_WS)\n    if src.startswith(\"}\", pos):\n        return pos + 1, nested_dict.dict\n    while True:\n        pos, key, value = parse_key_value_pair(src, pos, parse_float)\n        key_parent, key_stem = key[:-1], key[-1]\n        if flags.is_(key, Flags.FROZEN):\n            raise suffixed_err(src, pos, f\"Can not mutate immutable namespace {key}\")\n        try:\n            nest = nested_dict.get_or_create_nest(key_parent, access_lists=False)\n        except KeyError:\n            raise suffixed_err(src, pos, \"Can not overwrite a value\")\n        if key_stem in nest:\n            raise suffixed_err(src, pos, f'Duplicate inline table key \"{key_stem}\"')\n        nest[key_stem] = value\n        pos = skip_chars(src, pos, TOML_WS)\n        c = src[pos : pos + 1]\n        if c == \"}\":\n            return pos + 1, nested_dict.dict\n        if c != \",\":\n            raise suffixed_err(src, pos, \"Unclosed inline table\")\n        if isinstance(value, (dict, list)):\n            flags.set(key, Flags.FROZEN, recursive=True)\n        pos += 1\n        pos = skip_chars(src, pos, TOML_WS)", "loc": 30}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "parse_basic_str_escape", "parameters": ["src", "pos"], "param_types": {"src": "str", "pos": "Pos"}, "return_type": "Tuple[Pos, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "parse_hex_char", "skip_chars", "suffixed_err"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_basic_str_escape(  # noqa: C901\n    src: str, pos: Pos, *, multiline: bool = False\n) -> Tuple[Pos, str]:\n    escape_id = src[pos : pos + 2]\n    pos += 2\n    if multiline and escape_id in {\"\\\\ \", \"\\\\\\t\", \"\\\\\\n\"}:\n        # Skip whitespace until next non-whitespace character or end of\n        # the doc. Error if non-whitespace is found before newline.\n        if escape_id != \"\\\\\\n\":\n            pos = skip_chars(src, pos, TOML_WS)\n            try:\n                char = src[pos]\n            except IndexError:\n                return pos, \"\"\n            if char != \"\\n\":\n                raise suffixed_err(src, pos, 'Unescaped \"\\\\\" in a string')\n            pos += 1\n        pos = skip_chars(src, pos, TOML_WS_AND_NEWLINE)\n        return pos, \"\"\n    if escape_id == \"\\\\u\":\n        return parse_hex_char(src, pos, 4)\n    if escape_id == \"\\\\U\":\n        return parse_hex_char(src, pos, 8)\n    try:\n        return pos, BASIC_STR_ESCAPE_REPLACEMENTS[escape_id]\n    except KeyError:\n        if len(escape_id) != 2:\n            raise suffixed_err(src, pos, \"Unterminated string\")\n        raise suffixed_err(src, pos, 'Unescaped \"\\\\\" in a string')", "loc": 29}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "parse_hex_char", "parameters": ["src", "pos", "hex_len"], "param_types": {"src": "str", "pos": "Pos", "hex_len": "int"}, "return_type": "Tuple[Pos, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HEXDIGIT_CHARS.issuperset", "chr", "int", "is_unicode_scalar_value", "len", "suffixed_err"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_hex_char(src: str, pos: Pos, hex_len: int) -> Tuple[Pos, str]:\n    hex_str = src[pos : pos + hex_len]\n    if len(hex_str) != hex_len or not HEXDIGIT_CHARS.issuperset(hex_str):\n        raise suffixed_err(src, pos, \"Invalid hex value\")\n    pos += hex_len\n    hex_int = int(hex_str, 16)\n    if not is_unicode_scalar_value(hex_int):\n        raise suffixed_err(src, pos, \"Escaped character is not a Unicode scalar value\")\n    return pos, chr(hex_int)", "loc": 9}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "parse_multiline_str", "parameters": ["src", "pos"], "param_types": {"src": "str", "pos": "Pos"}, "return_type": "Tuple[Pos, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_basic_str", "skip_until", "src.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_multiline_str(src: str, pos: Pos, *, literal: bool) -> Tuple[Pos, str]:\n    pos += 3\n    if src.startswith(\"\\n\", pos):\n        pos += 1\n\n    if literal:\n        delim = \"'\"\n        end_pos = skip_until(\n            src,\n            pos,\n            \"'''\",\n            error_on=ILLEGAL_MULTILINE_LITERAL_STR_CHARS,\n            error_on_eof=True,\n        )\n        result = src[pos:end_pos]\n        pos = end_pos + 3\n    else:\n        delim = '\"'\n        pos, result = parse_basic_str(src, pos, multiline=True)\n\n    # Add at maximum two extra apostrophes/quotes if the end sequence\n    # is 4 or 5 chars long instead of just 3.\n    if not src.startswith(delim, pos):\n        return pos, result\n    pos += 1\n    if not src.startswith(delim, pos):\n        return pos, result + delim\n    pos += 1\n    return pos, result + (delim * 2)", "loc": 29}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "parse_basic_str", "parameters": ["src", "pos"], "param_types": {"src": "str", "pos": "Pos"}, "return_type": "Tuple[Pos, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_escapes", "src.startswith", "suffixed_err"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_basic_str(src: str, pos: Pos, *, multiline: bool) -> Tuple[Pos, str]:\n    if multiline:\n        error_on = ILLEGAL_MULTILINE_BASIC_STR_CHARS\n        parse_escapes = parse_basic_str_escape_multiline\n    else:\n        error_on = ILLEGAL_BASIC_STR_CHARS\n        parse_escapes = parse_basic_str_escape\n    result = \"\"\n    start_pos = pos\n    while True:\n        try:\n            char = src[pos]\n        except IndexError:\n            raise suffixed_err(src, pos, \"Unterminated string\")\n        if char == '\"':\n            if not multiline:\n                return pos + 1, result + src[start_pos:pos]\n            if src.startswith('\"\"\"', pos):\n                return pos + 3, result + src[start_pos:pos]\n            pos += 1\n            continue\n        if char == \"\\\\\":\n            result += src[start_pos:pos]\n            pos, parsed_escape = parse_escapes(src, pos)\n            result += parsed_escape\n            start_pos = pos\n            continue\n        if char in error_on:\n            raise suffixed_err(src, pos, f'Illegal character \"{char!r}\"')\n        pos += 1", "loc": 30}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "parse_value", "parameters": ["src", "pos", "parse_float"], "param_types": {"src": "str", "pos": "Pos", "parse_float": "ParseFloat"}, "return_type": "Tuple[Pos, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RE_DATETIME.match", "RE_LOCALTIME.match", "RE_NUMBER.match", "datetime_match.end", "localtime_match.end", "match_to_datetime", "match_to_localtime", "match_to_number", "number_match.end", "parse_array", "parse_float", "parse_inline_table", "parse_literal_str", "parse_multiline_str", "parse_one_line_basic_str", "src.startswith", "suffixed_err"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_value(src: str, pos: Pos, parse_float: ParseFloat) -> Tuple[Pos, Any]:  # noqa: C901\n    try:\n        char: Optional[str] = src[pos]\n    except IndexError:\n        char = None\n\n    # Basic strings\n    if char == '\"':\n        if src.startswith('\"\"\"', pos):\n            return parse_multiline_str(src, pos, literal=False)\n        return parse_one_line_basic_str(src, pos)\n\n    # Literal strings\n    if char == \"'\":\n        if src.startswith(\"'''\", pos):\n            return parse_multiline_str(src, pos, literal=True)\n        return parse_literal_str(src, pos)\n\n    # Booleans\n    if char == \"t\":\n        if src.startswith(\"true\", pos):\n            return pos + 4, True\n    if char == \"f\":\n        if src.startswith(\"false\", pos):\n            return pos + 5, False\n\n    # Dates and times\n    datetime_match = RE_DATETIME.match(src, pos)\n    if datetime_match:\n        try:\n            datetime_obj = match_to_datetime(datetime_match)\n        except ValueError:\n            raise suffixed_err(src, pos, \"Invalid date or datetime\")\n        return datetime_match.end(), datetime_obj\n    localtime_match = RE_LOCALTIME.match(src, pos)\n    if localtime_match:\n        return localtime_match.end(), match_to_localtime(localtime_match)\n\n    # Integers and \"normal\" floats.\n    # The regex will greedily match any type starting with a decimal\n    # char, so needs to be located after handling of dates and times.\n    number_match = RE_NUMBER.match(src, pos)\n    if number_match:\n        return number_match.end(), match_to_number(number_match, parse_float)\n\n    # Arrays\n    if char == \"[\":\n        return parse_array(src, pos, parse_float)\n\n    # Inline tables\n    if char == \"{\":\n        return parse_inline_table(src, pos, parse_float)\n\n    # Special floats\n    first_three = src[pos : pos + 3]\n    if first_three in {\"inf\", \"nan\"}:\n        return pos + 3, parse_float(first_three)\n    first_four = src[pos : pos + 4]\n    if first_four in {\"-inf\", \"+inf\", \"-nan\", \"+nan\"}:\n        return pos + 4, parse_float(first_four)\n\n    raise suffixed_err(src, pos, \"Invalid value\")", "loc": 62}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "suffixed_err", "parameters": ["src", "pos", "msg"], "param_types": {"src": "str", "pos": "Pos", "msg": "str"}, "return_type": "TOMLDecodeError", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TOMLDecodeError", "coord_repr", "len", "src.count", "src.rindex"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return a `TOMLDecodeError` where error message is suffixed with coordinates in source.", "source_code": "def suffixed_err(src: str, pos: Pos, msg: str) -> TOMLDecodeError:\n    \"\"\"Return a `TOMLDecodeError` where error message is suffixed with\n    coordinates in source.\"\"\"\n\n    def coord_repr(src: str, pos: Pos) -> str:\n        if pos >= len(src):\n            return \"end of document\"\n        line = src.count(\"\\n\", 0, pos) + 1\n        if line == 1:\n            column = pos + 1\n        else:\n            column = pos - src.rindex(\"\\n\", 0, pos)\n        return f\"line {line}, column {column}\"\n\n    return TOMLDecodeError(f\"{msg} (at {coord_repr(src, pos)})\")", "loc": 15}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": "Flags", "function_name": "unset_all", "parameters": ["self", "key"], "param_types": {"key": "Key"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cont.pop"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unset_all(self, key: Key) -> None:\n    cont = self._flags\n    for k in key[:-1]:\n        if k not in cont:\n            return\n        cont = cont[k][\"nested\"]\n    cont.pop(key[-1], None)", "loc": 7}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": "Flags", "function_name": "set_for_relative_key", "parameters": ["self", "head_key", "rel_key", "flag"], "param_types": {"head_key": "Key", "rel_key": "Key", "flag": "int"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cont[k]['flags'].add", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_for_relative_key(self, head_key: Key, rel_key: Key, flag: int) -> None:\n    cont = self._flags\n    for k in head_key:\n        if k not in cont:\n            cont[k] = {\"flags\": set(), \"recursive_flags\": set(), \"nested\": {}}\n        cont = cont[k][\"nested\"]\n    for k in rel_key:\n        if k in cont:\n            cont[k][\"flags\"].add(flag)\n        else:\n            cont[k] = {\"flags\": {flag}, \"recursive_flags\": set(), \"nested\": {}}\n        cont = cont[k][\"nested\"]", "loc": 12}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": "Flags", "function_name": "set", "parameters": ["self", "key", "flag"], "param_types": {"key": "Key", "flag": "int"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cont[key_stem]['recursive_flags' if recursive else 'flags'].add", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set(self, key: Key, flag: int, *, recursive: bool) -> None:  # noqa: A003\n    cont = self._flags\n    key_parent, key_stem = key[:-1], key[-1]\n    for k in key_parent:\n        if k not in cont:\n            cont[k] = {\"flags\": set(), \"recursive_flags\": set(), \"nested\": {}}\n        cont = cont[k][\"nested\"]\n    if key_stem not in cont:\n        cont[key_stem] = {\"flags\": set(), \"recursive_flags\": set(), \"nested\": {}}\n    cont[key_stem][\"recursive_flags\" if recursive else \"flags\"].add(flag)", "loc": 10}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": "Flags", "function_name": "is_", "parameters": ["self", "key", "flag"], "param_types": {"key": "Key", "flag": "int"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_(self, key: Key, flag: int) -> bool:\n    if not key:\n        return False  # document root has no flags\n    cont = self._flags\n    for k in key[:-1]:\n        if k not in cont:\n            return False\n        inner_cont = cont[k]\n        if flag in inner_cont[\"recursive_flags\"]:\n            return True\n        cont = inner_cont[\"nested\"]\n    key_stem = key[-1]\n    if key_stem in cont:\n        cont = cont[key_stem]\n        return flag in cont[\"flags\"] or flag in cont[\"recursive_flags\"]\n    return False", "loc": 16}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": "NestedDict", "function_name": "get_or_create_nest", "parameters": ["self", "key"], "param_types": {"key": "Key"}, "return_type": "dict", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["KeyError", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_or_create_nest(\n    self,\n    key: Key,\n    *,\n    access_lists: bool = True,\n) -> dict:\n    cont: Any = self.dict\n    for k in key:\n        if k not in cont:\n            cont[k] = {}\n        cont = cont[k]\n        if access_lists and isinstance(cont, list):\n            cont = cont[-1]\n        if not isinstance(cont, dict):\n            raise KeyError(\"There is no nest behind this key\")\n    return cont", "loc": 16}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": "NestedDict", "function_name": "append_nest_to_list", "parameters": ["self", "key"], "param_types": {"key": "Key"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["KeyError", "isinstance", "list_.append", "self.get_or_create_nest"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def append_nest_to_list(self, key: Key) -> None:\n    cont = self.get_or_create_nest(key[:-1])\n    last_key = key[-1]\n    if last_key in cont:\n        list_ = cont[last_key]\n        if not isinstance(list_, list):\n            raise KeyError(\"An object other than list found behind this key\")\n        list_.append({})\n    else:\n        cont[last_key] = [{}]", "loc": 10}
{"file": "isort\\isort\\_vendored\\tomli\\_parser.py", "class_name": null, "function_name": "coord_repr", "parameters": ["src", "pos"], "param_types": {"src": "str", "pos": "Pos"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "src.count", "src.rindex"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def coord_repr(src: str, pos: Pos) -> str:\n    if pos >= len(src):\n        return \"end of document\"\n    line = src.count(\"\\n\", 0, pos) + 1\n    if line == 1:\n        column = pos + 1\n    else:\n        column = pos - src.rindex(\"\\n\", 0, pos)\n    return f\"line {line}, column {column}\"", "loc": 9}
{"file": "isort\\isort\\_vendored\\tomli\\_re.py", "class_name": null, "function_name": "match_to_datetime", "parameters": ["match"], "param_types": {"match": "'re.Match'"}, "return_type": "Union[datetime, date]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cached_tz", "date", "datetime", "int", "match.groups", "micros_str.ljust"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convert a `RE_DATETIME` match to `datetime.datetime` or `datetime.date`.", "source_code": "def match_to_datetime(match: \"re.Match\") -> Union[datetime, date]:\n    \"\"\"Convert a `RE_DATETIME` match to `datetime.datetime` or `datetime.date`.\n\n    Raises ValueError if the match does not correspond to a valid date\n    or datetime.\n    \"\"\"\n    (\n        year_str,\n        month_str,\n        day_str,\n        hour_str,\n        minute_str,\n        sec_str,\n        micros_str,\n        zulu_time,\n        offset_sign_str,\n        offset_hour_str,\n        offset_minute_str,\n    ) = match.groups()\n    year, month, day = int(year_str), int(month_str), int(day_str)\n    if hour_str is None:\n        return date(year, month, day)\n    hour, minute, sec = int(hour_str), int(minute_str), int(sec_str)\n    micros = int(micros_str.ljust(6, \"0\")) if micros_str else 0\n    if offset_sign_str:\n        tz: Optional[tzinfo] = cached_tz(offset_hour_str, offset_minute_str, offset_sign_str)\n    elif zulu_time:\n        tz = timezone.utc\n    else:  # local date-time\n        tz = None\n    return datetime(year, month, day, hour, minute, sec, micros, tzinfo=tz)", "loc": 31}
{"file": "isort\\isort\\_vendored\\tomli\\_re.py", "class_name": null, "function_name": "cached_tz", "parameters": ["hour_str", "minute_str", "sign_str"], "param_types": {"hour_str": "str", "minute_str": "str", "sign_str": "str"}, "return_type": "timezone", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "lru_cache", "timedelta", "timezone"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cached_tz(hour_str: str, minute_str: str, sign_str: str) -> timezone:\n    sign = 1 if sign_str == \"+\" else -1\n    return timezone(\n        timedelta(\n            hours=sign * int(hour_str),\n            minutes=sign * int(minute_str),\n        )\n    )", "loc": 8}
{"file": "isort\\scripts\\build_config_option_docs.py", "class_name": null, "function_name": "config_default", "parameters": ["default"], "param_types": {"default": "Any"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["default_str.startswith", "isinstance", "list", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def config_default(default: Any) -> str:\n    if isinstance(default, (frozenset, tuple)):\n        default = list(default)\n    default_str = str(default)\n    if default_str in CONFIG_DEFAULTS:\n        return CONFIG_DEFAULTS[default_str]\n\n    if default_str.startswith(\"py\"):\n        return default_str[2:]\n    return default_str", "loc": 10}
{"file": "isort\\scripts\\build_config_option_docs.py", "class_name": null, "function_name": "human", "parameters": ["name"], "param_types": {"name": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "name.replace", "name.replace('-', '_').split", "part.capitalize"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def human(name: str) -> str:\n    if name in HUMAN_NAME:\n        return HUMAN_NAME[name]\n\n    return \" \".join(\n        part if part in (\"of\",) else part.capitalize() for part in name.replace(\"-\", \"_\").split(\"_\")\n    )", "loc": 7}
{"file": "isort\\scripts\\build_config_option_docs.py", "class_name": null, "function_name": "config_options", "parameters": [], "param_types": {}, "return_type": "Generator[ConfigOption, None, None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ConfigOption", "cli_actions.items", "cli_actions.pop", "config.items", "description_mapping.get", "example_mapping.get", "isinstance", "len", "sorted", "tuple", "type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def config_options() -> Generator[ConfigOption, None, None]:\n    cli_actions = {action.dest: action for action in parser._actions}\n    for name, default in config.items():\n        extra_kwargs = {}\n        description: str | None = description_mapping.get(name, None)\n\n        cli = cli_actions.pop(name, None)\n        if cli:\n            extra_kwargs[\"cli_options\"] = cli.option_strings\n            if cli.help and not description:\n                description = cli.help\n\n        default_display = default\n        if isinstance(default, (set, frozenset)) and len(default) > 0:\n            default_display = tuple(sorted(default))\n\n        # todo: refactor place for example params\n        # needs to integrate with isort/settings/_Config\n        # needs to integrate with isort/main/_build_arg_parser\n        yield ConfigOption(\n            name=name,\n            type=type(default),\n            default=default_display,\n            config_name=name,\n            description=description or \"**No Description**\",\n            example=example_mapping.get(name, None),\n            **extra_kwargs,\n        )\n\n    for name, cli in cli_actions.items():\n        extra_kwargs = {}\n        description: str | None = description_mapping.get(name, None)\n        if cli.type:\n            extra_kwargs[\"type\"] = cli.type\n        elif cli.default is not None:\n            extra_kwargs[\"type\"] = type(cli.default)\n\n        if cli.help and not description:\n            description = cli.help\n\n        yield ConfigOption(\n            name=name,\n            default=cli.default,\n            cli_options=cli.option_strings,\n            example=example_mapping.get(name, None),\n            description=description or \"**No Description**\",\n            **extra_kwargs,\n        )", "loc": 48}
{"file": "isort\\scripts\\build_profile_docs.py", "class_name": null, "function_name": "format_profile", "parameters": ["profile_name", "profile"], "param_types": {"profile_name": "str", "profile": "dict[str, Any]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "profile.get", "profile.items"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_profile(profile_name: str, profile: dict[str, Any]) -> str:\n    options = \"\\n\".join(f\" - **{name}**: `{value!r}`\" for name, value in profile.items())\n    return f\"\"\"\n#{profile_name}\n\n{profile.get(\"description\", \"\")}\n{options}\n\"\"\"", "loc": 8}
{"file": "mimesis\\mimesis\\keys.py", "class_name": null, "function_name": "romanize", "parameters": ["locale"], "param_types": {"locale": "Locale"}, "return_type": "Callable[[str], str]", "param_doc": {"locale": "Locale."}, "return_doc": "A closure that takes a string and returns a romanized string.", "raises_doc": [], "called_functions": ["ValueError", "str.maketrans", "string.translate", "validate_locale"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Create a closure function to romanize a given string in the specified locale. Supported locales are: - Locale.RU (Russian) - Locale.UK (Ukrainian) - Locale.KK (Kazakh)", "source_code": "def romanize(locale: Locale) -> Callable[[str], str]:\n    \"\"\"Create a closure function to romanize a given string in the specified locale.\n\n    Supported locales are:\n\n    - Locale.RU (Russian)\n    - Locale.UK (Ukrainian)\n    - Locale.KK (Kazakh)\n\n    :param locale: Locale.\n    :return: A closure that takes a string and returns a romanized string.\n    \"\"\"\n    locale = validate_locale(locale)\n\n    if locale not in (Locale.RU, Locale.UK, Locale.KK):\n        raise ValueError(f\"Romanization is not available for: {locale}\")\n\n    table = str.maketrans({**ROMANIZATION_DICT[locale.value], **COMMON_LETTERS})\n\n    def key(string: str) -> str:\n        \"\"\"Romanize a given string in the specified locale.\n\n        :param string: Cyrillic string.\n        :return: Romanized string.\n        \"\"\"\n        return string.translate(table)\n\n    return key", "loc": 28}
{"file": "mimesis\\mimesis\\keys.py", "class_name": null, "function_name": "maybe", "parameters": ["value", "probability"], "param_types": {"value": "Any", "probability": "float"}, "return_type": "Callable[[Any, Random], Any]", "param_doc": {"value": "The value that may be returned.", "probability": "The probability of returning **value**."}, "return_doc": "A closure that takes two arguments.", "raises_doc": [], "called_functions": ["random.choices"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return a closure (a key function). The returned closure itself returns either **value** or the first argument passed to closure with a certain probability (0.5 by default).", "source_code": "def maybe(value: Any, probability: float = 0.5) -> Callable[[Any, Random], Any]:\n    \"\"\"Return a closure (a key function).\n\n    The returned closure itself returns either **value** or\n    the first argument passed to closure with a certain probability (0.5 by default).\n\n    :param value: The value that may be returned.\n    :param probability: The probability of returning **value**.\n    :return: A closure that takes two arguments.\n    \"\"\"\n\n    def key(result: Any, random: Random) -> Any:\n        if 0 < probability <= 1:\n            value_weight = 1 - probability\n            (result,) = random.choices(\n                population=[result, value],\n                weights=[value_weight, probability],\n                k=1,\n            )\n        return result\n\n    return key", "loc": 22}
{"file": "mimesis\\mimesis\\keys.py", "class_name": null, "function_name": "key", "parameters": ["result", "random"], "param_types": {"result": "Any", "random": "Random"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["random.choices"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def key(result: Any, random: Random) -> Any:\n    if 0 < probability <= 1:\n        value_weight = 1 - probability\n        (result,) = random.choices(\n            population=[result, value],\n            weights=[value_weight, probability],\n            k=1,\n        )\n    return result", "loc": 9}
{"file": "mimesis\\mimesis\\locales.py", "class_name": null, "function_name": "validate_locale", "parameters": ["locale"], "param_types": {"locale": "Locale | str"}, "return_type": "Locale", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Locale", "LocaleError", "isinstance"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate_locale(locale: Locale | str) -> Locale:\n    if isinstance(locale, str):\n        try:\n            return Locale(locale)\n        except ValueError:\n            raise LocaleError(locale)\n\n    if not isinstance(locale, Locale):\n        raise LocaleError(locale)\n\n    return locale", "loc": 11}
{"file": "mimesis\\mimesis\\random.py", "class_name": "Random", "function_name": "randints", "parameters": ["self", "n", "a", "b"], "param_types": {"n": "int", "a": "int", "b": "int"}, "return_type": "list[int]", "param_doc": {"n": "Number of elements.", "a": "Minimum value of range.", "b": "Maximum value of range."}, "return_doc": "List of random integers.", "raises_doc": [{"type": "ValueError", "desc": "if the number is less or equal to zero."}], "called_functions": ["ValueError", "int", "range", "self.random"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generate a list of random integers.", "source_code": "def randints(self, n: int = 3, a: int = 1, b: int = 100) -> list[int]:\n    \"\"\"Generate a list of random integers.\n\n    :param n: Number of elements.\n    :param a: Minimum value of range.\n    :param b: Maximum value of range.\n    :return: List of random integers.\n    :raises ValueError: if the number is less or equal to zero.\n    \"\"\"\n    if n <= 0:\n        raise ValueError(\"Amount out of range.\")\n\n    return [int(self.random() * (b - a)) + a for _ in range(n)]", "loc": 13}
{"file": "mimesis\\mimesis\\random.py", "class_name": "Random", "function_name": "generate_string_by_mask", "parameters": ["self", "mask", "char", "digit"], "param_types": {"mask": "str", "char": "str", "digit": "str"}, "return_type": "str", "param_doc": {"mask": "Mask of code.", "char": "Placeholder for characters.", "digit": "Placeholder for digits."}, "return_doc": "Custom code.", "raises_doc": [], "called_functions": ["ValueError", "bytearray", "code.decode", "enumerate", "int", "len", "mask.encode", "ord", "random_int", "self.random"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Generate custom code using ascii uppercase and random integers.", "source_code": "def generate_string_by_mask(\n    self,\n    mask: str = \"@###\",\n    char: str = \"@\",\n    digit: str = \"#\",\n) -> str:\n    \"\"\"Generate custom code using ascii uppercase and random integers.\n\n    :param mask: Mask of code.\n    :param char: Placeholder for characters.\n    :param digit: Placeholder for digits.\n    :return: Custom code.\n    \"\"\"\n    char_code = ord(char)\n    digit_code = ord(digit)\n\n    if char_code == digit_code:\n        raise ValueError(\n            \"The same placeholder cannot be \"\n            \"used for both numbers and characters.\"\n        )\n\n    def random_int(a: int, b: int) -> int:\n        b = b - a\n        return int(self.random() * b) + a\n\n    _mask = mask.encode()\n    code = bytearray(len(_mask))\n    for i, p in enumerate(_mask):\n        if p == char_code:\n            a = random_int(65, 91)  # A-Z\n        elif p == digit_code:\n            a = random_int(48, 58)  # 0-9\n        else:\n            a = p\n        code[i] = a\n    return code.decode()", "loc": 37}
{"file": "mimesis\\mimesis\\random.py", "class_name": "Random", "function_name": "uniform", "parameters": ["self", "a", "b", "precision"], "param_types": {"a": "float", "b": "float", "precision": "int"}, "return_type": "float", "param_doc": {"a": "Minimum value.", "b": "Maximum value.", "precision": "Round a number to a given"}, "return_doc": "", "raises_doc": [], "called_functions": ["round", "self.random"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Get a random number in the range [a, b) or [a, b] depending on rounding.", "source_code": "def uniform(self, a: float, b: float, precision: int = 15) -> float:\n    \"\"\"Get a random number in the range [a, b) or [a, b] depending on rounding.\n\n    :param a: Minimum value.\n    :param b: Maximum value.\n    :param precision: Round a number to a given\n        precision in decimal digits, default is 15.\n    \"\"\"\n    return round(a + (b - a) * self.random(), precision)", "loc": 9}
{"file": "mimesis\\mimesis\\random.py", "class_name": "Random", "function_name": "weighted_choice", "parameters": ["self", "choices"], "param_types": {"choices": "dict[t.Any, float]"}, "return_type": "t.Any", "param_doc": {"choices": "A dictionary where keys are choices and values are weights."}, "return_doc": "Random key from dictionary.", "raises_doc": [{"type": "ValueError", "desc": "If choices are empty."}], "called_functions": ["ValueError", "choices.keys", "choices.values", "list", "self.choices"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def weighted_choice(self, choices: dict[t.Any, float]) -> t.Any:\n    \"\"\"Returns a random element according to the specified weights.\n\n    :param choices: A dictionary where keys are choices and values are weights.\n    :raises ValueError: If choices are empty.\n    :return: Random key from dictionary.\n    \"\"\"\n    if not choices:\n        raise ValueError(\"Choices cannot be empty.\")\n\n    population = list(choices.keys())\n    weights = list(choices.values())\n    return self.choices(population, weights=weights, k=1)[0]", "loc": 13}
{"file": "mimesis\\mimesis\\random.py", "class_name": "Random", "function_name": "choice_enum_item", "parameters": ["self", "enum"], "param_types": {"enum": "t.Any"}, "return_type": "t.Any", "param_doc": {"enum": "Enum object."}, "return_doc": "Random value of enum.", "raises_doc": [], "called_functions": ["list", "self.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Get random value of enum object.", "source_code": "def choice_enum_item(self, enum: t.Any) -> t.Any:\n    \"\"\"Get random value of enum object.\n\n    :param enum: Enum object.\n    :return: Random value of enum.\n    \"\"\"\n    return self.choice(list(enum))", "loc": 7}
{"file": "mimesis\\mimesis\\schema.py", "class_name": "BaseField", "function_name": "perform", "parameters": ["self", "name", "key"], "param_types": {"name": "str | None", "key": "Key"}, "return_type": "Any", "param_doc": {"name": "Name of the method.", "key": "A key function (any callable object)", "kwargs": "Kwargs of method."}, "return_doc": "The result of method.", "raises_doc": [{"type": "ValueError", "desc": "if provider is not supported or if field is not defined."}], "called_functions": ["FieldError", "callable", "key", "self._lookup_method", "self._validate_aliases", "self.get_random_instance"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Performs the value of the field by its name. It takes any string that represents the name of any method of any supported data provider and the ``**kwargs`` of this method. .. note:: Some data providers have methods with the same names, and in such cases, you can explicitly define that the method belongs to data-provider ``field(name='provider.name')`` otherwise it will return the data from the first provider which has a method ``name``. Allowed delimiters: ``.``, ``:``, ``/`` and space: - ``provider.name`` - ``provider:name`` - ``provider/name`` - ``provider name`` You can apply a *key function* to the result returned by the method, by passing a parameter **key** with a callable object which returns the final result. The key function has the option to accept two parameters: **result** and **random**. In case you require access to a random instance within the key function, you must modify the function to accept both of them, where the first corresponds to the method result and the second corresponds to the instance of random.", "source_code": "def perform(\n    self,\n    name: str | None = None,\n    key: Key = None,\n    **kwargs: Any,\n) -> Any:\n    \"\"\"Performs the value of the field by its name.\n\n    It takes any string that represents the name of any method of\n    any supported data provider and the ``**kwargs`` of this method.\n\n    .. note:: Some data providers have methods with the same names,\n        and in such cases, you can explicitly define that the method\n        belongs to data-provider ``field(name='provider.name')`` otherwise\n        it will return the data from the first provider which\n        has a method ``name``.\n\n        Allowed delimiters: ``.``, ``:``, ``/`` and space:\n\n        - ``provider.name``\n        - ``provider:name``\n        - ``provider/name``\n        - ``provider name``\n\n    You can apply a *key function* to the result returned by\n    the method, by passing a parameter **key** with a callable\n    object which returns the final result.\n\n    The key function has the option to accept two parameters: **result**\n    and **random**. In case you require access to a random instance within\n    the key function, you must modify the function to accept both of them,\n    where the first corresponds to the method result and the second\n    corresponds to the instance of random.\n\n    :param name: Name of the method.\n    :param key: A key function (any callable object)\n        which will be applied to result.\n    :param kwargs: Kwargs of method.\n    :return: The result of method.\n    :raises ValueError: if provider is not supported or if field is not defined.\n    \"\"\"\n    # Validate aliases before lookup\n    self._validate_aliases()\n\n    if name is None:\n        raise FieldError()\n\n    random = self.get_random_instance()\n\n    # First, try to find a custom field handler.\n    if name in self._handlers:\n        result = self._handlers[name](random, **kwargs)  # type: ignore\n    else:\n        result = self._lookup_method(name)(**kwargs)\n\n    if key and callable(key):\n        try:\n            # If a key function accepts two parameters\n            # then pass random instance to it.\n            return key(result, random)  # type: ignore\n        except TypeError:\n            return key(result)\n\n    return result", "loc": 64}
{"file": "mimesis\\mimesis\\schema.py", "class_name": "BaseField", "function_name": "register_handler", "parameters": ["self", "field_name", "field_handler"], "param_types": {"field_name": "str", "field_handler": "FieldHandler"}, "return_type": "None", "param_doc": {"field_name": "Name of the field.", "field_handler": "Callable object."}, "return_doc": "", "raises_doc": [], "called_functions": ["FieldArityError", "FieldNameError", "TypeError", "callable", "field_name.isidentifier", "inspect.signature", "isinstance", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Register a new field handler.", "source_code": "def register_handler(self, field_name: str, field_handler: FieldHandler) -> None:\n    \"\"\"Register a new field handler.\n\n    :param field_name: Name of the field.\n    :param field_handler: Callable object.\n    \"\"\"\n\n    if not isinstance(field_name, str):\n        raise TypeError(\"Field name must be a string.\")\n\n    if not field_name.isidentifier():\n        raise FieldNameError(field_name)\n\n    if not callable(field_handler):\n        raise TypeError(\"Handler must be a callable object.\")\n\n    callable_signature = inspect.signature(field_handler)\n\n    if len(callable_signature.parameters) <= 1:\n        raise FieldArityError()\n\n    if field_name not in self._handlers:\n        self._handlers[field_name] = field_handler", "loc": 23}
{"file": "mimesis\\mimesis\\schema.py", "class_name": "BaseField", "function_name": "register_handlers", "parameters": ["self", "fields"], "param_types": {"fields": "RegisterableFieldHandlers"}, "return_type": "None", "param_doc": {"fields": "A sequence of sequences with field name and handler."}, "return_doc": "None.", "raises_doc": [], "called_functions": ["self.register_handler"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Register the new field handlers.", "source_code": "def register_handlers(self, fields: RegisterableFieldHandlers) -> None:\n    \"\"\"Register the new field handlers.\n\n    :param fields: A sequence of sequences with field name and handler.\n    :return: None.\n    \"\"\"\n    for name, handler in fields:\n        self.register_handler(name, handler)", "loc": 8}
{"file": "mimesis\\mimesis\\schema.py", "class_name": "BaseField", "function_name": "unregister_handlers", "parameters": ["self", "field_names"], "param_types": {"field_names": "Sequence[str]"}, "return_type": "None", "param_doc": {"field_names": "Names of the fields."}, "return_doc": "None.", "raises_doc": [], "called_functions": ["self.unregister_handler"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Unregister a field handlers with given names.", "source_code": "def unregister_handlers(self, field_names: Sequence[str] = ()) -> None:\n    \"\"\"Unregister a field handlers with given names.\n\n    :param field_names: Names of the fields.\n    :return: None.\n    \"\"\"\n\n    for name in field_names:\n        self.unregister_handler(name)", "loc": 9}
{"file": "mimesis\\mimesis\\schema.py", "class_name": "Schema", "function_name": "to_json", "parameters": ["self", "file_path"], "param_types": {"file_path": "str"}, "return_type": "None", "param_doc": {"file_path": "File a path.", "kwargs": "Extra keyword arguments for :py:func:`json.dump` class."}, "return_doc": "", "raises_doc": [], "called_functions": ["json.dump", "open", "self.create"], "control_structures": [], "behavior_type": ["file_io", "serialization"], "doc_summary": "Export a schema as a JSON file.", "source_code": "def to_json(self, file_path: str, **kwargs: Any) -> None:\n    \"\"\"Export a schema as a JSON file.\n\n    :param file_path: File a path.\n    :param kwargs: Extra keyword arguments for :py:func:`json.dump` class.\n    \"\"\"\n    with open(file_path, \"w\", encoding=\"utf-8\") as fp:\n        json.dump(self.create(), fp, **kwargs)", "loc": 8}
{"file": "mimesis\\mimesis\\schema.py", "class_name": "Schema", "function_name": "to_pickle", "parameters": ["self", "file_path"], "param_types": {"file_path": "str"}, "return_type": "None", "param_doc": {"file_path": "The file path.", "kwargs": "Extra keyword arguments for :py:func:`pickle.dump` class."}, "return_doc": "", "raises_doc": [], "called_functions": ["open", "pickle.dump", "self.create"], "control_structures": [], "behavior_type": ["file_io", "serialization"], "doc_summary": "Export a schema as the pickled representation of the object to the file.", "source_code": "def to_pickle(self, file_path: str, **kwargs: Any) -> None:\n    \"\"\"Export a schema as the pickled representation of the object to the file.\n\n    :param file_path: The file path.\n    :param kwargs: Extra keyword arguments for :py:func:`pickle.dump` class.\n    \"\"\"\n    with open(file_path, \"wb\") as fp:\n        pickle.dump(self.create(), fp, **kwargs)", "loc": 8}
{"file": "mimesis\\mimesis\\schema.py", "class_name": "Schema", "function_name": "create", "parameters": ["self"], "param_types": {}, "return_type": "list[JSON]", "param_doc": {}, "return_doc": "List of fulfilled schemas.", "raises_doc": [], "called_functions": ["range", "self.__schema"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Creates a list of a fulfilled schemas. .. note:: This method evaluates immediately, so be careful when creating large datasets otherwise you're risking running out of memory. If you need a lazy version of this method, see :meth:`iterator`.", "source_code": "def create(self) -> list[JSON]:\n    \"\"\"Creates a list of a fulfilled schemas.\n\n    .. note::\n        This method evaluates immediately, so be careful when creating\n        large datasets otherwise you're risking running out of memory.\n\n        If you need a lazy version of this method, see :meth:`iterator`.\n\n    :return: List of fulfilled schemas.\n    \"\"\"\n    return [self.__schema() for _ in range(self.iterations)]", "loc": 12}
{"file": "mimesis\\mimesis\\shortcuts.py", "class_name": null, "function_name": "luhn_checksum", "parameters": ["num"], "param_types": {"num": "str"}, "return_type": "str", "param_doc": {"num": "The number to calculate a checksum for as a string."}, "return_doc": "Checksum for number.", "raises_doc": [], "called_functions": ["enumerate", "int", "reversed", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Calculate a checksum for num using the Luhn algorithm. Used to validate credit card numbers, IMEI numbers, and other identification numbers.", "source_code": "def luhn_checksum(num: str) -> str:\n    \"\"\"Calculate a checksum for num using the Luhn algorithm.\n\n    Used to validate credit card numbers, IMEI numbers,\n    and other identification numbers.\n\n    :param num: The number to calculate a checksum for as a string.\n    :return: Checksum for number.\n    \"\"\"\n    check = 0\n    for i, s in enumerate(reversed(num)):\n        sx = int(s)\n        if i % 2 == 0:\n            sx *= 2\n        if sx > 9:\n            sx -= 9\n        check += sx\n    return str(check * 9 % 10)", "loc": 18}
{"file": "mimesis\\mimesis\\plugins\\factory.py", "class_name": "FactoryField", "function_name": "evaluate", "parameters": ["self", "instance", "step", "extra"], "param_types": {"instance": "Resolver", "step": "BuildStep", "extra": "dict[str, Any] | None"}, "return_type": "Any", "param_doc": {"instance": "(factory.builder.Resolver): The object holding currently computed attributes.", "step": "(factory.builder.BuildStep): The object holding the current build step.", "extra": "Extra call-time added kwargs that would be passed to ``Field``."}, "return_doc": "", "raises_doc": [], "called_functions": ["_field", "kwargs.update", "self._get_cached_instance", "step.builder.factory_meta.declarations.get"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Evaluates the lazy field.", "source_code": "def evaluate(\n    self,\n    instance: Resolver,\n    step: BuildStep,\n    extra: dict[str, Any] | None = None,\n) -> Any:\n    \"\"\"Evaluates the lazy field.\n\n    :param instance: (factory.builder.Resolver): The object holding currently computed attributes.\n    :param step: (factory.builder.BuildStep): The object holding the current build step.\n    :param extra: Extra call-time added kwargs that would be passed to ``Field``.\n    \"\"\"\n    kwargs: dict[str, Any] = {}\n    kwargs.update(self.kwargs)\n    kwargs.update(extra or {})\n\n    field_handlers = step.builder.factory_meta.declarations.get(\n        \"field_handlers\", []\n    )\n\n    _field = self._get_cached_instance(\n        locale=self.locale,\n        field_handlers=field_handlers,\n    )\n    return _field(self.field, **kwargs)", "loc": 25}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "street_number", "parameters": ["self", "maximum"], "param_types": {"maximum": "int"}, "return_type": "str", "param_doc": {"maximum": "Maximum value."}, "return_doc": "Street number.", "raises_doc": [], "called_functions": ["self.random.randint", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random street number.", "source_code": "def street_number(self, maximum: int = 1400) -> str:\n    \"\"\"Generates a random street number.\n\n    :param maximum: Maximum value.\n    :return: Street number.\n    \"\"\"\n    return str(self.random.randint(1, maximum))", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "street_name", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Street name.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random street name.", "source_code": "def street_name(self) -> str:\n    \"\"\"Generates a random street name.\n\n    :return: Street name.\n    \"\"\"\n    street_names: list[str] = self._extract([\"street\", \"name\"])\n    return self.random.choice(street_names)", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "street_suffix", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Street suffix.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random street suffix.", "source_code": "def street_suffix(self) -> str:\n    \"\"\"Generates a random street suffix.\n\n    :return: Street suffix.\n    \"\"\"\n    suffixes: list[str] = self._extract([\"street\", \"suffix\"])\n    return self.random.choice(suffixes)", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "address", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Full address.", "raises_doc": [], "called_functions": ["fmt.format", "self._extract", "self.random.choice", "self.random.randints", "self.street_name", "self.street_number", "self.street_suffix"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random full address.", "source_code": "def address(self) -> str:\n    \"\"\"Generates a random full address.\n\n    :return: Full address.\n    \"\"\"\n    fmt: str = self._extract([\"address_fmt\"])\n\n    st_num = self.street_number()\n    st_name = self.street_name()\n\n    if self.locale in SHORTENED_ADDRESS_FMT:\n        return fmt.format(\n            st_num=st_num,\n            st_name=st_name,\n        )\n\n    if self.locale == \"ja\":\n        return fmt.format(\n            self.random.choice(self._extract([\"city\"])),\n            # Generate a list of random integers\n            # in n of 3, from 1 to 100.\n            *self.random.randints(n=3, a=1, b=100),\n        )\n\n    return fmt.format(\n        st_num=st_num,\n        st_name=st_name,\n        st_sfx=self.street_suffix(),\n    )", "loc": 29}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "state", "parameters": ["self", "abbr"], "param_types": {"abbr": "bool"}, "return_type": "str", "param_doc": {"abbr": "Return ISO 3166-2 code."}, "return_doc": "Administrative district.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random administrative district of the country.", "source_code": "def state(self, abbr: bool = False) -> str:\n    \"\"\"Generates a random administrative district of the country.\n\n    :param abbr: Return ISO 3166-2 code.\n    :return: Administrative district.\n    \"\"\"\n    key = \"abbr\" if abbr else \"name\"\n    states: list[str] = self._extract([\"state\", key])\n    return self.random.choice(states)", "loc": 9}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "postal_code", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Postal code.", "raises_doc": [], "called_functions": ["self._extract", "self.random.generate_string_by_mask"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a postal code for current locale.", "source_code": "def postal_code(self) -> str:\n    \"\"\"Generates a postal code for current locale.\n\n    :return: Postal code.\n    \"\"\"\n    return self.random.generate_string_by_mask(self._extract([\"postal_code_fmt\"]))", "loc": 6}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "country_code", "parameters": ["self", "code"], "param_types": {"code": "CountryCode | None"}, "return_type": "str", "param_doc": {"code": "Country code."}, "return_doc": "Country code in selected format.", "raises_doc": [{"type": "KeyError", "desc": "if fmt is not supported."}], "called_functions": ["self.random.choice", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random code of country. Default format is :attr:`~enums.CountryCode.A2` (ISO 3166-1-alpha2), you can change it by passing parameter ``fmt``.", "source_code": "def country_code(self, code: CountryCode | None = CountryCode.A2) -> str:\n    \"\"\"Generates a random code of country.\n\n    Default format is :attr:`~enums.CountryCode.A2` (ISO 3166-1-alpha2),\n    you can change it by passing parameter ``fmt``.\n\n    :param code: Country code.\n    :return: Country code in selected format.\n    :raises KeyError: if fmt is not supported.\n    \"\"\"\n    key = self.validate_enum(code, CountryCode)\n    return self.random.choice(COUNTRY_CODES[key])", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "country_emoji_flag", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Flag emoji.", "raises_doc": [], "called_functions": ["chr", "ord", "self.country_code"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a randomly chosen country emoji flag. :example: ", "source_code": "def country_emoji_flag(self) -> str:\n    \"\"\"Generates a randomly chosen country emoji flag.\n\n    :example:\n        \n\n    :return: Flag emoji.\n    \"\"\"\n    code = self.country_code(\n        code=CountryCode.A2,\n    )\n\n    offset = ord(\"\") - ord(\"A\")\n    first = ord(code[0]) + offset\n    second = ord(code[1]) + offset\n    return chr(first) + chr(second)", "loc": 16}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "country", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "The Country.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random country.", "source_code": "def country(self) -> str:\n    \"\"\"Generates a random country.\n\n    :return: The Country.\n    \"\"\"\n    countries: list[str] = self._extract([\"country\", \"name\"])\n    return self.random.choice(countries)", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "city", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "City name.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random city.", "source_code": "def city(self) -> str:\n    \"\"\"Generates a random city.\n\n    :return: City name.\n    \"\"\"\n    cities: list[str] = self._extract([\"city\"])\n    return self.random.choice(cities)", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\address.py", "class_name": "Address", "function_name": "continent", "parameters": ["self", "code"], "param_types": {"code": "bool"}, "return_type": "str", "param_doc": {"code": "Return code of a continent."}, "return_doc": "Continent name.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def continent(self, code: bool = False) -> str:\n    \"\"\"Returns a random continent name or continent code.\n\n    :param code: Return code of a continent.\n    :return: Continent name.\n    \"\"\"\n    codes: list[str] = self._extract([\"continent\"])\n\n    if code:\n        codes = CONTINENT_CODES\n\n    return self.random.choice(codes)", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\base.py", "class_name": "BaseProvider", "function_name": "reseed", "parameters": ["self", "seed"], "param_types": {"seed": "Seed"}, "return_type": "None", "param_doc": {"seed": "Seed for random."}, "return_doc": "", "raises_doc": [], "called_functions": ["self.random.seed", "t.cast"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Reseeds the internal random generator. In case we use the default seed, we need to create a per instance random generator. In this case, two providers with the same seed will always return the same values.", "source_code": "def reseed(self, seed: Seed = MissingSeed) -> None:\n    \"\"\"Reseeds the internal random generator.\n\n    In case we use the default seed, we need to create a per instance\n    random generator. In this case, two providers with the same seed\n    will always return the same values.\n\n    :param seed: Seed for random.\n        When set to `None` the current system time is used.\n    \"\"\"\n    self.seed = seed\n    if seed is MissingSeed:\n        # Remove casts after mypy will fix this inference:\n        if _random.global_seed is not MissingSeed:\n            self.random.seed(t.cast(t.Any, _random.global_seed))\n    else:\n        self.random.seed(t.cast(t.Any, seed))", "loc": 17}
{"file": "mimesis\\mimesis\\providers\\base.py", "class_name": "BaseProvider", "function_name": "validate_enum", "parameters": ["self", "item", "enum"], "param_types": {"item": "t.Any", "enum": "t.Any"}, "return_type": "t.Any", "param_doc": {"item": "Item of an enum object.", "enum": "Enum object."}, "return_doc": "Value of item.", "raises_doc": [{"type": "NonEnumerableError", "desc": "If enums has not such an item."}], "called_functions": ["NonEnumerableError", "isinstance", "self.random.choice_enum_item"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Validates various enum objects that are used as arguments for methods.", "source_code": "def validate_enum(self, item: t.Any, enum: t.Any) -> t.Any:\n    \"\"\"Validates various enum objects that are used as arguments for methods.\n\n    :param item: Item of an enum object.\n    :param enum: Enum object.\n    :return: Value of item.\n    :raises NonEnumerableError: If enums has not such an item.\n    \"\"\"\n    if item is None:\n        result = self.random.choice_enum_item(enum)\n    elif item and isinstance(item, enum):\n        result = item\n    else:\n        raise NonEnumerableError(enum)\n\n    return result.value", "loc": 16}
{"file": "mimesis\\mimesis\\providers\\base.py", "class_name": "BaseDataProvider", "function_name": "update_dataset", "parameters": ["self", "data"], "param_types": {"data": "JSON"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TypeError", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Updates dataset merging a given dict into default data. This method may be useful when you need to override data for a given key in JSON file.", "source_code": "def update_dataset(self, data: JSON) -> None:\n    \"\"\"Updates dataset merging a given dict into default data.\n\n    This method may be useful when you need to override data\n    for a given key in JSON file.\n    \"\"\"\n    if not isinstance(data, dict):\n        raise TypeError(\"The data must be a dict.\")\n\n    self._dataset |= data", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\base.py", "class_name": "BaseDataProvider", "function_name": "override_locale", "parameters": ["self", "locale"], "param_types": {"locale": "Locale"}, "return_type": "t.Generator['BaseDataProvider', None, None]", "param_doc": {"locale": "Locale."}, "return_doc": "Provider with overridden locale.", "raises_doc": [], "called_functions": ["Locale", "ValueError", "self._override_locale"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Context manager that allows overriding current locale. Temporarily overrides current locale for locale-dependent providers.", "source_code": "def override_locale(\n    self,\n    locale: Locale,\n) -> t.Generator[\"BaseDataProvider\", None, None]:\n    \"\"\"Context manager that allows overriding current locale.\n\n    Temporarily overrides current locale for\n    locale-dependent providers.\n\n    :param locale: Locale.\n    :return: Provider with overridden locale.\n    \"\"\"\n    try:\n        origin_locale = Locale(self.locale)\n        self._override_locale(locale)\n        try:\n            yield self\n        finally:\n            self._override_locale(origin_locale)\n    except AttributeError:\n        raise ValueError(f\"{self.__class__.__name__} has not locale dependent\")", "loc": 21}
{"file": "mimesis\\mimesis\\providers\\code.py", "class_name": "Code", "function_name": "isbn", "parameters": ["self", "fmt", "locale"], "param_types": {"fmt": "ISBNFormat | None", "locale": "Locale"}, "return_type": "str", "param_doc": {"fmt": "ISBN format.", "locale": "Locale code."}, "return_doc": "ISBN.", "raises_doc": [{"type": "NonEnumerableError", "desc": "if code is not enum ISBNFormat."}], "called_functions": ["ISBN_MASKS[fmt_value].format", "self.random.generate_string_by_mask", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates ISBN for current locale. To change ISBN format, pass parameter ``code`` with needed value of the enum object :class:`~mimesis.enums.ISBNFormat`", "source_code": "def isbn(\n    self, fmt: ISBNFormat | None = None, locale: Locale = Locale.DEFAULT\n) -> str:\n    \"\"\"Generates ISBN for current locale.\n\n    To change ISBN format, pass parameter ``code`` with needed value of\n    the enum object :class:`~mimesis.enums.ISBNFormat`\n\n    :param fmt: ISBN format.\n    :param locale: Locale code.\n    :return: ISBN.\n    :raises NonEnumerableError: if code is not enum ISBNFormat.\n    \"\"\"\n    fmt_value = self.validate_enum(item=fmt, enum=ISBNFormat)\n    mask = ISBN_MASKS[fmt_value].format(ISBN_GROUPS[locale.value])\n    return self.random.generate_string_by_mask(mask)", "loc": 16}
{"file": "mimesis\\mimesis\\providers\\code.py", "class_name": "Code", "function_name": "ean", "parameters": ["self", "fmt"], "param_types": {"fmt": "EANFormat | None"}, "return_type": "str", "param_doc": {"fmt": "Format of EAN."}, "return_doc": "EAN.", "raises_doc": [{"type": "NonEnumerableError", "desc": "if code is not enum EANFormat."}], "called_functions": ["self.random.generate_string_by_mask", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates EAN. To change an EAN format, pass parameter ``code`` with needed value of the enum object :class:`~mimesis.enums.EANFormat`.", "source_code": "def ean(self, fmt: EANFormat | None = None) -> str:\n    \"\"\"Generates EAN.\n\n    To change an EAN format, pass parameter ``code`` with needed value of\n    the enum object :class:`~mimesis.enums.EANFormat`.\n\n    :param fmt: Format of EAN.\n    :return: EAN.\n    :raises NonEnumerableError: if code is not enum EANFormat.\n    \"\"\"\n    key = self.validate_enum(\n        item=fmt,\n        enum=EANFormat,\n    )\n    mask = EAN_MASKS[key]\n    return self.random.generate_string_by_mask(mask=mask)", "loc": 16}
{"file": "mimesis\\mimesis\\providers\\code.py", "class_name": "Code", "function_name": "imei", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "IMEI.", "raises_doc": [], "called_functions": ["luhn_checksum", "self.random.choice", "self.random.randint", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random IMEI.", "source_code": "def imei(self) -> str:\n    \"\"\"Generates a random IMEI.\n\n    :return: IMEI.\n    \"\"\"\n    num = self.random.choice(IMEI_TACS)\n    num += str(self.random.randint(100000, 999999))\n    return num + luhn_checksum(num)", "loc": 8}
{"file": "mimesis\\mimesis\\providers\\cryptographic.py", "class_name": "Cryptographic", "function_name": "uuid_object", "parameters": ["self"], "param_types": {}, "return_type": "UUID", "param_doc": {}, "return_doc": "UUID4 object.", "raises_doc": [], "called_functions": ["UUID", "self.random.getrandbits"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates UUID4 object.", "source_code": "def uuid_object(self) -> UUID:\n    \"\"\"Generates UUID4 object.\n\n    :return: UUID4 object.\n    \"\"\"\n    rand_bits = self.random.getrandbits(128)\n    return UUID(int=rand_bits, version=4)", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\cryptographic.py", "class_name": "Cryptographic", "function_name": "uuid", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "UUID4 as string.", "raises_doc": [], "called_functions": ["self.uuid_object", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates UUID4 string.", "source_code": "def uuid(self) -> str:\n    \"\"\"Generates UUID4 string.\n\n    :return: UUID4 as string.\n    \"\"\"\n    return str(self.uuid_object())", "loc": 6}
{"file": "mimesis\\mimesis\\providers\\cryptographic.py", "class_name": "Cryptographic", "function_name": "hash", "parameters": ["self", "algorithm"], "param_types": {"algorithm": "Algorithm | None"}, "return_type": "str", "param_doc": {"algorithm": "Enum object :class:`~mimesis.enums.Algorithm`."}, "return_doc": "Hash.", "raises_doc": [{"type": "NonEnumerableError", "desc": "When algorithm is unsupported."}], "called_functions": ["func", "getattr", "self.uuid", "self.uuid().encode", "self.validate_enum", "str", "value.hexdigest"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates random hash. To change hashing algorithm, pass parameter ``algorithm`` with needed value of the enum object :class:`~mimesis.enums.Algorithm`", "source_code": "def hash(self, algorithm: Algorithm | None = None) -> str:  # noqa: A003\n    \"\"\"Generates random hash.\n\n    To change hashing algorithm, pass parameter ``algorithm``\n    with needed value of the enum object :class:`~mimesis.enums.Algorithm`\n\n    :param algorithm: Enum object :class:`~mimesis.enums.Algorithm`.\n    :return: Hash.\n    :raises NonEnumerableError: When algorithm is unsupported.\n    \"\"\"\n    key = self.validate_enum(algorithm, Algorithm)\n    func = getattr(hashlib, key)\n    value = func(self.uuid().encode())\n    return str(value.hexdigest())", "loc": 14}
{"file": "mimesis\\mimesis\\providers\\cryptographic.py", "class_name": "Cryptographic", "function_name": "token_bytes", "parameters": ["self", "entropy"], "param_types": {"entropy": "int"}, "return_type": "bytes", "param_doc": {"entropy": "Number of bytes (default: 32)."}, "return_doc": "Random bytes.", "raises_doc": [], "called_functions": ["bytes", "range", "self.random.randint"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates byte string containing ``entropy`` bytes. The string has ``entropy`` random bytes, each byte converted to two hex digits.", "source_code": "def token_bytes(self, entropy: int = 32) -> bytes:\n    \"\"\"Generates byte string containing ``entropy`` bytes.\n\n    The string has ``entropy`` random bytes, each byte\n    converted to two hex digits.\n\n    :param entropy: Number of bytes (default: 32).\n    :return: Random bytes.\n    \"\"\"\n    return bytes([self.random.randint(0, 255) for _ in range(entropy)])", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\cryptographic.py", "class_name": "Cryptographic", "function_name": "token_hex", "parameters": ["self", "entropy"], "param_types": {"entropy": "int"}, "return_type": "str", "param_doc": {"entropy": "Number of bytes (default: 32)."}, "return_doc": "Token.", "raises_doc": [], "called_functions": ["self.token_bytes", "self.token_bytes(entropy).hex"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random text string, in hexadecimal. The string has *entropy* random bytes, each byte converted to two hex digits.  If *entropy* is ``None`` or not supplied, a reasonable default is used.", "source_code": "def token_hex(self, entropy: int = 32) -> str:\n    \"\"\"Generates a random text string, in hexadecimal.\n\n    The string has *entropy* random bytes, each byte converted to two\n    hex digits.  If *entropy* is ``None`` or not supplied, a reasonable\n    default is used.\n\n    :param entropy: Number of bytes (default: 32).\n    :return: Token.\n    \"\"\"\n    return self.token_bytes(entropy).hex()", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\cryptographic.py", "class_name": "Cryptographic", "function_name": "token_urlsafe", "parameters": ["self", "entropy"], "param_types": {"entropy": "int"}, "return_type": "str", "param_doc": {"entropy": "Number of bytes (default: 32)."}, "return_doc": "URL-safe token.", "raises_doc": [], "called_functions": ["self.token_bytes", "urlsafe_b64encode", "urlsafe_b64encode(token).rstrip", "urlsafe_b64encode(token).rstrip(b'=').decode"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random URL-safe text string, in Base64 encoding. The string has *entropy* random bytes.  If *entropy* is ``None`` or not supplied, a reasonable default is used.", "source_code": "def token_urlsafe(self, entropy: int = 32) -> str:\n    \"\"\"Generates a random URL-safe text string, in Base64 encoding.\n\n    The string has *entropy* random bytes.  If *entropy* is ``None``\n    or not supplied, a reasonable default is used.\n\n    :param entropy: Number of bytes (default: 32).\n    :return: URL-safe token.\n    \"\"\"\n    token = self.token_bytes(entropy)\n    return urlsafe_b64encode(token).rstrip(b\"=\").decode()", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\cryptographic.py", "class_name": "Cryptographic", "function_name": "mnemonic_phrase", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Mnemonic phrase.", "raises_doc": [], "called_functions": ["' '.join", "self.random.choice", "self.random.choices"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates BIP-39 looking mnemonic phrase.", "source_code": "def mnemonic_phrase(self) -> str:\n    \"\"\"Generates BIP-39 looking mnemonic phrase.\n\n    :return: Mnemonic phrase.\n    \"\"\"\n    length = self.random.choice([12, 24])\n    phrases = self.random.choices(WORDLIST, k=length)\n    return \" \".join(phrases)", "loc": 8}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "bulk_create_datetimes", "parameters": ["date_start", "date_end"], "param_types": {"date_start": "DateTime", "date_end": "DateTime"}, "return_type": "list[DateTime]", "param_doc": {"date_start": "Begin of the range.", "date_end": "End of the range.", "kwargs": "Keyword arguments for :py:class:`datetime.timedelta`"}, "return_doc": "List of datetime objects", "raises_doc": [], "called_functions": ["ValueError", "dt_objects.append", "timedelta"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Bulk create datetime objects. This method creates a list of datetime objects from ``date_start`` to ``date_end``. You can use the following keyword arguments: * ``days`` * ``hours`` * ``minutes`` * ``seconds`` * ``microseconds`` .. warning:: Empty ``**kwargs`` produces **timedelta(0)** which obviously cannot be used as step, so you have to pass valid ``**kwargs`` for :py:class:`datetime.timedelta` which will be used as a step by which ``date_start`` will be incremented until it reaches ``date_end`` to avoid infinite loop which eventually leads to ``OverflowError``. See :py:class:`datetime.timedelta` for more details.", "source_code": "def bulk_create_datetimes(\n    date_start: DateTime,\n    date_end: DateTime,\n    **kwargs: t.Any,\n) -> list[DateTime]:\n    \"\"\"Bulk create datetime objects.\n\n    This method creates a list of datetime objects from\n    ``date_start`` to ``date_end``.\n\n    You can use the following keyword arguments:\n\n    * ``days``\n    * ``hours``\n    * ``minutes``\n    * ``seconds``\n    * ``microseconds``\n\n    .. warning::\n\n        Empty ``**kwargs`` produces **timedelta(0)** which obviously\n        cannot be used as step, so you have to pass valid ``**kwargs``\n        for :py:class:`datetime.timedelta` which will be used as a step\n        by which ``date_start`` will be incremented until it reaches ``date_end``\n        to avoid infinite loop which eventually leads to ``OverflowError``.\n\n    See :py:class:`datetime.timedelta` for more details.\n\n    :param date_start: Begin of the range.\n    :param date_end: End of the range.\n    :param kwargs: Keyword arguments for :py:class:`datetime.timedelta`\n    :return: List of datetime objects\n    :raises: ValueError: When ``date_start``/``date_end`` not passed,\n        when ``date_start`` larger than ``date_end`` or when the given\n        keywords for `datetime.timedelta` represent a non-positive timedelta.\n    \"\"\"\n    dt_objects = []\n\n    if not date_start and not date_end:\n        raise ValueError(\"You must pass date_start and date_end\")\n\n    if date_end < date_start:\n        raise ValueError(\"date_start can not be larger than date_end\")\n\n    if timedelta(**kwargs) <= timedelta():\n        raise ValueError(\"timedelta must be positive\")\n\n    while date_start <= date_end:\n        date_start += timedelta(**kwargs)\n        dt_objects.append(date_start)\n\n    return dt_objects", "loc": 52}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "week_date", "parameters": ["self", "start", "end"], "param_types": {"start": "int", "end": "int"}, "return_type": "str", "param_doc": {"start": "Starting year.", "end": "Ending year."}, "return_doc": "Week number.", "raises_doc": [], "called_functions": ["self.random.randint", "self.year"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates week number with year.", "source_code": "def week_date(self, start: int = 2017, end: int = _CURRENT_YEAR) -> str:\n    \"\"\"Generates week number with year.\n\n    :param start: Starting year.\n    :param end: Ending year.\n    :return: Week number.\n    \"\"\"\n    year = self.year(start, end)\n    week = self.random.randint(1, 52)\n    return f\"{year}-W{week}\"", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "day_of_week", "parameters": ["self", "abbr"], "param_types": {"abbr": "bool"}, "return_type": "str", "param_doc": {"abbr": "Abbreviated day name."}, "return_doc": "Day of the week.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random day of the week.", "source_code": "def day_of_week(self, abbr: bool = False) -> str:\n    \"\"\"Generates a random day of the week.\n\n    :param abbr: Abbreviated day name.\n    :return: Day of the week.\n    \"\"\"\n    key = \"abbr\" if abbr else \"name\"\n    days: list[str] = self._extract([\"day\", key])\n    return self.random.choice(days)", "loc": 9}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "month", "parameters": ["self", "abbr"], "param_types": {"abbr": "bool"}, "return_type": "str", "param_doc": {"abbr": "Abbreviated month name."}, "return_doc": "Month name.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random month of the year.", "source_code": "def month(self, abbr: bool = False) -> str:\n    \"\"\"Generates a random month of the year.\n\n    :param abbr: Abbreviated month name.\n    :return: Month name.\n    \"\"\"\n    key = \"abbr\" if abbr else \"name\"\n    months: list[str] = self._extract([\"month\", key])\n    return self.random.choice(months)", "loc": 9}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "periodicity", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Periodicity.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random periodicity string.", "source_code": "def periodicity(self) -> str:\n    \"\"\"Generates a random periodicity string.\n\n    :return: Periodicity.\n    \"\"\"\n    periodicity: list[str] = self._extract([\"periodicity\"])\n    return self.random.choice(periodicity)", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "date", "parameters": ["self", "start", "end"], "param_types": {"start": "int", "end": "int"}, "return_type": "Date", "param_doc": {"start": "Minimum value of year.", "end": "Maximum value of year."}, "return_doc": "Formatted date.", "raises_doc": [], "called_functions": ["date", "monthrange", "self.random.randint"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random date object.", "source_code": "def date(self, start: int = 2000, end: int = _CURRENT_YEAR) -> Date:\n    \"\"\"Generates a random date object.\n\n    :param start: Minimum value of year.\n    :param end: Maximum value of year.\n    :return: Formatted date.\n    \"\"\"\n    year = self.random.randint(start, end)\n    month = self.random.randint(1, 12)\n    day = self.random.randint(1, monthrange(year, month)[1])\n    date_object = date(year, month, day)\n    return date_object", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "formatted_date", "parameters": ["self", "fmt"], "param_types": {"fmt": "str"}, "return_type": "str", "param_doc": {"fmt": "The format of date, if None then use standard", "kwargs": "Keyword arguments for :meth:`~.date()`"}, "return_doc": "Formatted date.", "raises_doc": [], "called_functions": ["date_obj.strftime", "self._extract", "self.date"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates random date as string.", "source_code": "def formatted_date(self, fmt: str = \"\", **kwargs: t.Any) -> str:\n    \"\"\"Generates random date as string.\n\n    :param fmt: The format of date, if None then use standard\n        accepted in the current locale.\n    :param kwargs: Keyword arguments for :meth:`~.date()`\n    :return: Formatted date.\n    \"\"\"\n    date_obj = self.date(**kwargs)\n\n    if not fmt:\n        fmt = self._extract([\"formats\", \"date\"])\n\n    return date_obj.strftime(fmt)", "loc": 14}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "time", "parameters": ["self"], "param_types": {}, "return_type": "Time", "param_doc": {}, "return_doc": "``datetime.time`` object.", "raises_doc": [], "called_functions": ["self.random.randint", "time"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random time object.", "source_code": "def time(self) -> Time:\n    \"\"\"Generates a random time object.\n\n    :return: ``datetime.time`` object.\n    \"\"\"\n    random_time = time(\n        self.random.randint(0, 23),\n        self.random.randint(0, 59),\n        self.random.randint(0, 59),\n        self.random.randint(0, 999999),\n    )\n    return random_time", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "formatted_time", "parameters": ["self", "fmt"], "param_types": {"fmt": "str"}, "return_type": "str", "param_doc": {"fmt": "The format of time, if None then use standard"}, "return_doc": "String formatted time.", "raises_doc": [], "called_functions": ["self._extract", "self.time", "time_obj.strftime"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates formatted time as string.", "source_code": "def formatted_time(self, fmt: str = \"\") -> str:\n    \"\"\"Generates formatted time as string.\n\n    :param fmt: The format of time, if None then use standard\n        accepted in the current locale.\n    :return: String formatted time.\n    \"\"\"\n    time_obj = self.time()\n\n    if not fmt:\n        fmt = self._extract([\"formats\", \"time\"])\n    return time_obj.strftime(fmt)", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "timezone", "parameters": ["self", "region"], "param_types": {"region": "TimezoneRegion | None"}, "return_type": "str", "param_doc": {"region": "Timezone region."}, "return_doc": "Timezone.", "raises_doc": [], "called_functions": ["self.random.choice", "self.validate_enum", "tz.startswith"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random timezone.", "source_code": "def timezone(self, region: TimezoneRegion | None = None) -> str:\n    \"\"\"Generates a random timezone.\n\n    :param region: Timezone region.\n    :return: Timezone.\n    \"\"\"\n    region_name = self.validate_enum(region, TimezoneRegion)\n    return self.random.choice(\n        [tz for tz in TIMEZONES if tz.startswith(region_name)]\n    )", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "datetime", "parameters": ["self", "start", "end", "timezone"], "param_types": {"start": "int", "end": "int", "timezone": "str | None"}, "return_type": "DateTime", "param_doc": {"start": "Minimum value of year.", "end": "Maximum value of year.", "timezone": "Set custom timezone (pytz required)."}, "return_doc": "Datetime", "raises_doc": [], "called_functions": ["ImportError", "datetime.combine", "pytz.timezone", "self.date", "self.time", "tz.localize"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates random datetime.", "source_code": "def datetime(\n    self,\n    start: int = _CURRENT_YEAR,\n    end: int = _CURRENT_YEAR,\n    timezone: str | None = None,\n) -> DateTime:\n    \"\"\"Generates random datetime.\n\n    :param start: Minimum value of year.\n    :param end: Maximum value of year.\n    :param timezone: Set custom timezone (pytz required).\n    :return: Datetime\n    \"\"\"\n    datetime_obj = datetime.combine(\n        date=self.date(start, end),\n        time=self.time(),\n    )\n    if timezone:\n        if not pytz:\n            raise ImportError(\"Timezones are supported only with pytz\")\n        tz = pytz.timezone(timezone)\n        datetime_obj = tz.localize(datetime_obj)\n\n    return datetime_obj", "loc": 24}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "formatted_datetime", "parameters": ["self", "fmt"], "param_types": {"fmt": "str"}, "return_type": "str", "param_doc": {"fmt": "Custom format (default is format for current locale)", "kwargs": "Keyword arguments for :meth:`~.datetime()`"}, "return_doc": "Formatted datetime string.", "raises_doc": [], "called_functions": ["dt_obj.strftime", "self._extract", "self.datetime"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates datetime string in human-readable format.", "source_code": "def formatted_datetime(self, fmt: str = \"\", **kwargs: t.Any) -> str:\n    \"\"\"Generates datetime string in human-readable format.\n\n    :param fmt: Custom format (default is format for current locale)\n    :param kwargs: Keyword arguments for :meth:`~.datetime()`\n    :return: Formatted datetime string.\n    \"\"\"\n    dt_obj = self.datetime(**kwargs)\n\n    if not fmt:\n        date_fmt = self._extract([\"formats\", \"date\"])\n        time_fmt = self._extract([\"formats\", \"time\"])\n        fmt = f\"{date_fmt} {time_fmt}\"\n\n    return dt_obj.strftime(fmt)", "loc": 15}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "timestamp", "parameters": ["self", "fmt"], "param_types": {"fmt": "TimestampFormat"}, "return_type": "str | int", "param_doc": {"fmt": "Format of timestamp (Default is TimestampFormat.POSIX).", "kwargs": "Kwargs for :meth:`~.datetime()`."}, "return_doc": "Timestamp.", "raises_doc": [], "called_functions": ["int", "self.datetime", "self.validate_enum", "stamp.isoformat", "stamp.strftime", "stamp.timestamp"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random timestamp in given format. Supported formats are: - TimestampFormat.POSIX - TimestampFormat.RFC_3339 - TimestampFormat.ISO_8601 Example: >>> from mimesis import Datetime >>> from mimesis.enums import TimestampFormat >>> dt = Datetime() >>> dt.timestamp(fmt=TimestampFormat.POSIX) 1697322442 >>> dt.timestamp(fmt=TimestampFormat.RFC_3339) '2023-12-08T18:46:34' >>> dt.timestamp(fmt=TimestampFormat.ISO_8601) '2009-05-30T21:45:57.328600'", "source_code": "def timestamp(\n    self, fmt: TimestampFormat = TimestampFormat.POSIX, **kwargs: t.Any\n) -> str | int:\n    \"\"\"Generates a random timestamp in given format.\n\n    Supported formats are:\n\n    - TimestampFormat.POSIX\n    - TimestampFormat.RFC_3339\n    - TimestampFormat.ISO_8601\n\n    Example:\n\n    >>> from mimesis import Datetime\n    >>> from mimesis.enums import TimestampFormat\n    >>> dt = Datetime()\n    >>> dt.timestamp(fmt=TimestampFormat.POSIX)\n    1697322442\n    >>> dt.timestamp(fmt=TimestampFormat.RFC_3339)\n    '2023-12-08T18:46:34'\n    >>> dt.timestamp(fmt=TimestampFormat.ISO_8601)\n    '2009-05-30T21:45:57.328600'\n\n    :param fmt: Format of timestamp (Default is TimestampFormat.POSIX).\n    :param kwargs: Kwargs for :meth:`~.datetime()`.\n    :return: Timestamp.\n    \"\"\"\n    self.validate_enum(fmt, TimestampFormat)\n    stamp = self.datetime(**kwargs)\n\n    if fmt == TimestampFormat.RFC_3339:\n        return stamp.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n    elif fmt == TimestampFormat.ISO_8601:\n        return stamp.isoformat()\n    else:\n        return int(stamp.timestamp())", "loc": 36}
{"file": "mimesis\\mimesis\\providers\\date.py", "class_name": "Datetime", "function_name": "duration", "parameters": ["self", "min_duration", "max_duration", "duration_unit"], "param_types": {"min_duration": "int", "max_duration": "int", "duration_unit": "DurationUnit | None"}, "return_type": "timedelta", "param_doc": {"min_duration": "Minimum duration.", "max_duration": "Maximum duration.", "duration_unit": "Duration unit."}, "return_doc": "Duration as timedelta.", "raises_doc": [], "called_functions": ["TypeError", "ValueError", "isinstance", "self.random.randint", "self.validate_enum", "timedelta"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generate a random duration. The default duration unit is Duration.MINUTES. When the duration unit is None, then random duration from DurationUnit is chosen. A timedelta object represents a duration, the difference between two datetime or date instances.", "source_code": "def duration(\n    self,\n    min_duration: int = 1,\n    max_duration: int = 10,\n    duration_unit: DurationUnit | None = DurationUnit.MINUTES,\n) -> timedelta:\n    \"\"\"Generate a random duration.\n\n    The default duration unit is Duration.MINUTES.\n\n    When the duration unit is None, then random\n    duration from DurationUnit is chosen.\n\n    A timedelta object represents a duration, the difference\n    between two datetime or date instances.\n\n    :param min_duration: Minimum duration.\n    :param max_duration: Maximum duration.\n    :param duration_unit: Duration unit.\n    :return: Duration as timedelta.\n    \"\"\"\n    if min_duration > max_duration:\n        raise ValueError(\"min_duration must be less or equal to max_duration\")\n\n    if not isinstance(min_duration, int) or not isinstance(max_duration, int):\n        raise TypeError(\"min_duration and max_duration must be integers\")\n\n    unit = self.validate_enum(duration_unit, DurationUnit)\n    return timedelta(**{unit: self.random.randint(min_duration, max_duration)})", "loc": 29}
{"file": "mimesis\\mimesis\\providers\\development.py", "class_name": "Development", "function_name": "calver", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Calendar versioning string.", "raises_doc": [], "called_functions": ["datetime.now", "self.random.randint"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random calendar versioning string.", "source_code": "def calver(self) -> str:\n    \"\"\"Generates a random calendar versioning string.\n\n    :return: Calendar versioning string.\n\n    :Example:\n        2016.11.08\n    \"\"\"\n    year = self.random.randint(2016, datetime.now().year)\n    month = self.random.randint(1, 12)\n    day = self.random.randint(1, 29)\n    return f\"{year}.{month}.{day}\"", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\file.py", "class_name": "File", "function_name": "extension", "parameters": ["self", "file_type"], "param_types": {"file_type": "FileType | None"}, "return_type": "str", "param_doc": {"file_type": "Enum object FileType."}, "return_doc": "Extension of the file.", "raises_doc": [], "called_functions": ["self.random.choice", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random file extension.", "source_code": "def extension(self, file_type: FileType | None = None) -> str:\n    \"\"\"Generates a random file extension.\n\n    :param file_type: Enum object FileType.\n    :return: Extension of the file.\n\n    :Example:\n        .py\n    \"\"\"\n    key = self.validate_enum(item=file_type, enum=FileType)\n    extensions = EXTENSIONS[key]\n    return self.random.choice(extensions)", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\file.py", "class_name": "File", "function_name": "mime_type", "parameters": ["self", "type_"], "param_types": {"type_": "MimeType | None"}, "return_type": "str", "param_doc": {"type_": "Enum object MimeType."}, "return_doc": "Mime type.", "raises_doc": [], "called_functions": ["self.random.choice", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random mime type.", "source_code": "def mime_type(self, type_: MimeType | None = None) -> str:\n    \"\"\"Generates a random mime type.\n\n    :param type_: Enum object MimeType.\n    :return: Mime type.\n    \"\"\"\n    key = self.validate_enum(item=type_, enum=MimeType)\n    types = MIME_TYPES[key]\n    return self.random.choice(types)", "loc": 9}
{"file": "mimesis\\mimesis\\providers\\file.py", "class_name": "File", "function_name": "size", "parameters": ["self", "minimum", "maximum"], "param_types": {"minimum": "int", "maximum": "int"}, "return_type": "str", "param_doc": {"minimum": "Maximum value.", "maximum": "Minimum value."}, "return_doc": "Size of file.", "raises_doc": [], "called_functions": ["self.random.choice", "self.random.randint"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random file size as string.", "source_code": "def size(self, minimum: int = 1, maximum: int = 100) -> str:\n    \"\"\"Generates a random file size as string.\n\n    :param minimum: Maximum value.\n    :param maximum: Minimum value.\n    :return: Size of file.\n\n    :Example:\n        56 kB\n    \"\"\"\n    num = self.random.randint(minimum, maximum)\n    unit = self.random.choice([\"bytes\", \"kB\", \"MB\", \"GB\", \"TB\"])\n    return f\"{num} {unit}\"", "loc": 13}
{"file": "mimesis\\mimesis\\providers\\file.py", "class_name": "File", "function_name": "file_name", "parameters": ["self", "file_type"], "param_types": {"file_type": "FileType | None"}, "return_type": "str", "param_doc": {"file_type": "Enum object FileType"}, "return_doc": "File name.", "raises_doc": [], "called_functions": ["self.extension", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random file name with an extension.", "source_code": "def file_name(self, file_type: FileType | None = None) -> str:\n    \"\"\"Generates a random file name with an extension.\n\n    :param file_type: Enum object FileType\n    :return: File name.\n\n    :Example:\n        legislative.txt\n    \"\"\"\n    ext = self.extension(file_type)\n    name = self.random.choice(FILENAMES)\n    return f\"{name}{ext}\"", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\finance.py", "class_name": "Finance", "function_name": "company", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Company name.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random company name.", "source_code": "def company(self) -> str:\n    \"\"\"Generates a random company name.\n\n    :return: Company name.\n    \"\"\"\n    names: list[str] = self._extract([\"company\", \"name\"])\n\n    return self.random.choice(names)", "loc": 8}
{"file": "mimesis\\mimesis\\providers\\finance.py", "class_name": "Finance", "function_name": "company_type", "parameters": ["self", "abbr"], "param_types": {"abbr": "bool"}, "return_type": "str", "param_doc": {"abbr": "Abbreviated company type."}, "return_doc": "Types of business entity.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random type of business entity.", "source_code": "def company_type(self, abbr: bool = False) -> str:\n    \"\"\"Generates a random type of business entity.\n\n    :param abbr: Abbreviated company type.\n    :return: Types of business entity.\n    \"\"\"\n    key = \"abbr\" if abbr else \"title\"\n\n    company_types: list[str] = self._extract([\"company\", \"type\", key])\n    return self.random.choice(company_types)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\finance.py", "class_name": "Finance", "function_name": "currency_iso_code", "parameters": ["self", "allow_random"], "param_types": {"allow_random": "bool"}, "return_type": "str", "param_doc": {"allow_random": "Get a random ISO code."}, "return_doc": "Currency code.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def currency_iso_code(self, allow_random: bool = False) -> str:\n    \"\"\"Returns a currency code for current locale.\n\n    :param allow_random: Get a random ISO code.\n    :return: Currency code.\n    \"\"\"\n    code: str = self._extract([\"currency-code\"])\n\n    if allow_random:\n        return self.random.choice(CURRENCY_ISO_CODES)\n    return code", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\finance.py", "class_name": "Finance", "function_name": "bank", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Bank name.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random bank name.", "source_code": "def bank(self) -> str:\n    \"\"\"Generates a random bank name.\n\n    :return: Bank name.\n    \"\"\"\n    banks: list[str] = self._extract([\"banks\"])\n    return self.random.choice(banks)", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\generic.py", "class_name": "Generic", "function_name": "reseed", "parameters": ["self", "seed"], "param_types": {"seed": "Seed"}, "return_type": "None", "param_doc": {"seed": "Seed for random."}, "return_doc": "None.", "raises_doc": [], "called_functions": ["getattr", "provider.reseed", "self.__dir__", "super", "super().reseed"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "Reseed the internal random generator. Overrides method `BaseProvider.reseed()`.", "source_code": "def reseed(self, seed: Seed = MissingSeed) -> None:\n    \"\"\"Reseed the internal random generator.\n\n    Overrides method `BaseProvider.reseed()`.\n\n    :param seed: Seed for random.\n    :return: None.\n    \"\"\"\n    # Make sure to reseed the random generator on Generic itself.\n    super().reseed(seed)\n\n    for attr in self.__dir__():\n        try:\n            provider = getattr(self, attr)\n            provider.reseed(seed)\n        except AttributeError:\n            continue", "loc": 17}
{"file": "mimesis\\mimesis\\providers\\generic.py", "class_name": "Generic", "function_name": "add_provider", "parameters": ["self", "cls"], "param_types": {"cls": "t.Type[BaseProvider]"}, "return_type": "None", "param_doc": {"cls": "Custom provider.", "kwargs": "Keyword arguments for provider."}, "return_doc": "Absolutely none.", "raises_doc": [{"type": "TypeError", "desc": "if cls is Generic, if cls is not"}], "called_functions": ["TypeError", "cls", "cls.__name__.lower", "inspect.isclass", "isinstance", "issubclass", "kwargs.pop", "setattr"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Adds a custom provider to a Generic() object.", "source_code": "def add_provider(self, cls: t.Type[BaseProvider], **kwargs: t.Any) -> None:\n    \"\"\"Adds a custom provider to a Generic() object.\n\n    :param cls: Custom provider.\n    :param kwargs: Keyword arguments for provider.\n    :raises TypeError: if cls is Generic, if cls is not\n        class or is not a subclass of BaseProvider.\n    :return: Absolutely none.\n    \"\"\"\n\n    if inspect.isclass(cls):\n        if not issubclass(cls, BaseProvider):\n            raise TypeError(\n                \"The provider must be a \"\n                \"subclass of mimesis.providers.BaseProvider\"\n            )\n        try:\n            name = cls.Meta.name\n        except AttributeError:\n            name = cls.__name__.lower()\n\n        # Enforce the same seed is used across all providers.\n        kwargs.pop(\"seed\", None)\n\n        instance = cls(seed=self.seed, **kwargs)\n        if isinstance(instance, Generic):\n            raise TypeError(\"Cannot add Generic instance to itself.\")\n        setattr(self, name, instance)\n    else:\n        raise TypeError(\"The provider must be a class\")", "loc": 30}
{"file": "mimesis\\mimesis\\providers\\generic.py", "class_name": "Generic", "function_name": "add_providers", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {"providers": "Custom providers."}, "return_doc": "None", "raises_doc": [], "called_functions": ["self.add_provider"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Adds multiple custom providers to a Generic() object. This method is a convenience method for adding multiple providers at once. It is equivalent to calling :meth:`add_provider` for each provider in the list of providers. Example: >>> from mimesis import Generic >>> from myproviders import ProviderA, ProviderB >>> g = Generic() >>> g.add_providers(ProviderA, ProviderB) >>> g.providera.never() >>> g.providerb.gonna() If you want to pass keyword arguments to the providers, you can do so by using :meth:`add_provider` instead.", "source_code": "def add_providers(self, *providers: t.Type[BaseProvider]) -> None:\n    \"\"\"Adds multiple custom providers to a Generic() object.\n\n    This method is a convenience method for adding multiple providers\n    at once. It is equivalent to calling :meth:`add_provider` for each\n    provider in the list of providers.\n\n    Example:\n\n    >>> from mimesis import Generic\n    >>> from myproviders import ProviderA, ProviderB\n    >>> g = Generic()\n    >>> g.add_providers(ProviderA, ProviderB)\n    >>> g.providera.never()\n    >>> g.providerb.gonna()\n\n    If you want to pass keyword arguments to the providers, you can\n    do so by using :meth:`add_provider` instead.\n\n    :param providers: Custom providers.\n    :return: None\n    \"\"\"\n    for provider in providers:\n        self.add_provider(provider)", "loc": 24}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "dsn", "parameters": ["self", "dsn_type"], "param_types": {"dsn_type": "DSNType | None"}, "return_type": "str", "param_doc": {"dsn_type": "DSN type.", "kwargs": "Additional keyword-arguments for hostname method."}, "return_doc": "", "raises_doc": [], "called_functions": ["self.hostname", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random DSN (Data Source Name).", "source_code": "def dsn(self, dsn_type: DSNType | None = None, **kwargs: t.Any) -> str:\n    \"\"\"Generates a random DSN (Data Source Name).\n\n    :param dsn_type: DSN type.\n    :param kwargs: Additional keyword-arguments for hostname method.\n    \"\"\"\n    hostname = self.hostname(**kwargs)\n    scheme, port = self.validate_enum(dsn_type, DSNType)\n    return f\"{scheme}://{hostname}:{port}\"", "loc": 9}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "ip_v4_object", "parameters": ["self"], "param_types": {}, "return_type": "IPv4Address", "param_doc": {}, "return_doc": ":py:class:`ipaddress.IPv4Address` object.", "raises_doc": [], "called_functions": ["IPv4Address", "self.random.randint"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random :py:class:`ipaddress.IPv4Address` object. If you only need special purpose IPv4 addresses, use :meth:`special_ip_v4_object`.", "source_code": "def ip_v4_object(self) -> IPv4Address:\n    \"\"\"Generates a random :py:class:`ipaddress.IPv4Address` object.\n\n    If you only need special purpose IPv4 addresses,\n    use :meth:`special_ip_v4_object`.\n\n    :return: :py:class:`ipaddress.IPv4Address` object.\n    \"\"\"\n    return IPv4Address(\n        self.random.randint(0, self._MAX_IPV4),\n    )", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "ip_v4_with_port", "parameters": ["self", "port_range"], "param_types": {"port_range": "PortRange"}, "return_type": "str", "param_doc": {"port_range": "PortRange enum object."}, "return_doc": "IPv4 address as string.", "raises_doc": [], "called_functions": ["self.ip_v4", "self.port"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random IPv4 address as string.", "source_code": "def ip_v4_with_port(self, port_range: PortRange = PortRange.ALL) -> str:\n    \"\"\"Generates a random IPv4 address as string.\n\n    :param port_range: PortRange enum object.\n    :return: IPv4 address as string.\n\n    :Example:\n        19.121.223.58:8000\n    \"\"\"\n    addr = self.ip_v4()\n    port = self.port(port_range)\n    return f\"{addr}:{port}\"", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "ip_v4", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.ip_v4_object", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random IPv4 address as string. :Example: 19.121.223.58", "source_code": "def ip_v4(self) -> str:\n    \"\"\"Generates a random IPv4 address as string.\n\n    :Example:\n        19.121.223.58\n    \"\"\"\n    return str(self.ip_v4_object())", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "ip_v6_object", "parameters": ["self"], "param_types": {}, "return_type": "IPv6Address", "param_doc": {}, "return_doc": ":py:class:`ipaddress.IPv6Address` object.", "raises_doc": [], "called_functions": ["IPv6Address", "self.random.randint"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates random :py:class:`ipaddress.IPv6Address` object.", "source_code": "def ip_v6_object(self) -> IPv6Address:\n    \"\"\"Generates random :py:class:`ipaddress.IPv6Address` object.\n\n    :return: :py:class:`ipaddress.IPv6Address` object.\n    \"\"\"\n    return IPv6Address(\n        self.random.randint(\n            0,\n            self._MAX_IPV6,\n        ),\n    )", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "ip_v6", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "IPv6 address string.", "raises_doc": [], "called_functions": ["self.ip_v6_object", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random IPv6 address as string.", "source_code": "def ip_v6(self) -> str:\n    \"\"\"Generates a random IPv6 address as string.\n\n    :return: IPv6 address string.\n\n    :Example:\n        2001:c244:cf9d:1fb1:c56d:f52c:8a04:94f3\n    \"\"\"\n    return str(self.ip_v6_object())", "loc": 9}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "mac_address", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Random MAC address.", "raises_doc": [], "called_functions": ["':'.join", "self.random.randint"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random MAC address.", "source_code": "def mac_address(self) -> str:\n    \"\"\"Generates a random MAC address.\n\n    :return: Random MAC address.\n\n    :Example:\n        00:16:3e:25:e7:f1\n    \"\"\"\n    mac_hex = [\n        0x00,\n        0x16,\n        0x3E,\n        self.random.randint(0x00, 0x7F),\n        self.random.randint(0x00, 0xFF),\n        self.random.randint(0x00, 0xFF),\n    ]\n    mac = [f\"{x:02x}\" for x in mac_hex]\n    return \":\".join(mac)", "loc": 18}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "stock_image_url", "parameters": ["width", "height", "keywords"], "param_types": {"width": "int | str", "height": "int | str", "keywords": "Keywords | None"}, "return_type": "str", "param_doc": {"width": "Width of the image.", "height": "Height of the image.", "keywords": "Sequence of search keywords."}, "return_doc": "URL of the image.", "raises_doc": [], "called_functions": ["','.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random stock image URL hosted on Unsplash. See Random search term on https://source.unsplash.com/ for more details.", "source_code": "def stock_image_url(\n    width: int | str = 1920,\n    height: int | str = 1080,\n    keywords: Keywords | None = None,\n) -> str:\n    \"\"\"Generates a random stock image URL hosted on Unsplash.\n\n    See Random search term on https://source.unsplash.com/\n    for more details.\n\n    :param width: Width of the image.\n    :param height: Height of the image.\n    :param keywords: Sequence of search keywords.\n    :return: URL of the image.\n    \"\"\"\n    if keywords is not None:\n        keywords_str = \",\".join(keywords)\n    else:\n        keywords_str = \"\"\n\n    return f\"https://source.unsplash.com/{width}x{height}?{keywords_str}\"", "loc": 21}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "hostname", "parameters": ["self", "tld_type", "subdomains"], "param_types": {"tld_type": "TLDType | None", "subdomains": "list[str] | None"}, "return_type": "str", "param_doc": {"tld_type": "TLDType.", "subdomains": "List of subdomains (make sure they are valid)."}, "return_doc": "Hostname.", "raises_doc": [], "called_functions": ["self.random.choice", "self.tld"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random hostname without a scheme.", "source_code": "def hostname(\n    self,\n    tld_type: TLDType | None = None,\n    subdomains: list[str] | None = None,\n) -> str:\n    \"\"\"Generates a random hostname without a scheme.\n\n    :param tld_type: TLDType.\n    :param subdomains: List of subdomains (make sure they are valid).\n    :return: Hostname.\n    \"\"\"\n    tld = self.tld(tld_type=tld_type)\n    host = self.random.choice(USERNAMES)\n\n    if subdomains:\n        subdomain = self.random.choice(subdomains)\n        host = f\"{subdomain}.{host}\"\n\n    return f\"{host}{tld}\"", "loc": 19}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "url", "parameters": ["self", "scheme", "port_range", "tld_type", "subdomains"], "param_types": {"scheme": "URLScheme | None", "port_range": "PortRange | None", "tld_type": "TLDType | None", "subdomains": "list[str] | None"}, "return_type": "str", "param_doc": {"scheme": "The scheme.", "port_range": "PortRange enum object.", "tld_type": "TLDType.", "subdomains": "List of subdomains (make sure they are valid)."}, "return_doc": "URL.", "raises_doc": [], "called_functions": ["self.hostname", "self.port", "self.validate_enum"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random URL.", "source_code": "def url(\n    self,\n    scheme: URLScheme | None = URLScheme.HTTPS,\n    port_range: PortRange | None = None,\n    tld_type: TLDType | None = None,\n    subdomains: list[str] | None = None,\n) -> str:\n    \"\"\"Generates a random URL.\n\n    :param scheme: The scheme.\n    :param port_range: PortRange enum object.\n    :param tld_type: TLDType.\n    :param subdomains: List of subdomains (make sure they are valid).\n    :return: URL.\n    \"\"\"\n    host = self.hostname(tld_type, subdomains)\n    url_scheme = self.validate_enum(scheme, URLScheme)\n\n    url = f\"{url_scheme}://{host}\"\n\n    if port_range is not None:\n        url = f\"{url}:{self.port(port_range)}\"\n\n    return f\"{url}/\"", "loc": 24}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "uri", "parameters": ["self", "scheme", "tld_type", "subdomains", "query_params_count"], "param_types": {"scheme": "URLScheme | None", "tld_type": "TLDType | None", "subdomains": "list[str] | None", "query_params_count": "int | None"}, "return_type": "str", "param_doc": {"scheme": "Scheme.", "tld_type": "TLDType.", "subdomains": "List of subdomains (make sure they are valid).", "query_params_count": "Query params."}, "return_doc": "URI.", "raises_doc": [], "called_functions": ["self._datetime.date", "self._datetime.date(start=2010, end=self._datetime._CURRENT_YEAR).strftime", "self._datetime.date(start=2010, end=self._datetime._CURRENT_YEAR).strftime('%Y-%m-%d').replace", "self.query_string", "self.slug", "self.url"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random URI.", "source_code": "def uri(\n    self,\n    scheme: URLScheme | None = URLScheme.HTTPS,\n    tld_type: TLDType | None = None,\n    subdomains: list[str] | None = None,\n    query_params_count: int | None = None,\n) -> str:\n    \"\"\"Generates a random URI.\n\n    :param scheme: Scheme.\n    :param tld_type: TLDType.\n    :param subdomains: List of subdomains (make sure they are valid).\n    :param query_params_count: Query params.\n    :return: URI.\n    \"\"\"\n    directory = (\n        self._datetime.date(start=2010, end=self._datetime._CURRENT_YEAR)\n        .strftime(\"%Y-%m-%d\")\n        .replace(\"-\", \"/\")\n    )\n    url = self.url(scheme, None, tld_type, subdomains)\n    uri = f\"{url}{directory}/{self.slug()}\"\n\n    if query_params_count:\n        uri += f\"?{self.query_string(query_params_count)}\"\n\n    return uri", "loc": 27}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "query_parameters", "parameters": ["self", "length"], "param_types": {"length": "int | None"}, "return_type": "dict[str, str]", "param_doc": {"length": "Length of query parameters dictionary (maximum is 32)."}, "return_doc": "Dict of query parameters.", "raises_doc": [], "called_functions": ["ValueError", "dict", "len", "list", "pick_unique_words", "self._text.word", "self._text.words", "self.random.randint", "set", "words.add", "zip"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Generates an arbitrary query parameters as a dict.", "source_code": "def query_parameters(self, length: int | None = None) -> dict[str, str]:\n    \"\"\"Generates an arbitrary query parameters as a dict.\n\n    :param length: Length of query parameters dictionary (maximum is 32).\n    :return: Dict of query parameters.\n    \"\"\"\n\n    def pick_unique_words(quantity: int = 5) -> list[str]:\n        words: set[str] = set()\n\n        while len(words) != quantity:\n            words.add(self._text.word())\n\n        return list(words)\n\n    if not length:\n        length = self.random.randint(1, 10)\n\n    if length > 32:\n        raise ValueError(\"Maximum allowed length of query parameters is 32.\")\n\n    return dict(zip(pick_unique_words(length), self._text.words(length)))", "loc": 22}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "top_level_domain", "parameters": ["self", "tld_type"], "param_types": {"tld_type": "TLDType"}, "return_type": "str", "param_doc": {"tld_type": "Enum object :class:`enums.TLDType`"}, "return_doc": "Top level domain.", "raises_doc": [{"type": "NonEnumerableError", "desc": "if tld_type not in :class:`enums.TLDType`."}], "called_functions": ["self.random.choice", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates random top level domain.", "source_code": "def top_level_domain(self, tld_type: TLDType = TLDType.CCTLD) -> str:\n    \"\"\"Generates random top level domain.\n\n    :param tld_type: Enum object :class:`enums.TLDType`\n    :return: Top level domain.\n    :raises NonEnumerableError: if tld_type not in :class:`enums.TLDType`.\n    \"\"\"\n    key = self.validate_enum(item=tld_type, enum=TLDType)\n    return self.random.choice(TLD[key])", "loc": 9}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "port", "parameters": ["self", "port_range"], "param_types": {"port_range": "PortRange"}, "return_type": "int", "param_doc": {"port_range": "PortRange enum object."}, "return_doc": "Port number.", "raises_doc": [{"type": "NonEnumerableError", "desc": "if port_range is not in PortRange."}], "called_functions": ["self.random.randint", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random port.", "source_code": "def port(self, port_range: PortRange = PortRange.ALL) -> int:\n    \"\"\"Generates a random port.\n\n    :param port_range: PortRange enum object.\n    :return: Port number.\n    :raises NonEnumerableError: if port_range is not in PortRange.\n\n    :Example:\n        8080\n    \"\"\"\n\n    rng = self.validate_enum(port_range, PortRange)\n    return self.random.randint(*rng)", "loc": 13}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "path", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {"args": "Arguments to pass to :meth:`slug`.", "kwargs": "Keyword arguments to pass to :meth:`slug`."}, "return_doc": "Path.", "raises_doc": [], "called_functions": ["self.slug", "self.slug(*args, **kwargs).replace"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random path.", "source_code": "def path(self, *args: t.Any, **kwargs: t.Any) -> str:\n    \"\"\"Generates a random path.\n\n    :param args: Arguments to pass to :meth:`slug`.\n    :param kwargs: Keyword arguments to pass to :meth:`slug`.\n    :return: Path.\n    \"\"\"\n    return self.slug(*args, **kwargs).replace(\"-\", \"/\")", "loc": 8}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "slug", "parameters": ["self", "parts_count"], "param_types": {"parts_count": "int | None"}, "return_type": "str", "param_doc": {"parts_count": "Slug's parts count."}, "return_doc": "Slug.", "raises_doc": [], "called_functions": ["'-'.join", "ValueError", "self._text.words", "self.random.randint"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random slug of given parts count.", "source_code": "def slug(self, parts_count: int | None = None) -> str:\n    \"\"\"Generates a random slug of given parts count.\n\n    :param parts_count: Slug's parts count.\n    :return: Slug.\n    \"\"\"\n\n    if not parts_count:\n        parts_count = self.random.randint(2, 12)\n\n    if parts_count > 12:\n        raise ValueError(\"Slug's parts count must be <= 12\")\n\n    if parts_count < 2:\n        raise ValueError(\"Slug must contain more than 2 parts\")\n\n    return \"-\".join(self._text.words(parts_count))", "loc": 17}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "http_response_headers", "parameters": ["self"], "param_types": {}, "return_type": "dict[str, t.Any]", "param_doc": {}, "return_doc": "Response headers as dict.", "raises_doc": [], "called_functions": ["b64encode", "b64encode(self.random.randbytes(n=32)).decode", "self._code.locale_code", "self._file.mime_type", "self._text.words", "self.hostname", "self.path", "self.random.choice", "self.random.randbytes", "self.random.randbytes(16).hex", "self.random.randint"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random HTTP response headers. The following headers are included: - Allow - Age - Server - Content-Type - X-Request-ID - Content-Language - Content-Location - Set-Cookie - Upgrade-Insecure-Requests - X-Content-Type-Options - X-XSS-Protection - Connection - X-Frame-Options - Content-Encoding - Cross-Origin-Opener-Policy - Cross-Origin-Resource-Policy - Strict-Transport-Security", "source_code": "def http_response_headers(self) -> dict[str, t.Any]:\n    \"\"\"Generates a random HTTP response headers.\n\n    The following headers are included:\n\n    - Allow\n    - Age\n    - Server\n    - Content-Type\n    - X-Request-ID\n    - Content-Language\n    - Content-Location\n    - Set-Cookie\n    - Upgrade-Insecure-Requests\n    - X-Content-Type-Options\n    - X-XSS-Protection\n    - Connection\n    - X-Frame-Options\n    - Content-Encoding\n    - Cross-Origin-Opener-Policy\n    - Cross-Origin-Resource-Policy\n    - Strict-Transport-Security\n\n    :return: Response headers as dict.\n    \"\"\"\n    max_age = self.random.randint(0, 60 * 60 * 15)\n    cookie_attributes = [\n        \"Secure\",\n        \"HttpOnly\",\n        \"SameSite=Lax\",\n        \"SameSite=Strict\",\n        f\"Max-Age={max_age}\",\n        f\"Domain={self.hostname()}\",\n    ]\n    k, v = self._text.words(quantity=2)\n    cookie_attr = self.random.choice(cookie_attributes)\n    csrf_token = b64encode(self.random.randbytes(n=32)).decode()\n    cookie_value = f\"csrftoken={csrf_token}; {k}={v}; {cookie_attr}\"\n\n    headers = {\n        \"Allow\": \"*\",\n        \"Age\": max_age,\n        \"Server\": self.random.choice(HTTP_SERVERS),\n        \"Content-Type\": self._file.mime_type(),\n        \"X-Request-ID\": self.random.randbytes(16).hex(),\n        \"Content-Language\": self._code.locale_code(),\n        \"Content-Location\": self.path(parts_count=4),\n        \"Set-Cookie\": cookie_value,\n        \"Upgrade-Insecure-Requests\": 1,\n        \"X-Content-Type-Options\": \"nosniff\",\n        \"X-XSS-Protection\": 1,\n        \"Connection\": self.random.choice([\"close\", \"keep-alive\"]),\n        \"X-Frame-Options\": self.random.choice([\"DENY\", \"SAMEORIGIN\"]),\n        \"Content-Encoding\": self.random.choice(CONTENT_ENCODING_DIRECTIVES),\n        \"Cross-Origin-Opener-Policy\": self.random.choice(CORS_OPENER_POLICIES),\n        \"Cross-Origin-Resource-Policy\": self.random.choice(CORS_RESOURCE_POLICIES),\n        \"Strict-Transport-Security\": f\"max-age={max_age}\",\n    }\n    return headers", "loc": 59}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "http_request_headers", "parameters": ["self"], "param_types": {}, "return_type": "dict[str, t.Any]", "param_doc": {}, "return_doc": "Request headers as dict.", "raises_doc": [], "called_functions": ["b64encode", "b64encode(self.random.randbytes(32)).hex", "b64encode(self.random.randbytes(64)).hex", "b64encode(self.random.randbytes(n=32)).decode", "self._code.locale_code", "self._file.mime_type", "self._text.words", "self.hostname", "self.random.choice", "self.random.randbytes", "self.random.randint", "self.uri", "self.user_agent"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random HTTP request headers. The following headers are included: - Referer - Authorization - Cookie - User-Agent - X-CSRF-Token - Content-Type - Content-Length - Connection - Cache-Control - Accept - Host - Accept-Language", "source_code": "def http_request_headers(self) -> dict[str, t.Any]:\n    \"\"\"Generates a random HTTP request headers.\n\n    The following headers are included:\n\n    - Referer\n    - Authorization\n    - Cookie\n    - User-Agent\n    - X-CSRF-Token\n    - Content-Type\n    - Content-Length\n    - Connection\n    - Cache-Control\n    - Accept\n    - Host\n    - Accept-Language\n\n    :return: Request headers as dict.\n    \"\"\"\n    k, v = self._text.words(quantity=2)\n    max_age = self.random.randint(0, 60 * 60 * 15)\n    token = b64encode(self.random.randbytes(64)).hex()\n    csrf_token = b64encode(self.random.randbytes(n=32)).decode()\n    headers = {\n        \"Referer\": self.uri(),\n        \"Authorization\": f\"Bearer {token}\",\n        \"Cookie\": f\"csrftoken={csrf_token}; {k}={v}\",\n        \"User-Agent\": self.user_agent(),\n        \"X-CSRF-Token\": b64encode(self.random.randbytes(32)).hex(),\n        \"Content-Type\": self._file.mime_type(),\n        \"Content-Length\": self.random.randint(0, 10000),\n        \"Connection\": self.random.choice([\"close\", \"keep-alive\"]),\n        \"Cache-Control\": self.random.choice(\n            [\n                \"no-cache\",\n                \"no-store\",\n                \"must-revalidate\",\n                \"public\",\n                \"private\",\n                f\"max-age={max_age}\",\n            ]\n        ),\n        \"Accept\": self.random.choice(\n            [\n                \"*/*\",\n                self._file.mime_type(),\n            ]\n        ),\n        \"Host\": self.hostname(),\n        \"Accept-Language\": self.random.choice(\n            [\n                \"*\",\n                self._code.locale_code(),\n            ]\n        ),\n    }\n    return headers", "loc": 58}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "special_ip_v4_object", "parameters": ["self", "purpose"], "param_types": {"purpose": "IPv4Purpose | None"}, "return_type": "IPv4Address", "param_doc": {"purpose": "Enum object :class:`enums.IPv4Purpose`."}, "return_doc": "IPv4 address.", "raises_doc": [{"type": "NonEnumerableError", "desc": "if purpose not in :class:`enums.IPv4Purpose`."}], "called_functions": ["IPv4Address", "self.random.randint", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a special purpose IPv4 address.", "source_code": "def special_ip_v4_object(self, purpose: IPv4Purpose | None = None) -> IPv4Address:\n    \"\"\"Generates a special purpose IPv4 address.\n\n    :param purpose: Enum object :class:`enums.IPv4Purpose`.\n    :return: IPv4 address.\n    :raises NonEnumerableError: if purpose not in :class:`enums.IPv4Purpose`.\n    \"\"\"\n    ranges = self.validate_enum(purpose, IPv4Purpose)\n    number = self.random.randint(*ranges)\n    return IPv4Address(number)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": "Internet", "function_name": "special_ip_v4", "parameters": ["self", "purpose"], "param_types": {"purpose": "IPv4Purpose | None"}, "return_type": "str", "param_doc": {"purpose": "Enum object :class:`enums.IPv4Purpose`."}, "return_doc": "IPv4 address as string.", "raises_doc": [], "called_functions": ["self.special_ip_v4_object", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a special purpose IPv4 address as string.", "source_code": "def special_ip_v4(self, purpose: IPv4Purpose | None = None) -> str:\n    \"\"\"Generates a special purpose IPv4 address as string.\n\n    :param purpose: Enum object :class:`enums.IPv4Purpose`.\n    :return: IPv4 address as string.\n    \"\"\"\n    return str(self.special_ip_v4_object(purpose))", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\internet.py", "class_name": null, "function_name": "pick_unique_words", "parameters": ["quantity"], "param_types": {"quantity": "int"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "list", "self._text.word", "set", "words.add"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def pick_unique_words(quantity: int = 5) -> list[str]:\n    words: set[str] = set()\n\n    while len(words) != quantity:\n        words.add(self._text.word())\n\n    return list(words)", "loc": 7}
{"file": "mimesis\\mimesis\\providers\\numeric.py", "class_name": "Numeric", "function_name": "increment", "parameters": ["self", "accumulator"], "param_types": {"accumulator": "str | None"}, "return_type": "int", "param_doc": {"accumulator": "Accumulator (used to create associative incrementation)."}, "return_doc": "Integer.", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates an incrementing number. Each call of this method returns an incrementing number (with the step of +1). If **accumulator** passed then increments number associated with it. Example: >>> self.increment() 1 >>> self.increment(accumulator=\"a\") 1 >>> self.increment() 2 >>> self.increment(accumulator=\"a\") 2 >>> self.increment(accumulator=\"b\") 1 >>> self.increment(accumulator=\"a\") 3", "source_code": "def increment(self, accumulator: str | None = None) -> int:\n    \"\"\"Generates an incrementing number.\n\n    Each call of this method returns an incrementing number (with the step of +1).\n\n    If **accumulator** passed then increments number associated with it.\n\n    Example:\n        >>> self.increment()\n        1\n        >>> self.increment(accumulator=\"a\")\n        1\n        >>> self.increment()\n        2\n        >>> self.increment(accumulator=\"a\")\n        2\n        >>> self.increment(accumulator=\"b\")\n        1\n        >>> self.increment(accumulator=\"a\")\n        3\n\n    :param accumulator: Accumulator (used to create associative incrementation).\n    :return: Integer.\n    \"\"\"\n    if not accumulator:\n        accumulator = self.__default_accumulator_value\n\n    self.__increment_dict[accumulator] += 1\n    return self.__increment_dict[accumulator]", "loc": 29}
{"file": "mimesis\\mimesis\\providers\\numeric.py", "class_name": "Numeric", "function_name": "floats", "parameters": ["self", "start", "end", "n", "precision"], "param_types": {"start": "float", "end": "float", "n": "int", "precision": "int"}, "return_type": "list[float]", "param_doc": {"start": "Start range.", "end": "End range.", "n": "Length of the list.", "precision": "Round a number to a given"}, "return_doc": "The list of floating-point numbers.", "raises_doc": [], "called_functions": ["range", "self.float_number"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a list of random float numbers.", "source_code": "def floats(\n    self, start: float = 0, end: float = 1, n: int = 10, precision: int = 15\n) -> list[float]:\n    \"\"\"Generates a list of random float numbers.\n\n    :param start: Start range.\n    :param end: End range.\n    :param n: Length of the list.\n    :param precision: Round a number to a given\n        precision in decimal digits, default is 15.\n    :return: The list of floating-point numbers.\n    \"\"\"\n    return [self.float_number(start, end, precision) for _ in range(n)]", "loc": 13}
{"file": "mimesis\\mimesis\\providers\\numeric.py", "class_name": "Numeric", "function_name": "complex_number", "parameters": ["self", "start_real", "end_real", "start_imag", "end_imag", "precision_real", "precision_imag"], "param_types": {"start_real": "float", "end_real": "float", "start_imag": "float", "end_imag": "float", "precision_real": "int", "precision_imag": "int"}, "return_type": "complex", "param_doc": {"start_real": "Start real range.", "end_real": "End real range.", "start_imag": "Start imaginary range.", "end_imag": "End imaginary range.", "precision_real": "Round a real part of", "precision_imag": "Round the imaginary part of"}, "return_doc": "Complex numbers.", "raises_doc": [], "called_functions": ["complex", "self.random.uniform"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random complex number.", "source_code": "def complex_number(\n    self,\n    start_real: float = 0.0,\n    end_real: float = 1.0,\n    start_imag: float = 0.0,\n    end_imag: float = 1.0,\n    precision_real: int = 15,\n    precision_imag: int = 15,\n) -> complex:\n    \"\"\"Generates a random complex number.\n\n    :param start_real: Start real range.\n    :param end_real: End real range.\n    :param start_imag: Start imaginary range.\n    :param end_imag: End imaginary range.\n    :param precision_real:  Round a real part of\n        number to a given precision.\n    :param precision_imag:  Round the imaginary part of\n        number to a given precision.\n    :return: Complex numbers.\n    \"\"\"\n    real_part = self.random.uniform(start_real, end_real, precision_real)\n    imag_part = self.random.uniform(start_imag, end_imag, precision_imag)\n    return complex(real_part, imag_part)", "loc": 24}
{"file": "mimesis\\mimesis\\providers\\numeric.py", "class_name": "Numeric", "function_name": "complexes", "parameters": ["self", "start_real", "end_real", "start_imag", "end_imag", "precision_real", "precision_imag", "n"], "param_types": {"start_real": "float", "end_real": "float", "start_imag": "float", "end_imag": "float", "precision_real": "int", "precision_imag": "int", "n": "int"}, "return_type": "list[complex]", "param_doc": {"start_real": "Start real range.", "end_real": "End real range.", "start_imag": "Start imaginary range.", "end_imag": "End imaginary range.", "precision_real": "Round a real part of", "precision_imag": "Round the imaginary part of", "n": "Length of the list."}, "return_doc": "A list of random complex numbers.", "raises_doc": [], "called_functions": ["numbers.append", "range", "self.complex_number"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Generates a list of random complex numbers.", "source_code": "def complexes(\n    self,\n    start_real: float = 0,\n    end_real: float = 1,\n    start_imag: float = 0,\n    end_imag: float = 1,\n    precision_real: int = 15,\n    precision_imag: int = 15,\n    n: int = 10,\n) -> list[complex]:\n    \"\"\"Generates a list of random complex numbers.\n\n    :param start_real: Start real range.\n    :param end_real: End real range.\n    :param start_imag: Start imaginary range.\n    :param end_imag: End imaginary range.\n    :param precision_real:  Round a real part of\n        number to a given precision.\n    :param precision_imag:  Round the imaginary part of\n        number to a given precision.\n    :param n: Length of the list.\n    :return: A list of random complex numbers.\n    \"\"\"\n    numbers = []\n    for _ in range(n):\n        numbers.append(\n            self.complex_number(\n                start_real=start_real,\n                end_real=end_real,\n                start_imag=start_imag,\n                end_imag=end_imag,\n                precision_real=precision_real,\n                precision_imag=precision_imag,\n            ),\n        )\n    return numbers", "loc": 36}
{"file": "mimesis\\mimesis\\providers\\numeric.py", "class_name": "Numeric", "function_name": "decimal_number", "parameters": ["self", "start", "end"], "param_types": {"start": "float", "end": "float"}, "return_type": "Decimal", "param_doc": {"start": "Start range.", "end": "End range."}, "return_doc": ":py:class:`decimal.Decimal` object.", "raises_doc": [], "called_functions": ["Decimal.from_float", "self.float_number"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random decimal number.", "source_code": "def decimal_number(self, start: float = -1000.0, end: float = 1000.0) -> Decimal:\n    \"\"\"Generates a random decimal number.\n\n    :param start:  Start range.\n    :param end: End range.\n    :return: :py:class:`decimal.Decimal` object.\n    \"\"\"\n    return Decimal.from_float(self.float_number(start, end))", "loc": 8}
{"file": "mimesis\\mimesis\\providers\\numeric.py", "class_name": "Numeric", "function_name": "decimals", "parameters": ["self", "start", "end", "n"], "param_types": {"start": "float", "end": "float", "n": "int"}, "return_type": "list[Decimal]", "param_doc": {"start": "Start range.", "end": "End range.", "n": "Length of the list."}, "return_doc": "A list of :py:class:`decimal.Decimal` objects.", "raises_doc": [], "called_functions": ["range", "self.decimal_number"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a list of decimal numbers.", "source_code": "def decimals(\n    self, start: float = 0.0, end: float = 1000.0, n: int = 10\n) -> list[Decimal]:\n    \"\"\"Generates a list of decimal numbers.\n\n    :param start: Start range.\n    :param end: End range.\n    :param n: Length of the list.\n    :return: A list of :py:class:`decimal.Decimal` objects.\n    \"\"\"\n    return [self.decimal_number(start, end) for _ in range(n)]", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\numeric.py", "class_name": "Numeric", "function_name": "matrix", "parameters": ["self", "m", "n", "num_type"], "param_types": {"m": "int", "n": "int", "num_type": "NumType"}, "return_type": "Matrix", "param_doc": {"m": "Number of rows.", "n": "Number of columns.", "num_type": "NumType enum object.", "kwargs": "Other method-specific arguments."}, "return_doc": "A matrix of random numbers.", "raises_doc": [], "called_functions": ["getattr", "kwargs.update", "method", "range", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates m x n matrix with a random numbers. This method works with a variety of types, so you can pass method-specific `**kwargs`.", "source_code": "def matrix(\n    self,\n    m: int = 10,\n    n: int = 10,\n    num_type: NumType = NumType.FLOAT,\n    **kwargs: t.Any,\n) -> Matrix:\n    \"\"\"Generates m x n matrix with a random numbers.\n\n    This method works with a variety of types,\n    so you can pass method-specific `**kwargs`.\n\n    :param m: Number of rows.\n    :param n: Number of columns.\n    :param num_type: NumType enum object.\n    :param kwargs: Other method-specific arguments.\n    :return: A matrix of random numbers.\n    \"\"\"\n    key = self.validate_enum(num_type, NumType)\n    kwargs.update({\"n\": n})\n    method = getattr(self, key)\n    return [method(**kwargs) for _ in range(m)]", "loc": 22}
{"file": "mimesis\\mimesis\\providers\\path.py", "class_name": "Path", "function_name": "user", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Path to user.", "raises_doc": [], "called_functions": ["self.random.choice", "str", "user.capitalize", "user.lower"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random user.", "source_code": "def user(self) -> str:\n    \"\"\"Generates a random user.\n\n    :return: Path to user.\n\n    :Example:\n        /home/oretha\n    \"\"\"\n    user = self.random.choice(USERNAMES)\n    user = user.capitalize() if \"win\" in self.platform else user.lower()\n    return str(self._pathlib_home / user)", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\path.py", "class_name": "Path", "function_name": "users_folder", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Path.", "raises_doc": [], "called_functions": ["self.random.choice", "self.user", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random path to user's folders.", "source_code": "def users_folder(self) -> str:\n    \"\"\"Generates a random path to user's folders.\n\n    :return: Path.\n\n    :Example:\n        /home/taneka/Pictures\n    \"\"\"\n    user = self.user()\n    folder = self.random.choice(FOLDERS)\n    return str(self._pathlib_home / user / folder)", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\path.py", "class_name": "Path", "function_name": "dev_dir", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Path.", "raises_doc": [], "called_functions": ["self.random.choice", "self.user", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random path to development directory.", "source_code": "def dev_dir(self) -> str:\n    \"\"\"Generates a random path to development directory.\n\n    :return: Path.\n\n    :Example:\n        /home/sherrell/Development/Python\n    \"\"\"\n    user = self.user()\n    folder = self.random.choice([\"Development\", \"Dev\"])\n    stack = self.random.choice(PROGRAMMING_LANGS)\n    return str(self._pathlib_home / user / folder / stack)", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\path.py", "class_name": "Path", "function_name": "project_dir", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Path to project.", "raises_doc": [], "called_functions": ["self.dev_dir", "self.random.choice", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random path to project directory.", "source_code": "def project_dir(self) -> str:\n    \"\"\"Generates a random path to project directory.\n\n    :return: Path to project.\n\n    :Example:\n        /home/sherika/Development/Falcon/mercenary\n    \"\"\"\n    dev_dir = self.dev_dir()\n    project = self.random.choice(PROJECT_NAMES)\n    return str(self._pathlib_home / dev_dir / project)", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\payment.py", "class_name": "Payment", "function_name": "bitcoin_address", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Bitcoin address.", "raises_doc": [], "called_functions": ["''.join", "self.random.choice", "self.random.choices"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random bitcoin address. Keep in mind that although it generates **valid-looking** addresses, it does not mean that they are actually valid.", "source_code": "def bitcoin_address(self) -> str:\n    \"\"\"Generates a random bitcoin address.\n\n    Keep in mind that although it generates **valid-looking** addresses,\n    it does not mean that they are actually valid.\n\n    :return: Bitcoin address.\n\n    :Example:\n        3EktnHQD7RiAE6uzMj2ZifT9YgRrkSgzQX\n    \"\"\"\n    type_ = self.random.choice([\"1\", \"3\"])\n    characters = string.ascii_letters + string.digits\n    return type_ + \"\".join(self.random.choices(characters, k=33))", "loc": 14}
{"file": "mimesis\\mimesis\\providers\\payment.py", "class_name": "Payment", "function_name": "ethereum_address", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Ethereum address.", "raises_doc": [], "called_functions": ["address.hex", "bits.to_bytes", "self.random.getrandbits"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random Ethereum address. ..note: The address will look like Ethereum address, but keep in mind that it is not the valid address.", "source_code": "def ethereum_address(self) -> str:\n    \"\"\"Generates a random Ethereum address.\n\n    ..note: The address will look like Ethereum address,\n    but keep in mind that it is not the valid address.\n\n    :return: Ethereum address.\n\n    :Example:\n        0xe8ece9e6ff7dba52d4c07d37418036a89af9698d\n    \"\"\"\n    bits = self.random.getrandbits(160)\n    address = bits.to_bytes(20, byteorder=\"big\")\n    return \"0x\" + address.hex()", "loc": 14}
{"file": "mimesis\\mimesis\\providers\\payment.py", "class_name": "Payment", "function_name": "credit_card_number", "parameters": ["self", "card_type"], "param_types": {"card_type": "CardType | None"}, "return_type": "str", "param_doc": {"card_type": "Issuing Network. Default is Visa."}, "return_doc": "Credit card number.", "raises_doc": [{"type": "NotImplementedError", "desc": "if card_type not supported."}], "called_functions": ["' '.join", "NonEnumerableError", "len", "luhn_checksum", "re.compile", "regex.search", "regex.search(str_num + luhn_checksum(str_num)).groups", "self.random.choice", "self.random.choice_enum_item", "self.random.randint", "str"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Generates a random credit card number.", "source_code": "def credit_card_number(self, card_type: CardType | None = None) -> str:\n    \"\"\"Generates a random credit card number.\n\n    :param card_type: Issuing Network. Default is Visa.\n    :return: Credit card number.\n    :raises NotImplementedError: if card_type not supported.\n\n    :Example:\n        4455 5299 1152 2450\n    \"\"\"\n    length = 16\n    regex = re.compile(r\"(\\d{4})(\\d{4})(\\d{4})(\\d{4})\")\n\n    if card_type is None:\n        card_type = self.random.choice_enum_item(CardType)\n\n    if card_type == CardType.VISA:\n        number = self.random.randint(4000, 4999)\n    elif card_type == CardType.MASTER_CARD:\n        number = self.random.choice(\n            [\n                self.random.randint(2221, 2720),\n                self.random.randint(5100, 5599),\n            ]\n        )\n    elif card_type == CardType.AMERICAN_EXPRESS:\n        number = self.random.choice([34, 37])\n        length = 15\n        regex = re.compile(r\"(\\d{4})(\\d{6})(\\d{5})\")\n    else:\n        raise NonEnumerableError(CardType)\n\n    str_num = str(number)\n    while len(str_num) < length - 1:\n        str_num += self.random.choice(string.digits)\n\n    groups = regex.search(  # type: ignore\n        str_num + luhn_checksum(str_num),\n    ).groups()\n    card = \" \".join(groups)\n    return card", "loc": 41}
{"file": "mimesis\\mimesis\\providers\\payment.py", "class_name": "Payment", "function_name": "credit_card_owner", "parameters": ["self", "gender"], "param_types": {"gender": "Gender | None"}, "return_type": "dict[str, str]", "param_doc": {"gender": "Gender of the card owner."}, "return_doc": "", "raises_doc": [], "called_functions": ["self._person.full_name", "self._person.full_name(gender=gender).upper", "self.credit_card_expiration_date", "self.credit_card_number"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random credit card owner.", "source_code": "def credit_card_owner(\n    self,\n    gender: Gender | None = None,\n) -> dict[str, str]:\n    \"\"\"Generates a random credit card owner.\n\n    :param gender: Gender of the card owner.\n    :type gender: Gender enum.\n    :return:\n    \"\"\"\n    owner = {\n        \"credit_card\": self.credit_card_number(),\n        \"expiration_date\": self.credit_card_expiration_date(),\n        \"owner\": self._person.full_name(gender=gender).upper(),\n    }\n    return owner", "loc": 16}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "birthdate", "parameters": ["self", "min_year", "max_year"], "param_types": {"min_year": "int", "max_year": "int"}, "return_type": "Date", "param_doc": {"min_year": "Maximum birth year.", "max_year": "Minimum birth year."}, "return_doc": "Random date object.", "raises_doc": [], "called_functions": ["date", "self._is_leap_year", "self._validate_birth_year_params", "self.random.randint"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random birthdate as a :py:class:`datetime.date` object.", "source_code": "def birthdate(self, min_year: int = 1980, max_year: int = 2023) -> Date:\n    \"\"\"Generates a random birthdate as a :py:class:`datetime.date` object.\n\n    :param min_year: Maximum birth year.\n    :param max_year: Minimum birth year.\n    :return: Random date object.\n    \"\"\"\n    self._validate_birth_year_params(min_year, max_year)\n    year = self.random.randint(min_year, max_year)\n    feb_days = 29 if self._is_leap_year(year) else 28\n\n    month_days_map = {\n        1: 31,\n        2: feb_days,\n        3: 31,\n        4: 30,\n        5: 31,\n        6: 30,\n        7: 31,\n        8: 31,\n        9: 30,\n        10: 31,\n        11: 30,\n        12: 31,\n    }\n\n    month = self.random.randint(1, 12)\n    max_day = month_days_map[month]\n    day = self.random.randint(1, max_day)\n    return date(year=year, month=month, day=day)", "loc": 30}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "name", "parameters": ["self", "gender"], "param_types": {"gender": "Gender | None"}, "return_type": "str", "param_doc": {"gender": "Gender's enum object."}, "return_doc": "Name.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random name.", "source_code": "def name(self, gender: Gender | None = None) -> str:\n    \"\"\"Generates a random name.\n\n    :param gender: Gender's enum object.\n    :return: Name.\n\n    :Example:\n        John.\n    \"\"\"\n    key = self.validate_enum(gender, Gender)\n    names: list[str] = self._extract([\"names\", key])\n    return self.random.choice(names)", "loc": 12}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "surname", "parameters": ["self", "gender"], "param_types": {"gender": "Gender | None"}, "return_type": "str", "param_doc": {"gender": "Gender's enum object."}, "return_doc": "Surname.", "raises_doc": [], "called_functions": ["isinstance", "self._extract", "self.random.choice", "self.validate_enum"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random surname.", "source_code": "def surname(self, gender: Gender | None = None) -> str:\n    \"\"\"Generates a random surname.\n\n    :param gender: Gender's enum object.\n    :return: Surname.\n\n    :Example:\n        Smith.\n    \"\"\"\n    surnames: t.Sequence[str] = self._extract([\"surnames\"])\n\n    # Surnames separated by gender.\n    if isinstance(surnames, dict):\n        key = self.validate_enum(gender, Gender)\n        surnames = surnames[key]\n\n    return self.random.choice(surnames)", "loc": 17}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "patronymic", "parameters": ["self", "gender"], "param_types": {"gender": "Gender | None"}, "return_type": "str | None", "param_doc": {"gender": "Gender's enum object."}, "return_doc": "Patronymic name.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice", "self.validate_enum"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random patronymic name. Patronymics are available only for Locale.RU and Locale.UK.", "source_code": "def patronymic(self, gender: Gender | None = None) -> str | None:\n    \"\"\"Generates a random patronymic name.\n\n    Patronymics are available only for Locale.RU and Locale.UK.\n\n    :param gender: Gender's enum object.\n    :return: Patronymic name.\n    \"\"\"\n    gender = self.validate_enum(gender, Gender)\n    patronymics: list[str] = self._extract(\n        keys=[\n            \"patronymic\",\n            f\"{gender}\",\n        ],\n        default=[],\n    )\n\n    if not patronymics:\n        return None\n\n    return self.random.choice(patronymics)", "loc": 21}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "title", "parameters": ["self", "gender", "title_type"], "param_types": {"gender": "Gender | None", "title_type": "TitleType | None"}, "return_type": "str", "param_doc": {"gender": "The gender.", "title_type": "TitleType enum object."}, "return_doc": "The title.", "raises_doc": [{"type": "NonEnumerableError", "desc": "if gender or title_type in incorrect format."}], "called_functions": ["self._extract", "self.random.choice", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random title for name. You can generate a random prefix or suffix for name using this method.", "source_code": "def title(\n    self,\n    gender: Gender | None = None,\n    title_type: TitleType | None = None,\n) -> str:\n    \"\"\"Generates a random title for name.\n\n    You can generate a random prefix or suffix\n    for name using this method.\n\n    :param gender: The gender.\n    :param title_type: TitleType enum object.\n    :return: The title.\n    :raises NonEnumerableError: if gender or title_type in incorrect format.\n\n    :Example:\n        PhD.\n    \"\"\"\n    gender_key = self.validate_enum(gender, Gender)\n    title_key = self.validate_enum(title_type, TitleType)\n\n    titles: list[str] = self._extract([\"title\", gender_key, title_key])\n    return self.random.choice(titles)", "loc": 23}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "full_name", "parameters": ["self", "gender", "reverse"], "param_types": {"gender": "Gender | None", "reverse": "bool"}, "return_type": "str", "param_doc": {"reverse": "Return reversed full name.", "gender": "Gender's enum object."}, "return_doc": "Full name.", "raises_doc": [], "called_functions": ["self.name", "self.surname"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random full name.", "source_code": "def full_name(\n    self,\n    gender: Gender | None = None,\n    reverse: bool = False,\n) -> str:\n    \"\"\"Generates a random full name.\n\n    :param reverse: Return reversed full name.\n    :param gender: Gender's enum object.\n    :return: Full name.\n\n    :Example:\n        Johann Wolfgang.\n    \"\"\"\n    name = self.name(gender)\n    surname = self.surname(gender)\n    return f\"{surname} {name}\" if reverse else f\"{name} {surname}\"", "loc": 17}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "username", "parameters": ["self", "mask", "drange"], "param_types": {"mask": "str | None", "drange": "tuple[int, int]"}, "return_type": "str", "param_doc": {"mask": "Mask.", "drange": "Digits range."}, "return_doc": "Username as string.", "raises_doc": [{"type": "ValueError", "desc": "If template is not supported."}], "called_functions": ["ValueError", "any", "len", "re.findall", "self.random.choice", "self.random.randint", "str", "username.capitalize", "username.lower", "username.upper"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Generates a username by mask. Masks allow you to generate a variety of usernames. - **C** stands for capitalized username. - **U** stands for uppercase username. - **l** stands for lowercase username. - **d** stands for digits in the username. You can also use symbols to separate the different parts of the username: **.** **_** **-**", "source_code": "def username(\n    self, mask: str | None = None, drange: tuple[int, int] = (1800, 2100)\n) -> str:\n    \"\"\"Generates a username by mask.\n\n    Masks allow you to generate a variety of usernames.\n\n    - **C** stands for capitalized username.\n    - **U** stands for uppercase username.\n    - **l** stands for lowercase username.\n    - **d** stands for digits in the username.\n\n    You can also use symbols to separate the different parts\n    of the username: **.** **_** **-**\n\n    :param mask: Mask.\n    :param drange: Digits range.\n    :raises ValueError: If template is not supported.\n    :return: Username as string.\n\n    Example:\n        >>> username(mask='C_C_d')\n        Cotte_Article_1923\n        >>> username(mask='U.l.d')\n        ELKINS.wolverine.2013\n        >>> username(mask='l_l_d', drange=(1900, 2021))\n        plasmic_blockader_1907\n    \"\"\"\n    if len(drange) != 2:\n        raise ValueError(\"The drange parameter must contain only two integers.\")\n\n    if mask is None:\n        mask = \"l_d\"\n\n    required_tags = \"CUl\"\n    tags = re.findall(r\"[CUld.\\-_]\", mask)\n\n    if not any(tag in tags for tag in required_tags):\n        raise ValueError(\n            \"Username mask must contain at least one of these: (C, U, l).\"\n        )\n\n    final_username = \"\"\n    for tag in tags:\n        username = self.random.choice(USERNAMES)\n        if tag == \"C\":\n            final_username += username.capitalize()\n        if tag == \"U\":\n            final_username += username.upper()\n        elif tag == \"l\":\n            final_username += username.lower()\n        elif tag == \"d\":\n            final_username += str(self.random.randint(*drange))\n        elif tag in \"-_.\":\n            final_username += tag\n\n    return final_username", "loc": 57}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "password", "parameters": ["self", "length", "hashed"], "param_types": {"length": "int", "hashed": "bool"}, "return_type": "str", "param_doc": {"length": "Length of password.", "hashed": "SHA256 hash."}, "return_doc": "Password or hash of password.", "raises_doc": [], "called_functions": ["''.join", "hashlib.sha256", "password.encode", "self.random.choices", "sha256.hexdigest", "sha256.update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a password or hash of password.", "source_code": "def password(self, length: int = 8, hashed: bool = False) -> str:\n    \"\"\"Generates a password or hash of password.\n\n    :param length: Length of password.\n    :param hashed: SHA256 hash.\n    :return: Password or hash of password.\n\n    :Example:\n        k6dv2odff9#4h\n    \"\"\"\n    characters = ascii_letters + digits + punctuation\n    password = \"\".join(self.random.choices(characters, k=length))\n\n    if hashed:\n        sha256 = hashlib.sha256()\n        sha256.update(password.encode())\n        return sha256.hexdigest()\n\n    return password", "loc": 19}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "email", "parameters": ["self", "domains", "unique"], "param_types": {"domains": "t.Sequence[str] | None", "unique": "bool"}, "return_type": "str", "param_doc": {"domains": "List of custom domains for emails.", "unique": "Makes email addresses unique."}, "return_doc": "Email address.", "raises_doc": [{"type": "ValueError", "desc": "if unique is True and the provider was seeded."}], "called_functions": ["ValueError", "domain.startswith", "self._has_seed", "self.random.choice", "self.username", "str", "uuid.uuid4"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random email.", "source_code": "def email(\n    self,\n    domains: t.Sequence[str] | None = None,\n    unique: bool = False,\n) -> str:\n    \"\"\"Generates a random email.\n\n    :param domains: List of custom domains for emails.\n    :param unique: Makes email addresses unique.\n    :return: Email address.\n    :raises ValueError: if unique is True and the provider was seeded.\n\n    :Example:\n        foretime10@live.com\n    \"\"\"\n    if unique and self._has_seed():\n        raise ValueError(\n            \"You cannot use unique parameter with the seeded provider\"\n        )\n\n    if not domains:\n        domains = EMAIL_DOMAINS\n\n    domain = self.random.choice(domains)\n\n    if not domain.startswith(\"@\"):\n        domain = \"@\" + domain\n\n    if unique:\n        name = str(uuid.uuid4().hex)\n    else:\n        name = self.username(mask=\"ld\")\n\n    return f\"{name}{domain}\"", "loc": 34}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "gender", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random gender title. :Example: Male", "source_code": "def gender(self) -> str:\n    \"\"\"Generates a random gender title.\n\n    :Example:\n        Male\n    \"\"\"\n    genders: list[str] = self._extract([\"gender\"])\n    return self.random.choice(genders)", "loc": 8}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "occupation", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "The name of job.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random job.", "source_code": "def occupation(self) -> str:\n    \"\"\"Generates a random job.\n\n    :return: The name of job.\n\n    :Example:\n        Programmer.\n    \"\"\"\n    jobs: list[str] = self._extract([\"occupation\"])\n    return self.random.choice(jobs)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "political_views", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Political views.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Get a random political views.", "source_code": "def political_views(self) -> str:\n    \"\"\"Get a random political views.\n\n    :return: Political views.\n\n    :Example:\n        Liberal.\n    \"\"\"\n    views: list[str] = self._extract([\"political_views\"])\n    return self.random.choice(views)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "worldview", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Worldview.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random worldview.", "source_code": "def worldview(self) -> str:\n    \"\"\"Generates a random worldview.\n\n    :return: Worldview.\n\n    :Example:\n        Pantheism.\n    \"\"\"\n    views: list[str] = self._extract([\"worldview\"])\n    return self.random.choice(views)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "views_on", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Views on.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Get a random views on.", "source_code": "def views_on(self) -> str:\n    \"\"\"Get a random views on.\n\n    :return: Views on.\n\n    :Example:\n        Negative.\n    \"\"\"\n    views: list[str] = self._extract([\"views_on\"])\n    return self.random.choice(views)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "nationality", "parameters": ["self", "gender"], "param_types": {"gender": "Gender | None"}, "return_type": "str", "param_doc": {"gender": "Gender."}, "return_doc": "Nationality.", "raises_doc": [], "called_functions": ["isinstance", "self._extract", "self.random.choice", "self.validate_enum"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random nationality.", "source_code": "def nationality(self, gender: Gender | None = None) -> str:\n    \"\"\"Generates a random nationality.\n\n    :param gender: Gender.\n    :return: Nationality.\n\n    :Example:\n        Russian\n    \"\"\"\n    nationalities: list[str] = self._extract([\"nationality\"])\n\n    # Separated by gender\n    if isinstance(nationalities, dict):\n        key = self.validate_enum(gender, Gender)\n        nationalities = nationalities[key]\n\n    return self.random.choice(nationalities)", "loc": 17}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "university", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "University name.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random university name.", "source_code": "def university(self) -> str:\n    \"\"\"Generates a random university name.\n\n    :return: University name.\n\n    :Example:\n        MIT.\n    \"\"\"\n    universities: list[str] = self._extract([\"university\"])\n    return self.random.choice(universities)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "academic_degree", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Degree.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random academic degree.", "source_code": "def academic_degree(self) -> str:\n    \"\"\"Generates a random academic degree.\n\n    :return: Degree.\n\n    :Example:\n        Bachelor.\n    \"\"\"\n    degrees: list[str] = self._extract([\"academic_degree\"])\n    return self.random.choice(degrees)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "language", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Random language.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random language name.", "source_code": "def language(self) -> str:\n    \"\"\"Generates a random language name.\n\n    :return: Random language.\n\n    :Example:\n        Irish.\n    \"\"\"\n    languages: list[str] = self._extract([\"language\"])\n    return self.random.choice(languages)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\person.py", "class_name": "Person", "function_name": "phone_number", "parameters": ["self", "mask", "placeholder"], "param_types": {"mask": "str", "placeholder": "str"}, "return_type": "str", "param_doc": {"mask": "Mask for formatting number.", "placeholder": "A placeholder for a mask (default is #)."}, "return_doc": "Phone number.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice", "self.random.generate_string_by_mask"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random phone number.", "source_code": "def phone_number(self, mask: str = \"\", placeholder: str = \"#\") -> str:\n    \"\"\"Generates a random phone number.\n\n    :param mask: Mask for formatting number.\n    :param placeholder: A placeholder for a mask (default is #).\n    :return: Phone number.\n\n    :Example:\n        +7-(963)-409-11-22.\n    \"\"\"\n    if not mask:\n        code = self.random.choice(CALLING_CODES)\n        default = f\"{code}-(###)-###-####\"\n        masks = self._extract([\"telephone_fmt\"], default=[default])\n        mask = self.random.choice(masks)\n\n    return self.random.generate_string_by_mask(mask=mask, digit=placeholder)", "loc": 17}
{"file": "mimesis\\mimesis\\providers\\science.py", "class_name": "Science", "function_name": "measure_unit", "parameters": ["self", "name", "symbol"], "param_types": {"name": "MeasureUnit | None", "symbol": "bool"}, "return_type": "str", "param_doc": {"name": "Enum object UnitName.", "symbol": "Return only symbol"}, "return_doc": "Unit.", "raises_doc": [], "called_functions": ["self.validate_enum"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def measure_unit(\n    self,\n    name: MeasureUnit | None = None,\n    symbol: bool = False,\n) -> str:\n    \"\"\"Returns unit name from the International System of Units.\n\n    :param name: Enum object UnitName.\n    :param symbol: Return only symbol\n    :return: Unit.\n    \"\"\"\n    result: tuple[str, str] = self.validate_enum(\n        item=name,\n        enum=MeasureUnit,\n    )\n\n    if symbol:\n        return result[1]\n    return result[0]", "loc": 19}
{"file": "mimesis\\mimesis\\providers\\science.py", "class_name": "Science", "function_name": "metric_prefix", "parameters": ["self", "sign", "symbol"], "param_types": {"sign": "MetricPrefixSign | None", "symbol": "bool"}, "return_type": "str", "param_doc": {"sign": "Sing of prefix (positive/negative).", "symbol": "Return the symbol of the prefix."}, "return_doc": "Metric prefix for SI measure units.", "raises_doc": [{"type": "NonEnumerableError", "desc": "if sign is not supported."}], "called_functions": ["self.random.choice", "self.validate_enum"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random prefix for the International System of Units.", "source_code": "def metric_prefix(\n    self, sign: MetricPrefixSign | None = None, symbol: bool = False\n) -> str:\n    \"\"\"Generates a random prefix for the International System of Units.\n\n    :param sign: Sing of prefix (positive/negative).\n    :param symbol: Return the symbol of the prefix.\n    :return: Metric prefix for SI measure units.\n    :raises NonEnumerableError: if sign is not supported.\n\n    :Example:\n        mega\n    \"\"\"\n    prefixes = SI_PREFIXES_SYM if symbol else SI_PREFIXES\n\n    key = self.validate_enum(item=sign, enum=MetricPrefixSign)\n    return self.random.choice(prefixes[key])", "loc": 17}
{"file": "mimesis\\mimesis\\providers\\text.py", "class_name": "Text", "function_name": "level", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Level.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a word that indicates a level of something.", "source_code": "def level(self) -> str:\n    \"\"\"Generates a word that indicates a level of something.\n\n    :return: Level.\n\n    :Example:\n        critical.\n    \"\"\"\n    levels: list[str] = self._extract([\"level\"])\n    return self.random.choice(levels)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\text.py", "class_name": "Text", "function_name": "text", "parameters": ["self", "quantity"], "param_types": {"quantity": "int"}, "return_type": "str", "param_doc": {"quantity": "Quantity of sentences."}, "return_doc": "Text.", "raises_doc": [], "called_functions": ["' '.join", "self._extract", "self.random.choices"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates the text.", "source_code": "def text(self, quantity: int = 5) -> str:\n    \"\"\"Generates the text.\n\n    :param quantity: Quantity of sentences.\n    :return: Text.\n    \"\"\"\n    text = self._extract([\"text\"])\n    return \" \".join(self.random.choices(text, k=quantity))", "loc": 8}
{"file": "mimesis\\mimesis\\providers\\text.py", "class_name": "Text", "function_name": "words", "parameters": ["self", "quantity"], "param_types": {"quantity": "int"}, "return_type": "list[str]", "param_doc": {"quantity": "Quantity of words. Default is 5."}, "return_doc": "Word list.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choices"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a list of random words.", "source_code": "def words(self, quantity: int = 5) -> list[str]:\n    \"\"\"Generates a list of random words.\n\n    :param quantity: Quantity of words. Default is 5.\n    :return: Word list.\n\n    :Example:\n        [science, network, god, octopus, love]\n    \"\"\"\n    words = self._extract([\"words\"])\n    return self.random.choices(words, k=quantity)", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\text.py", "class_name": "Text", "function_name": "quote", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Random quote.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random quote.", "source_code": "def quote(self) -> str:\n    \"\"\"Generates a random quote.\n\n    :return: Random quote.\n\n    :Example:\n        \"Bond... James Bond.\"\n    \"\"\"\n    quotes: list[str] = self._extract([\"quotes\"])\n    return self.random.choice(quotes)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\text.py", "class_name": "Text", "function_name": "color", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "Color name.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random color name.", "source_code": "def color(self) -> str:\n    \"\"\"Generates a random color name.\n\n    :return: Color name.\n\n    :Example:\n        Red.\n    \"\"\"\n    colors: list[str] = self._extract([\"color\"])\n    return self.random.choice(colors)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\text.py", "class_name": "Text", "function_name": "hex_color", "parameters": ["self", "safe"], "param_types": {"safe": "bool"}, "return_type": "str", "param_doc": {"safe": "Get safe Flat UI hex color."}, "return_doc": "Hex color code.", "raises_doc": [], "called_functions": ["self.random.choice", "self.random.randint"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random HEX color.", "source_code": "def hex_color(self, safe: bool = False) -> str:\n    \"\"\"Generates a random HEX color.\n\n    :param safe: Get safe Flat UI hex color.\n    :return: Hex color code.\n\n    :Example:\n        #d8346b\n    \"\"\"\n    if safe:\n        return self.random.choice(SAFE_COLORS)\n\n    return f\"#{self.random.randint(0x000000, 0xFFFFFF):06x}\"", "loc": 13}
{"file": "mimesis\\mimesis\\providers\\text.py", "class_name": "Text", "function_name": "rgb_color", "parameters": ["self", "safe"], "param_types": {"safe": "bool"}, "return_type": "tuple[int, ...]", "param_doc": {"safe": "Get safe RGB tuple."}, "return_doc": "RGB tuple.", "raises_doc": [], "called_functions": ["self._hex_to_rgb", "self.hex_color"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random RGB color tuple.", "source_code": "def rgb_color(self, safe: bool = False) -> tuple[int, ...]:\n    \"\"\"Generates a random RGB color tuple.\n\n    :param safe: Get safe RGB tuple.\n    :return: RGB tuple.\n\n    :Example:\n        (252, 85, 32)\n    \"\"\"\n    color = self.hex_color(safe)\n    return self._hex_to_rgb(color)", "loc": 11}
{"file": "mimesis\\mimesis\\providers\\text.py", "class_name": "Text", "function_name": "answer", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "An answer.", "raises_doc": [], "called_functions": ["self._extract", "self.random.choice"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Generates a random answer in the current language.", "source_code": "def answer(self) -> str:\n    \"\"\"Generates a random answer in the current language.\n\n    :return: An answer.\n\n    :Example:\n        No\n    \"\"\"\n    answers: list[str] = self._extract([\"answers\"])\n    return self.random.choice(answers)", "loc": 10}
{"file": "mimesis\\mimesis\\providers\\text.py", "class_name": "Text", "function_name": "emoji", "parameters": ["self", "category"], "param_types": {"category": "EmojyCategory | None"}, "return_type": "str", "param_doc": {"category": ":class:`~mimesis.enums.EmojyCategory`."}, "return_doc": "Emoji code.", "raises_doc": [{"type": "NonEnumerableError", "desc": "When category is not supported."}], "called_functions": ["''.join", "chr", "int", "isinstance", "self.random.choice", "self.validate_enum"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Generates a random emoji from the specified category. Generates a random emoji from the specified category. If the category is not specified, a random emoji from any category will be returned.", "source_code": "def emoji(self, category: EmojyCategory | None = EmojyCategory.DEFAULT) -> str:\n    \"\"\"Generates a random emoji from the specified category.\n\n    Generates a random emoji from the specified category.\n    If the category is not specified, a random emoji\n    from any category will be returned.\n\n    :param category: :class:`~mimesis.enums.EmojyCategory`.\n    :raises NonEnumerableError: When category is not supported.\n    :return: Emoji code.\n    :example:\n        \n    \"\"\"\n    category = self.validate_enum(category, EmojyCategory)\n    symbol = self.random.choice(self._emojis[category])\n\n    base = 16\n    # Some emoji consist of multiple Unicode characters.\n    if isinstance(symbol, list):\n        return \"\".join([chr(int(s, base)) for s in symbol])\n    return chr(int(symbol, base))", "loc": 21}
{"file": "mimesis\\mimesis\\providers\\transport.py", "class_name": "Transport", "function_name": "vehicle_registration_code", "parameters": ["self", "locale"], "param_types": {"locale": "Locale | None"}, "return_type": "str", "param_doc": {"locale": "Registration code for locale (country)."}, "return_doc": "Vehicle registration code.", "raises_doc": [], "called_functions": ["self.random.choice"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def vehicle_registration_code(self, locale: Locale | None = None) -> str:\n    \"\"\"Returns vehicle registration code.\n\n    :param locale: Registration code for locale (country).\n    :return: Vehicle registration code.\n    \"\"\"\n    if locale:\n        return VRC_BY_LOCALES[locale.value]\n\n    return self.random.choice(VR_CODES)", "loc": 10}
{"file": "mimesis\\tasks\\minifier.py", "class_name": null, "function_name": "human_repr", "parameters": ["num"], "param_types": {"num": "float"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["abs"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def human_repr(num: float) -> str:\n    for unit in [\"B\", \"KB\", \"MB\"]:\n        if abs(num) < 1024.0:\n            return f\"{num:3.1f}{unit}\"\n        num /= 1024.0\n    return f\"{num:.1f}\"", "loc": 6}
{"file": "mimesis\\tasks\\minifier.py", "class_name": "Minimizer", "function_name": "run", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["human_repr", "print", "self.minify"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Start json minimizer and exit when all json files were minimized.", "source_code": "def run(self) -> None:\n    \"\"\"Start json minimizer and exit when all json files were minimized.\"\"\"\n    for file in self.files:\n        self.minify(file)\n\n    after = human_repr(self.after_total)\n    before = human_repr(self.before_total)\n    saved = human_repr(self.before_total - self.after_total)\n\n    info = (\n        \"\\nTotal: \"\n        f\"{Fore.LIGHTGREEN_EX}{before}{Style.RESET_ALL} -> {Fore.LIGHTGREEN_EX}{after}{Style.RESET_ALL}. \"\n        f\"Compressed: {Fore.LIGHTGREEN_EX}{saved}{Style.RESET_ALL}\\n\"\n    )\n    print(info)", "loc": 15}
{"file": "mimesis\\tasks\\minifier.py", "class_name": "Minimizer", "function_name": "minify", "parameters": ["self", "file"], "param_types": {"file": "Path"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["file.read_text", "file.relative_to", "file.stat", "file.write_text", "human_repr", "json.dumps", "json.loads", "print", "str"], "control_structures": [], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def minify(self, file: Path) -> None:\n    size_before = file.stat().st_size\n    self.before_total += size_before\n    before = human_repr(size_before)\n\n    minimized = json.dumps(\n        json.loads(file.read_text()), separators=(\",\", \":\"), ensure_ascii=False\n    )\n    file.write_text(minimized)\n\n    size_after = file.stat().st_size\n    self.after_total += size_after\n    after = human_repr(size_after)\n\n    rel_file = file.relative_to(file.parent.parent)\n    info = (\n        f\"{Fore.BLUE}{str(rel_file):<30}{Style.RESET_ALL} : \"\n        f\"{Fore.LIGHTGREEN_EX}minimized{Style.RESET_ALL} : \"\n        f\"{Fore.YELLOW}{before:<7}{Style.RESET_ALL} -> {Fore.LIGHTGREEN_EX}{after:<7}{Style.RESET_ALL}\"\n    )\n    print(info)", "loc": 21}
{"file": "py-backwards\\py_backwards\\compiler.py", "class_name": null, "function_name": "compile_files", "parameters": ["input_", "output", "target", "root"], "param_types": {"input_": "str", "output": "str", "target": "CompilationTarget", "root": "Optional[str]"}, "return_type": "CompilationResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CompilationResult", "_compile_file", "dependencies.update", "get_input_output_paths", "set", "sorted", "time"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Compiles all files from input_ to output.", "source_code": "def compile_files(input_: str, output: str, target: CompilationTarget,\n                  root: Optional[str] = None) -> CompilationResult:\n    \"\"\"Compiles all files from input_ to output.\"\"\"\n    dependencies = set()\n    start = time()\n    count = 0\n    for paths in get_input_output_paths(input_, output, root):\n        count += 1\n        dependencies.update(_compile_file(paths, target))\n    return CompilationResult(count, time() - start, target,\n                             sorted(dependencies))", "loc": 11}
{"file": "py-backwards\\py_backwards\\files.py", "class_name": null, "function_name": "get_input_output_paths", "parameters": ["input_", "output", "root"], "param_types": {"input_": "str", "output": "str", "root": "Optional[str]"}, "return_type": "Iterable[InputOutput]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InputOutput", "Path", "Path(input_).exists", "Path(output).joinpath", "child_input.relative_to", "input_.endswith", "input_path.glob", "input_path.relative_to", "output.endswith", "output_path.joinpath"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Get input/output paths pairs.", "source_code": "def get_input_output_paths(input_: str, output: str,\n                           root: Optional[str]) -> Iterable[InputOutput]:\n    \"\"\"Get input/output paths pairs.\"\"\"\n    if output.endswith('.py') and not input_.endswith('.py'):\n        raise InvalidInputOutput\n\n    if not Path(input_).exists():\n        raise InputDoesntExists\n\n    if input_.endswith('.py'):\n        if output.endswith('.py'):\n            yield InputOutput(Path(input_), Path(output))\n        else:\n            input_path = Path(input_)\n            if root is None:\n                output_path = Path(output).joinpath(input_path.name)\n            else:\n                output_path = Path(output).joinpath(input_path.relative_to(root))\n            yield InputOutput(input_path, output_path)\n    else:\n        output_path = Path(output)\n        input_path = Path(input_)\n        root_path = input_path if root is None else Path(root)\n        for child_input in input_path.glob('**/*.py'):\n            child_output = output_path.joinpath(\n                child_input.relative_to(root_path))\n            yield InputOutput(child_input, child_output)", "loc": 27}
{"file": "py-backwards\\py_backwards\\main.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ArgumentParser", "compile_files", "const.TARGETS.keys", "init_settings", "messages.compilation_result", "messages.input_doesnt_exists", "messages.invalid_output", "messages.permission_error", "messages.syntax_error", "messages.transformation_error", "parser.add_argument", "parser.parse_args", "print"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main() -> int:\n    parser = ArgumentParser(\n        'py-backwards',\n        description='Python to python compiler that allows you to use some '\n                    'Python 3.6 features in older versions.')\n    parser.add_argument('-i', '--input', type=str, nargs='+', required=True,\n                        help='input file or folder')\n    parser.add_argument('-o', '--output', type=str, required=True,\n                        help='output file or folder')\n    parser.add_argument('-t', '--target', type=str,\n                        required=True, choices=const.TARGETS.keys(),\n                        help='target python version')\n    parser.add_argument('-r', '--root', type=str, required=False,\n                        help='sources root')\n    parser.add_argument('-d', '--debug', action='store_true', required=False,\n                        help='enable debug output')\n    args = parser.parse_args()\n    init_settings(args)\n\n    try:\n        for input_ in args.input:\n            result = compile_files(input_, args.output,\n                                   const.TARGETS[args.target],\n                                   args.root)\n    except exceptions.CompilationError as e:\n        print(messages.syntax_error(e), file=sys.stderr)\n        return 1\n    except exceptions.TransformationError as e:\n        print(messages.transformation_error(e), file=sys.stderr)\n        return 1\n    except exceptions.InputDoesntExists:\n        print(messages.input_doesnt_exists(args.input), file=sys.stderr)\n        return 1\n    except exceptions.InvalidInputOutput:\n        print(messages.invalid_output(args.input, args.output),\n              file=sys.stderr)\n        return 1\n    except PermissionError:\n        print(messages.permission_error(args.output), file=sys.stderr)\n        return 1\n\n    print(messages.compilation_result(result))\n    return 0", "loc": 43}
{"file": "py-backwards\\py_backwards\\messages.py", "class_name": null, "function_name": "syntax_error", "parameters": ["e"], "param_types": {"e": "CompilationError"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "'{red}Syntax error in \"{e.filename}\", line {e.lineno}, pos {e.offset}:{reset}\\n{lines}'.format", "_get_lines_with_highlighted_error"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def syntax_error(e: CompilationError) -> str:\n    lines = _get_lines_with_highlighted_error(e)\n\n    return ('{red}Syntax error in \"{e.filename}\", '\n            'line {e.lineno}, pos {e.offset}:{reset}\\n{lines}').format(\n        red=Fore.RED,\n        e=e,\n        reset=Style.RESET_ALL,\n        bright=Style.BRIGHT,\n        lines='\\n'.join(lines))", "loc": 10}
{"file": "py-backwards\\py_backwards\\messages.py", "class_name": null, "function_name": "compilation_result", "parameters": ["result"], "param_types": {"result": "CompilationResult"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n    '.join", "'\\n  Additional dependencies:\\n{bright}    {dependencies}{reset}'.format", "'{bright}Compilation succeed{reset}:\\n  target: {bright}{target}{reset}\\n  files: {bright}{files}{reset}\\n  took: {bright}{time:.2f}{reset} seconds{dependencies}'.format", "'{}.{}'.format"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def compilation_result(result: CompilationResult) -> str:\n    if result.dependencies:\n        dependencies = ('\\n  Additional dependencies:\\n'\n                        '{bright}    {dependencies}{reset}').format(\n            dependencies='\\n    '.join(dep for dep in result.dependencies),\n            bright=Style.BRIGHT,\n            reset=Style.RESET_ALL)\n    else:\n        dependencies = ''\n\n    return ('{bright}Compilation succeed{reset}:\\n'\n            '  target: {bright}{target}{reset}\\n'\n            '  files: {bright}{files}{reset}\\n'\n            '  took: {bright}{time:.2f}{reset} seconds{dependencies}').format(\n        bright=Style.BRIGHT,\n        reset=Style.RESET_ALL,\n        target='{}.{}'.format(*result.target),\n        files=result.files,\n        time=result.time,\n        dependencies=dependencies)", "loc": 20}
{"file": "py-backwards\\py_backwards\\transformers\\base.py", "class_name": null, "function_name": "import_rewrite", "parameters": ["previous", "current"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["extend"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def import_rewrite(previous, current):\n    try:\n        extend(previous)\n    except ImportError:\n        extend(current)", "loc": 5}
{"file": "py-backwards\\py_backwards\\transformers\\base.py", "class_name": "BaseImportRewrite", "function_name": "visit_Import", "parameters": ["self", "node"], "param_types": {"node": "ast.Import"}, "return_type": "Union[ast.Import, ast.Try]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_matched_rewrite", "self._replace_import", "self.generic_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_Import(self, node: ast.Import) -> Union[ast.Import, ast.Try]:\n    rewrite = self._get_matched_rewrite(node.names[0].name)\n    if rewrite:\n        return self._replace_import(node, *rewrite)\n\n    return self.generic_visit(node)", "loc": 6}
{"file": "py-backwards\\py_backwards\\transformers\\base.py", "class_name": "BaseImportRewrite", "function_name": "visit_ImportFrom", "parameters": ["self", "node"], "param_types": {"node": "ast.ImportFrom"}, "return_type": "Union[ast.ImportFrom, ast.Try, ast.AST]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dict", "self._get_matched_rewrite", "self._get_names_to_replace", "self._replace_import_from_module", "self._replace_import_from_names", "self.generic_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_ImportFrom(self, node: ast.ImportFrom) -> Union[ast.ImportFrom, ast.Try, ast.AST]:\n    rewrite = self._get_matched_rewrite(node.module)\n    if rewrite:\n        return self._replace_import_from_module(node, *rewrite)\n\n    names_to_replace = dict(self._get_names_to_replace(node))\n    if names_to_replace:\n        return self._replace_import_from_names(node, names_to_replace)\n\n    return self.generic_visit(node)", "loc": 10}
{"file": "py-backwards\\py_backwards\\transformers\\class_without_bases.py", "class_name": "ClassWithoutBasesTransformer", "function_name": "visit_ClassDef", "parameters": ["self", "node"], "param_types": {"node": "ast.ClassDef"}, "return_type": "ast.ClassDef", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.Name", "self.generic_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_ClassDef(self, node: ast.ClassDef) -> ast.ClassDef:\n    if not node.bases:\n        node.bases = [ast.Name(id='object')]\n        self._tree_changed = True\n\n    return self.generic_visit(node)  # type: ignore", "loc": 6}
{"file": "py-backwards\\py_backwards\\transformers\\dict_unpacking.py", "class_name": null, "function_name": "merge_dicts", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["result.update"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def merge_dicts():\n    def _py_backwards_merge_dicts(dicts):\n        result = {}\n        for dict_ in dicts:\n            result.update(dict_)\n        return result", "loc": 6}
{"file": "py-backwards\\py_backwards\\transformers\\dict_unpacking.py", "class_name": "DictUnpackingTransformer", "function_name": "visit_Dict", "parameters": ["self", "node"], "param_types": {"node": "ast.Dict"}, "return_type": "Union[ast.Dict, ast.Call]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._merge_dicts", "self._prepare_splitted", "self._split_by_None", "self.generic_visit", "zip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_Dict(self, node: ast.Dict) -> Union[ast.Dict, ast.Call]:\n    if None not in node.keys:\n        return self.generic_visit(node)  # type: ignore\n\n    self._tree_changed = True\n    pairs = zip(node.keys, node.values)\n    splitted = self._split_by_None(pairs)\n    prepared = self._prepare_splitted(splitted)\n    return self._merge_dicts(prepared)", "loc": 9}
{"file": "py-backwards\\py_backwards\\transformers\\formatted_values.py", "class_name": "FormattedValuesTransformer", "function_name": "visit_FormattedValue", "parameters": ["self", "node"], "param_types": {"node": "ast.FormattedValue"}, "return_type": "ast.Call", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "ast.Attribute", "ast.Call", "ast.Str", "self.generic_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_FormattedValue(self, node: ast.FormattedValue) -> ast.Call:\n    self._tree_changed = True\n\n    if node.format_spec:\n        template = ''.join(['{:', node.format_spec.s, '}'])  # type: ignore\n    else:\n        template = '{}'\n\n    format_call = ast.Call(func=ast.Attribute(value=ast.Str(s=template),\n                                              attr='format'),\n                           args=[node.value],\n                           keywords=[])\n    return self.generic_visit(format_call)  # type: ignore", "loc": 13}
{"file": "py-backwards\\py_backwards\\transformers\\formatted_values.py", "class_name": "FormattedValuesTransformer", "function_name": "visit_JoinedStr", "parameters": ["self", "node"], "param_types": {"node": "ast.JoinedStr"}, "return_type": "ast.Call", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.Attribute", "ast.Call", "ast.List", "ast.Str", "self.generic_visit"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_JoinedStr(self, node: ast.JoinedStr) -> ast.Call:\n    self._tree_changed = True\n\n    join_call = ast.Call(func=ast.Attribute(value=ast.Str(s=''),\n                                            attr='join'),\n                         args=[ast.List(elts=node.values)],\n                         keywords=[])\n    return self.generic_visit(join_call)  # type: ignore", "loc": 8}
{"file": "py-backwards\\py_backwards\\transformers\\import_dbm.py", "class_name": null, "function_name": "import_rewrite", "parameters": ["previous", "current"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["__import__", "extend"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def import_rewrite(previous, current):\n    if __import__('six').PY2:\n        extend(current)\n    else:\n        extend(previous)", "loc": 5}
{"file": "py-backwards\\py_backwards\\transformers\\import_dbm.py", "class_name": "ImportDbmTransformer", "function_name": "visit_Import", "parameters": ["self", "node"], "param_types": {"node": "ast.Import"}, "return_type": "Union[ast.Import, ast.Try]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["super", "super().visit_Import"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_Import(self, node: ast.Import) -> Union[ast.Import, ast.Try]:\n    if node.names[0].name == 'dbm' and node.names[0].asname == 'ndbm':\n        return node\n\n    return super().visit_Import(node)", "loc": 5}
{"file": "py-backwards\\py_backwards\\transformers\\import_dbm.py", "class_name": "ImportDbmTransformer", "function_name": "visit_ImportFrom", "parameters": ["self", "node"], "param_types": {"node": "ast.ImportFrom"}, "return_type": "Union[ast.ImportFrom, ast.Try, ast.AST]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.Import", "ast.alias", "self.wrapper.get_body", "super", "super().visit_ImportFrom"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_ImportFrom(self, node: ast.ImportFrom) -> Union[ast.ImportFrom, ast.Try, ast.AST]:\n    names = [name.name for name in node.names]\n    if node.module == 'dbm' and names == ['ndbm']:\n        import_ = ast.Import(names=[ast.alias(name='dbm',\n                                              asname='ndbm')])\n        return self.wrapper.get_body(previous=node, current=import_)[0]  # type: ignore\n\n    return super().visit_ImportFrom(node)", "loc": 8}
{"file": "py-backwards\\py_backwards\\transformers\\metaclass.py", "class_name": "MetaclassTransformer", "function_name": "visit_ClassDef", "parameters": ["self", "node"], "param_types": {"node": "ast.ClassDef"}, "return_type": "ast.ClassDef", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.List", "class_bases.get_body", "self.generic_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_ClassDef(self, node: ast.ClassDef) -> ast.ClassDef:\n    if node.keywords:\n        metaclass = node.keywords[0].value\n        node.bases = class_bases.get_body(metaclass=metaclass,  # type: ignore\n                                          bases=ast.List(elts=node.bases))\n        node.keywords = []\n        self._tree_changed = True\n\n    return self.generic_visit(node)  # type: ignore", "loc": 9}
{"file": "py-backwards\\py_backwards\\transformers\\return_from_generator.py", "class_name": null, "function_name": "return_from_generator", "parameters": ["return_value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["StopIteration", "let"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def return_from_generator(return_value):\n    let(exc)\n    exc = StopIteration()\n    exc.value = return_value\n    raise exc", "loc": 5}
{"file": "py-backwards\\py_backwards\\transformers\\return_from_generator.py", "class_name": "ReturnFromGeneratorTransformer", "function_name": "visit_FunctionDef", "parameters": ["self", "node"], "param_types": {"node": "ast.FunctionDef"}, "return_type": "ast.FunctionDef", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._find_generator_returns", "self._replace_return", "self.generic_visit"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_FunctionDef(self, node: ast.FunctionDef) -> ast.FunctionDef:\n    generator_returns = self._find_generator_returns(node)\n\n    if generator_returns:\n        self._tree_changed = True\n\n    for parent, return_ in generator_returns:\n        self._replace_return(parent, return_)\n\n    return self.generic_visit(node)  # type: ignore", "loc": 10}
{"file": "py-backwards\\py_backwards\\transformers\\starred_unpacking.py", "class_name": "StarredUnpackingTransformer", "function_name": "visit_List", "parameters": ["self", "node"], "param_types": {"node": "ast.List"}, "return_type": "ast.List", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._has_starred", "self._to_sum_of_lists", "self.generic_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_List(self, node: ast.List) -> ast.List:\n    if not self._has_starred(node.elts):\n        return self.generic_visit(node)  # type: ignore\n\n    self._tree_changed = True\n\n    return self.generic_visit(self._to_sum_of_lists(node.elts))  # type: ignore", "loc": 7}
{"file": "py-backwards\\py_backwards\\transformers\\starred_unpacking.py", "class_name": "StarredUnpackingTransformer", "function_name": "visit_Call", "parameters": ["self", "node"], "param_types": {"node": "ast.Call"}, "return_type": "ast.Call", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.Starred", "self._has_starred", "self._to_sum_of_lists", "self.generic_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_Call(self, node: ast.Call) -> ast.Call:\n    if not self._has_starred(node.args):\n        return self.generic_visit(self.generic_visit(node))  # type: ignore\n\n    self._tree_changed = True\n\n    args = self._to_sum_of_lists(node.args)\n    node.args = [ast.Starred(value=args)]\n    return self.generic_visit(node)  # type: ignore", "loc": 9}
{"file": "py-backwards\\py_backwards\\transformers\\string_types.py", "class_name": "StringTypesTransformer", "function_name": "transform", "parameters": ["cls", "tree"], "param_types": {"tree": "ast.AST"}, "return_type": "TransformationResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TransformationResult", "find"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def transform(cls, tree: ast.AST) -> TransformationResult:\n    tree_changed = False\n\n    for node in find(tree, ast.Name):\n        if node.id == 'str':\n            node.id = 'unicode'\n            tree_changed = True\n\n    return TransformationResult(tree, tree_changed, [])", "loc": 9}
{"file": "py-backwards\\py_backwards\\transformers\\super_without_arguments.py", "class_name": "SuperWithoutArgumentsTransformer", "function_name": "visit_Call", "parameters": ["self", "node"], "param_types": {"node": "ast.Call"}, "return_type": "ast.Call", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "len", "self._replace_super_args", "self.generic_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_Call(self, node: ast.Call) -> ast.Call:\n    if isinstance(node.func, ast.Name) and node.func.id == 'super' and not len(node.args):\n        self._replace_super_args(node)\n        self._tree_changed = True\n\n    return self.generic_visit(node)  # type: ignore", "loc": 6}
{"file": "py-backwards\\py_backwards\\transformers\\variables_annotations.py", "class_name": "VariablesAnnotationsTransformer", "function_name": "transform", "parameters": ["cls", "tree"], "param_types": {"tree": "ast.AST"}, "return_type": "TransformationResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TransformationResult", "ast.Assign", "find", "get_node_position", "insert_at", "position.holder.pop", "warn"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def transform(cls, tree: ast.AST) -> TransformationResult:\n    tree_changed = False\n\n    for node in find(tree, ast.AnnAssign):\n        try:\n            position = get_node_position(tree, node)\n        except NodeNotFound:\n            warn('Assignment outside of body')\n            continue\n\n        tree_changed = True\n        position.holder.pop(position.index)  # type: ignore\n\n        if node.value is not None:\n            insert_at(position.index, position.parent,\n                      ast.Assign(targets=[node.target],  # type: ignore\n                                 value=node.value,\n                                 type_comment=node.annotation),\n                      position.attribute)\n\n    return TransformationResult(tree, tree_changed, [])", "loc": 21}
{"file": "py-backwards\\py_backwards\\transformers\\yield_from.py", "class_name": null, "function_name": "yield_from", "parameters": ["generator", "exc", "assignment"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["extend", "iter", "let", "next"], "control_structures": ["Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def yield_from(generator, exc, assignment):\n    let(iterable)\n    iterable = iter(generator)\n    while True:\n        try:\n            yield next(iterable)\n        except StopIteration as exc:\n            extend(assignment)\n            break", "loc": 9}
{"file": "py-backwards\\py_backwards\\utils\\helpers.py", "class_name": null, "function_name": "eager", "parameters": ["fn"], "param_types": {"fn": "Callable[..., Iterable[T]]"}, "return_type": "Callable[..., List[T]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fn", "list", "wraps"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def eager(fn: Callable[..., Iterable[T]]) -> Callable[..., List[T]]:\n    @wraps(fn)\n    def wrapped(*args: Any, **kwargs: Any) -> List[T]:\n        return list(fn(*args, **kwargs))\n\n    return wrapped", "loc": 6}
{"file": "py-backwards\\py_backwards\\utils\\helpers.py", "class_name": null, "function_name": "get_source", "parameters": ["fn"], "param_types": {"fn": "Callable[..., Any]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "getsource", "getsource(fn).split", "len", "re.findall"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_source(fn: Callable[..., Any]) -> str:\n    \"\"\"Returns source code of the function.\"\"\"\n    source_lines = getsource(fn).split('\\n')\n    padding = len(re.findall(r'^(\\s*)', source_lines[0])[0])\n    return '\\n'.join(line[padding:] for line in source_lines)", "loc": 5}
{"file": "py-backwards\\py_backwards\\utils\\helpers.py", "class_name": "VariablesGenerator", "function_name": "generate", "parameters": ["cls", "variable"], "param_types": {"variable": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'_py_backwards_{}_{}'.format"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Generates unique name for variable.", "source_code": "def generate(cls, variable: str) -> str:\n    \"\"\"Generates unique name for variable.\"\"\"\n    try:\n        return '_py_backwards_{}_{}'.format(variable, cls._counter)\n    finally:\n        cls._counter += 1", "loc": 6}
{"file": "py-backwards\\py_backwards\\utils\\snippet.py", "class_name": null, "function_name": "find_variables", "parameters": ["tree"], "param_types": {"tree": "ast.AST"}, "return_type": "Iterable[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["find", "get_node_position", "isinstance", "position.holder.pop"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Finds variables and remove `let` calls.", "source_code": "def find_variables(tree: ast.AST) -> Iterable[str]:\n    \"\"\"Finds variables and remove `let` calls.\"\"\"\n    for node in find(tree, ast.Call):\n        if isinstance(node.func, ast.Name) and node.func.id == 'let':\n            position = get_node_position(tree, node)\n            position.holder.pop(position.index)  # type: ignore\n            yield node.args[0].id  # type: ignore", "loc": 7}
{"file": "py-backwards\\py_backwards\\utils\\snippet.py", "class_name": null, "function_name": "extend_tree", "parameters": ["tree", "variables"], "param_types": {"tree": "ast.AST", "variables": "Dict[str, Variable]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["find", "get_node_position", "isinstance", "replace_at"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def extend_tree(tree: ast.AST, variables: Dict[str, Variable]) -> None:\n    for node in find(tree, ast.Call):\n        if isinstance(node.func, ast.Name) and node.func.id == 'extend':\n            position = get_node_position(tree, node)\n            replace_at(position.index, position.parent,  # type: ignore\n                       variables[node.args[0].id],  # type: ignore\n                       position.attribute)  # type: ignore", "loc": 7}
{"file": "py-backwards\\py_backwards\\utils\\snippet.py", "class_name": "VariablesReplacer", "function_name": "replace", "parameters": ["cls", "tree", "variables"], "param_types": {"tree": "T", "variables": "Dict[str, Variable]"}, "return_type": "T", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls", "inst.visit"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Replaces all variables with unique names.", "source_code": "def replace(cls, tree: T, variables: Dict[str, Variable]) -> T:\n    \"\"\"Replaces all variables with unique names.\"\"\"\n    inst = cls(variables)\n    inst.visit(tree)\n    return tree", "loc": 5}
{"file": "py-backwards\\py_backwards\\utils\\snippet.py", "class_name": "snippet", "function_name": "get_body", "parameters": ["self"], "param_types": {}, "return_type": "List[ast.AST]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["VariablesReplacer.replace", "ast.parse", "extend_tree", "get_source", "self._get_variables"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Get AST of snippet body with replaced variables.", "source_code": "def get_body(self, **snippet_kwargs: Variable) -> List[ast.AST]:\n    \"\"\"Get AST of snippet body with replaced variables.\"\"\"\n    source = get_source(self._fn)\n    tree = ast.parse(source)\n    variables = self._get_variables(tree, snippet_kwargs)\n    extend_tree(tree, variables)\n    VariablesReplacer.replace(tree, variables)\n    return tree.body[0].body  # type: ignore", "loc": 8}
{"file": "py-backwards\\py_backwards\\utils\\tree.py", "class_name": null, "function_name": "get_parent", "parameters": ["tree", "node", "rebuild"], "param_types": {"tree": "ast.AST", "node": "ast.AST", "rebuild": "bool"}, "return_type": "ast.AST", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Parent for {} not found'.format", "NodeNotFound", "_build_parents"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Get parent of node in tree.", "source_code": "def get_parent(tree: ast.AST, node: ast.AST, rebuild: bool = False) -> ast.AST:\n    \"\"\"Get parent of node in tree.\"\"\"\n    if node not in _parents or rebuild:\n        _build_parents(tree)\n\n    try:\n        return _parents[node]\n    except IndexError:\n        raise NodeNotFound('Parent for {} not found'.format(node))", "loc": 9}
{"file": "py-backwards\\py_backwards\\utils\\tree.py", "class_name": null, "function_name": "get_node_position", "parameters": ["tree", "node"], "param_types": {"tree": "ast.AST", "node": "ast.AST"}, "return_type": "NodePosition", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NodePosition", "get_parent", "hasattr", "parent.body.index", "parent.orelse.index"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Get node position with non-Exp parent.", "source_code": "def get_node_position(tree: ast.AST, node: ast.AST) -> NodePosition:\n    \"\"\"Get node position with non-Exp parent.\"\"\"\n    parent = get_parent(tree, node)\n\n    while not hasattr(parent, 'body') and not hasattr(parent, 'orelse'):\n        node = parent\n        parent = get_parent(tree, parent)\n\n    if node in parent.body:  # type: ignore\n        return NodePosition(parent, 'body', parent.body,  # type: ignore\n                            parent.body.index(node))  # type: ignore\n    else:\n        return NodePosition(parent, 'orelse', parent.orelse,  # type: ignore\n                            parent.orelse.index(node))  # type: ignore", "loc": 14}
{"file": "py-backwards\\py_backwards\\utils\\tree.py", "class_name": null, "function_name": "find", "parameters": ["tree", "type_"], "param_types": {"tree": "ast.AST", "type_": "Type[T]"}, "return_type": "Iterable[T]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.walk", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Finds all nodes with type T.", "source_code": "def find(tree: ast.AST, type_: Type[T]) -> Iterable[T]:\n    \"\"\"Finds all nodes with type T.\"\"\"\n    for node in ast.walk(tree):\n        if isinstance(node, type_):\n            yield node  # type: ignore", "loc": 5}
{"file": "py-backwards\\py_backwards\\utils\\tree.py", "class_name": null, "function_name": "insert_at", "parameters": ["index", "parent", "nodes", "holder_attribute"], "param_types": {"index": "int", "parent": "ast.AST", "nodes": "Union[ast.AST, List[ast.AST]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "getattr(parent, holder_attribute).insert", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Inserts nodes to parents body at index.", "source_code": "def insert_at(index: int, parent: ast.AST,\n              nodes: Union[ast.AST, List[ast.AST]],\n              holder_attribute='body') -> None:\n    \"\"\"Inserts nodes to parents body at index.\"\"\"\n    if not isinstance(nodes, list):\n        nodes = [nodes]\n\n    for child in nodes[::-1]:\n        getattr(parent, holder_attribute).insert(index, child)  # type: ignore", "loc": 9}
{"file": "py-backwards\\py_backwards\\utils\\tree.py", "class_name": null, "function_name": "replace_at", "parameters": ["index", "parent", "nodes", "holder_attribute"], "param_types": {"index": "int", "parent": "ast.AST", "nodes": "Union[ast.AST, List[ast.AST]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "getattr(parent, holder_attribute).pop", "insert_at"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Replaces node in parents body at index with nodes.", "source_code": "def replace_at(index: int, parent: ast.AST,\n               nodes: Union[ast.AST, List[ast.AST]],\n               holder_attribute='body') -> None:\n    \"\"\"Replaces node in parents body at index with nodes.\"\"\"\n    getattr(parent, holder_attribute).pop(index)  # type: ignore\n    insert_at(index, parent, nodes, holder_attribute)", "loc": 6}
{"file": "py-backwards\\py_backwards\\utils\\tree.py", "class_name": null, "function_name": "get_closest_parent_of", "parameters": ["tree", "node", "type_"], "param_types": {"tree": "ast.AST", "node": "ast.AST", "type_": "Type[T]"}, "return_type": "T", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_parent", "isinstance"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Get a closest parent of passed type.", "source_code": "def get_closest_parent_of(tree: ast.AST, node: ast.AST,\n                          type_: Type[T]) -> T:\n    \"\"\"Get a closest parent of passed type.\"\"\"\n    parent = node\n\n    while True:\n        parent = get_parent(tree, parent)\n\n        if isinstance(parent, type_):\n            return parent  # type: ignore", "loc": 10}
{"file": "python-semantic-release\\scripts\\bump_version_in_docs.py", "class_name": null, "function_name": "envsubst", "parameters": ["filepath", "version", "release_tag"], "param_types": {"filepath": "Path", "version": "str", "release_tag": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bool", "filepath.read_text", "filepath.write_text", "pattern.search", "pattern.sub", "print"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def envsubst(filepath: Path, version: str, release_tag: str) -> None:\n    file_content = filepath.read_text()\n\n    found = False\n    for pattern, replacement in [\n        (version_replace_pattern, version),\n        (tag_replace_pattern, release_tag),\n    ]:\n        if not found and (found := bool(pattern.search(file_content))):\n            print(f\"Applying envsubst to {filepath}\")\n\n        file_content = pattern.sub(replacement, file_content)\n\n    filepath.write_text(file_content)", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\enums.py", "class_name": "LevelBump", "function_name": "from_string", "parameters": ["cls", "val"], "param_types": {"val": "str"}, "return_type": "LevelBump", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["val.upper", "val.upper().replace"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Get the level from string representation. For backwards-compatibility, dashes are replaced with underscores so that: >>> LevelBump.from_string(\"no-release\") == LevelBump.NO_RELEASE", "source_code": "def from_string(cls, val: str) -> LevelBump:\n    \"\"\"\n    Get the level from string representation. For backwards-compatibility,\n    dashes are replaced with underscores so that:\n    >>> LevelBump.from_string(\"no-release\") == LevelBump.NO_RELEASE\n    Equally,\n    >>> LevelBump.from_string(\"minor\") == LevelBump.MINOR\n    \"\"\"\n    return cls[val.upper().replace(\"-\", \"_\")]", "loc": 9}
{"file": "python-semantic-release\\src\\semantic_release\\gitproject.py", "class_name": "GitProject", "function_name": "git_add", "parameters": ["self", "paths", "force", "strict", "noop"], "param_types": {"paths": "Sequence[Path | str]", "force": "bool", "strict": "bool", "noop": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["GitAddError", "Path", "Repo", "dict", "filter", "indented", "noop_report", "repo.git.add", "self.logger.exception", "self.logger.warning", "str", "str.join", "{'force': force}.items"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def git_add(\n    self,\n    paths: Sequence[Path | str],\n    force: bool = False,\n    strict: bool = False,\n    noop: bool = False,\n) -> None:\n    if noop:\n        noop_report(\n            indented(\n                f\"\"\"\\\n                would have run:\n                    git add {str.join(\" \", [str(Path(p)) for p in paths])}\n                \"\"\"\n            )\n        )\n        return\n\n    git_args = dict(\n        filter(\n            lambda k_v: k_v[1],  # if truthy\n            {\n                \"force\": force,\n            }.items(),\n        )\n    )\n\n    with Repo(str(self.project_root)) as repo:\n        # TODO: in future this loop should be 1 line:\n        # repo.index.add(all_paths_to_add, force=False)  # noqa: ERA001\n        # but since 'force' is deliberately ineffective (as in docstring) in gitpython 3.1.18\n        # we have to do manually add each filepath, and catch the exception if it is an ignored file\n        for updated_path in paths:\n            try:\n                repo.git.add(str(Path(updated_path)), **git_args)\n            except GitCommandError as err:  # noqa: PERF203, acceptable performance loss\n                err_msg = f\"Failed to add path ({updated_path}) to index\"\n                if strict:\n                    self.logger.exception(str(err))\n                    raise GitAddError(err_msg) from err\n                self.logger.warning(err_msg)", "loc": 41}
{"file": "python-semantic-release\\src\\semantic_release\\gitproject.py", "class_name": "GitProject", "function_name": "git_commit", "parameters": ["self", "message", "date", "commit_all", "no_verify", "noop"], "param_types": {"message": "str", "date": "int | None", "commit_all": "bool", "no_verify": "bool", "noop": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["GitCommitEmptyIndexError", "GitCommitError", "Repo", "bool", "dict", "filter", "indented", "message.replace", "noop_report", "repo.git.commit", "repo.index.diff", "self._get_custom_environment", "self.is_dirty", "self.logger.exception", "str", "{'a': commit_all, 'm': message, 'date': date, 'no_verify': no_verify}.items"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def git_commit(\n    self,\n    message: str,\n    date: int | None = None,\n    commit_all: bool = False,\n    no_verify: bool = False,\n    noop: bool = False,\n) -> None:\n    git_args = dict(\n        filter(\n            lambda k_v: k_v[1],  # if truthy\n            {\n                \"a\": commit_all,\n                \"m\": message,\n                \"date\": date,\n                \"no_verify\": no_verify,\n            }.items(),\n        )\n    )\n\n    if noop:\n        command = (\n            f\"\"\"\\\n            GIT_AUTHOR_NAME={self._commit_author.name} \\\\\n            GIT_AUTHOR_EMAIL={self._commit_author.email} \\\\\n            GIT_COMMITTER_NAME={self._commit_author.name} \\\\\n            GIT_COMMITTER_EMAIL={self._commit_author.email} \\\\\n            \"\"\"\n            if self._commit_author\n            else \"\"\n        )\n\n        # Indents the newlines so that terminal formatting is happy - note the\n        # git commit line of the output is 24 spaces indented too\n        # Only this message needs such special handling because of the newlines\n        # that might be in a commit message between the subject and body\n        indented_commit_message = message.replace(\"\\n\\n\", \"\\n\\n\" + \" \" * 24)\n\n        command += f\"git commit -m '{indented_commit_message}'\"\n        command += \"--all\" if commit_all else \"\"\n        command += \"--no-verify\" if no_verify else \"\"\n\n        noop_report(\n            indented(\n                f\"\"\"\\\n                would have run:\n                    {command}\n                \"\"\"\n            )\n        )\n        return\n\n    with Repo(str(self.project_root)) as repo:\n        has_index_changes = bool(repo.index.diff(\"HEAD\"))\n        has_working_changes = self.is_dirty()\n        will_commit_files = has_index_changes or (\n            has_working_changes and commit_all\n        )\n\n        if not will_commit_files:\n            raise GitCommitEmptyIndexError(\"No changes to commit!\")\n\n        with self._get_custom_environment(repo):\n            try:\n                repo.git.commit(**git_args)\n            except GitCommandError as err:\n                self.logger.exception(str(err))\n                raise GitCommitError(\"Failed to commit changes\") from err", "loc": 68}
{"file": "python-semantic-release\\src\\semantic_release\\gitproject.py", "class_name": "GitProject", "function_name": "git_tag", "parameters": ["self", "tag_name", "message", "isotimestamp", "noop"], "param_types": {"tag_name": "str", "message": "str", "isotimestamp": "str", "noop": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["GitTagError", "Repo", "ValueError", "datetime.fromisoformat", "indented", "noop_report", "repo.git.tag", "self._get_custom_environment", "self.logger.exception", "str", "str.join"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def git_tag(\n    self, tag_name: str, message: str, isotimestamp: str, noop: bool = False\n) -> None:\n    try:\n        datetime.fromisoformat(isotimestamp)\n    except ValueError as err:\n        raise ValueError(\"Invalid timestamp format\") from err\n\n    if noop:\n        command = str.join(\n            \" \",\n            [\n                f\"GIT_COMMITTER_DATE={isotimestamp}\",\n                *(\n                    [\n                        f\"GIT_AUTHOR_NAME={self._commit_author.name}\",\n                        f\"GIT_AUTHOR_EMAIL={self._commit_author.email}\",\n                        f\"GIT_COMMITTER_NAME={self._commit_author.name}\",\n                        f\"GIT_COMMITTER_EMAIL={self._commit_author.email}\",\n                    ]\n                    if self._commit_author\n                    else [\"\"]\n                ),\n                f\"git tag -a {tag_name} -m '{message}'\",\n            ],\n        )\n\n        noop_report(\n            indented(\n                f\"\"\"\\\n                would have run:\n                    {command}\n                \"\"\"\n            )\n        )\n        return\n\n    with Repo(str(self.project_root)) as repo, self._get_custom_environment(\n        repo,\n        {\"GIT_COMMITTER_DATE\": isotimestamp},\n    ):\n        try:\n            repo.git.tag(\"-a\", tag_name, m=message)\n        except GitCommandError as err:\n            self.logger.exception(str(err))\n            raise GitTagError(f\"Failed to create tag ({tag_name})\") from err", "loc": 46}
{"file": "python-semantic-release\\src\\semantic_release\\gitproject.py", "class_name": "GitProject", "function_name": "git_push_branch", "parameters": ["self", "remote_url", "branch", "noop"], "param_types": {"remote_url": "str", "branch": "str", "noop": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["GitPushError", "Repo", "indented", "noop_report", "repo.git.push", "self._cred_masker.mask", "self.logger.exception", "str"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def git_push_branch(self, remote_url: str, branch: str, noop: bool = False) -> None:\n    if noop:\n        noop_report(\n            indented(\n                f\"\"\"\\\n                would have run:\n                    git push {self._cred_masker.mask(remote_url)} {branch}\n                \"\"\"\n            )\n        )\n        return\n\n    with Repo(str(self.project_root)) as repo:\n        try:\n            repo.git.push(remote_url, branch)\n        except GitCommandError as err:\n            self.logger.exception(str(err))\n            raise GitPushError(\n                f\"Failed to push branch ({branch}) to remote\"\n            ) from err", "loc": 20}
{"file": "python-semantic-release\\src\\semantic_release\\gitproject.py", "class_name": "GitProject", "function_name": "git_push_tag", "parameters": ["self", "remote_url", "tag", "noop"], "param_types": {"remote_url": "str", "tag": "str", "noop": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["GitPushError", "Repo", "indented", "noop_report", "repo.git.push", "self._cred_masker.mask", "self.logger.exception", "str"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def git_push_tag(self, remote_url: str, tag: str, noop: bool = False) -> None:\n    if noop:\n        noop_report(\n            indented(\n                f\"\"\"\\\n                would have run:\n                    git push {self._cred_masker.mask(remote_url)} tag {tag}\n                \"\"\"  # noqa: E501\n            )\n        )\n        return\n\n    with Repo(str(self.project_root)) as repo:\n        try:\n            repo.git.push(remote_url, \"tag\", tag)\n        except GitCommandError as err:\n            self.logger.exception(str(err))\n            raise GitPushError(f\"Failed to push tag ({tag}) to remote\") from err", "loc": 18}
{"file": "python-semantic-release\\src\\semantic_release\\helpers.py", "class_name": null, "function_name": "get_number_from_str", "parameters": ["string", "default", "interpret_hex"], "param_types": {"string": "str", "default": "int", "interpret_hex": "bool"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["abs", "hex_number_pattern.search", "int", "match.group", "number_pattern.search"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_number_from_str(\n    string: str, default: int = -1, interpret_hex: bool = False\n) -> int:\n    if interpret_hex and (match := hex_number_pattern.search(string)):\n        return abs(int(match.group(\"number\"), 16))\n\n    if match := number_pattern.search(string):\n        return int(match.group(\"number\"))\n\n    return default", "loc": 10}
{"file": "python-semantic-release\\src\\semantic_release\\helpers.py", "class_name": null, "function_name": "sort_numerically", "parameters": ["iterable", "reverse", "allow_hex"], "param_types": {"iterable": "Iterable[str]", "reverse": "bool", "allow_hex": "bool"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_number_from_str", "hex_number_pattern.search", "number_pattern.search", "pattern_match.group", "prefixes.keys", "prefixes[prefix].append", "reduce", "sorted", "unmatched_items.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def sort_numerically(\n    iterable: Iterable[str], reverse: bool = False, allow_hex: bool = False\n) -> list[str]:\n    # Alphabetically sort prefixes first, then sort by number\n    alphabetized_list = sorted(iterable)\n\n    # Extract prefixes in order to group items by prefix\n    unmatched_items = []\n    prefixes: dict[str, list[str]] = {}\n    for item in alphabetized_list:\n        if not (\n            pattern_match := (\n                (hex_number_pattern.search(item) if allow_hex else None)\n                or number_pattern.search(item)\n            )\n        ):\n            unmatched_items.append(item)\n            continue\n\n        prefix = prefix if (prefix := pattern_match.group(\"prefix\")) else \"\"\n\n        if prefix not in prefixes:\n            prefixes[prefix] = []\n\n        prefixes[prefix].append(item)\n\n    # Sort prefixes and items by number mixing in unmatched items as alphabetized with other prefixes\n    return reduce(\n        lambda acc, next_item: acc + next_item,\n        [\n            (\n                sorted(\n                    prefixes[prefix],\n                    key=lambda x: get_number_from_str(\n                        x, default=-1, interpret_hex=allow_hex\n                    ),\n                    reverse=reverse,\n                )\n                if prefix in prefixes\n                else [prefix]\n            )\n            for prefix in sorted([*prefixes.keys(), *unmatched_items])\n        ],\n        [],\n    )", "loc": 45}
{"file": "python-semantic-release\\src\\semantic_release\\helpers.py", "class_name": null, "function_name": "text_reducer", "parameters": ["text", "filter_pair"], "param_types": {"text": "str", "filter_pair": "tuple[Pattern[str], str]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["filter_pattern.sub"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Reduce function to apply mulitple filters to a string", "source_code": "def text_reducer(text: str, filter_pair: tuple[Pattern[str], str]) -> str:\n    \"\"\"Reduce function to apply mulitple filters to a string\"\"\"\n    if not text:  # abort if the paragraph is empty\n        return text\n\n    filter_pattern, replacement = filter_pair\n    return filter_pattern.sub(replacement, text)", "loc": 7}
{"file": "python-semantic-release\\src\\semantic_release\\helpers.py", "class_name": null, "function_name": "validate_types_in_sequence", "parameters": ["sequence", "types"], "param_types": {"sequence": "Sequence", "types": "type | tuple[type, ...]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["all", "isinstance"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Validate that all elements in a sequence are of a specific type", "source_code": "def validate_types_in_sequence(\n    sequence: Sequence, types: type | tuple[type, ...]\n) -> bool:\n    \"\"\"Validate that all elements in a sequence are of a specific type\"\"\"\n    return all(isinstance(item, types) for item in sequence)", "loc": 5}
{"file": "python-semantic-release\\src\\semantic_release\\helpers.py", "class_name": null, "function_name": "format_arg", "parameters": ["value"], "param_types": {"value": "Any"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["str", "type", "value.strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Helper to format an argument an argument for logging", "source_code": "def format_arg(value: Any) -> str:\n    \"\"\"Helper to format an argument an argument for logging\"\"\"\n    if type(value) == str:\n        return f\"'{value.strip()}'\"\n    return str(value)", "loc": 5}
{"file": "python-semantic-release\\src\\semantic_release\\helpers.py", "class_name": null, "function_name": "check_tag_format", "parameters": ["tag_format"], "param_types": {"tag_format": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "string.Formatter", "string.Formatter().parse"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_tag_format(tag_format: str) -> None:\n    if \"version\" not in (f[1] for f in string.Formatter().parse(tag_format)):\n        raise ValueError(\n            f\"Invalid tag_format {tag_format!r}, must use 'version' as a format key\"\n        )", "loc": 5}
{"file": "python-semantic-release\\src\\semantic_release\\helpers.py", "class_name": null, "function_name": "logged_function", "parameters": ["logger"], "param_types": {"logger": "Logger"}, "return_type": "Callable[[_FuncType[_R]], _FuncType[_R]]", "param_doc": {"logger": "Logger to send output to."}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "format_arg", "func", "kwargs.items", "logger.debug", "str", "wraps"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Decorator which adds debug logging of a function's input arguments and return value. The input arguments are logged before the function is called, and the return value is logged once it has completed.", "source_code": "def logged_function(logger: Logger) -> Callable[[_FuncType[_R]], _FuncType[_R]]:\n    \"\"\"\n    Decorator which adds debug logging of a function's input arguments and return\n    value.\n\n    The input arguments are logged before the function is called, and the\n    return value is logged once it has completed.\n\n    :param logger: Logger to send output to.\n    \"\"\"\n\n    def _logged_function(func: _FuncType[_R]) -> _FuncType[_R]:\n        @wraps(func)\n        def _wrapper(*args: Any, **kwargs: Any) -> _R:\n            logger.debug(\n                \"%s(%s, %s)\",\n                func.__name__,\n                \", \".join([format_arg(x) for x in args]),\n                \", \".join([f\"{k}={format_arg(v)}\" for k, v in kwargs.items()]),\n            )\n\n            # Call function\n            result = func(*args, **kwargs)\n\n            # Log result\n            logger.debug(\"%s -> %s\", func.__qualname__, str(result))\n            return result\n\n        return _wrapper\n\n    return _logged_function", "loc": 31}
{"file": "python-semantic-release\\src\\semantic_release\\helpers.py", "class_name": null, "function_name": "dynamic_import", "parameters": ["import_path"], "param_types": {"import_path": "str"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ImportError", "Path", "Path(module_name).is_absolute", "Path(module_name).resolve", "Path(module_name).with_suffix", "ValueError", "getattr", "import_path.split", "importlib.import_module", "importlib.util.module_from_spec", "importlib.util.spec_from_file_location", "logged_function", "logger.debug", "module_filepath.exists", "spec.loader.exec_module", "str", "str(Path(module_name).with_suffix('')).replace", "str(Path(module_name).with_suffix('')).replace(os.sep, '.').lstrip", "str.join", "sys.modules.update"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Dynamically import an object from a conventionally formatted \"module:attribute\" string", "source_code": "def dynamic_import(import_path: str) -> Any:\n    \"\"\"\n    Dynamically import an object from a conventionally formatted \"module:attribute\"\n    string\n    \"\"\"\n    if \":\" not in import_path:\n        raise ValueError(\n            f\"Invalid import path {import_path!r}, must use 'module:Class' format\"\n        )\n\n    # Split the import path into module and attribute\n    module_name, attr = import_path.split(\":\", maxsplit=1)\n\n    # Check if the module is a file path, if it can be resolved and exists on disk then import as a file\n    module_filepath = Path(module_name).resolve()\n    if module_filepath.exists():\n        module_path = (\n            module_filepath.stem\n            if Path(module_name).is_absolute()\n            else str(Path(module_name).with_suffix(\"\")).replace(os.sep, \".\").lstrip(\".\")\n        )\n\n        if module_path not in sys.modules:\n            logger.debug(\"Loading '%s' from file '%s'\", module_path, module_filepath)\n            spec = importlib.util.spec_from_file_location(\n                module_path, str(module_filepath)\n            )\n            if spec is None:\n                raise ImportError(f\"Could not import {module_filepath}\")\n\n            module = importlib.util.module_from_spec(spec)  # type: ignore[arg-type]\n            sys.modules.update({spec.name: module})\n            spec.loader.exec_module(module)  # type: ignore[union-attr]\n\n        return getattr(sys.modules[module_path], attr)\n\n    # Otherwise, import as a module\n    try:\n        logger.debug(\"Importing module '%s'\", module_name)\n        module = importlib.import_module(module_name)\n        logger.debug(\"Loading '%s' from module '%s'\", attr, module_name)\n        return getattr(module, attr)\n    except TypeError as err:\n        raise ImportError(\n            str.join(\n                \"\\n\",\n                [\n                    str(err.args[0]),\n                    \"Verify the import format matches 'module:attribute' or 'path/to/module:attribute'\",\n                ],\n            )\n        ) from err", "loc": 52}
{"file": "python-semantic-release\\src\\semantic_release\\__init__.py", "class_name": null, "function_name": "setup_hook", "parameters": ["argv"], "param_types": {"argv": "list[str]"}, "return_type": "None", "param_doc": {"argv": "sys.argv"}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "len", "main"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "A hook to be used in setup.py to enable `python setup.py publish`.", "source_code": "def setup_hook(argv: list[str]) -> None:\n    \"\"\"\n    A hook to be used in setup.py to enable `python setup.py publish`.\n\n    :param argv: sys.argv\n    \"\"\"\n    if len(argv) > 1 and any(\n        cmd in argv for cmd in [\"version\", \"publish\", \"changelog\"]\n    ):\n        from semantic_release.cli.commands.main import main\n\n        main()", "loc": 12}
{"file": "python-semantic-release\\src\\semantic_release\\__main__.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cli_main", "format_exception", "print", "str", "str(err).splitlines", "str.join", "sys.exc_info", "sys.exit"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main() -> None:\n    try:\n        cli_main(args=sys.argv[1:])\n        print(\"semantic-release completed successfully.\", file=sys.stderr)\n    except KeyboardInterrupt:\n        print(\"\\n-- User Abort! --\", file=sys.stderr)\n        sys.exit(127)\n    except Exception as err:  # noqa: BLE001, graceful error handling across application\n        if globals.log_level <= SemanticReleaseLogLevels.DEBUG:\n            print(f\"{err.__class__.__name__}: {err}\\n\", file=sys.stderr)\n            etype, value, traceback = sys.exc_info()\n            print(\n                str.join(\n                    \"\",\n                    format_exception(\n                        etype,\n                        value,\n                        traceback,\n                        limit=None,\n                        chain=True,\n                    )[:-1],\n                ),\n                file=sys.stderr,\n            )\n\n        print(\n            str.join(\"\\n\", [f\"::ERROR:: {line}\" for line in str(err).splitlines()]),\n            file=sys.stderr,\n        )\n\n        if globals.log_level > SemanticReleaseLogLevels.DEBUG:\n            print(\n                \"Run semantic-release in very verbose mode (-vv) to see the full traceback.\",\n                file=sys.stderr,\n            )\n\n        sys.exit(1)", "loc": 37}
{"file": "python-semantic-release\\src\\semantic_release\\changelog\\context.py", "class_name": null, "function_name": "make_changelog_context", "parameters": ["hvcs_client", "release_history", "mode", "prev_changelog_file", "insertion_flag", "mask_initial_release"], "param_types": {"hvcs_client": "HvcsBase", "release_history": "ReleaseHistory", "mode": "ChangelogMode", "prev_changelog_file": "Path", "insertion_flag": "str", "mask_initial_release": "bool"}, "return_type": "ChangelogContext", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChangelogContext", "hvcs_client.__class__.__name__.lower", "hvcs_client.get_changelog_context_filters", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_changelog_context(\n    hvcs_client: HvcsBase,\n    release_history: ReleaseHistory,\n    mode: ChangelogMode,\n    prev_changelog_file: Path,\n    insertion_flag: str,\n    mask_initial_release: bool,\n) -> ChangelogContext:\n    return ChangelogContext(\n        repo_name=hvcs_client.repo_name,\n        repo_owner=hvcs_client.owner,\n        history=release_history,\n        changelog_mode=mode.value,\n        changelog_insertion_flag=insertion_flag,\n        mask_initial_release=mask_initial_release,\n        prev_changelog_file=str(prev_changelog_file),\n        hvcs_type=hvcs_client.__class__.__name__.lower(),\n        filters=(\n            *hvcs_client.get_changelog_context_filters(),\n            create_pypi_url,\n            read_file,\n            convert_md_to_rst,\n            autofit_text_width,\n            sort_numerically,\n        ),\n    )", "loc": 26}
{"file": "python-semantic-release\\src\\semantic_release\\changelog\\context.py", "class_name": null, "function_name": "convert_md_to_rst", "parameters": ["md_content"], "param_types": {"md_content": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["pattern.sub", "regexp", "replacements.values"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def convert_md_to_rst(md_content: str) -> str:\n    rst_content = md_content\n    replacements = {\n        # Replace markdown doubleunder bold with rst bold\n        \"bold-inline\": (regexp(r\"(?<=\\s)__(.+?)__(?=\\s|$)\"), r\"**\\1**\"),\n        # Replace markdown italics with rst italics\n        \"italic-inline\": (regexp(r\"(?<=\\s)_([^_].+?[^_])_(?=\\s|$)\"), r\"*\\1*\"),\n        # Replace markdown bullets with rst bullets\n        \"bullets\": (regexp(r\"^(\\s*)-(\\s)\"), r\"\\1*\\2\"),\n        # Replace markdown inline raw content with rst inline raw content\n        \"raw-inline\": (regexp(r\"(?<=\\s)(`[^`]+`)(?![`_])\"), r\"`\\1`\"),\n        # Replace markdown inline link with rst inline link\n        \"link-inline\": (\n            regexp(r\"(?<=\\s)\\[([^\\]]+)\\]\\(([^)]+)\\)(?=\\s|$)\"),\n            r\"`\\1 <\\2>`_\",\n        ),\n    }\n\n    for pattern, replacement in replacements.values():\n        rst_content = pattern.sub(replacement, rst_content)\n\n    return rst_content", "loc": 22}
{"file": "python-semantic-release\\src\\semantic_release\\changelog\\context.py", "class_name": null, "function_name": "autofit_text_width", "parameters": ["text", "maxwidth", "indent_size"], "param_types": {"text": "str", "maxwidth": "int", "indent_size": "int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["filter", "formatted_description.append", "formatted_paragraph.append", "input_text.split", "len", "list", "paragraph.replace", "paragraph.replace('\\r', '').replace", "paragraph.replace('\\r', '').replace('\\n', ' ').strip", "paragraph.replace('\\r', '').replace('\\n', ' ').strip().split", "str.join", "str.join('\\n\\n', formatted_description).strip", "text.strip"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Format the description text to fit within a specified width", "source_code": "def autofit_text_width(text: str, maxwidth: int = 100, indent_size: int = 0) -> str:\n    \"\"\"Format the description text to fit within a specified width\"\"\"\n    input_text = text.strip()\n\n    if len(input_text) <= maxwidth:\n        # If the text is already within the maxwidth, return immediately\n        return input_text\n\n    indent = \" \" * indent_size\n    formatted_description = []\n\n    # Re-format text to fit within the maxwidth\n    for paragraph in input_text.split(\"\\n\\n\"):\n        formatted_paragraph = []\n\n        # Split the paragraph into words with no empty strings\n        words = list(\n            filter(\n                None, paragraph.replace(\"\\r\", \"\").replace(\"\\n\", \" \").strip().split(\" \")\n            )\n        )\n\n        # Initialize the line for each paragraph\n        line = words[0]\n        next_line = \"\"\n\n        for word in words[1:]:\n            # Check if the current line + the next word (and a space) will fit within the maxwidth\n            # If it does, then update the current line\n            next_line = f\"{line} {word}\"\n            if len(next_line) <= maxwidth:\n                line = next_line\n                continue\n\n            # Add the current line to the paragraph and start a new line\n            formatted_paragraph.append(line)\n            line = f\"{indent}{word}\"\n\n        # Store the last line in the paragraph since it hasn't reached the maxwidth yet\n        formatted_paragraph.append(line)\n\n        #\n        formatted_description.append(str.join(\"\\n\", formatted_paragraph))\n\n    # Print the formatted description\n    return str.join(\"\\n\\n\", formatted_description).strip()", "loc": 46}
{"file": "python-semantic-release\\src\\semantic_release\\changelog\\context.py", "class_name": "ReleaseNotesContext", "function_name": "bind_to_environment", "parameters": ["self", "env"], "param_types": {"env": "Environment"}, "return_type": "Environment", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dict", "env_globals.items", "filter", "self.__dict__.items"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def bind_to_environment(self, env: Environment) -> Environment:\n    env_globals = dict(\n        filter(lambda k_v: k_v[0] != \"filters\", self.__dict__.items())\n    )\n\n    for g, v in env_globals.items():\n        env.globals[g] = v\n\n    for f in self.filters:\n        env.filters[f.__name__] = f\n\n    return env", "loc": 12}
{"file": "python-semantic-release\\src\\semantic_release\\changelog\\context.py", "class_name": "ChangelogContext", "function_name": "bind_to_environment", "parameters": ["self", "env"], "param_types": {"env": "Environment"}, "return_type": "Environment", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def bind_to_environment(self, env: Environment) -> Environment:\n    env.globals[\"context\"] = self\n    env.globals[\"ctx\"] = self\n    for f in self.filters:\n        env.filters[f.__name__] = f\n    return env", "loc": 6}
{"file": "python-semantic-release\\src\\semantic_release\\changelog\\release_history.py", "class_name": "ReleaseHistory", "function_name": "release", "parameters": ["self", "version", "tagger", "committer", "tagged_date"], "param_types": {"version": "Version", "tagger": "Actor", "committer": "Actor", "tagged_date": "datetime"}, "return_type": "ReleaseHistory", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ReleaseHistory", "ValueError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def release(\n    self, version: Version, tagger: Actor, committer: Actor, tagged_date: datetime\n) -> ReleaseHistory:\n    if version in self.released:\n        raise ValueError(f\"{version} has already been released!\")\n\n    # return a new instance to avoid potential accidental\n    # mutation\n    return ReleaseHistory(\n        unreleased={},\n        released={\n            version: {\n                \"tagger\": tagger,\n                \"committer\": committer,\n                \"tagged_date\": tagged_date,\n                \"elements\": self.unreleased,\n                \"version\": version,\n            },\n            **self.released,\n        },\n    )", "loc": 21}
{"file": "python-semantic-release\\src\\semantic_release\\changelog\\template.py", "class_name": null, "function_name": "environment", "parameters": ["template_dir", "block_start_string", "block_end_string", "variable_start_string", "variable_end_string", "comment_start_string", "comment_end_string", "line_statement_prefix", "line_comment_prefix", "trim_blocks", "lstrip_blocks", "newline_sequence", "keep_trailing_newline", "extensions", "autoescape"], "param_types": {"template_dir": "Path | str", "block_start_string": "str", "block_end_string": "str", "variable_start_string": "str", "variable_end_string": "str", "comment_start_string": "str", "comment_end_string": "str", "line_statement_prefix": "str | None", "line_comment_prefix": "str | None", "trim_blocks": "bool", "lstrip_blocks": "bool", "newline_sequence": "Literal['\\n', '\\r', '\\r\\n']", "keep_trailing_newline": "bool", "extensions": "Iterable[str]", "autoescape": "bool | str"}, "return_type": "SandboxedEnvironment", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ComplexDirectorySandboxedEnvironment", "FileSystemLoader", "dynamic_import", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Create a jinja2.sandbox.SandboxedEnvironment with certain parameter resrictions. For example the Loader is fixed to FileSystemLoader, although the searchpath is configurable.", "source_code": "def environment(\n    template_dir: Path | str = \".\",\n    block_start_string: str = \"{%\",\n    block_end_string: str = \"%}\",\n    variable_start_string: str = \"{{\",\n    variable_end_string: str = \"}}\",\n    comment_start_string: str = \"{#\",\n    comment_end_string: str = \"#}\",\n    line_statement_prefix: str | None = None,\n    line_comment_prefix: str | None = None,\n    trim_blocks: bool = False,\n    lstrip_blocks: bool = False,\n    newline_sequence: Literal[\"\\n\", \"\\r\", \"\\r\\n\"] = \"\\n\",\n    keep_trailing_newline: bool = False,\n    extensions: Iterable[str] = (),\n    autoescape: bool | str = True,\n) -> SandboxedEnvironment:\n    \"\"\"\n    Create a jinja2.sandbox.SandboxedEnvironment with certain parameter resrictions.\n\n    For example the Loader is fixed to FileSystemLoader, although the searchpath\n    is configurable.\n\n    ``autoescape`` can be a string in which case it should follow the convention\n    ``module:attr``, in this instance it will be dynamically imported.\n    See https://jinja.palletsprojects.com/en/3.1.x/api/#jinja2.Environment for full\n    parameter descriptions\n    \"\"\"\n    autoescape_value: bool | Callable[[str | None], bool]\n    if isinstance(autoescape, str):\n        autoescape_value = dynamic_import(autoescape)\n    else:\n        autoescape_value = autoescape\n\n    return ComplexDirectorySandboxedEnvironment(\n        block_start_string=block_start_string,\n        block_end_string=block_end_string,\n        variable_start_string=variable_start_string,\n        variable_end_string=variable_end_string,\n        comment_start_string=comment_start_string,\n        comment_end_string=comment_end_string,\n        line_statement_prefix=line_statement_prefix,\n        line_comment_prefix=line_comment_prefix,\n        trim_blocks=trim_blocks,\n        lstrip_blocks=lstrip_blocks,\n        newline_sequence=newline_sequence,\n        keep_trailing_newline=keep_trailing_newline,\n        extensions=extensions,\n        autoescape=autoescape_value,\n        loader=FileSystemLoader(template_dir, encoding=\"utf-8\"),\n    )", "loc": 51}
{"file": "python-semantic-release\\src\\semantic_release\\changelog\\template.py", "class_name": "ComplexDirectorySandboxedEnvironment", "function_name": "join_path", "parameters": ["self", "template", "parent"], "param_types": {"template": "str", "parent": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PurePosixPath", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Add support for complex directory structures in the template directory. This method overrides the default functionality of the SandboxedEnvironment where all 'include' keywords expect to be in the same directory as the calling", "source_code": "def join_path(self, template: str, parent: str) -> str:\n    \"\"\"\n    Add support for complex directory structures in the template directory.\n\n    This method overrides the default functionality of the SandboxedEnvironment\n    where all 'include' keywords expect to be in the same directory as the calling\n    template, however this is unintuitive when using a complex directory structure.\n\n    This override simulates the changing of directories when you include the template\n    from a child directory. When the child then includes a template, it will make the\n    path relative to the child directory rather than the top level template directory.\n    \"\"\"\n    # Must be posixpath because jinja only knows how to handle posix path includes\n    return str(PurePosixPath(parent).parent / template)", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\changelog_writer.py", "class_name": null, "function_name": "get_default_tpl_dir", "parameters": ["style", "sub_dir"], "param_types": {"style": "str", "sub_dir": "str | None"}, "return_type": "Path", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InternalError", "Path", "default_templates_path.is_dir", "files", "module_base_path.joinpath", "str", "str.join", "sub_dir.strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_default_tpl_dir(style: str, sub_dir: str | None = None) -> Path:\n    module_base_path = Path(str(files(semantic_release.__name__)))\n    default_templates_path = module_base_path.joinpath(\n        f\"data/templates/{style}\",\n        \"\" if sub_dir is None else sub_dir.strip(\"/\"),\n    )\n\n    if default_templates_path.is_dir():\n        return default_templates_path\n\n    raise InternalError(\n        str.join(\n            \" \",\n            [\n                \"Default template directory not found at\",\n                f\"{default_templates_path}. Installation corrupted!\",\n            ],\n        )\n    )", "loc": 19}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\changelog_writer.py", "class_name": null, "function_name": "apply_user_changelog_template_directory", "parameters": ["template_dir", "environment", "destination_dir", "noop"], "param_types": {"template_dir": "Path", "environment": "Environment", "destination_dir": "Path", "noop": "bool"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["noop_report", "recursive_render", "str.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def apply_user_changelog_template_directory(\n    template_dir: Path,\n    environment: Environment,\n    destination_dir: Path,\n    noop: bool = False,\n) -> list[str]:\n    if noop:\n        noop_report(\n            str.join(\n                \" \",\n                [\n                    \"would have recursively rendered the template directory\",\n                    f\"{template_dir!r} relative to {destination_dir!r}.\",\n                    \"Paths which would be modified by this operation cannot be\",\n                    \"determined in no-op mode.\",\n                ],\n            )\n        )\n        return []\n\n    return recursive_render(\n        template_dir, environment=environment, _root_dir=destination_dir\n    )", "loc": 23}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\changelog_writer.py", "class_name": null, "function_name": "write_default_changelog", "parameters": ["changelog_file", "destination_dir", "output_format", "changelog_context", "changelog_style", "noop"], "param_types": {"changelog_file": "Path", "destination_dir": "Path", "output_format": "ChangelogOutputFormat", "changelog_context": "ChangelogContext", "changelog_style": "str", "noop": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["changelog_file.relative_to", "changelog_file.write_text", "noop_report", "render_default_changelog_file", "str", "str.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write_default_changelog(\n    changelog_file: Path,\n    destination_dir: Path,\n    output_format: ChangelogOutputFormat,\n    changelog_context: ChangelogContext,\n    changelog_style: str,\n    noop: bool = False,\n) -> str:\n    if noop:\n        noop_report(\n            str.join(\n                \" \",\n                [\n                    \"would have written your changelog to\",\n                    str(changelog_file.relative_to(destination_dir)),\n                ],\n            )\n        )\n        return str(changelog_file)\n\n    changelog_text = render_default_changelog_file(\n        output_format=output_format,\n        changelog_context=changelog_context,\n        changelog_style=changelog_style,\n    )\n    # write_text() will automatically normalize newlines to the OS, so we just use an universal newline here\n    changelog_file.write_text(f\"{changelog_text}\\n\", encoding=\"utf-8\")\n\n    return str(changelog_file)", "loc": 29}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\changelog_writer.py", "class_name": null, "function_name": "write_changelog_files", "parameters": ["runtime_ctx", "release_history", "hvcs_client", "noop"], "param_types": {"runtime_ctx": "RuntimeContext", "release_history": "ReleaseHistory", "hvcs_client": "HvcsBase", "noop": "bool"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "apply_user_changelog_template_directory", "changelog_context.bind_to_environment", "f.is_file", "len", "logger.info", "make_changelog_context", "suppress", "template_dir.is_dir", "template_dir.rglob", "user_templates.extend", "user_templates.remove", "write_default_changelog"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write_changelog_files(\n    runtime_ctx: RuntimeContext,\n    release_history: ReleaseHistory,\n    hvcs_client: HvcsBase,\n    noop: bool = False,\n) -> list[str]:\n    project_dir = Path(runtime_ctx.repo_dir)\n    template_dir = runtime_ctx.template_dir\n\n    changelog_context = make_changelog_context(\n        hvcs_client=hvcs_client,\n        release_history=release_history,\n        mode=runtime_ctx.changelog_mode,\n        insertion_flag=runtime_ctx.changelog_insertion_flag,\n        prev_changelog_file=runtime_ctx.changelog_file,\n        mask_initial_release=runtime_ctx.changelog_mask_initial_release,\n    )\n\n    user_templates = []\n\n    # Update known templates list if Directory exists and directory has actual files to render\n    if template_dir.is_dir():\n        user_templates.extend(\n            [\n                f\n                for f in template_dir.rglob(\"*\")\n                if f.is_file() and f.suffix == JINJA2_EXTENSION\n            ]\n        )\n\n        with suppress(ValueError):\n            # do not include a release notes override when considering number of changelog templates\n            user_templates.remove(template_dir / DEFAULT_RELEASE_NOTES_TPL_FILE)\n\n    # Render user templates if found\n    if len(user_templates) > 0:\n        return apply_user_changelog_template_directory(\n            template_dir=template_dir,\n            environment=changelog_context.bind_to_environment(\n                runtime_ctx.template_environment\n            ),\n            destination_dir=project_dir,\n            noop=noop,\n        )\n\n    logger.info(\n        \"No contents found in %r, using default changelog template\", template_dir\n    )\n    return [\n        write_default_changelog(\n            changelog_file=runtime_ctx.changelog_file,\n            destination_dir=project_dir,\n            output_format=runtime_ctx.changelog_output_format,\n            changelog_context=changelog_context,\n            changelog_style=runtime_ctx.changelog_style,\n            noop=noop,\n        )\n    ]", "loc": 58}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\changelog_writer.py", "class_name": null, "function_name": "generate_release_notes", "parameters": ["hvcs_client", "release", "template_dir", "history", "style", "mask_initial_release", "license_name"], "param_types": {"hvcs_client": "HvcsBase", "release": "Release", "template_dir": "Path", "history": "ReleaseHistory", "style": "str", "mask_initial_release": "bool", "license_name": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ReleaseNotesContext", "ReleaseNotesContext(repo_name=hvcs_client.repo_name, repo_owner=hvcs_client.owner, hvcs_type=hvcs_client.__class__.__name__.lower(), version=release['version'], release=release, mask_initial_release=mask_initial_release, license_name=license_name, filters=(*hvcs_client.get_changelog_context_filters(), create_pypi_url, autofit_text_width, sort_numerically)).bind_to_environment", "environment", "get_default_tpl_dir", "hvcs_client.__class__.__name__.lower", "hvcs_client.get_changelog_context_filters", "render_release_notes", "users_tpl_file.is_file"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def generate_release_notes(\n    hvcs_client: HvcsBase,\n    release: Release,\n    template_dir: Path,\n    history: ReleaseHistory,\n    style: str,\n    mask_initial_release: bool,\n    license_name: str = \"\",\n) -> str:\n    users_tpl_file = template_dir / DEFAULT_RELEASE_NOTES_TPL_FILE\n\n    # Determine if the user has a custom release notes template or we should use\n    # the default template directory with our default release notes template\n    tpl_dir = (\n        template_dir\n        if users_tpl_file.is_file()\n        else get_default_tpl_dir(\n            style=style, sub_dir=ChangelogOutputFormat.MARKDOWN.value\n        )\n    )\n\n    release_notes_tpl_file = (\n        users_tpl_file.name\n        if users_tpl_file.is_file()\n        else DEFAULT_RELEASE_NOTES_TPL_FILE\n    )\n\n    release_notes_env = ReleaseNotesContext(\n        repo_name=hvcs_client.repo_name,\n        repo_owner=hvcs_client.owner,\n        hvcs_type=hvcs_client.__class__.__name__.lower(),\n        version=release[\"version\"],\n        release=release,\n        mask_initial_release=mask_initial_release,\n        license_name=license_name,\n        filters=(\n            *hvcs_client.get_changelog_context_filters(),\n            create_pypi_url,\n            autofit_text_width,\n            sort_numerically,\n        ),\n    ).bind_to_environment(\n        # Use a new, non-configurable environment for release notes -\n        # not user-configurable at the moment\n        environment(autoescape=False, template_dir=tpl_dir)\n    )\n\n    # TODO: Remove in v11\n    release_notes_env.globals[\"context\"] = release_notes_env.globals[\"ctx\"] = {\n        \"history\": history,\n        \"mask_initial_release\": mask_initial_release,\n    }\n\n    return render_release_notes(\n        release_notes_template_file=release_notes_tpl_file,\n        template_env=release_notes_env,\n    )", "loc": 57}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\cli_context.py", "class_name": "CliContextObj", "function_name": "runtime_ctx", "parameters": ["self"], "param_types": {}, "return_type": "RuntimeContext", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._init_runtime_ctx"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Lazy load the runtime context. This is done to avoid configuration loading when the command is not run. This is useful for commands like `--help` and `--version`", "source_code": "def runtime_ctx(self) -> RuntimeContext:\n    \"\"\"\n    Lazy load the runtime context. This is done to avoid configuration loading when\n    the command is not run. This is useful for commands like `--help` and `--version`\n    \"\"\"\n    if self._runtime_ctx is None:\n        self._runtime_ctx = self._init_runtime_ctx()\n    return self._runtime_ctx", "loc": 8}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "DefaultChangelogTemplatesConfig", "function_name": "interpret_output_format", "parameters": ["self"], "param_types": {}, "return_type": "Self", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChangelogOutputFormat", "Path", "Path(self.changelog_file).suffix.lstrip", "model_validator"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def interpret_output_format(self) -> Self:\n    # Set the output format value when no user input is given\n    if self.output_format == ChangelogOutputFormat.NONE:\n        try:\n            # Note: If the user gave no extension, force '.' so enumeration fails,\n            # and defaults to markdown\n            # Otherwise normal files with extensions will just look for the extension support\n            self.output_format = ChangelogOutputFormat(\n                Path(self.changelog_file).suffix.lstrip(\".\") or \".\"\n            )\n        except ValueError:\n            self.output_format = ChangelogOutputFormat.MARKDOWN\n\n    return self", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "ChangelogConfig", "function_name": "validate_match", "parameters": ["cls", "patterns"], "param_types": {"patterns": "Tuple[str, ...]"}, "return_type": "Tuple[str, ...]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "enumerate", "field_validator", "regexp"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate_match(cls, patterns: Tuple[str, ...]) -> Tuple[str, ...]:\n    curr_index = 0\n    try:\n        for i, pattern in enumerate(patterns):\n            curr_index = i\n            regexp(pattern)\n    except RegExpError as err:\n        raise ValueError(\n            f\"exclude_commit_patterns[{curr_index}]: Invalid regular expression\"\n        ) from err\n    return patterns", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "ChangelogConfig", "function_name": "changelog_file_deprecation_warning", "parameters": ["cls", "val"], "param_types": {"val": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["field_validator", "logger.warning", "str.join"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def changelog_file_deprecation_warning(cls, val: str) -> str:\n    logger.warning(\n        str.join(\n            \" \",\n            [\n                \"The 'changelog.changelog_file' configuration option is moving to 'changelog.default_templates.changelog_file'.\",\n                \"Please update your configuration as the compatibility will break in v10.\",\n            ],\n        )\n    )\n    return val", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "ChangelogConfig", "function_name": "move_changelog_file", "parameters": ["self"], "param_types": {}, "return_type": "Self", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DefaultChangelogTemplatesConfig.model_validate", "model_validator", "self.default_templates.model_dump"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def move_changelog_file(self) -> Self:\n    # TODO: Remove this method in v11\n    if not self.changelog_file:\n        return self\n\n    if self.changelog_file == self.default_templates.changelog_file:\n        return self\n\n    # Re-evaluate now that we are passing the changelog_file option down to default_templates\n    # and only reset the output_format if it was not already set by the user\n    self.default_templates = DefaultChangelogTemplatesConfig.model_validate(\n        {\n            **self.default_templates.model_dump(),\n            \"changelog_file\": self.changelog_file,\n            \"output_format\": (\n                self.default_templates.output_format\n                if self.default_templates.output_format\n                != ChangelogOutputFormat.MARKDOWN\n                else ChangelogOutputFormat.NONE\n            ),\n        }\n    )\n\n    return self", "loc": 24}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "ChangelogConfig", "function_name": "load_default_insertion_flag_on_missing", "parameters": ["self"], "param_types": {}, "return_type": "Self", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "model_validator"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_default_insertion_flag_on_missing(self) -> Self:\n    # Set the insertion flag value when no user input is given\n    if not self.insertion_flag:\n        defaults = {\n            ChangelogOutputFormat.MARKDOWN: \"<!-- version list -->\",\n            ChangelogOutputFormat.RESTRUCTURED_TEXT: f\"..{os.linesep}    version list\",\n        }\n        try:\n            self.insertion_flag = defaults[self.default_templates.output_format]\n        except KeyError as err:\n            raise ValueError(\n                \"changelog.default_templates.output_format cannot be None\"\n            ) from err\n\n    return self", "loc": 15}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "BranchConfig", "function_name": "validate_match", "parameters": ["cls", "match"], "param_types": {"match": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "field_validator", "regexp"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate_match(cls, match: str) -> str:\n    # Allow the special case of a plain wildcard although it's not a valid regex\n    if match == \"*\":\n        return \".*\"\n\n    try:\n        regexp(match)\n    except RegExpError as err:\n        raise ValueError(f\"Invalid regex {match!r}\") from err\n    return match", "loc": 10}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "RemoteConfig", "function_name": "resolve_env_vars", "parameters": ["cls", "val"], "param_types": {"val": "Any"}, "return_type": "str | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EnvConfigVar.model_validate", "EnvConfigVar.model_validate(val).getvalue", "field_validator", "isinstance"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def resolve_env_vars(cls, val: Any) -> str | None:\n    ret_val = (\n        val\n        if not isinstance(val, dict)\n        else (EnvConfigVar.model_validate(val).getvalue())\n    )\n    return ret_val or None", "loc": 7}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "RemoteConfig", "function_name": "set_default_token", "parameters": ["self"], "param_types": {}, "return_type": "Self", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["model_validator", "self._get_default_token"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_default_token(self) -> Self:\n    # Set the default token name for the given VCS when no user input is given\n    if self.token:\n        return self\n    if self.type not in _known_hvcs:\n        return self\n    if env_token := self._get_default_token():\n        self.token = env_token\n    return self", "loc": 9}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "RemoteConfig", "function_name": "check_url_scheme", "parameters": ["self"], "param_types": {}, "return_type": "Self", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "model_validator", "self.check_insecure_flag"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_url_scheme(self) -> Self:\n    if self.url and isinstance(self.url, str):\n        self.check_insecure_flag(self.url, \"url\")\n\n    if self.domain and isinstance(self.domain, str):\n        self.check_insecure_flag(self.domain, \"domain\")\n\n    if self.api_domain and isinstance(self.api_domain, str):\n        self.check_insecure_flag(self.api_domain, \"api_domain\")\n\n    return self", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "RemoteConfig", "function_name": "check_insecure_flag", "parameters": ["self", "url_str", "field_name"], "param_types": {"url_str": "str", "field_name": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "logger.warning", "parse_url", "str.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_insecure_flag(self, url_str: str, field_name: str) -> None:\n    if not url_str:\n        return\n\n    scheme = parse_url(url_str).scheme\n    if scheme == \"http\" and not self.insecure:\n        raise ValueError(\n            str.join(\n                \"\\n\",\n                [\n                    \"Insecure 'HTTP' URL detected and disabled by default.\",\n                    \"Set the 'insecure' flag to 'True' to enable insecure connections.\",\n                ],\n            )\n        )\n\n    if scheme == \"https\" and self.insecure:\n        logger.warning(\n            str.join(\n                \"\\n\",\n                [\n                    f\"'{field_name}' starts with 'https://' but the 'insecure' flag is set.\",\n                    \"This flag is only necessary for 'http://' URLs.\",\n                ],\n            )\n        )", "loc": 26}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "RawConfig", "function_name": "verify_git_repo_dir", "parameters": ["cls", "dir_path"], "param_types": {"dir_path": "Path"}, "return_type": "Path", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InvalidGitRepositoryError", "Path", "Path(git_repo.working_tree_dir or git_repo.working_dir).expanduser", "Path(git_repo.working_tree_dir or git_repo.working_dir).expanduser().absolute", "Repo", "dir_path.absolute", "field_validator", "found_path.resolve", "logging.warning", "str"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def verify_git_repo_dir(cls, dir_path: Path) -> Path:\n    try:\n        # Check for repository & walk up parent directories\n        with Repo(str(dir_path), search_parent_directories=True) as git_repo:\n            found_path = (\n                Path(git_repo.working_tree_dir or git_repo.working_dir)\n                .expanduser()\n                .absolute()\n            )\n\n    except InvalidGitRepositoryError as err:\n        raise InvalidGitRepositoryError(\"No valid git repository found!\") from err\n\n    if dir_path.absolute() != found_path:\n        logging.warning(\n            \"Found .git/ in higher parent directory rather than provided in configuration.\"\n        )\n\n    return found_path.resolve()", "loc": 19}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "RawConfig", "function_name": "tag_commit_parser_deprecation_warning", "parameters": ["cls", "val"], "param_types": {"val": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["field_validator", "logger.warning", "str.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def tag_commit_parser_deprecation_warning(cls, val: str) -> str:\n    if val == \"tag\":\n        logger.warning(\n            str.join(\n                \" \",\n                [\n                    \"The legacy 'tag' parser is deprecated and will be removed in v11.\",\n                    \"Recommend swapping to our emoji parser (higher-compatibility)\",\n                    \"or switch to another supported parser.\",\n                ],\n            )\n        )\n    return val", "loc": 13}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "RawConfig", "function_name": "angular_commit_parser_deprecation_warning", "parameters": ["cls", "val"], "param_types": {"val": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["field_validator", "logger.warning", "str.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def angular_commit_parser_deprecation_warning(cls, val: str) -> str:\n    if val == \"angular\":\n        logger.warning(\n            str.join(\n                \" \",\n                [\n                    \"The 'angular' parser is deprecated and will be removed in v11.\",\n                    \"The Angular parser is being renamed to the conventional commit parser,\",\n                    \"which is selected by switching the 'commit_parser' value to 'conventional'.\",\n                ],\n            )\n        )\n    return val", "loc": 13}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "RawConfig", "function_name": "set_default_opts", "parameters": ["self"], "param_types": {}, "return_type": "Self", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParserLoadError", "RootModel", "ValidationError", "callable", "dynamic_import", "hasattr", "is_dataclass", "isinstance", "model_validator", "opts_obj.model_dump", "parser_opts_type", "str", "str.join"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_default_opts(self) -> Self:\n    # Set the default parser options for the given commit parser when no user input is given\n    if not self.commit_parser_options and self.commit_parser:\n        parser_opts_type = None\n        # If the commit parser is a known one, pull the default options object from it\n        if self.commit_parser in _known_commit_parsers:\n            # TODO: BREAKING CHANGE v11\n            # parser_opts_type = (\n            #     _known_commit_parsers[self.commit_parser]\n            #     .get_default_options()\n            #     .__class__\n            # )\n            parser_opts_type = _known_commit_parsers[\n                self.commit_parser\n            ].parser_options\n        else:\n            try:\n                # if its a custom parser, try to import it and pull the default options object type\n                custom_class = dynamic_import(self.commit_parser)\n                # TODO: BREAKING CHANGE v11\n                # parser_opts_type = custom_class.get_default_options().__class__\n                if hasattr(custom_class, \"parser_options\"):\n                    parser_opts_type = custom_class.parser_options\n\n            except ModuleNotFoundError as err:\n                raise ParserLoadError(\n                    str.join(\n                        \"\\n\",\n                        [\n                            str(err),\n                            \"Unable to import your custom parser! Check your configuration!\",\n                        ],\n                    )\n                ) from err\n\n            except AttributeError as err:\n                raise ParserLoadError(\n                    str.join(\n                        \"\\n\",\n                        [\n                            str(err),\n                            \"Unable to find your custom parser class inside the given module.\",\n                            \"Check your configuration!\",\n                        ],\n                    )\n                ) from err\n\n        # from either the custom opts class or the known parser opts class, create an instance\n        if callable(parser_opts_type):\n            opts_obj: Any = parser_opts_type()\n            # if the opts object is a dataclass, wrap it in a RootModel so it can be transformed to a Mapping\n            opts_obj = (\n                opts_obj if not is_dataclass(opts_obj) else RootModel(opts_obj)\n            )\n            # Must be a mapping, so if it's a BaseModel, dump the model to a dict\n            self.commit_parser_options = (\n                opts_obj.model_dump()\n                if isinstance(opts_obj, (BaseModel, RootModel))\n                else opts_obj\n            )\n            if not isinstance(self.commit_parser_options, Mapping):\n                raise ValidationError(\n                    f\"Invalid parser options: {opts_obj}. Must be a mapping.\"\n                )\n\n    return self", "loc": 66}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "RuntimeContext", "function_name": "select_branch_options", "parameters": ["choices", "active_branch"], "param_types": {"choices": "Dict[str, BranchConfig]", "active_branch": "str"}, "return_type": "BranchConfig", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotAReleaseBranch", "choices.items", "logger.debug", "logger.info", "regexp", "regexp(options.match).match"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_branch_options(\n    choices: Dict[str, BranchConfig], active_branch: str\n) -> BranchConfig:\n    for group, options in choices.items():\n        if regexp(options.match).match(active_branch):\n            logger.info(\n                \"Using group %r options, as %r matches %r\",\n                group,\n                options.match,\n                active_branch,\n            )\n            return options\n        logger.debug(\n            \"Rejecting group %r as %r doesn't match %r\",\n            group,\n            options.match,\n            active_branch,\n        )\n\n    raise NotAReleaseBranch(\n        f\"branch {active_branch!r} isn't in any release groups; \"\n        \"no release will be made\"\n    )", "loc": 23}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\config.py", "class_name": "RuntimeContext", "function_name": "apply_log_masking", "parameters": ["self", "masker"], "param_types": {"masker": "MaskingFilter"}, "return_type": "MaskingFilter", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_recursive_getattr", "masker.add_mask_for", "repr", "str"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def apply_log_masking(self, masker: MaskingFilter) -> MaskingFilter:\n    for attr in self._mask_attrs_:\n        masker.add_mask_for(str(_recursive_getattr(self, attr)), f\"context.{attr}\")\n        masker.add_mask_for(repr(_recursive_getattr(self, attr)), f\"context.{attr}\")\n    return masker", "loc": 5}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\github_actions_output.py", "class_name": "VersionGitHubActionsOutput", "function_name": "commit_sha", "parameters": ["self", "value"], "param_types": {"value": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TypeError", "ValueError", "isinstance", "regexp", "regexp('^[0-9a-f]{40}$').match"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def commit_sha(self, value: str) -> None:\n    if not isinstance(value, str):\n        raise TypeError(\"output 'commit_sha' should be a string\")\n\n    if not regexp(r\"^[0-9a-f]{40}$\").match(value):\n        raise ValueError(\n            \"output 'commit_sha' should be a valid 40-hex-character SHA\"\n        )\n\n    self._commit_sha = value", "loc": 10}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\github_actions_output.py", "class_name": "VersionGitHubActionsOutput", "function_name": "to_output_text", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "ValueError", "missing.add", "multiline_output_values.items", "output_values.items", "self.gh_client.create_release_url", "set", "str", "str(self.is_prerelease).lower", "str(self.released).lower", "str.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def to_output_text(self) -> str:\n    missing: set[str] = set()\n    if self.version is None:\n        missing.add(\"version\")\n    if self.released is None:\n        missing.add(\"released\")\n    if self.released:\n        if self.release_notes is None:\n            missing.add(\"release_notes\")\n        if self._mode is PersistenceMode.PERMANENT and self.commit_sha is None:\n            missing.add(\"commit_sha\")\n\n    if missing:\n        raise ValueError(\n            f\"some required outputs were not set: {', '.join(missing)}\"\n        )\n\n    output_values: dict[str, Any] = {\n        \"released\": str(self.released).lower(),\n        \"version\": str(self.version),\n        \"tag\": self.tag,\n        \"is_prerelease\": str(self.is_prerelease).lower(),\n        \"link\": self.gh_client.create_release_url(self.tag) if self.tag else \"\",\n        \"previous_version\": str(self.prev_version) if self.prev_version else \"\",\n        \"commit_sha\": self.commit_sha if self.commit_sha else \"\",\n    }\n\n    multiline_output_values: dict[str, str] = {\n        \"release_notes\": self.release_notes if self.release_notes else \"\",\n    }\n\n    output_lines = [\n        *[f\"{key}={value!s}{os.linesep}\" for key, value in output_values.items()],\n        *[\n            f\"{key}<<EOF{os.linesep}{value}EOF{os.linesep}\"\n            if value\n            else f\"{key}={os.linesep}\"\n            for key, value in multiline_output_values.items()\n        ],\n    ]\n\n    return str.join(\"\", output_lines)", "loc": 42}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\masking_filter.py", "class_name": "MaskingFilter", "function_name": "add_mask_for", "parameters": ["self", "data", "name"], "param_types": {"data": "str", "name": "str"}, "return_type": "MaskingFilter", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.debug", "self._redact_patterns[name].add"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_mask_for(self, data: str, name: str = \"redacted\") -> MaskingFilter:\n    if data and data not in self._UNWANTED:\n        logger.debug(\"Adding redact pattern '%r' to redact_patterns\", name)\n        self._redact_patterns[name].add(data)\n    return self", "loc": 5}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\masking_filter.py", "class_name": "MaskingFilter", "function_name": "filter", "parameters": ["self", "record"], "param_types": {"record": "LogRecord"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "record.args.items", "self.mask", "str", "tuple", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def filter(self, record: LogRecord) -> bool:\n    # Note if we blindly mask all types, we will actually cast arguments to\n    # log functions from external libraries to strings before they are\n    # formatted into the message - for example, a dependency calling\n    # log.debug(\"%d\", 15) will raise a TypeError as this filter would\n    # otherwise convert 15 to \"15\", and \"%d\" % \"15\" raises the error.\n    # One may find a specific example of where this issue could manifest itself\n    # here: https://github.com/urllib3/urllib3/blob/a5b29ac1025f9bb30f2c9b756f3b171389c2c039/src/urllib3/connectionpool.py#L1003\n    # Anything which could reasonably be expected to be logged without being\n    # cast to a string should be excluded from the cast here.\n    record.msg = self.mask(record.msg)\n    if record.args is None:\n        pass\n    elif isinstance(record.args, dict):\n        record.args = {\n            k: v if type(v) in (bool, int, float) else self.mask(str(v))\n            for k, v in record.args.items()\n        }\n    else:\n        record.args = tuple(\n            arg if type(arg) in (bool, int, float) else self.mask(str(arg))\n            for arg in record.args\n        )\n    return True", "loc": 24}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\masking_filter.py", "class_name": "MaskingFilter", "function_name": "mask", "parameters": ["self", "msg"], "param_types": {"msg": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.sub", "isinstance", "logger.debug", "msg.replace", "self._redact_patterns.items", "type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def mask(self, msg: str) -> str:\n    if not isinstance(msg, str):\n        logger.debug(  # type: ignore[unreachable]\n            \"cannot mask object of type %s\", type(msg)\n        )\n        return msg\n    for mask, values in self._redact_patterns.items():\n        repl_string = (\n            self.REPLACE_STR\n            if not self._use_named_masks\n            else f\"<{mask!r} (value removed)>\"\n        )\n        for data in values:\n            if isinstance(data, str):\n                msg = msg.replace(data, repl_string)\n            elif isinstance(data, re.Pattern):\n                msg = data.sub(repl_string, msg)\n    return msg", "loc": 18}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\util.py", "class_name": null, "function_name": "noop_report", "parameters": ["msg"], "param_types": {"msg": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["rich.markup.escape", "rprint"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Rich-prints a msg with a standard prefix to report when an action is not being taken due to a \"noop\" flag", "source_code": "def noop_report(msg: str) -> None:\n    \"\"\"\n    Rich-prints a msg with a standard prefix to report when an action is not being\n    taken due to a \"noop\" flag\n    \"\"\"\n    rprint(f\"[bold cyan][:shield: NOP] {rich.markup.escape(msg)}\")", "loc": 6}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\util.py", "class_name": null, "function_name": "indented", "parameters": ["msg", "prefix"], "param_types": {"msg": "str", "prefix": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dedent", "indent"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Convenience function for text-formatting for the console. Ensures the least indented line of the msg string is indented by ``prefix`` with consistent alignment of the remainder of ``msg`` irrespective of the level of", "source_code": "def indented(msg: str, prefix: str = \" \" * 4) -> str:\n    \"\"\"\n    Convenience function for text-formatting for the console.\n\n    Ensures the least indented line of the msg string is indented by ``prefix`` with\n    consistent alignment of the remainder of ``msg`` irrespective of the level of\n    indentation in the Python source code\n    \"\"\"\n    return indent(dedent(msg), prefix=prefix)", "loc": 9}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\util.py", "class_name": null, "function_name": "parse_toml", "parameters": ["raw_text"], "param_types": {"raw_text": "str"}, "return_type": "dict[Any, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InvalidConfiguration", "str", "toml_text.get", "toml_text.get('tool', {}).get", "tomlkit.loads", "tomlkit.loads(raw_text).unwrap"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Attempts to parse raw configuration for semantic_release using tomlkit.loads, raising InvalidConfiguration if the TOML is invalid or there's no top level \"semantic_release\"", "source_code": "def parse_toml(raw_text: str) -> dict[Any, Any]:\n    \"\"\"\n    Attempts to parse raw configuration for semantic_release\n    using tomlkit.loads, raising InvalidConfiguration if the\n    TOML is invalid or there's no top level \"semantic_release\"\n    or \"tool.semantic_release\" keys\n    \"\"\"\n    try:\n        toml_text = tomlkit.loads(raw_text).unwrap()\n    except TOMLKitError as exc:\n        raise InvalidConfiguration(str(exc)) from exc\n\n    # Look for [tool.semantic_release]\n    cfg_text = toml_text.get(\"tool\", {}).get(\"semantic_release\")\n    if cfg_text is not None:\n        return cfg_text\n    # Look for [semantic_release] or return {} if not found\n    return toml_text.get(\"semantic_release\", {})", "loc": 18}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\util.py", "class_name": null, "function_name": "load_raw_config_file", "parameters": ["config_file"], "param_types": {"config_file": "Path | str"}, "return_type": "dict[Any, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["(Path() / config_file).resolve().read_text", "InvalidConfiguration", "Path", "Path() / config_file.resolve", "dedent", "json.loads", "logger.debug", "logger.info", "parse_toml", "str"], "control_structures": ["Try"], "behavior_type": ["serialization"], "doc_summary": "Load raw configuration as a dict from the filename specified by config_filename, trying the following parsing methods: 1. try to parse with tomli.load (guessing it's a TOML file)", "source_code": "def load_raw_config_file(config_file: Path | str) -> dict[Any, Any]:\n    \"\"\"\n    Load raw configuration as a dict from the filename specified\n    by config_filename, trying the following parsing methods:\n\n    1. try to parse with tomli.load (guessing it's a TOML file)\n    2. try to parse with json.load (guessing it's a JSON file)\n    3. raise InvalidConfiguration if none of the above parsing\n       methods work\n\n    This function will also raise FileNotFoundError if it is raised\n    while trying to read the specified configuration file\n    \"\"\"\n    logger.info(\"Loading configuration from %s\", config_file)\n    raw_text = (Path() / config_file).resolve().read_text(encoding=\"utf-8\")\n    try:\n        logger.debug(\"Trying to parse configuration %s in TOML format\", config_file)\n        return parse_toml(raw_text)\n    except InvalidConfiguration as e:\n        logger.debug(\"Configuration %s is invalid TOML: %s\", config_file, str(e))\n        logger.debug(\"trying to parse %s as JSON\", config_file)\n        try:\n            # could be a \"parse_json\" function but it's a one-liner here\n            return json.loads(raw_text)[\"semantic_release\"]\n        except KeyError:\n            # valid configuration, but no \"semantic_release\" or \"tool.semantic_release\"\n            # top level key\n            logger.debug(\n                \"configuration has no 'semantic_release' or 'tool.semantic_release' \"\n                \"top-level key\"\n            )\n            return {}\n        except json.JSONDecodeError as jde:\n            raise InvalidConfiguration(\n                dedent(\n                    f\"\"\"\n                    None of the supported configuration parsers were able to parse\n                    the configuration file {config_file}:\n                    * TOML: {e!s}\n                    * JSON: {jde!s}\n                    \"\"\"\n                )\n            ) from jde", "loc": 43}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\changelog.py", "class_name": null, "function_name": "get_license_name_for_release", "parameters": ["tag_name", "project_root"], "param_types": {"tag_name": "str", "project_root": "Path"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path.cwd", "Path.cwd().resolve", "Repo", "allowed_dir.joinpath", "config_toml.unwrap", "config_toml.unwrap().get", "git_repo.git.show", "isinstance", "license_cfg.get", "proj_toml.relative_to", "project_metadata.get", "str", "suppress", "tomlkit.parse"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_license_name_for_release(tag_name: str, project_root: Path) -> str:\n    # Retrieve the license name at the time of the specific release tag\n    project_metadata: dict[str, str] = {}\n    curr_dir = Path.cwd().resolve()\n    allowed_directories = [\n        dir_path\n        for dir_path in [curr_dir, *curr_dir.parents]\n        if str(project_root) in str(dir_path)\n    ]\n    for allowed_dir in allowed_directories:\n        proj_toml = allowed_dir.joinpath(\"pyproject.toml\")\n        with Repo(project_root) as git_repo, suppress(GitCommandError):\n            toml_contents = git_repo.git.show(\n                f\"{tag_name}:{proj_toml.relative_to(project_root)}\"\n            )\n            config_toml = tomlkit.parse(toml_contents)\n            project_metadata = config_toml.unwrap().get(\"project\", project_metadata)\n            break\n\n    license_cfg = project_metadata.get(\n        \"license-expression\",\n        project_metadata.get(\n            \"license\",\n            \"\",\n        ),\n    )\n\n    if not isinstance(license_cfg, (str, dict)) or license_cfg is None:\n        return \"\"\n\n    return (\n        license_cfg.get(\"text\", \"\")  # type: ignore[attr-defined]\n        if isinstance(license_cfg, dict)\n        else license_cfg or \"\"\n    )", "loc": 35}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\changelog.py", "class_name": null, "function_name": "post_release_notes", "parameters": ["release_tag", "release_notes", "prerelease", "hvcs_client", "noop"], "param_types": {"release_tag": "str", "release_notes": "str", "prerelease": "bool", "hvcs_client": "RemoteHvcsBase", "noop": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hvcs_client.create_or_update_release", "noop_report", "release_notes.replace", "str.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def post_release_notes(\n    release_tag: str,\n    release_notes: str,\n    prerelease: bool,\n    hvcs_client: RemoteHvcsBase,\n    noop: bool = False,\n) -> None:\n    if noop:\n        noop_report(\n            str.join(\n                \"\\n\",\n                [\n                    f\"would have posted the following release notes for tag {release_tag}:\",\n                    # Escape square brackets to ensure all content is displayed in the console\n                    # (i.e. prevent interpretation of ansi escape sequences that is valid markdown)\n                    release_notes.replace(\"[\", \"\\\\[\"),\n                ],\n            )\n        )\n        return\n\n    hvcs_client.create_or_update_release(\n        release_tag,\n        release_notes,\n        prerelease=prerelease,\n    )", "loc": 26}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\changelog.py", "class_name": null, "function_name": "changelog", "parameters": ["cli_ctx", "release_tag"], "param_types": {"cli_ctx": "CliContextObj", "release_tag": "str | None"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ReleaseHistory.from_git_history", "Repo", "click.command", "click.echo", "click.get_current_context", "click.option", "ctx.exit", "generate_release_notes", "get_license_name_for_release", "isinstance", "logger.exception", "post_release_notes", "repr", "str", "str.join", "translator.from_tag", "write_changelog_files"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Generate and optionally publish a changelog for your project", "source_code": "def changelog(cli_ctx: CliContextObj, release_tag: str | None) -> None:\n    \"\"\"Generate and optionally publish a changelog for your project\"\"\"\n    ctx = click.get_current_context()\n    runtime = cli_ctx.runtime_ctx\n    translator = runtime.version_translator\n    hvcs_client = runtime.hvcs_client\n\n    with Repo(str(runtime.repo_dir)) as git_repo:\n        release_history = ReleaseHistory.from_git_history(\n            repo=git_repo,\n            translator=translator,\n            commit_parser=runtime.commit_parser,\n            exclude_commit_patterns=runtime.changelog_excluded_commit_patterns,\n        )\n\n    write_changelog_files(\n        runtime_ctx=runtime,\n        release_history=release_history,\n        hvcs_client=hvcs_client,\n        noop=runtime.global_cli_options.noop,\n    )\n\n    if not release_tag:\n        return\n\n    if not isinstance(hvcs_client, RemoteHvcsBase):\n        click.echo(\n            \"Remote does not support releases. Skipping release notes update...\",\n            err=True,\n        )\n        return\n\n    if not (version := translator.from_tag(release_tag)):\n        click.echo(\n            str.join(\n                \" \",\n                [\n                    f\"Tag {release_tag!r} does not match the tag format\",\n                    repr(translator.tag_format),\n                ],\n            ),\n            err=True,\n        )\n        ctx.exit(1)\n\n    try:\n        release = release_history.released[version]\n    except KeyError:\n        click.echo(f\"tag {release_tag} not in release history\", err=True)\n        ctx.exit(2)\n\n    release_notes = generate_release_notes(\n        hvcs_client,\n        release,\n        runtime.template_dir,\n        release_history,\n        style=runtime.changelog_style,\n        mask_initial_release=runtime.changelog_mask_initial_release,\n        license_name=get_license_name_for_release(\n            tag_name=release_tag,\n            project_root=runtime.repo_dir,\n        ),\n    )\n\n    try:\n        post_release_notes(\n            release_tag=release_tag,\n            release_notes=release_notes,\n            prerelease=version.is_prerelease,\n            hvcs_client=hvcs_client,\n            noop=runtime.global_cli_options.noop,\n        )\n    except Exception as e:  # noqa: BLE001 # TODO: catch specific exceptions\n        logger.exception(e)\n        click.echo(\"Failed to post release notes to remote\", err=True)\n        ctx.exit(1)", "loc": 76}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\generate_config.py", "class_name": null, "function_name": "generate_config", "parameters": ["fmt", "is_pyproject_toml"], "param_types": {"fmt": "str", "is_pyproject_toml": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RawConfig", "RawConfig().model_dump", "click.Choice", "click.command", "click.echo", "click.option", "json.dumps", "tomlkit.dumps"], "control_structures": ["If"], "behavior_type": ["serialization"], "doc_summary": "Generate default configuration for semantic-release, to help you get started quickly. You can inspect the defaults, write to a file and then edit according to your needs. For example, to append the default configuration to your pyproject.toml", "source_code": "def generate_config(fmt: str = \"toml\", is_pyproject_toml: bool = False) -> None:\n    \"\"\"\n    Generate default configuration for semantic-release, to help you get started\n    quickly. You can inspect the defaults, write to a file and then edit according to\n    your needs. For example, to append the default configuration to your pyproject.toml\n    file, you can use the following command:\n\n        semantic-release generate-config --pyproject >> pyproject.toml\n    \"\"\"\n    # due to possible IntEnum values (which are not supported by tomlkit.dumps, see sdispater/tomlkit#237),\n    # we must ensure the transformation of the model to a dict uses json serializable values\n    config = RawConfig().model_dump(mode=\"json\", exclude_none=True)\n\n    config_dct = {\"semantic_release\": config}\n    if is_pyproject_toml and fmt == \"toml\":\n        config_dct = {\"tool\": config_dct}\n\n    if fmt == \"toml\":\n        click.echo(tomlkit.dumps(config_dct))\n\n    elif fmt == \"json\":\n        click.echo(json.dumps(config_dct, indent=4))", "loc": 22}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\main.py", "class_name": null, "function_name": "main", "parameters": ["ctx", "config_file", "verbosity", "noop", "strict"], "param_types": {"ctx": "click.Context", "config_file": "str", "verbosity": "int", "noop": "bool", "strict": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CliContextObj", "Console", "GlobalCommandLineOptions", "RichHandler", "click.IntRange", "click.Path", "click.command", "click.option", "click.version_option", "len", "logger.addHandler", "logger.debug", "logger.filters.clear", "logger.handlers.clear", "logger.setLevel", "logging.Formatter", "logging.getLevelName", "rich_handler.setFormatter", "rprint"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Python Semantic Release Automated Semantic Versioning based on version 2.0.0 of the Semantic Versioning specification, which can be found at https://semver.org/spec/v2.0.0.html.", "source_code": "def main(\n    ctx: click.Context,\n    config_file: str = DEFAULT_CONFIG_FILE,\n    verbosity: int = 0,\n    noop: bool = False,\n    strict: bool = False,\n) -> None:\n    \"\"\"\n    Python Semantic Release\n\n    Automated Semantic Versioning based on version 2.0.0 of the Semantic Versioning\n    specification, which can be found at https://semver.org/spec/v2.0.0.html.\n\n    Detect the next semantically correct version for a project based on the Git\n    history, create and publish a changelog to a remote VCS, build a project.\n\n    For more information, visit https://python-semantic-release.readthedocs.io/\n    \"\"\"\n    globals.log_level = LOG_LEVELS[verbosity]\n\n    # Set up our pretty console formatter\n    rich_handler = RichHandler(\n        console=Console(stderr=True), rich_tracebacks=True, tracebacks_suppress=[click]\n    )\n    rich_handler.setFormatter(logging.Formatter(FORMAT, datefmt=\"[%X]\"))\n\n    # Set up logging with our pretty console formatter\n    logger = globals.logger\n    logger.handlers.clear()\n    logger.filters.clear()\n    logger.addHandler(rich_handler)\n    logger.setLevel(globals.log_level)\n    logger.debug(\"logging level set to: %s\", logging.getLevelName(globals.log_level))\n\n    if noop:\n        rprint(\n            \":shield: [bold cyan]You are running in no-operation mode, because the \"\n            \"'--noop' flag was supplied\"\n        )\n\n    cli_options = GlobalCommandLineOptions(\n        noop=noop, verbosity=verbosity, config_file=config_file, strict=strict\n    )\n\n    logger.debug(\"global cli options: %s\", cli_options)\n\n    ctx.obj = CliContextObj(ctx, logger, cli_options)", "loc": 47}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\main.py", "class_name": "Cli", "function_name": "get_command", "parameters": ["self", "_ctx", "name"], "param_types": {"_ctx": "click.Context", "name": "str"}, "return_type": "click.Command | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "importlib.import_module", "name.lower", "name.lower().replace", "subcmd_name.upper"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_command(self, _ctx: click.Context, name: str) -> click.Command | None:\n    subcmd_name = name.lower().replace(\"-\", \"_\")\n    try:\n        subcmd_def: Cli.SubCmds = Cli.SubCmds.__dict__[subcmd_name.upper()]\n        module_path = subcmd_def.value\n        subcmd_module = importlib.import_module(module_path)\n        return getattr(subcmd_module, subcmd_name)\n    except (KeyError, ModuleNotFoundError, AttributeError):\n        return None", "loc": 9}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\publish.py", "class_name": null, "function_name": "publish_distributions", "parameters": ["tag", "hvcs_client", "dist_glob_patterns", "noop"], "param_types": {"tag": "str", "hvcs_client": "RemoteHvcsBase", "dist_glob_patterns": "tuple[str, ...]", "noop": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hvcs_client.upload_dists", "logger.info", "noop_report", "repr", "str.join"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def publish_distributions(\n    tag: str,\n    hvcs_client: RemoteHvcsBase,\n    dist_glob_patterns: tuple[str, ...],\n    noop: bool = False,\n) -> None:\n    if noop:\n        noop_report(\n            str.join(\n                \" \",\n                [\n                    \"would have uploaded files matching any of the globs\",\n                    str.join(\", \", [repr(g) for g in dist_glob_patterns]),\n                    \"to a remote VCS release, if supported\",\n                ],\n            )\n        )\n        return\n\n    logger.info(\"Uploading distributions to release\")\n    for pattern in dist_glob_patterns:\n        hvcs_client.upload_dists(tag=tag, dist_glob=pattern)  # type: ignore[attr-defined]", "loc": 22}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\publish.py", "class_name": null, "function_name": "publish", "parameters": ["cli_ctx", "tag"], "param_types": {"cli_ctx": "CliContextObj", "tag": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Repo", "click.command", "click.echo", "click.get_current_context", "click.option", "ctx.exit", "isinstance", "publish_distributions", "repr", "str", "str.join", "tags_and_versions"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Build and publish a distribution to a VCS release.", "source_code": "def publish(cli_ctx: CliContextObj, tag: str) -> None:\n    \"\"\"Build and publish a distribution to a VCS release.\"\"\"\n    ctx = click.get_current_context()\n    runtime = cli_ctx.runtime_ctx\n    hvcs_client = runtime.hvcs_client\n    translator = runtime.version_translator\n    dist_glob_patterns = runtime.dist_glob_patterns\n\n    with Repo(str(runtime.repo_dir)) as git_repo:\n        repo_tags = git_repo.tags\n\n    if tag == \"latest\":\n        try:\n            tag = str(tags_and_versions(repo_tags, translator)[0][0])\n        except IndexError:\n            click.echo(\n                str.join(\n                    \" \",\n                    [\n                        \"No tags found with format\",\n                        repr(translator.tag_format),\n                        \"couldn't identify latest version\",\n                    ],\n                ),\n                err=True,\n            )\n            ctx.exit(1)\n\n    if tag not in {tag.name for tag in repo_tags}:\n        click.echo(f\"Tag '{tag}' not found in local repository!\", err=True)\n        ctx.exit(1)\n\n    if not isinstance(hvcs_client, RemoteHvcsBase):\n        click.echo(\n            \"Remote does not support artifact upload. Exiting with no action taken...\",\n            err=True,\n        )\n        return\n\n    publish_distributions(\n        tag=tag,\n        hvcs_client=hvcs_client,\n        dist_glob_patterns=dist_glob_patterns,\n        noop=runtime.global_cli_options.noop,\n    )", "loc": 45}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\version.py", "class_name": null, "function_name": "is_forced_prerelease", "parameters": ["as_prerelease", "forced_level_bump", "prerelease"], "param_types": {"as_prerelease": "bool", "forced_level_bump": "LevelBump | None", "prerelease": "bool"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["iter", "list", "locals", "locals().items", "logger.debug", "str.join"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Determine if this release is forced to have prerelease on/off. If ``force_prerelease`` is set then yes. Otherwise if we are forcing a specific level bump without force_prerelease,", "source_code": "def is_forced_prerelease(\n    as_prerelease: bool, forced_level_bump: LevelBump | None, prerelease: bool\n) -> bool:\n    \"\"\"\n    Determine if this release is forced to have prerelease on/off.\n    If ``force_prerelease`` is set then yes.\n    Otherwise if we are forcing a specific level bump without force_prerelease,\n    it's False.\n    Otherwise (``force_level is None``) use the value of ``prerelease``\n    \"\"\"\n    local_vars = list(locals().items())\n    logger.debug(\n        \"%s: %s\",\n        is_forced_prerelease.__name__,\n        str.join(\", \", iter(f\"{k} = {v}\" for k, v in local_vars)),\n    )\n    return (\n        as_prerelease\n        or forced_level_bump is LevelBump.PRERELEASE_REVISION\n        or ((forced_level_bump is None) and prerelease)\n    )", "loc": 21}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\version.py", "class_name": null, "function_name": "last_released", "parameters": ["repo_dir", "tag_format"], "param_types": {"repo_dir": "Path", "tag_format": "str"}, "return_type": "tuple[Tag, Version] | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Repo", "VersionTranslator", "str", "tags_and_versions"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def last_released(repo_dir: Path, tag_format: str) -> tuple[Tag, Version] | None:\n    with Repo(str(repo_dir)) as git_repo:\n        ts_and_vs = tags_and_versions(\n            git_repo.tags, VersionTranslator(tag_format=tag_format)\n        )\n\n    return ts_and_vs[0] if ts_and_vs else None", "loc": 7}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\version.py", "class_name": null, "function_name": "version_from_forced_level", "parameters": ["repo_dir", "forced_level_bump", "translator"], "param_types": {"repo_dir": "Path", "forced_level_bump": "LevelBump", "translator": "VersionTranslator"}, "return_type": "Version", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InternalError", "Repo", "default_initial_version.bump", "latest_version.bump", "latest_version.to_prerelease", "str", "tags_and_versions", "translator.from_tag", "translator.str_to_tag", "version.bump"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def version_from_forced_level(\n    repo_dir: Path, forced_level_bump: LevelBump, translator: VersionTranslator\n) -> Version:\n    with Repo(str(repo_dir)) as git_repo:\n        ts_and_vs = tags_and_versions(git_repo.tags, translator)\n\n    # If we have no tags, return the default version\n    if not ts_and_vs:\n        # Since the translator is configured by the user, we can't guarantee that it will\n        # be able to parse the default version. So we first cast it to a tag using the default\n        # value and the users configured tag format, then parse it back to a version object\n        default_initial_version = translator.from_tag(\n            translator.str_to_tag(DEFAULT_VERSION)\n        )\n        if default_initial_version is None:\n            # This should never happen, but if it does, it's a bug\n            raise InternalError(\n                \"Translator was unable to parse the embedded default version\"\n            )\n        return default_initial_version.bump(forced_level_bump)\n\n    _, latest_version = ts_and_vs[0]\n    if forced_level_bump is not LevelBump.PRERELEASE_REVISION:\n        return latest_version.bump(forced_level_bump)\n\n    # We need to find the latest version with the prerelease token\n    # we're looking for, and return that version + an increment to\n    # the prerelease revision.\n\n    # NOTE this can probably be cleaned up.\n    # ts_and_vs are in order, so check if we're looking at prereleases\n    # for the same (major, minor, patch) as the latest version.\n    # If we are, we can increment the revision and we're done. If\n    # we don't find a prerelease targeting this version with the same\n    # token as the one we're looking to prerelease, we can use revision 1.\n    for _, version in ts_and_vs:\n        if not (\n            version.major == latest_version.major\n            and version.minor == latest_version.minor\n            and version.patch == latest_version.patch\n        ):\n            break\n        if (\n            version.is_prerelease\n            and version.prerelease_token == translator.prerelease_token\n        ):\n            return version.bump(LevelBump.PRERELEASE_REVISION)\n    return latest_version.to_prerelease(token=translator.prerelease_token, revision=1)", "loc": 48}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\version.py", "class_name": null, "function_name": "apply_version_to_source_files", "parameters": ["repo_dir", "version_declarations", "version", "noop"], "param_types": {"repo_dir": "Path", "version_declarations": "Sequence[IVersionReplacer]", "version": "Version", "noop": "bool"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["decl.update_file_w_version", "len", "logger.debug", "noop_report", "str", "str.join", "updated_file.relative_to"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def apply_version_to_source_files(\n    repo_dir: Path,\n    version_declarations: Sequence[IVersionReplacer],\n    version: Version,\n    noop: bool = False,\n) -> list[str]:\n    if len(version_declarations) < 1:\n        return []\n\n    if not noop:\n        logger.debug(\"Updating version %s in repository files...\", version)\n\n    paths = [\n        decl.update_file_w_version(new_version=version, noop=noop)\n        for decl in version_declarations\n    ]\n\n    repo_filepaths = [\n        str(updated_file.relative_to(repo_dir))\n        for updated_file in paths\n        if updated_file is not None\n    ]\n\n    if noop:\n        noop_report(\n            str.join(\n                \"\",\n                [\n                    \"would have updated versions in the following paths:\",\n                    *[f\"\\n    {filepath}\" for filepath in repo_filepaths],\n                ],\n            )\n        )\n\n    return repo_filepaths", "loc": 35}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\version.py", "class_name": null, "function_name": "shell", "parameters": ["cmd"], "param_types": {"cmd": "str"}, "return_type": "subprocess.CompletedProcess", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TypeError", "defaultdict", "logger.debug", "logger.warning", "shellingham.detect_shell", "subprocess.run"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def shell(\n    cmd: str, *, env: Mapping[str, str] | None = None, check: bool = True\n) -> subprocess.CompletedProcess:\n    shell: str | None\n    try:\n        shell, _ = shellingham.detect_shell()\n    except shellingham.ShellDetectionFailure:\n        logger.warning(\"failed to detect shell, using default shell: %s\", DEFAULT_SHELL)\n        logger.debug(\"stack trace\", exc_info=True)\n        shell = DEFAULT_SHELL\n\n    if not shell:\n        raise TypeError(\"'shell' is None\")\n\n    shell_cmd_param = defaultdict(\n        lambda: \"-c\",\n        {\n            \"cmd\": \"/c\",\n            \"powershell\": \"-Command\",\n            \"pwsh\": \"-Command\",\n        },\n    )\n\n    return subprocess.run(  # noqa: S603\n        [shell, shell_cmd_param[shell], cmd],\n        env=(env or {}),\n        check=check,\n    )", "loc": 28}
{"file": "python-semantic-release\\src\\semantic_release\\cli\\commands\\version.py", "class_name": null, "function_name": "build_distributions", "parameters": ["build_command", "build_command_env", "noop"], "param_types": {"build_command": "str | None", "build_command_env": "Mapping[str, str] | None", "noop": "bool"}, "return_type": "None", "param_doc": {"build_command": "The build command to run.", "build_command_env": "The environment variables to use when running the", "noop": "Whether or not to run the build command."}, "return_doc": "", "raises_doc": [], "called_functions": ["dict", "filter", "get_windows_env", "is_windows", "logger.error", "logger.exception", "logger.info", "noop_report", "os.getenv", "rprint", "shell", "str", "str(True).lower", "{'PATH': os.getenv('PATH', ''), 'HOME': os.getenv('HOME', None), 'VIRTUAL_ENV': os.getenv('VIRTUAL_ENV', None), **(get_windows_env() if is_windows() else {}), 'CI': os.getenv('CI', None), 'GITHUB_ACTIONS': os.getenv('GITHUB_ACTIONS', None), 'GITLAB_CI': os.getenv('GITLAB_CI', None), 'GITEA_ACTIONS': os.getenv('GITEA_ACTIONS', None), 'BITBUCKET_CI': str(True).lower() if os.getenv('BITBUCKET_REPO_FULL_NAME', None) else None, 'PSR_DOCKER_GITHUB_ACTION': os.getenv('PSR_DOCKER_GITHUB_ACTION', None), **(build_command_env or {})}.items"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Run the build command to build the distributions.", "source_code": "def build_distributions(\n    build_command: str | None,\n    build_command_env: Mapping[str, str] | None = None,\n    noop: bool = False,\n) -> None:\n    \"\"\"\n    Run the build command to build the distributions.\n\n    :param build_command: The build command to run.\n    :param build_command_env: The environment variables to use when running the\n        build command.\n    :param noop: Whether or not to run the build command.\n\n    :raises: BuildDistributionsError: if the build command fails\n    \"\"\"\n    if not build_command:\n        rprint(\"[green]No build command specified, skipping\")\n        return\n\n    if noop:\n        noop_report(f\"would have run the build_command {build_command}\")\n        return\n\n    logger.info(\"Running build command %s\", build_command)\n    rprint(f\"[bold green]:hammer_and_wrench: Running build command: {build_command}\")\n\n    build_env_vars: dict[str, str] = dict(\n        filter(\n            lambda k_v: k_v[1] is not None,  # type: ignore[arg-type]\n            {\n                # Common values\n                \"PATH\": os.getenv(\"PATH\", \"\"),\n                \"HOME\": os.getenv(\"HOME\", None),\n                \"VIRTUAL_ENV\": os.getenv(\"VIRTUAL_ENV\", None),\n                # Windows environment variables\n                **(get_windows_env() if is_windows() else {}),\n                # affects build decisions\n                \"CI\": os.getenv(\"CI\", None),\n                # Identifies which CI environment\n                \"GITHUB_ACTIONS\": os.getenv(\"GITHUB_ACTIONS\", None),\n                \"GITLAB_CI\": os.getenv(\"GITLAB_CI\", None),\n                \"GITEA_ACTIONS\": os.getenv(\"GITEA_ACTIONS\", None),\n                \"BITBUCKET_CI\": (\n                    str(True).lower()\n                    if os.getenv(\"BITBUCKET_REPO_FULL_NAME\", None)\n                    else None\n                ),\n                \"PSR_DOCKER_GITHUB_ACTION\": os.getenv(\"PSR_DOCKER_GITHUB_ACTION\", None),\n                **(build_command_env or {}),\n            }.items(),\n        )\n    )\n\n    try:\n        shell(build_command, env=build_env_vars, check=True)\n        rprint(\"[bold green]Build completed successfully!\")\n    except subprocess.CalledProcessError as exc:\n        logger.exception(exc)\n        logger.error(\"Build command failed with exit code %s\", exc.returncode)  # noqa: TRY400\n        raise BuildDistributionsError from exc", "loc": 60}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\angular.py", "class_name": "AngularCommitParser", "function_name": "commit_body_components_separator", "parameters": ["self", "accumulator", "text"], "param_types": {"accumulator": "dict[str, list[str]]", "text": "str"}, "return_type": "dict[str, list[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["accumulator['breaking_descriptions'].append", "accumulator['descriptions'].append", "accumulator['notices'].append", "breaking_re.match", "filter", "match.group", "predicate.split", "regexp", "regexp(',? and | *[,;/& ] *').sub", "self.issue_selector.search", "self.notice_selector.match", "set", "set(accumulator['linked_issues']).union", "sort_numerically", "validator.search"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def commit_body_components_separator(\n    self, accumulator: dict[str, list[str]], text: str\n) -> dict[str, list[str]]:\n    if (match := breaking_re.match(text)) and (brk_desc := match.group(1)):\n        accumulator[\"breaking_descriptions\"].append(brk_desc)\n\n    elif (match := self.notice_selector.match(text)) and (\n        notice := match.group(\"notice\")\n    ):\n        accumulator[\"notices\"].append(notice)\n\n    elif match := self.issue_selector.search(text):\n        # if match := self.issue_selector.search(text):\n        predicate = regexp(r\",? and | *[,;/& ] *\").sub(\n            \",\", match.group(\"issue_predicate\") or \"\"\n        )\n        # Almost all issue trackers use a number to reference an issue so\n        # we use a simple regexp to validate the existence of a number which helps filter out\n        # any non-issue references that don't fit our expected format\n        has_number = regexp(r\"\\d+\")\n        new_issue_refs: set[str] = set(\n            filter(\n                lambda issue_str, validator=has_number: validator.search(issue_str),  # type: ignore[arg-type]\n                predicate.split(\",\"),\n            )\n        )\n        if new_issue_refs:\n            accumulator[\"linked_issues\"] = sort_numerically(\n                set(accumulator[\"linked_issues\"]).union(new_issue_refs)\n            )\n\n    # Prevent appending duplicate descriptions\n    if text not in accumulator[\"descriptions\"]:\n        accumulator[\"descriptions\"].append(text)\n\n    return accumulator", "loc": 36}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\angular.py", "class_name": "AngularCommitParser", "function_name": "parse_message", "parameters": ["self", "message"], "param_types": {"message": "str"}, "return_type": "ParsedMessageResult | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["LONG_TYPE_NAMES.get", "ParsedMessageResult", "mr_match.group", "parse_paragraphs", "parsed.group", "reduce", "self.mr_selector.search", "self.options.tag_to_level.get", "self.re_parser.match", "tuple"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_message(self, message: str) -> ParsedMessageResult | None:\n    if not (parsed := self.re_parser.match(message)):\n        return None\n\n    parsed_break = parsed.group(\"break\")\n    parsed_scope = parsed.group(\"scope\") or \"\"\n    parsed_subject = parsed.group(\"subject\")\n    parsed_text = parsed.group(\"text\")\n    parsed_type = parsed.group(\"type\")\n\n    linked_merge_request = \"\"\n    if mr_match := self.mr_selector.search(parsed_subject):\n        linked_merge_request = mr_match.group(\"mr_number\")\n\n    body_components: dict[str, list[str]] = reduce(\n        self.commit_body_components_separator,\n        [\n            # Insert the subject before the other paragraphs\n            parsed_subject,\n            *parse_paragraphs(parsed_text or \"\"),\n        ],\n        {\n            \"breaking_descriptions\": [],\n            \"descriptions\": [],\n            \"notices\": [],\n            \"linked_issues\": [],\n        },\n    )\n\n    level_bump = (\n        LevelBump.MAJOR\n        # TODO: remove parsed break support as it is not part of the angular commit spec (its part of conventional commits spec)\n        if body_components[\"breaking_descriptions\"] or parsed_break\n        else self.options.tag_to_level.get(\n            parsed_type, self.options.default_bump_level\n        )\n    )\n\n    return ParsedMessageResult(\n        bump=level_bump,\n        type=parsed_type,\n        category=LONG_TYPE_NAMES.get(parsed_type, parsed_type),\n        scope=parsed_scope,\n        descriptions=tuple(body_components[\"descriptions\"]),\n        breaking_descriptions=tuple(body_components[\"breaking_descriptions\"]),\n        release_notices=tuple(body_components[\"notices\"]),\n        linked_issues=tuple(body_components[\"linked_issues\"]),\n        linked_merge_request=linked_merge_request,\n    )", "loc": 49}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\angular.py", "class_name": "AngularCommitParser", "function_name": "parse_commit", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "ParseResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit.from_parsed_message_result", "_logged_parse_error", "force_str", "self.parse_message"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_commit(self, commit: Commit) -> ParseResult:\n    if not (parsed_msg_result := self.parse_message(force_str(commit.message))):\n        return _logged_parse_error(\n            commit,\n            f\"Unable to parse commit message: {commit.message!r}\",\n        )\n\n    return ParsedCommit.from_parsed_message_result(commit, parsed_msg_result)", "loc": 8}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\angular.py", "class_name": "AngularCommitParser", "function_name": "parse", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "ParseResult | list[ParseResult]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "_logged_parse_error", "add_linked_merge_request", "force_str", "isinstance", "iter", "list", "map", "mr_match.group", "next", "parsed_result._asdict", "self.is_merge_commit", "self.mr_selector.search", "self.unsquash_commit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse a commit message If the commit message is a squashed merge commit, it will be split into multiple commits, each of which will be parsed separately. Single commits", "source_code": "def parse(self, commit: Commit) -> ParseResult | list[ParseResult]:\n    \"\"\"\n    Parse a commit message\n\n    If the commit message is a squashed merge commit, it will be split into\n    multiple commits, each of which will be parsed separately. Single commits\n    will be returned as a list of a single ParseResult.\n    \"\"\"\n    if self.options.ignore_merge_commits and self.is_merge_commit(commit):\n        return _logged_parse_error(\n            commit, \"Ignoring merge commit: %s\" % commit.hexsha[:8]\n        )\n\n    separate_commits: list[Commit] = (\n        self.unsquash_commit(commit)\n        if self.options.parse_squash_commits\n        else [commit]\n    )\n\n    # Parse each commit individually if there were more than one\n    parsed_commits: list[ParseResult] = list(\n        map(self.parse_commit, separate_commits)\n    )\n\n    def add_linked_merge_request(\n        parsed_result: ParseResult, mr_number: str\n    ) -> ParseResult:\n        return (\n            parsed_result\n            if not isinstance(parsed_result, ParsedCommit)\n            else ParsedCommit(\n                **{\n                    **parsed_result._asdict(),\n                    \"linked_merge_request\": mr_number,\n                }\n            )\n        )\n\n    # TODO: improve this for other VCS systems other than GitHub & BitBucket\n    # Github works as the first commit in a squash merge commit has the PR number\n    # appended to the first line of the commit message\n    lead_commit = next(iter(parsed_commits))\n\n    if isinstance(lead_commit, ParsedCommit) and lead_commit.linked_merge_request:\n        # If the first commit has linked merge requests, assume all commits\n        # are part of the same PR and add the linked merge requests to all\n        # parsed commits\n        parsed_commits = [\n            lead_commit,\n            *map(\n                lambda parsed_result, mr=lead_commit.linked_merge_request: (  # type: ignore[misc]\n                    add_linked_merge_request(parsed_result, mr)\n                ),\n                parsed_commits[1:],\n            ),\n        ]\n\n    elif isinstance(lead_commit, ParseError) and (\n        mr_match := self.mr_selector.search(force_str(lead_commit.message))\n    ):\n        # Handle BitBucket Squash Merge Commits (see #1085), which have non angular commit\n        # format but include the PR number in the commit subject that we want to extract\n        linked_merge_request = mr_match.group(\"mr_number\")\n\n        # apply the linked MR to all commits\n        parsed_commits = [\n            add_linked_merge_request(parsed_result, linked_merge_request)\n            for parsed_result in parsed_commits\n        ]\n\n    return parsed_commits", "loc": 71}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\angular.py", "class_name": "AngularCommitParser", "function_name": "unsquash_commit", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "list[Commit]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Commit", "deep_copy_commit", "force_str", "self.unsquash_commit_message"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unsquash_commit(self, commit: Commit) -> list[Commit]:\n    # GitHub EXAMPLE:\n    # feat(changelog): add autofit_text_width filter to template environment (#1062)\n    #\n    # This change adds an equivalent style formatter that can apply a text alignment\n    # to a maximum width and also maintain an indent over paragraphs of text\n    #\n    # * docs(changelog-templates): add definition & usage of autofit_text_width template filter\n    #\n    # * test(changelog-context): add test cases to check autofit_text_width filter use\n    #\n    # `git merge --squash` EXAMPLE:\n    # Squashed commit of the following:\n    #\n    # commit 63ec09b9e844e616dcaa7bae35a0b66671b59fbb\n    # Author: codejedi365 <codejedi365@gmail.com>\n    # Date:   Sun Oct 13 12:05:23 2024 -0600\n    #\n    #     feat(release-config): some commit subject\n    #\n\n    # Return a list of artificial commits (each with a single commit message)\n    return [\n        # create a artificial commit object (copy of original but with modified message)\n        Commit(\n            **{\n                **deep_copy_commit(commit),\n                \"message\": commit_msg,\n            }\n        )\n        for commit_msg in self.unsquash_commit_message(force_str(commit.message))\n    ] or [commit]", "loc": 32}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\angular.py", "class_name": "AngularCommitParser", "function_name": "unsquash_commit_message", "parameters": ["self", "message"], "param_types": {"message": "str"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["filter", "list", "map", "message.replace", "message.replace('\\r', '').strip", "reduce", "self.filters['git-header-commit'][0].split"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unsquash_commit_message(self, message: str) -> list[str]:\n    normalized_message = message.replace(\"\\r\", \"\").strip()\n\n    # split by obvious separate commits (applies to manual git squash merges)\n    obvious_squashed_commits = self.filters[\"git-header-commit\"][0].split(\n        normalized_message\n    )\n\n    separate_commit_msgs: list[str] = reduce(\n        lambda all_msgs, msgs: all_msgs + msgs,\n        map(self._find_squashed_commits_in_str, obvious_squashed_commits),\n        [],\n    )\n\n    return list(filter(None, separate_commit_msgs))", "loc": 15}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\angular.py", "class_name": null, "function_name": "add_linked_merge_request", "parameters": ["parsed_result", "mr_number"], "param_types": {"parsed_result": "ParseResult", "mr_number": "str"}, "return_type": "ParseResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "isinstance", "parsed_result._asdict"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_linked_merge_request(\n    parsed_result: ParseResult, mr_number: str\n) -> ParseResult:\n    return (\n        parsed_result\n        if not isinstance(parsed_result, ParsedCommit)\n        else ParsedCommit(\n            **{\n                **parsed_result._asdict(),\n                \"linked_merge_request\": mr_number,\n            }\n        )\n    )", "loc": 13}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\emoji.py", "class_name": "EmojiCommitParser", "function_name": "commit_body_components_separator", "parameters": ["self", "accumulator", "text"], "param_types": {"accumulator": "dict[str, list[str]]", "text": "str"}, "return_type": "dict[str, list[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["accumulator['descriptions'].append", "accumulator['notices'].append", "filter", "match.group", "predicate.split", "regexp", "regexp(',? and | *[,;/& ] *').sub", "self.issue_selector.search", "self.notice_selector.match", "set", "set(accumulator['linked_issues']).union", "sort_numerically", "validator.search"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def commit_body_components_separator(\n    self, accumulator: dict[str, list[str]], text: str\n) -> dict[str, list[str]]:\n    if (match := self.notice_selector.match(text)) and (\n        notice := match.group(\"notice\")\n    ):\n        accumulator[\"notices\"].append(notice)\n        return accumulator\n\n    if self.options.parse_linked_issues and (\n        match := self.issue_selector.search(text)\n    ):\n        predicate = regexp(r\",? and | *[,;/& ] *\").sub(\n            \",\", match.group(\"issue_predicate\") or \"\"\n        )\n        # Almost all issue trackers use a number to reference an issue so\n        # we use a simple regexp to validate the existence of a number which helps filter out\n        # any non-issue references that don't fit our expected format\n        has_number = regexp(r\"\\d+\")\n        new_issue_refs: set[str] = set(\n            filter(\n                lambda issue_str, validator=has_number: validator.search(issue_str),  # type: ignore[arg-type]\n                predicate.split(\",\"),\n            )\n        )\n        if new_issue_refs:\n            accumulator[\"linked_issues\"] = sort_numerically(\n                set(accumulator[\"linked_issues\"]).union(new_issue_refs)\n            )\n            return accumulator\n\n    # Prevent appending duplicate descriptions\n    if text not in accumulator[\"descriptions\"]:\n        accumulator[\"descriptions\"].append(text)\n\n    return accumulator", "loc": 36}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\emoji.py", "class_name": "EmojiCommitParser", "function_name": "parse_message", "parameters": ["self", "message"], "param_types": {"message": "str"}, "return_type": "ParsedMessageResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedMessageResult", "len", "match.group", "message.split", "mr_match.group", "parse_paragraphs", "reduce", "self.emoji_selector.search", "self.mr_selector.search", "self.mr_selector.sub", "self.mr_selector.sub('', subject).strip", "self.options.tag_to_level.get", "tuple"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_message(self, message: str) -> ParsedMessageResult:\n    msg_parts = message.split(\"\\n\", maxsplit=1)\n    subject = msg_parts[0]\n    msg_body = msg_parts[1] if len(msg_parts) > 1 else \"\"\n\n    linked_merge_request = \"\"\n    if mr_match := self.mr_selector.search(subject):\n        linked_merge_request = mr_match.group(\"mr_number\")\n        subject = self.mr_selector.sub(\"\", subject).strip()\n\n    # Search for emoji of the highest importance in the subject\n    match = self.emoji_selector.search(subject)\n    primary_emoji = match.group(\"type\") if match else \"Other\"\n    parsed_scope = (match.group(\"scope\") if match else None) or \"\"\n\n    level_bump = self.options.tag_to_level.get(\n        primary_emoji, self.options.default_bump_level\n    )\n\n    # All emojis will remain part of the returned description\n    body_components: dict[str, list[str]] = reduce(\n        self.commit_body_components_separator,\n        [\n            subject,\n            *parse_paragraphs(msg_body),\n        ],\n        {\n            \"descriptions\": [],\n            \"notices\": [],\n            \"linked_issues\": [],\n        },\n    )\n\n    descriptions = tuple(body_components[\"descriptions\"])\n\n    return ParsedMessageResult(\n        bump=level_bump,\n        type=primary_emoji,\n        category=primary_emoji,\n        scope=parsed_scope,\n        descriptions=(\n            descriptions[:1] if level_bump is LevelBump.MAJOR else descriptions\n        ),\n        breaking_descriptions=(\n            descriptions[1:] if level_bump is LevelBump.MAJOR else ()\n        ),\n        release_notices=tuple(body_components[\"notices\"]),\n        linked_issues=tuple(body_components[\"linked_issues\"]),\n        linked_merge_request=linked_merge_request,\n    )", "loc": 50}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\emoji.py", "class_name": "EmojiCommitParser", "function_name": "parse", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "ParseResult | list[ParseResult]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParseError", "ParsedCommit", "add_linked_merge_request", "isinstance", "iter", "list", "logger.debug", "map", "next", "parsed_result._asdict", "self.is_merge_commit", "self.unsquash_commit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse a commit message If the commit message is a squashed merge commit, it will be split into multiple commits, each of which will be parsed separately. Single commits", "source_code": "def parse(self, commit: Commit) -> ParseResult | list[ParseResult]:\n    \"\"\"\n    Parse a commit message\n\n    If the commit message is a squashed merge commit, it will be split into\n    multiple commits, each of which will be parsed separately. Single commits\n    will be returned as a list of a single ParseResult.\n    \"\"\"\n    if self.options.ignore_merge_commits and self.is_merge_commit(commit):\n        err_msg = \"Ignoring merge commit: %s\" % commit.hexsha[:8]\n        logger.debug(err_msg)\n        return ParseError(commit, err_msg)\n\n    separate_commits: list[Commit] = (\n        self.unsquash_commit(commit)\n        if self.options.parse_squash_commits\n        else [commit]\n    )\n\n    # Parse each commit individually if there were more than one\n    parsed_commits: list[ParseResult] = list(\n        map(self.parse_commit, separate_commits)\n    )\n\n    def add_linked_merge_request(\n        parsed_result: ParseResult, mr_number: str\n    ) -> ParseResult:\n        return (\n            parsed_result\n            if not isinstance(parsed_result, ParsedCommit)\n            else ParsedCommit(\n                **{\n                    **parsed_result._asdict(),\n                    \"linked_merge_request\": mr_number,\n                }\n            )\n        )\n\n    # TODO: improve this for other VCS systems other than GitHub & BitBucket\n    # Github works as the first commit in a squash merge commit has the PR number\n    # appended to the first line of the commit message\n    lead_commit = next(iter(parsed_commits))\n\n    if isinstance(lead_commit, ParsedCommit) and lead_commit.linked_merge_request:\n        # If the first commit has linked merge requests, assume all commits\n        # are part of the same PR and add the linked merge requests to all\n        # parsed commits\n        parsed_commits = [\n            lead_commit,\n            *map(\n                lambda parsed_result, mr=lead_commit.linked_merge_request: (  # type: ignore[misc]\n                    add_linked_merge_request(parsed_result, mr)\n                ),\n                parsed_commits[1:],\n            ),\n        ]\n\n    return parsed_commits", "loc": 58}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\emoji.py", "class_name": "EmojiCommitParser", "function_name": "unsquash_commit", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "list[Commit]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Commit", "deep_copy_commit", "force_str", "self.unsquash_commit_message"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unsquash_commit(self, commit: Commit) -> list[Commit]:\n    # GitHub EXAMPLE:\n    # (changelog): add autofit_text_width filter to template environment (#1062)\n    #\n    # This change adds an equivalent style formatter that can apply a text alignment\n    # to a maximum width and also maintain an indent over paragraphs of text\n    #\n    # *  Support Japanese language\n    #\n    # * (changelog-context): add test cases to check autofit_text_width filter use\n    #\n    # `git merge --squash` EXAMPLE:\n    # Squashed commit of the following:\n    #\n    # commit 63ec09b9e844e616dcaa7bae35a0b66671b59fbb\n    # Author: codejedi365 <codejedi365@gmail.com>\n    # Date:   Sun Oct 13 12:05:23 2024 -0000\n    #\n    #      (homepage): Lazyload home screen images\n    #\n    #\n    # Return a list of artificial commits (each with a single commit message)\n    return [\n        # create a artificial commit object (copy of original but with modified message)\n        Commit(\n            **{\n                **deep_copy_commit(commit),\n                \"message\": commit_msg,\n            }\n        )\n        for commit_msg in self.unsquash_commit_message(force_str(commit.message))\n    ] or [commit]", "loc": 32}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\emoji.py", "class_name": "EmojiCommitParser", "function_name": "unsquash_commit_message", "parameters": ["self", "message"], "param_types": {"message": "str"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["filter", "list", "map", "message.replace", "message.replace('\\r', '').strip", "reduce", "self.filters['git-header-commit'][0].split"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unsquash_commit_message(self, message: str) -> list[str]:\n    normalized_message = message.replace(\"\\r\", \"\").strip()\n\n    # split by obvious separate commits (applies to manual git squash merges)\n    obvious_squashed_commits = self.filters[\"git-header-commit\"][0].split(\n        normalized_message\n    )\n\n    separate_commit_msgs: list[str] = reduce(\n        lambda all_msgs, msgs: all_msgs + msgs,\n        map(self._find_squashed_commits_in_str, obvious_squashed_commits),\n        [],\n    )\n\n    return list(filter(None, separate_commit_msgs))", "loc": 15}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\emoji.py", "class_name": null, "function_name": "add_linked_merge_request", "parameters": ["parsed_result", "mr_number"], "param_types": {"parsed_result": "ParseResult", "mr_number": "str"}, "return_type": "ParseResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "isinstance", "parsed_result._asdict"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_linked_merge_request(\n    parsed_result: ParseResult, mr_number: str\n) -> ParseResult:\n    return (\n        parsed_result\n        if not isinstance(parsed_result, ParsedCommit)\n        else ParsedCommit(\n            **{\n                **parsed_result._asdict(),\n                \"linked_merge_request\": mr_number,\n            }\n        )\n    )", "loc": 13}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\scipy.py", "class_name": "ScipyCommitParser", "function_name": "commit_body_components_separator", "parameters": ["self", "accumulator", "text"], "param_types": {"accumulator": "dict[str, list[str]]", "text": "str"}, "return_type": "dict[str, list[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["accumulator['descriptions'].append", "accumulator['notices'].append", "filter", "match.group", "predicate.split", "regexp", "regexp(',? and | *[,;/& ] *').sub", "self.issue_selector.search", "self.notice_selector.match", "set", "set(accumulator['linked_issues']).union", "sort_numerically", "validator.search"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def commit_body_components_separator(\n    self, accumulator: dict[str, list[str]], text: str\n) -> dict[str, list[str]]:\n    if (match := self.notice_selector.match(text)) and (\n        notice := match.group(\"notice\")\n    ):\n        accumulator[\"notices\"].append(notice)\n        return accumulator\n\n    if match := self.issue_selector.search(text):\n        # if match := self.issue_selector.search(text):\n        predicate = regexp(r\",? and | *[,;/& ] *\").sub(\n            \",\", match.group(\"issue_predicate\") or \"\"\n        )\n        # Almost all issue trackers use a number to reference an issue so\n        # we use a simple regexp to validate the existence of a number which helps filter out\n        # any non-issue references that don't fit our expected format\n        has_number = regexp(r\"\\d+\")\n        new_issue_refs: set[str] = set(\n            filter(\n                lambda issue_str, validator=has_number: validator.search(issue_str),  # type: ignore[arg-type]\n                predicate.split(\",\"),\n            )\n        )\n        if new_issue_refs:\n            accumulator[\"linked_issues\"] = sort_numerically(\n                set(accumulator[\"linked_issues\"]).union(new_issue_refs)\n            )\n            return accumulator\n\n    # Prevent appending duplicate descriptions\n    if text not in accumulator[\"descriptions\"]:\n        accumulator[\"descriptions\"].append(text)\n\n    return accumulator", "loc": 35}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\scipy.py", "class_name": "ScipyCommitParser", "function_name": "parse_message", "parameters": ["self", "message"], "param_types": {"message": "str"}, "return_type": "ParsedMessageResult | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedMessageResult", "mr_match.group", "parse_paragraphs", "parsed.group", "reduce", "self.commit_msg_pattern.match", "self.mr_selector.search", "self.mr_selector.sub", "self.mr_selector.sub('', parsed_subject).strip", "self.options.tag_to_level.get", "tag_to_section.get", "tuple"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_message(self, message: str) -> ParsedMessageResult | None:\n    if not (parsed := self.commit_msg_pattern.match(message)):\n        return None\n\n    parsed_scope = parsed.group(\"scope\") or \"\"\n    parsed_subject = parsed.group(\"subject\")\n    parsed_text = parsed.group(\"text\")\n    parsed_type = parsed.group(\"type\")\n\n    linked_merge_request = \"\"\n    if mr_match := self.mr_selector.search(parsed_subject):\n        linked_merge_request = mr_match.group(\"mr_number\")\n        parsed_subject = self.mr_selector.sub(\"\", parsed_subject).strip()\n\n    body_components: dict[str, list[str]] = reduce(\n        self.commit_body_components_separator,\n        [\n            # Insert the subject before the other paragraphs\n            parsed_subject,\n            *parse_paragraphs(parsed_text or \"\"),\n        ],\n        {\n            \"descriptions\": [],\n            \"notices\": [],\n            \"linked_issues\": [],\n        },\n    )\n\n    level_bump = self.options.tag_to_level.get(\n        parsed_type, self.options.default_bump_level\n    )\n\n    return ParsedMessageResult(\n        bump=level_bump,\n        type=parsed_type,\n        category=tag_to_section.get(parsed_type, \"None\"),\n        scope=parsed_scope,\n        descriptions=tuple(\n            body_components[\"descriptions\"]\n            if level_bump != LevelBump.MAJOR\n            else [parsed_subject]\n        ),\n        breaking_descriptions=tuple(\n            body_components[\"descriptions\"][1:]\n            if level_bump == LevelBump.MAJOR\n            else []\n        ),\n        release_notices=tuple(body_components[\"notices\"]),\n        linked_issues=tuple(body_components[\"linked_issues\"]),\n        linked_merge_request=linked_merge_request,\n    )", "loc": 51}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\scipy.py", "class_name": "ScipyCommitParser", "function_name": "parse_commit", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "ParseResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit.from_parsed_message_result", "_logged_parse_error", "force_str", "self.parse_message"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_commit(self, commit: Commit) -> ParseResult:\n    if not (parsed_msg_result := self.parse_message(force_str(commit.message))):\n        return _logged_parse_error(\n            commit,\n            f\"Unable to parse commit message: {commit.message!r}\",\n        )\n\n    return ParsedCommit.from_parsed_message_result(commit, parsed_msg_result)", "loc": 8}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\scipy.py", "class_name": "ScipyCommitParser", "function_name": "parse", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "ParseResult | list[ParseResult]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "_logged_parse_error", "add_linked_merge_request", "force_str", "isinstance", "iter", "list", "map", "mr_match.group", "next", "parsed_result._asdict", "self.is_merge_commit", "self.mr_selector.search", "self.unsquash_commit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse a commit message If the commit message is a squashed merge commit, it will be split into multiple commits, each of which will be parsed separately. Single commits", "source_code": "def parse(self, commit: Commit) -> ParseResult | list[ParseResult]:\n    \"\"\"\n    Parse a commit message\n\n    If the commit message is a squashed merge commit, it will be split into\n    multiple commits, each of which will be parsed separately. Single commits\n    will be returned as a list of a single ParseResult.\n    \"\"\"\n    if self.options.ignore_merge_commits and self.is_merge_commit(commit):\n        return _logged_parse_error(\n            commit, \"Ignoring merge commit: %s\" % commit.hexsha[:8]\n        )\n\n    separate_commits: list[Commit] = (\n        self.unsquash_commit(commit)\n        if self.options.parse_squash_commits\n        else [commit]\n    )\n\n    # Parse each commit individually if there were more than one\n    parsed_commits: list[ParseResult] = list(\n        map(self.parse_commit, separate_commits)\n    )\n\n    def add_linked_merge_request(\n        parsed_result: ParseResult, mr_number: str\n    ) -> ParseResult:\n        return (\n            parsed_result\n            if not isinstance(parsed_result, ParsedCommit)\n            else ParsedCommit(\n                **{\n                    **parsed_result._asdict(),\n                    \"linked_merge_request\": mr_number,\n                }\n            )\n        )\n\n    # TODO: improve this for other VCS systems other than GitHub & BitBucket\n    # Github works as the first commit in a squash merge commit has the PR number\n    # appended to the first line of the commit message\n    lead_commit = next(iter(parsed_commits))\n\n    if isinstance(lead_commit, ParsedCommit) and lead_commit.linked_merge_request:\n        # If the first commit has linked merge requests, assume all commits\n        # are part of the same PR and add the linked merge requests to all\n        # parsed commits\n        parsed_commits = [\n            lead_commit,\n            *map(\n                lambda parsed_result, mr=lead_commit.linked_merge_request: (  # type: ignore[misc]\n                    add_linked_merge_request(parsed_result, mr)\n                ),\n                parsed_commits[1:],\n            ),\n        ]\n\n    elif isinstance(lead_commit, ParseError) and (\n        mr_match := self.mr_selector.search(force_str(lead_commit.message))\n    ):\n        # Handle BitBucket Squash Merge Commits (see #1085), which have non angular commit\n        # format but include the PR number in the commit subject that we want to extract\n        linked_merge_request = mr_match.group(\"mr_number\")\n\n        # apply the linked MR to all commits\n        parsed_commits = [\n            add_linked_merge_request(parsed_result, linked_merge_request)\n            for parsed_result in parsed_commits\n        ]\n\n    return parsed_commits", "loc": 71}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\scipy.py", "class_name": "ScipyCommitParser", "function_name": "unsquash_commit", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "list[Commit]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Commit", "deep_copy_commit", "force_str", "self.unsquash_commit_message"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unsquash_commit(self, commit: Commit) -> list[Commit]:\n    # GitHub EXAMPLE:\n    # feat(changelog): add autofit_text_width filter to template environment (#1062)\n    #\n    # This change adds an equivalent style formatter that can apply a text alignment\n    # to a maximum width and also maintain an indent over paragraphs of text\n    #\n    # * docs(changelog-templates): add definition & usage of autofit_text_width template filter\n    #\n    # * test(changelog-context): add test cases to check autofit_text_width filter use\n    #\n    # `git merge --squash` EXAMPLE:\n    # Squashed commit of the following:\n    #\n    # commit 63ec09b9e844e616dcaa7bae35a0b66671b59fbb\n    # Author: codejedi365 <codejedi365@gmail.com>\n    # Date:   Sun Oct 13 12:05:23 2024 -0600\n    #\n    #     feat(release-config): some commit subject\n    #\n\n    # Return a list of artificial commits (each with a single commit message)\n    return [\n        # create a artificial commit object (copy of original but with modified message)\n        Commit(\n            **{\n                **deep_copy_commit(commit),\n                \"message\": commit_msg,\n            }\n        )\n        for commit_msg in self.unsquash_commit_message(force_str(commit.message))\n    ] or [commit]", "loc": 32}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\scipy.py", "class_name": "ScipyCommitParser", "function_name": "unsquash_commit_message", "parameters": ["self", "message"], "param_types": {"message": "str"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["filter", "list", "map", "message.replace", "message.replace('\\r', '').strip", "reduce", "self.filters['git-header-commit'][0].split"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unsquash_commit_message(self, message: str) -> list[str]:\n    normalized_message = message.replace(\"\\r\", \"\").strip()\n\n    # split by obvious separate commits (applies to manual git squash merges)\n    obvious_squashed_commits = self.filters[\"git-header-commit\"][0].split(\n        normalized_message\n    )\n\n    separate_commit_msgs: list[str] = reduce(\n        lambda all_msgs, msgs: all_msgs + msgs,\n        map(self._find_squashed_commits_in_str, obvious_squashed_commits),\n        [],\n    )\n\n    return list(filter(None, separate_commit_msgs))", "loc": 15}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\scipy.py", "class_name": null, "function_name": "add_linked_merge_request", "parameters": ["parsed_result", "mr_number"], "param_types": {"parsed_result": "ParseResult", "mr_number": "str"}, "return_type": "ParseResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "isinstance", "parsed_result._asdict"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_linked_merge_request(\n    parsed_result: ParseResult, mr_number: str\n) -> ParseResult:\n    return (\n        parsed_result\n        if not isinstance(parsed_result, ParsedCommit)\n        else ParsedCommit(\n            **{\n                **parsed_result._asdict(),\n                \"linked_merge_request\": mr_number,\n            }\n        )\n    )", "loc": 13}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\tag.py", "class_name": "TagCommitParser", "function_name": "parse", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "ParseResult | list[ParseResult]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "_logged_parse_error", "breaking_re.match", "descriptions.insert", "logger.debug", "match.group", "parse_paragraphs", "parsed.group", "re_parser.match", "str", "subject.replace", "subject.strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse(self, commit: Commit) -> ParseResult | list[ParseResult]:\n    message = str(commit.message)\n\n    # Attempt to parse the commit message with a regular expression\n    parsed = re_parser.match(message)\n    if not parsed:\n        return _logged_parse_error(\n            commit, error=f\"Unable to parse the given commit message: {message!r}\"\n        )\n\n    subject = parsed.group(\"subject\")\n\n    # Check tags for minor or patch\n    if self.options.minor_tag in message:\n        level = \"feature\"\n        level_bump = LevelBump.MINOR\n        if subject:\n            subject = subject.replace(self.options.minor_tag, \"\")\n\n    elif self.options.patch_tag in message:\n        level = \"fix\"\n        level_bump = LevelBump.PATCH\n        if subject:\n            subject = subject.replace(self.options.patch_tag, \"\")\n\n    else:\n        # We did not find any tags in the commit message\n        return _logged_parse_error(\n            commit, error=f\"Unable to parse the given commit message: {message!r}\"\n        )\n\n    if parsed.group(\"text\"):\n        descriptions = parse_paragraphs(parsed.group(\"text\"))\n    else:\n        descriptions = []\n    descriptions.insert(0, subject.strip())\n\n    # Look for descriptions of breaking changes\n    breaking_descriptions = [\n        match.group(1)\n        for match in (breaking_re.match(p) for p in descriptions[1:])\n        if match\n    ]\n    if breaking_descriptions:\n        level = \"breaking\"\n        level_bump = LevelBump.MAJOR\n        logger.debug(\n            \"commit %s upgraded to a %s level_bump due to included breaking descriptions\",\n            commit.hexsha[:8],\n            level_bump,\n        )\n\n    logger.debug(\n        \"commit %s introduces a %s level_bump\", commit.hexsha[:8], level_bump\n    )\n\n    return ParsedCommit(\n        bump=level_bump,\n        type=level,\n        scope=\"\",\n        descriptions=descriptions,\n        breaking_descriptions=breaking_descriptions,\n        commit=commit,\n    )", "loc": 64}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\token.py", "class_name": "ParsedCommit", "function_name": "message", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["force_str", "force_str(self.commit.message).replace"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "A string representation of the commit message. This is a pass through property for convience to access the ``message`` attribute of the ``commit`` object.", "source_code": "def message(self) -> str:\n    \"\"\"\n    A string representation of the commit message.\n\n    This is a pass through property for convience to access the ``message``\n    attribute of the ``commit`` object.\n\n    If the message is of type ``bytes`` then it will be decoded to a ``UTF-8`` string.\n    \"\"\"\n    return force_str(self.commit.message).replace(\"\\r\", \"\")", "loc": 10}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\token.py", "class_name": "ParsedCommit", "function_name": "from_parsed_message_result", "parameters": ["commit", "parsed_message_result"], "param_types": {"commit": "Commit", "parsed_message_result": "ParsedMessageResult"}, "return_type": "ParsedCommit", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "list"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "A convience method to create a ParsedCommit object from a ParsedMessageResult object and a Commit object.", "source_code": "def from_parsed_message_result(\n    commit: Commit, parsed_message_result: ParsedMessageResult\n) -> ParsedCommit:\n    \"\"\"A convience method to create a ParsedCommit object from a ParsedMessageResult object and a Commit object.\"\"\"\n    return ParsedCommit(\n        bump=parsed_message_result.bump,\n        # TODO: breaking v11, swap back to type rather than category\n        type=parsed_message_result.category,\n        scope=parsed_message_result.scope,\n        descriptions=list(parsed_message_result.descriptions),\n        breaking_descriptions=list(parsed_message_result.breaking_descriptions),\n        commit=commit,\n        release_notices=parsed_message_result.release_notices,\n        linked_issues=parsed_message_result.linked_issues,\n        linked_merge_request=parsed_message_result.linked_merge_request,\n        include_in_changelog=parsed_message_result.include_in_changelog,\n    )", "loc": 17}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\token.py", "class_name": "ParseError", "function_name": "message", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["force_str", "force_str(self.commit.message).replace"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "A string representation of the commit message. This is a pass through property for convience to access the ``message`` attribute of the ``commit`` object.", "source_code": "def message(self) -> str:\n    \"\"\"\n    A string representation of the commit message.\n\n    This is a pass through property for convience to access the ``message``\n    attribute of the ``commit`` object.\n\n    If the message is of type ``bytes`` then it will be decoded to a ``UTF-8`` string.\n    \"\"\"\n    return force_str(self.commit.message).replace(\"\\r\", \"\")", "loc": 10}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\util.py", "class_name": null, "function_name": "parse_paragraphs", "parameters": ["text"], "param_types": {"text": "str"}, "return_type": "list[str]", "param_doc": {"text": "The text string to be divided."}, "return_doc": "A list of condensed paragraphs, as strings.", "raises_doc": [], "called_functions": ["adj['pattern'].sub", "adjusted_text.strip", "adjusted_text.strip().split", "filter", "list", "reduce", "spread_out_git_footers['pattern'].sub", "un_word_wrap['pattern'].sub", "un_word_wrap['pattern'].sub(un_word_wrap['repl'], paragraph).strip"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "This will take a text block and return a list containing each paragraph with single line breaks collapsed into spaces. To handle Windows line endings, carriage returns '\\r' are removed before separating into paragraphs. It will attempt to detect Git footers and they will not be condensed.", "source_code": "def parse_paragraphs(text: str) -> list[str]:\n    r\"\"\"\n    This will take a text block and return a list containing each\n    paragraph with single line breaks collapsed into spaces.\n\n    To handle Windows line endings, carriage returns '\\r' are removed before\n    separating into paragraphs.\n\n    It will attempt to detect Git footers and they will not be condensed.\n\n    :param text: The text string to be divided.\n    :return: A list of condensed paragraphs, as strings.\n    \"\"\"\n    adjusted_text = reduce(\n        lambda txt, adj: adj[\"pattern\"].sub(adj[\"repl\"], txt),\n        [trim_line_endings, un_word_wrap_hyphen],\n        text,\n    )\n\n    # Repeat replacements until no more changes are made\n    prev_iteration = \"\"\n    while prev_iteration != adjusted_text:\n        prev_iteration = adjusted_text\n        adjusted_text = spread_out_git_footers[\"pattern\"].sub(\n            spread_out_git_footers[\"repl\"], adjusted_text\n        )\n\n    return list(\n        filter(\n            None,\n            [\n                un_word_wrap[\"pattern\"].sub(un_word_wrap[\"repl\"], paragraph).strip()\n                for paragraph in adjusted_text.strip().split(\"\\n\\n\")\n            ],\n        )\n    )", "loc": 36}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\util.py", "class_name": null, "function_name": "force_str", "parameters": ["msg"], "param_types": {"msg": "str | bytes | bytearray | memoryview"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "message.decode", "msg.tobytes", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def force_str(msg: str | bytes | bytearray | memoryview) -> str:\n    # This shouldn't be a thing but typing is being weird around what\n    # git.commit.message returns and the memoryview type won't go away\n    message = msg.tobytes() if isinstance(msg, memoryview) else msg\n    return (\n        message.decode(\"utf-8\")\n        if isinstance(message, (bytes, bytearray))\n        else str(message)\n    )", "loc": 9}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\util.py", "class_name": null, "function_name": "deep_copy_commit", "parameters": ["commit"], "param_types": {"commit": "Commit"}, "return_type": "dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["deepcopy", "getattr", "hasattr", "suppress"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def deep_copy_commit(commit: Commit) -> dict[str, Any]:\n    keys = [\n        \"repo\",\n        \"binsha\",\n        \"author\",\n        \"authored_date\",\n        \"committer\",\n        \"committed_date\",\n        \"message\",\n        \"tree\",\n        \"parents\",\n        \"encoding\",\n        \"gpgsig\",\n        \"author_tz_offset\",\n        \"committer_tz_offset\",\n    ]\n    kwargs = {}\n    for key in keys:\n        with suppress(ValueError):\n            if hasattr(commit, key) and (value := getattr(commit, key)) is not None:\n                if key in [\"parents\", \"repo\", \"tree\"]:\n                    # These tend to have circular references so don't deepcopy them\n                    kwargs[key] = value\n                    continue\n\n                kwargs[key] = deepcopy(value)\n\n    return kwargs", "loc": 28}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\options_monorepo.py", "class_name": "ConventionalCommitMonorepoParserOptions", "function_name": "convert_strs_to_paths", "parameters": ["cls", "value"], "param_types": {"value": "Any"}, "return_type": "tuple[Path, ...]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "TypeError", "field_validator", "isinstance", "results.append", "tuple", "type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def convert_strs_to_paths(cls, value: Any) -> tuple[Path, ...]:\n    values = value if isinstance(value, Iterable) else [value]\n    results: list[Path] = []\n\n    for val in values:\n        if isinstance(val, (str, Path)):\n            results.append(Path(val))\n            continue\n\n        raise TypeError(f\"Invalid type: {type(val)}, expected str or Path.\")\n\n    return tuple(results)", "loc": 12}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\options_monorepo.py", "class_name": "ConventionalCommitMonorepoParserOptions", "function_name": "resolve_path", "parameters": ["cls", "dir_paths"], "param_types": {"dir_paths": "tuple[Path, ...]"}, "return_type": "tuple[Path, ...]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["(str_path := str(path)).startswith", "Path", "Path(str_path[1:]).expanduser", "Path(str_path[1:]).expanduser().absolute", "Path(str_path[1:]).expanduser().absolute().resolve", "field_validator", "path.expanduser", "path.expanduser().absolute", "path.expanduser().absolute().resolve", "str", "tuple"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def resolve_path(cls, dir_paths: tuple[Path, ...]) -> tuple[Path, ...]:\n    return tuple(\n        (\n            Path(f\"!{Path(str_path[1:]).expanduser().absolute().resolve()}\")\n            # maintains the negation prefix if it exists\n            if (str_path := str(path)).startswith(\"!\")\n            # otherwise, resolve the path normally\n            else path.expanduser().absolute().resolve()\n        )\n        for path in dir_paths\n    )", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\options_monorepo.py", "class_name": "ConventionalCommitMonorepoParserOptions", "function_name": "validate_scope_prefix", "parameters": ["cls", "scope_prefix"], "param_types": {"scope_prefix": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "field_validator", "regexp"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate_scope_prefix(cls, scope_prefix: str) -> str:\n    if not scope_prefix:\n        return \"\"\n\n    # Allow the special case of a plain wildcard although it's not a valid regex\n    if scope_prefix == \"*\":\n        return \".*\"\n\n    try:\n        regexp(scope_prefix)\n    except RegExpError as err:\n        raise ValueError(f\"Invalid regex {scope_prefix!r}\") from err\n\n    return scope_prefix", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser.py", "class_name": "ConventionalCommitParser", "function_name": "commit_body_components_separator", "parameters": ["self", "accumulator", "text"], "param_types": {"accumulator": "dict[str, list[str]]", "text": "str"}, "return_type": "dict[str, list[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["accumulator['breaking_descriptions'].append", "accumulator['descriptions'].append", "accumulator['notices'].append", "breaking_re.match", "filter", "match.group", "predicate.split", "regexp", "regexp(',? and | *[,;/& ] *').sub", "self.issue_selector.search", "self.notice_selector.match", "set", "set(accumulator['linked_issues']).union", "sort_numerically", "validator.search"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def commit_body_components_separator(\n    self, accumulator: dict[str, list[str]], text: str\n) -> dict[str, list[str]]:\n    if (match := breaking_re.match(text)) and (brk_desc := match.group(1)):\n        accumulator[\"breaking_descriptions\"].append(brk_desc)\n        return accumulator\n\n    if (match := self.notice_selector.match(text)) and (\n        notice := match.group(\"notice\")\n    ):\n        accumulator[\"notices\"].append(notice)\n        return accumulator\n\n    if match := self.issue_selector.search(text):\n        # if match := self.issue_selector.search(text):\n        predicate = regexp(r\",? and | *[,;/& ] *\").sub(\n            \",\", match.group(\"issue_predicate\") or \"\"\n        )\n        # Almost all issue trackers use a number to reference an issue so\n        # we use a simple regexp to validate the existence of a number which helps filter out\n        # any non-issue references that don't fit our expected format\n        has_number = regexp(r\"\\d+\")\n        new_issue_refs: set[str] = set(\n            filter(\n                lambda issue_str, validator=has_number: validator.search(issue_str),  # type: ignore[arg-type]\n                predicate.split(\",\"),\n            )\n        )\n        if new_issue_refs:\n            accumulator[\"linked_issues\"] = sort_numerically(\n                set(accumulator[\"linked_issues\"]).union(new_issue_refs)\n            )\n            return accumulator\n\n    # Prevent appending duplicate descriptions\n    if text not in accumulator[\"descriptions\"]:\n        accumulator[\"descriptions\"].append(text)\n\n    return accumulator", "loc": 39}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser.py", "class_name": "ConventionalCommitParser", "function_name": "parse_message", "parameters": ["self", "message"], "param_types": {"message": "str"}, "return_type": "ParsedMessageResult | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.commit_msg_pattern.match", "self.create_parsed_message_result"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_message(self, message: str) -> ParsedMessageResult | None:\n    return (\n        self.create_parsed_message_result(match)\n        if (match := self.commit_msg_pattern.match(message))\n        else None\n    )", "loc": 6}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser.py", "class_name": "ConventionalCommitParser", "function_name": "create_parsed_message_result", "parameters": ["self", "match"], "param_types": {"match": "RegexMatch[str]"}, "return_type": "ParsedMessageResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["LONG_TYPE_NAMES.get", "ParsedMessageResult", "match.group", "mr_match.group", "parse_paragraphs", "reduce", "self.mr_selector.search", "self.mr_selector.sub", "self.mr_selector.sub('', parsed_subject).strip", "self.options.tag_to_level.get", "tuple"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_parsed_message_result(\n    self, match: RegexMatch[str]\n) -> ParsedMessageResult:\n    parsed_break = match.group(\"break\")\n    parsed_scope = match.group(\"scope\") or \"\"\n    parsed_subject = match.group(\"subject\")\n    parsed_text = match.group(\"text\")\n    parsed_type = match.group(\"type\")\n\n    linked_merge_request = \"\"\n    if mr_match := self.mr_selector.search(parsed_subject):\n        linked_merge_request = mr_match.group(\"mr_number\")\n        parsed_subject = self.mr_selector.sub(\"\", parsed_subject).strip()\n\n    body_components: dict[str, list[str]] = reduce(\n        self.commit_body_components_separator,\n        [\n            # Insert the subject before the other paragraphs\n            parsed_subject,\n            *parse_paragraphs(parsed_text or \"\"),\n        ],\n        {\n            \"breaking_descriptions\": [],\n            \"descriptions\": [],\n            \"notices\": [],\n            \"linked_issues\": [],\n        },\n    )\n\n    level_bump = (\n        LevelBump.MAJOR\n        if body_components[\"breaking_descriptions\"] or parsed_break\n        else self.options.tag_to_level.get(\n            parsed_type, self.options.default_bump_level\n        )\n    )\n\n    return ParsedMessageResult(\n        bump=level_bump,\n        type=parsed_type,\n        category=LONG_TYPE_NAMES.get(parsed_type, parsed_type),\n        scope=parsed_scope,\n        descriptions=tuple(body_components[\"descriptions\"]),\n        breaking_descriptions=tuple(body_components[\"breaking_descriptions\"]),\n        release_notices=tuple(body_components[\"notices\"]),\n        linked_issues=tuple(body_components[\"linked_issues\"]),\n        linked_merge_request=linked_merge_request,\n    )", "loc": 48}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser.py", "class_name": "ConventionalCommitParser", "function_name": "parse_commit", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "ParseResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit.from_parsed_message_result", "force_str", "self.log_parse_error", "self.parse_message"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_commit(self, commit: Commit) -> ParseResult:\n    if not (parsed_msg_result := self.parse_message(force_str(commit.message))):\n        return self.log_parse_error(\n            commit,\n            f\"Unable to parse commit message: {commit.message!r}\",\n        )\n\n    return ParsedCommit.from_parsed_message_result(commit, parsed_msg_result)", "loc": 8}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser.py", "class_name": "ConventionalCommitParser", "function_name": "parse", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "ParseResult | list[ParseResult]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "add_linked_merge_request", "force_str", "isinstance", "iter", "list", "map", "mr_match.group", "next", "parsed_result._asdict", "self.is_merge_commit", "self.log_parse_error", "self.mr_selector.search", "self.unsquash_commit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse a commit message If the commit message is a squashed merge commit, it will be split into multiple commits, each of which will be parsed separately. Single commits", "source_code": "def parse(self, commit: Commit) -> ParseResult | list[ParseResult]:\n    \"\"\"\n    Parse a commit message\n\n    If the commit message is a squashed merge commit, it will be split into\n    multiple commits, each of which will be parsed separately. Single commits\n    will be returned as a list of a single ParseResult.\n    \"\"\"\n    if self.options.ignore_merge_commits and self.is_merge_commit(commit):\n        return self.log_parse_error(\n            commit, \"Ignoring merge commit: %s\" % commit.hexsha[:8]\n        )\n\n    separate_commits: list[Commit] = (\n        self.unsquash_commit(commit)\n        if self.options.parse_squash_commits\n        else [commit]\n    )\n\n    # Parse each commit individually if there were more than one\n    parsed_commits: list[ParseResult] = list(\n        map(self.parse_commit, separate_commits)\n    )\n\n    def add_linked_merge_request(\n        parsed_result: ParseResult, mr_number: str\n    ) -> ParseResult:\n        return (\n            parsed_result\n            if not isinstance(parsed_result, ParsedCommit)\n            else ParsedCommit(\n                **{\n                    **parsed_result._asdict(),\n                    \"linked_merge_request\": mr_number,\n                }\n            )\n        )\n\n    # TODO: improve this for other VCS systems other than GitHub & BitBucket\n    # Github works as the first commit in a squash merge commit has the PR number\n    # appended to the first line of the commit message\n    lead_commit = next(iter(parsed_commits))\n\n    if isinstance(lead_commit, ParsedCommit) and lead_commit.linked_merge_request:\n        # If the first commit has linked merge requests, assume all commits\n        # are part of the same PR and add the linked merge requests to all\n        # parsed commits\n        parsed_commits = [\n            lead_commit,\n            *map(\n                lambda parsed_result, mr=lead_commit.linked_merge_request: (  # type: ignore[misc]\n                    add_linked_merge_request(parsed_result, mr)\n                ),\n                parsed_commits[1:],\n            ),\n        ]\n\n    elif isinstance(lead_commit, ParseError) and (\n        mr_match := self.mr_selector.search(force_str(lead_commit.message))\n    ):\n        # Handle BitBucket Squash Merge Commits (see #1085), which have non angular commit\n        # format but include the PR number in the commit subject that we want to extract\n        linked_merge_request = mr_match.group(\"mr_number\")\n\n        # apply the linked MR to all commits\n        parsed_commits = [\n            add_linked_merge_request(parsed_result, linked_merge_request)\n            for parsed_result in parsed_commits\n        ]\n\n    return parsed_commits", "loc": 71}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser.py", "class_name": "ConventionalCommitParser", "function_name": "unsquash_commit", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "list[Commit]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Commit", "deep_copy_commit", "force_str", "self.unsquash_commit_message"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unsquash_commit(self, commit: Commit) -> list[Commit]:\n    # GitHub EXAMPLE:\n    # feat(changelog): add autofit_text_width filter to template environment (#1062)\n    #\n    # This change adds an equivalent style formatter that can apply a text alignment\n    # to a maximum width and also maintain an indent over paragraphs of text\n    #\n    # * docs(changelog-templates): add definition & usage of autofit_text_width template filter\n    #\n    # * test(changelog-context): add test cases to check autofit_text_width filter use\n    #\n    # `git merge --squash` EXAMPLE:\n    # Squashed commit of the following:\n    #\n    # commit 63ec09b9e844e616dcaa7bae35a0b66671b59fbb\n    # Author: codejedi365 <codejedi365@gmail.com>\n    # Date:   Sun Oct 13 12:05:23 2024 -0600\n    #\n    #     feat(release-config): some commit subject\n    #\n\n    # Return a list of artificial commits (each with a single commit message)\n    return [\n        # create a artificial commit object (copy of original but with modified message)\n        Commit(\n            **{\n                **deep_copy_commit(commit),\n                \"message\": commit_msg,\n            }\n        )\n        for commit_msg in self.unsquash_commit_message(force_str(commit.message))\n    ] or [commit]", "loc": 32}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser.py", "class_name": "ConventionalCommitParser", "function_name": "unsquash_commit_message", "parameters": ["self", "message"], "param_types": {"message": "str"}, "return_type": "list[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["filter", "list", "map", "message.replace", "message.replace('\\r', '').strip", "reduce", "self.filters['git-header-commit'][0].split"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unsquash_commit_message(self, message: str) -> list[str]:\n    normalized_message = message.replace(\"\\r\", \"\").strip()\n\n    # split by obvious separate commits (applies to manual git squash merges)\n    obvious_squashed_commits = self.filters[\"git-header-commit\"][0].split(\n        normalized_message\n    )\n\n    separate_commit_msgs: list[str] = reduce(\n        lambda all_msgs, msgs: all_msgs + msgs,\n        map(self._find_squashed_commits_in_str, obvious_squashed_commits),\n        [],\n    )\n\n    return list(filter(None, separate_commit_msgs))", "loc": 15}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser.py", "class_name": null, "function_name": "add_linked_merge_request", "parameters": ["parsed_result", "mr_number"], "param_types": {"parsed_result": "ParseResult", "mr_number": "str"}, "return_type": "ParseResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "isinstance", "parsed_result._asdict"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_linked_merge_request(\n    parsed_result: ParseResult, mr_number: str\n) -> ParseResult:\n    return (\n        parsed_result\n        if not isinstance(parsed_result, ParsedCommit)\n        else ParsedCommit(\n            **{\n                **parsed_result._asdict(),\n                \"linked_merge_request\": mr_number,\n            }\n        )\n    )", "loc": 13}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser_monorepo.py", "class_name": "ConventionalCommitMonorepoParser", "function_name": "parse", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "ParseResult | list[ParseResult]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "add_linked_merge_request", "force_str", "isinstance", "iter", "list", "map", "mr_match.group", "next", "parsed_result._asdict", "self._base_parser.is_merge_commit", "self._base_parser.log_parse_error", "self._base_parser.mr_selector.search", "self._base_parser.unsquash_commit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse(self, commit: Commit) -> ParseResult | list[ParseResult]:\n    if self.options.ignore_merge_commits and self._base_parser.is_merge_commit(\n        commit\n    ):\n        return self._base_parser.log_parse_error(\n            commit, \"Ignoring merge commit: %s\" % commit.hexsha[:8]\n        )\n\n    separate_commits: list[Commit] = (\n        self._base_parser.unsquash_commit(commit)\n        if self.options.parse_squash_commits\n        else [commit]\n    )\n\n    # Parse each commit individually if there were more than one\n    parsed_commits: list[ParseResult] = list(\n        map(self.parse_commit, separate_commits)\n    )\n\n    def add_linked_merge_request(\n        parsed_result: ParseResult, mr_number: str\n    ) -> ParseResult:\n        return (\n            parsed_result\n            if not isinstance(parsed_result, ParsedCommit)\n            else ParsedCommit(\n                **{\n                    **parsed_result._asdict(),\n                    \"linked_merge_request\": mr_number,\n                }\n            )\n        )\n\n    # TODO: improve this for other VCS systems other than GitHub & BitBucket\n    # Github works as the first commit in a squash merge commit has the PR number\n    # appended to the first line of the commit message\n    lead_commit = next(iter(parsed_commits))\n\n    if isinstance(lead_commit, ParsedCommit) and lead_commit.linked_merge_request:\n        # If the first commit has linked merge requests, assume all commits\n        # are part of the same PR and add the linked merge requests to all\n        # parsed commits\n        parsed_commits = [\n            lead_commit,\n            *map(\n                lambda parsed_result, mr=lead_commit.linked_merge_request: (  # type: ignore[misc]\n                    add_linked_merge_request(parsed_result, mr)\n                ),\n                parsed_commits[1:],\n            ),\n        ]\n\n    elif isinstance(lead_commit, ParseError) and (\n        mr_match := self._base_parser.mr_selector.search(\n            force_str(lead_commit.message)\n        )\n    ):\n        # Handle BitBucket Squash Merge Commits (see #1085), which have non angular commit\n        # format but include the PR number in the commit subject that we want to extract\n        linked_merge_request = mr_match.group(\"mr_number\")\n\n        # apply the linked MR to all commits\n        parsed_commits = [\n            add_linked_merge_request(parsed_result, linked_merge_request)\n            for parsed_result in parsed_commits\n        ]\n\n    return parsed_commits", "loc": 68}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser_monorepo.py", "class_name": "ConventionalCommitMonorepoParser", "function_name": "parse_message", "parameters": ["self", "message", "strict_scope"], "param_types": {"message": "str", "strict_scope": "bool"}, "return_type": "ParsedMessageResult | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._base_parser.create_parsed_message_result", "self._optional_scope_pattern.match", "self._strict_scope_pattern.match"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_message(\n    self, message: str, strict_scope: bool = False\n) -> ParsedMessageResult | None:\n    if (\n        not (parsed_match := self._strict_scope_pattern.match(message))\n        and strict_scope\n    ):\n        return None\n\n    if not parsed_match and not (\n        parsed_match := self._optional_scope_pattern.match(message)\n    ):\n        return None\n\n    return self._base_parser.create_parsed_message_result(parsed_match)", "loc": 15}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser_monorepo.py", "class_name": "ConventionalCommitMonorepoParser", "function_name": "parse_commit", "parameters": ["self", "commit"], "param_types": {"commit": "Commit"}, "return_type": "ParseResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit.from_parsed_message_result", "bool", "force_str", "self._has_relevant_changed_files", "self._logger.debug", "self.logged_parse_error", "self.parse_message", "str", "str.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Attempt to parse the commit message with a regular expression into a ParseResult.", "source_code": "def parse_commit(self, commit: Commit) -> ParseResult:\n    \"\"\"Attempt to parse the commit message with a regular expression into a ParseResult.\"\"\"\n    # Multiple scenarios to consider when parsing a commit message [Truth table]:\n    # =======================================================================================================\n    # |    ||                         INPUTS                         ||                                     |\n    # |  # ||------------------------+----------------+--------------||                Result               |\n    # |    || Example Commit Message | Relevant Files | Scope Prefix ||                                     |\n    # |----||------------------------+----------------+--------------||-------------------------------------|\n    # |  1 || type(prefix-cli): msg  |            yes |    \"prefix-\" ||                        ParsedCommit |\n    # |  2 || type(prefix-cli): msg  |            yes |           \"\" ||                        ParsedCommit |\n    # |  3 || type(prefix-cli): msg  |             no |    \"prefix-\" ||                        ParsedCommit |\n    # |  4 || type(prefix-cli): msg  |             no |           \"\" ||                ParseError[No files] |\n    # |  5 || type(scope-cli): msg   |            yes |    \"prefix-\" ||                        ParsedCommit |\n    # |  6 || type(scope-cli): msg   |            yes |           \"\" ||                        ParsedCommit |\n    # |  7 || type(scope-cli): msg   |             no |    \"prefix-\" ||  ParseError[No files & wrong scope] |\n    # |  8 || type(scope-cli): msg   |             no |           \"\" ||                ParseError[No files] |\n    # |  9 || type(cli): msg         |            yes |    \"prefix-\" ||                        ParsedCommit |\n    # | 10 || type(cli): msg         |            yes |           \"\" ||                        ParsedCommit |\n    # | 11 || type(cli): msg         |             no |    \"prefix-\" ||  ParseError[No files & wrong scope] |\n    # | 12 || type(cli): msg         |             no |           \"\" ||                ParseError[No files] |\n    # | 13 || type: msg              |            yes |    \"prefix-\" ||                        ParsedCommit |\n    # | 14 || type: msg              |            yes |           \"\" ||                        ParsedCommit |\n    # | 15 || type: msg              |             no |    \"prefix-\" ||  ParseError[No files & wrong scope] |\n    # | 16 || type: msg              |             no |           \"\" ||                ParseError[No files] |\n    # | 17 || non-conventional msg   |            yes |    \"prefix-\" ||          ParseError[Invalid Syntax] |\n    # | 18 || non-conventional msg   |            yes |           \"\" ||          ParseError[Invalid Syntax] |\n    # | 19 || non-conventional msg   |             no |    \"prefix-\" ||          ParseError[Invalid Syntax] |\n    # | 20 || non-conventional msg   |             no |           \"\" ||          ParseError[Invalid Syntax] |\n    # =======================================================================================================\n\n    # Initial Logic Flow:\n    # [1] When there are no relevant files and a scope prefix is defined, we enforce a strict scope\n    # [2] When there are no relevant files and no scope prefix is defined, we parse scoped or unscoped commits\n    # [3] When there are relevant files, we parse scoped or unscoped commits regardless of any defined prefix\n    has_relevant_changed_files = self._has_relevant_changed_files(commit)\n    strict_scope = bool(\n        not has_relevant_changed_files and self.options.scope_prefix\n    )\n    pmsg_result = self.parse_message(\n        message=force_str(commit.message),\n        strict_scope=strict_scope,\n    )\n\n    if pmsg_result and (has_relevant_changed_files or strict_scope):\n        self._logger.debug(\n            \"commit %s introduces a %s level_bump\",\n            commit.hexsha[:8],\n            pmsg_result.bump,\n        )\n\n        return ParsedCommit.from_parsed_message_result(commit, pmsg_result)\n\n    if pmsg_result and not has_relevant_changed_files:\n        return self.logged_parse_error(\n            commit,\n            f\"Commit {commit.hexsha[:7]} has no changed files matching the path filter(s)\",\n        )\n\n    if strict_scope and self.parse_message(str(commit.message), strict_scope=False):\n        return self.logged_parse_error(\n            commit,\n            str.join(\n                \" and \",\n                [\n                    f\"Commit {commit.hexsha[:7]} has no changed files matching the path filter(s)\",\n                    f\"the scope does not match scope prefix '{self.options.scope_prefix}'\",\n                ],\n            ),\n        )\n\n    return self.logged_parse_error(\n        commit,\n        f\"Format Mismatch! Unable to parse commit message: {commit.message!r}\",\n    )", "loc": 74}
{"file": "python-semantic-release\\src\\semantic_release\\commit_parser\\conventional\\parser_monorepo.py", "class_name": null, "function_name": "add_linked_merge_request", "parameters": ["parsed_result", "mr_number"], "param_types": {"parsed_result": "ParseResult", "mr_number": "str"}, "return_type": "ParseResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParsedCommit", "isinstance", "parsed_result._asdict"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_linked_merge_request(\n    parsed_result: ParseResult, mr_number: str\n) -> ParseResult:\n    return (\n        parsed_result\n        if not isinstance(parsed_result, ParsedCommit)\n        else ParsedCommit(\n            **{\n                **parsed_result._asdict(),\n                \"linked_merge_request\": mr_number,\n            }\n        )\n    )", "loc": 13}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\bitbucket.py", "class_name": "Bitbucket", "function_name": "remote_url", "parameters": ["self", "use_token"], "param_types": {"use_token": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "os.environ.get", "self.create_server_url"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Get the remote url including the token for authentication if requested", "source_code": "def remote_url(self, use_token: bool = True) -> str:\n    \"\"\"Get the remote url including the token for authentication if requested\"\"\"\n    if not use_token:\n        return self._remote_url\n\n    if not self.token:\n        raise ValueError(\"Requested to use token but no token set.\")\n\n    # If the user is set, assume the token is an user secret. This will work\n    # on any repository the user has access to.\n    # https://support.atlassian.com/bitbucket-cloud/docs/push-back-to-your-repository\n    # If the user variable is not set, assume it is a repository token\n    # which will only work on the repository it was created for.\n    # https://support.atlassian.com/bitbucket-cloud/docs/using-access-tokens\n    user = os.environ.get(\"BITBUCKET_USER\", \"x-token-auth\")\n\n    return self.create_server_url(\n        auth=f\"{user}:{self.token}\" if user else self.token,\n        path=f\"/{self.owner}/{self.repo_name}.git\",\n    )", "loc": 20}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\bitbucket.py", "class_name": "Bitbucket", "function_name": "pull_request_url", "parameters": ["self", "pr_number"], "param_types": {"pr_number": "str | int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "isinstance", "match.group", "regexp", "regexp('(\\\\d+)$').search", "self.create_repo_url"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def pull_request_url(self, pr_number: str | int) -> str:\n    # Strips off any character prefix like '#' that usually exists\n    if isinstance(pr_number, str) and (\n        match := regexp(r\"(\\d+)$\").search(pr_number)\n    ):\n        try:\n            pr_number = int(match.group(1))\n        except ValueError:\n            return \"\"\n\n    if isinstance(pr_number, int):\n        return self.create_repo_url(repo_path=f\"/pull-requests/{pr_number}\")\n\n    return \"\"", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\bitbucket.py", "class_name": "Bitbucket", "function_name": "format_w_official_vcs_name", "parameters": ["format_str"], "param_types": {"format_str": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["format_str.format"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_w_official_vcs_name(format_str: str) -> str:\n    if \"%s\" in format_str:\n        return format_str % Bitbucket.OFFICIAL_NAME\n\n    if \"{}\" in format_str:\n        return format_str.format(Bitbucket.OFFICIAL_NAME)\n\n    if \"{vcs_name}\" in format_str:\n        return format_str.format(vcs_name=Bitbucket.OFFICIAL_NAME)\n\n    return format_str", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\bitbucket.py", "class_name": "Bitbucket", "function_name": "create_release", "parameters": ["self", "tag", "release_notes", "prerelease", "assets", "noop"], "param_types": {"tag": "str", "release_notes": "str", "prerelease": "bool", "assets": "list[str] | None", "noop": "bool"}, "return_type": "int | str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["super", "super().create_release"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_release(\n    self,\n    tag: str,\n    release_notes: str,\n    prerelease: bool = False,\n    assets: list[str] | None = None,\n    noop: bool = False,\n) -> int | str:\n    return super().create_release(tag, release_notes, prerelease, assets, noop)", "loc": 9}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitea.py", "class_name": "Gitea", "function_name": "create_release", "parameters": ["self", "tag", "release_notes", "prerelease", "assets", "noop"], "param_types": {"tag": "str", "release_notes": "str", "prerelease": "bool", "assets": "list[str] | None", "noop": "bool"}, "return_type": "int", "param_doc": {"tag": "Tag to create release for", "release_notes": "The release notes for this version", "prerelease": "Whether or not this release should be specified as a"}, "return_doc": "Whether the request succeeded", "raises_doc": [], "called_functions": ["AssetUploadError", "AssetUploadError(f'Failed asset upload for {asset}').with_traceback", "IncompleteReleaseError", "UnexpectedResponse", "errors.append", "len", "logged_function", "logger.exception", "logger.info", "noop_report", "response.json", "response.raise_for_status", "self.create_api_url", "self.session.post", "self.upload_release_asset", "str.join"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Create a new release Ref: https://gitea.com/api/swagger#/repository/repoCreateRelease", "source_code": "def create_release(\n    self,\n    tag: str,\n    release_notes: str,\n    prerelease: bool = False,\n    assets: list[str] | None = None,\n    noop: bool = False,\n) -> int:\n    \"\"\"\n    Create a new release\n\n    Ref: https://gitea.com/api/swagger#/repository/repoCreateRelease\n\n    :param tag: Tag to create release for\n    :param release_notes: The release notes for this version\n    :param prerelease: Whether or not this release should be specified as a\n        prerelease\n\n    :return: Whether the request succeeded\n    \"\"\"\n    if noop:\n        noop_report(\n            str.join(\n                \" \",\n                [\n                    f\"would have created a release for tag {tag}\",\n                    \"with the following notes:\\n\",\n                    release_notes,\n                ],\n            )\n        )\n        if assets:\n            noop_report(\n                str.join(\n                    \"\\n\",\n                    [\n                        \"would have uploaded the following assets to the release:\",\n                        *assets,\n                    ],\n                )\n            )\n        return -1\n\n    logger.info(\"Creating release for tag %s\", tag)\n    releases_endpoint = self.create_api_url(\n        endpoint=f\"/repos/{self.owner}/{self.repo_name}/releases\",\n    )\n    response = self.session.post(\n        releases_endpoint,\n        json={\n            \"tag_name\": tag,\n            \"name\": tag,\n            \"body\": release_notes,\n            \"draft\": False,\n            \"prerelease\": prerelease,\n        },\n    )\n\n    # Raise an error if the request was not successful\n    response.raise_for_status()\n\n    try:\n        release_id: int = response.json()[\"id\"]\n        logger.info(\"Successfully created release with ID: %s\", release_id)\n    except JSONDecodeError as err:\n        raise UnexpectedResponse(\"Unreadable json response\") from err\n    except KeyError as err:\n        raise UnexpectedResponse(\"JSON response is missing an id\") from err\n\n    errors = []\n    for asset in assets or []:\n        logger.info(\"Uploading asset %s\", asset)\n        try:\n            self.upload_release_asset(release_id, asset)\n        except HTTPError as err:\n            errors.append(\n                AssetUploadError(f\"Failed asset upload for {asset}\").with_traceback(\n                    err.__traceback__\n                )\n            )\n\n    if len(errors) < 1:\n        return release_id\n\n    for error in errors:\n        logger.exception(error)\n\n    raise IncompleteReleaseError(\n        f\"Failed to upload asset{'s' if len(errors) > 1 else ''} to release!\"\n    )", "loc": 90}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitea.py", "class_name": "Gitea", "function_name": "get_release_id_by_tag", "parameters": ["self", "tag"], "param_types": {"tag": "str"}, "return_type": "int | None", "param_doc": {"tag": "Tag to get release for"}, "return_doc": "ID of found release", "raises_doc": [], "called_functions": ["UnexpectedResponse", "logged_function", "response.json", "response.raise_for_status", "self.create_api_url", "self.session.get"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Get a release by its tag name https://gitea.com/api/swagger#/repository/repoGetReleaseByTag", "source_code": "def get_release_id_by_tag(self, tag: str) -> int | None:\n    \"\"\"\n    Get a release by its tag name\n    https://gitea.com/api/swagger#/repository/repoGetReleaseByTag\n    :param tag: Tag to get release for\n\n    :return: ID of found release\n    \"\"\"\n    tag_endpoint = self.create_api_url(\n        endpoint=f\"/repos/{self.owner}/{self.repo_name}/releases/tags/{tag}\",\n    )\n    response = self.session.get(tag_endpoint)\n\n    # Raise an error if the request was not successful\n    response.raise_for_status()\n\n    try:\n        data = response.json()\n        return data[\"id\"]\n    except JSONDecodeError as err:\n        raise UnexpectedResponse(\"Unreadable json response\") from err\n    except KeyError as err:\n        raise UnexpectedResponse(\"JSON response is missing an id\") from err", "loc": 23}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitea.py", "class_name": "Gitea", "function_name": "edit_release_notes", "parameters": ["self", "release_id", "release_notes"], "param_types": {"release_id": "int", "release_notes": "str"}, "return_type": "int", "param_doc": {"id": "ID of release to update", "release_notes": "The release notes for this version"}, "return_doc": "The ID of the release that was edited", "raises_doc": [], "called_functions": ["logged_function", "logger.info", "response.raise_for_status", "self.create_api_url", "self.session.patch"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Edit a release with updated change notes https://gitea.com/api/swagger#/repository/repoEditRelease", "source_code": "def edit_release_notes(self, release_id: int, release_notes: str) -> int:\n    \"\"\"\n    Edit a release with updated change notes\n    https://gitea.com/api/swagger#/repository/repoEditRelease\n    :param id: ID of release to update\n    :param release_notes: The release notes for this version\n\n    :return: The ID of the release that was edited\n    \"\"\"\n    logger.info(\"Updating release %s\", release_id)\n    release_endpoint = self.create_api_url(\n        endpoint=f\"/repos/{self.owner}/{self.repo_name}/releases/{release_id}\",\n    )\n\n    response = self.session.patch(\n        release_endpoint,\n        json={\"body\": release_notes},\n    )\n\n    # Raise an error if the request was not successful\n    response.raise_for_status()\n\n    return release_id", "loc": 23}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitea.py", "class_name": "Gitea", "function_name": "create_or_update_release", "parameters": ["self", "tag", "release_notes", "prerelease"], "param_types": {"tag": "str", "release_notes": "str", "prerelease": "bool"}, "return_type": "int", "param_doc": {"version": "The version number", "changelog": "The release notes for this version"}, "return_doc": "The status of the request", "raises_doc": [], "called_functions": ["ValueError", "logged_function", "logger.debug", "logger.info", "self.create_release", "self.edit_release_notes", "self.get_release_id_by_tag"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Post release changelog", "source_code": "def create_or_update_release(\n    self, tag: str, release_notes: str, prerelease: bool = False\n) -> int:\n    \"\"\"\n    Post release changelog\n    :param version: The version number\n    :param changelog: The release notes for this version\n\n    :return: The status of the request\n    \"\"\"\n    logger.info(\"Creating release for %s\", tag)\n    try:\n        return self.create_release(tag, release_notes, prerelease)\n    except HTTPError as err:\n        logger.debug(\"error creating release: %s\", err)\n        logger.debug(\"looking for an existing release to update\")\n\n    release_id = self.get_release_id_by_tag(tag)\n    if release_id is None:\n        raise ValueError(\n            f\"release id for tag {tag} not found, and could not be created\"\n        )\n\n    # If this errors we let it die\n    logger.debug(\"Found existing release %s, updating\", release_id)\n    return self.edit_release_notes(release_id, release_notes)", "loc": 26}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitea.py", "class_name": "Gitea", "function_name": "asset_upload_url", "parameters": ["self", "release_id"], "param_types": {"release_id": "str"}, "return_type": "str", "param_doc": {"release_id": "ID of the release to upload to"}, "return_doc": "", "raises_doc": [], "called_functions": ["logged_function", "self.create_api_url"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Get the correct upload url for a release https://gitea.com/api/swagger#/repository/repoCreateReleaseAttachment", "source_code": "def asset_upload_url(self, release_id: str) -> str:\n    \"\"\"\n    Get the correct upload url for a release\n    https://gitea.com/api/swagger#/repository/repoCreateReleaseAttachment\n    :param release_id: ID of the release to upload to\n    \"\"\"\n    return self.create_api_url(\n        endpoint=f\"/repos/{self.owner}/{self.repo_name}/releases/{release_id}/assets\",\n    )", "loc": 9}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitea.py", "class_name": "Gitea", "function_name": "remote_url", "parameters": ["self", "use_token"], "param_types": {"use_token": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.create_server_url"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Get the remote url including the token for authentication if requested", "source_code": "def remote_url(self, use_token: bool = True) -> str:\n    \"\"\"Get the remote url including the token for authentication if requested\"\"\"\n    if not (self.token and use_token):\n        return self._remote_url\n\n    return self.create_server_url(\n        auth=self.token,\n        path=f\"{self.owner}/{self.repo_name}.git\",\n    )", "loc": 9}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitea.py", "class_name": "Gitea", "function_name": "issue_url", "parameters": ["self", "issue_num"], "param_types": {"issue_num": "str | int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "isinstance", "match.group", "regexp", "regexp('(\\\\d+)$').search", "self.create_repo_url"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def issue_url(self, issue_num: str | int) -> str:\n    # Strips off any character prefix like '#' that usually exists\n    if isinstance(issue_num, str) and (\n        match := regexp(r\"(\\d+)$\").search(issue_num)\n    ):\n        try:\n            issue_num = int(match.group(1))\n        except ValueError:\n            return \"\"\n\n    if isinstance(issue_num, int):\n        return self.create_repo_url(repo_path=f\"/issues/{issue_num}\")\n\n    return \"\"", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitea.py", "class_name": "Gitea", "function_name": "pull_request_url", "parameters": ["self", "pr_number"], "param_types": {"pr_number": "str | int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "isinstance", "match.group", "regexp", "regexp('(\\\\d+)$').search", "self.create_repo_url"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def pull_request_url(self, pr_number: str | int) -> str:\n    # Strips off any character prefix like '#' that usually exists\n    if isinstance(pr_number, str) and (\n        match := regexp(r\"(\\d+)$\").search(pr_number)\n    ):\n        try:\n            pr_number = int(match.group(1))\n        except ValueError:\n            return \"\"\n\n    if isinstance(pr_number, int):\n        return self.create_repo_url(repo_path=f\"/pulls/{pr_number}\")\n\n    return \"\"", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitea.py", "class_name": "Gitea", "function_name": "format_w_official_vcs_name", "parameters": ["format_str"], "param_types": {"format_str": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["format_str.format"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_w_official_vcs_name(format_str: str) -> str:\n    if \"%s\" in format_str:\n        return format_str % Gitea.OFFICIAL_NAME\n\n    if \"{}\" in format_str:\n        return format_str.format(Gitea.OFFICIAL_NAME)\n\n    if \"{vcs_name}\" in format_str:\n        return format_str.format(vcs_name=Gitea.OFFICIAL_NAME)\n\n    return format_str", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\github.py", "class_name": "Github", "function_name": "create_release", "parameters": ["self", "tag", "release_notes", "prerelease", "assets", "noop"], "param_types": {"tag": "str", "release_notes": "str", "prerelease": "bool", "assets": "list[str] | None", "noop": "bool"}, "return_type": "int", "param_doc": {"tag": "Tag to create release for", "release_notes": "The release notes for this version", "prerelease": "Whether or not this release should be created as a prerelease", "assets": "a list of artifacts to upload to the release"}, "return_doc": "the ID of the release", "raises_doc": [], "called_functions": ["AssetUploadError", "AssetUploadError(f'Failed asset upload for {asset}').with_traceback", "IncompleteReleaseError", "UnexpectedResponse", "errors.append", "len", "logged_function", "logger.exception", "logger.info", "noop_report", "response.json", "response.raise_for_status", "self.create_api_url", "self.session.post", "self.upload_release_asset", "str.join"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Create a new release REF: https://docs.github.com/rest/reference/repos#create-a-release", "source_code": "def create_release(\n    self,\n    tag: str,\n    release_notes: str,\n    prerelease: bool = False,\n    assets: list[str] | None = None,\n    noop: bool = False,\n) -> int:\n    \"\"\"\n    Create a new release\n\n    REF: https://docs.github.com/rest/reference/repos#create-a-release\n\n    :param tag: Tag to create release for\n\n    :param release_notes: The release notes for this version\n\n    :param prerelease: Whether or not this release should be created as a prerelease\n\n    :param assets: a list of artifacts to upload to the release\n\n    :return: the ID of the release\n    \"\"\"\n    if noop:\n        noop_report(\n            str.join(\n                \" \",\n                [\n                    f\"would have created a release for tag {tag}\",\n                    \"with the following notes:\\n\",\n                    release_notes,\n                ],\n            )\n        )\n        if assets:\n            noop_report(\n                str.join(\n                    \"\\n\",\n                    [\n                        \"would have uploaded the following assets to the release:\",\n                        *assets,\n                    ],\n                )\n            )\n        return -1\n\n    logger.info(\"Creating release for tag %s\", tag)\n    releases_endpoint = self.create_api_url(\n        endpoint=f\"/repos/{self.owner}/{self.repo_name}/releases\",\n    )\n    response = self.session.post(\n        releases_endpoint,\n        json={\n            \"tag_name\": tag,\n            \"name\": tag,\n            \"body\": release_notes,\n            \"draft\": False,\n            \"prerelease\": prerelease,\n        },\n    )\n\n    # Raise an error if the request was not successful\n    response.raise_for_status()\n\n    try:\n        release_id: int = response.json()[\"id\"]\n        logger.info(\"Successfully created release with ID: %s\", release_id)\n    except JSONDecodeError as err:\n        raise UnexpectedResponse(\"Unreadable json response\") from err\n    except KeyError as err:\n        raise UnexpectedResponse(\"JSON response is missing an id\") from err\n\n    errors = []\n    for asset in assets or []:\n        logger.info(\"Uploading asset %s\", asset)\n        try:\n            self.upload_release_asset(release_id, asset)\n        except HTTPError as err:\n            errors.append(\n                AssetUploadError(f\"Failed asset upload for {asset}\").with_traceback(\n                    err.__traceback__\n                )\n            )\n\n    if len(errors) < 1:\n        return release_id\n\n    for error in errors:\n        logger.exception(error)\n\n    raise IncompleteReleaseError(\n        f\"Failed to upload asset{'s' if len(errors) > 1 else ''} to release!\"\n    )", "loc": 93}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\github.py", "class_name": "Github", "function_name": "get_release_id_by_tag", "parameters": ["self", "tag"], "param_types": {"tag": "str"}, "return_type": "int | None", "param_doc": {"tag": "Tag to get release for"}, "return_doc": "ID of release, if found, else None", "raises_doc": [], "called_functions": ["UnexpectedResponse", "logged_function", "response.json", "response.raise_for_status", "self.create_api_url", "self.session.get"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Get a release by its tag name https://docs.github.com/rest/reference/repos#get-a-release-by-tag-name", "source_code": "def get_release_id_by_tag(self, tag: str) -> int | None:\n    \"\"\"\n    Get a release by its tag name\n    https://docs.github.com/rest/reference/repos#get-a-release-by-tag-name\n    :param tag: Tag to get release for\n    :return: ID of release, if found, else None\n    \"\"\"\n    tag_endpoint = self.create_api_url(\n        endpoint=f\"/repos/{self.owner}/{self.repo_name}/releases/tags/{tag}\",\n    )\n    response = self.session.get(tag_endpoint)\n\n    # Raise an error if the request was not successful\n    response.raise_for_status()\n\n    try:\n        data = response.json()\n        return data[\"id\"]\n    except JSONDecodeError as err:\n        raise UnexpectedResponse(\"Unreadable json response\") from err\n    except KeyError as err:\n        raise UnexpectedResponse(\"JSON response is missing an id\") from err", "loc": 22}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\github.py", "class_name": "Github", "function_name": "edit_release_notes", "parameters": ["self", "release_id", "release_notes"], "param_types": {"release_id": "int", "release_notes": "str"}, "return_type": "int", "param_doc": {"release_id": "ID of release to update", "release_notes": "The release notes for this version"}, "return_doc": "The ID of the release that was edited", "raises_doc": [], "called_functions": ["logged_function", "logger.info", "response.raise_for_status", "self.create_api_url", "self.session.post"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Edit a release with updated change notes https://docs.github.com/rest/reference/repos#update-a-release", "source_code": "def edit_release_notes(self, release_id: int, release_notes: str) -> int:\n    \"\"\"\n    Edit a release with updated change notes\n    https://docs.github.com/rest/reference/repos#update-a-release\n    :param release_id: ID of release to update\n    :param release_notes: The release notes for this version\n    :return: The ID of the release that was edited\n    \"\"\"\n    logger.info(\"Updating release %s\", release_id)\n    release_endpoint = self.create_api_url(\n        endpoint=f\"/repos/{self.owner}/{self.repo_name}/releases/{release_id}\",\n    )\n\n    response = self.session.post(\n        release_endpoint,\n        json={\"body\": release_notes},\n    )\n\n    # Raise an error if the update was unsuccessful\n    response.raise_for_status()\n\n    return release_id", "loc": 22}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\github.py", "class_name": "Github", "function_name": "create_or_update_release", "parameters": ["self", "tag", "release_notes", "prerelease"], "param_types": {"tag": "str", "release_notes": "str", "prerelease": "bool"}, "return_type": "int", "param_doc": {"tag": "The version number", "release_notes": "The release notes for this version", "prerelease": "Whether or not this release should be created as a prerelease"}, "return_doc": "The status of the request", "raises_doc": [], "called_functions": ["ValueError", "logged_function", "logger.debug", "logger.info", "self.create_release", "self.edit_release_notes", "self.get_release_id_by_tag"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Post release changelog", "source_code": "def create_or_update_release(\n    self, tag: str, release_notes: str, prerelease: bool = False\n) -> int:\n    \"\"\"\n    Post release changelog\n    :param tag: The version number\n    :param release_notes: The release notes for this version\n    :param prerelease: Whether or not this release should be created as a prerelease\n    :return: The status of the request\n    \"\"\"\n    logger.info(\"Creating release for %s\", tag)\n    try:\n        return self.create_release(tag, release_notes, prerelease)\n    except HTTPError as err:\n        logger.debug(\"error creating release: %s\", err)\n        logger.debug(\"looking for an existing release to update\")\n\n    release_id = self.get_release_id_by_tag(tag)\n    if release_id is None:\n        raise ValueError(\n            f\"release id for tag {tag} not found, and could not be created\"\n        )\n\n    logger.debug(\"Found existing release %s, updating\", release_id)\n    # If this errors we let it die\n    return self.edit_release_notes(release_id, release_notes)", "loc": 26}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\github.py", "class_name": "Github", "function_name": "asset_upload_url", "parameters": ["self", "release_id"], "param_types": {"release_id": "str"}, "return_type": "str | None", "param_doc": {"release_id": "ID of the release to upload to"}, "return_doc": "URL to upload for a release if found, else None", "raises_doc": [], "called_functions": ["UnexpectedResponse", "logged_function", "response.json", "response.raise_for_status", "self.create_api_url", "self.session.get", "upload_url.replace"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Get the correct upload url for a release https://docs.github.com/en/enterprise-server@3.5/rest/releases/releases#get-a-release", "source_code": "def asset_upload_url(self, release_id: str) -> str | None:\n    \"\"\"\n    Get the correct upload url for a release\n    https://docs.github.com/en/enterprise-server@3.5/rest/releases/releases#get-a-release\n    :param release_id: ID of the release to upload to\n    :return: URL to upload for a release if found, else None\n    \"\"\"\n    # https://docs.github.com/en/enterprise-server@3.5/rest/releases/assets#upload-a-release-asset\n    release_url = self.create_api_url(\n        endpoint=f\"/repos/{self.owner}/{self.repo_name}/releases/{release_id}\"\n    )\n\n    response = self.session.get(release_url)\n    response.raise_for_status()\n\n    try:\n        upload_url: str = response.json()[\"upload_url\"]\n        return upload_url.replace(\"{?name,label}\", \"\")\n    except JSONDecodeError as err:\n        raise UnexpectedResponse(\"Unreadable json response\") from err\n    except KeyError as err:\n        raise UnexpectedResponse(\n            \"JSON response is missing a key 'upload_url'\"\n        ) from err", "loc": 24}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\github.py", "class_name": "Github", "function_name": "remote_url", "parameters": ["self", "use_token"], "param_types": {"use_token": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.info", "os.getenv", "self.create_server_url"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Get the remote url including the token for authentication if requested", "source_code": "def remote_url(self, use_token: bool = True) -> str:\n    \"\"\"Get the remote url including the token for authentication if requested\"\"\"\n    if not (self.token and use_token):\n        logger.info(\"requested to use token for push but no token set, ignoring...\")\n        return self._remote_url\n\n    actor = os.getenv(\"GITHUB_ACTOR\", None)\n    return self.create_server_url(\n        auth=f\"{actor}:{self.token}\" if actor else self.token,\n        path=f\"/{self.owner}/{self.repo_name}.git\",\n    )", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\github.py", "class_name": "Github", "function_name": "issue_url", "parameters": ["self", "issue_num"], "param_types": {"issue_num": "str | int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "isinstance", "match.group", "regexp", "regexp('(\\\\d+)$').search", "self.create_repo_url"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def issue_url(self, issue_num: str | int) -> str:\n    # Strips off any character prefix like '#' that usually exists\n    if isinstance(issue_num, str) and (\n        match := regexp(r\"(\\d+)$\").search(issue_num)\n    ):\n        try:\n            issue_num = int(match.group(1))\n        except ValueError:\n            return \"\"\n\n    if isinstance(issue_num, int):\n        return self.create_repo_url(repo_path=f\"/issues/{issue_num}\")\n\n    return \"\"", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\github.py", "class_name": "Github", "function_name": "pull_request_url", "parameters": ["self", "pr_number"], "param_types": {"pr_number": "str | int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "isinstance", "match.group", "regexp", "regexp('(\\\\d+)$').search", "self.create_repo_url"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def pull_request_url(self, pr_number: str | int) -> str:\n    # Strips off any character prefix like '#' that usually exists\n    if isinstance(pr_number, str) and (\n        match := regexp(r\"(\\d+)$\").search(pr_number)\n    ):\n        try:\n            pr_number = int(match.group(1))\n        except ValueError:\n            return \"\"\n\n    if isinstance(pr_number, int):\n        return self.create_repo_url(repo_path=f\"/pull/{pr_number}\")\n\n    return \"\"", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\github.py", "class_name": "Github", "function_name": "format_w_official_vcs_name", "parameters": ["format_str"], "param_types": {"format_str": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["format_str.format"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_w_official_vcs_name(format_str: str) -> str:\n    if \"%s\" in format_str:\n        return format_str % Github.OFFICIAL_NAME\n\n    if \"{}\" in format_str:\n        return format_str.format(Github.OFFICIAL_NAME)\n\n    if \"{vcs_name}\" in format_str:\n        return format_str.format(vcs_name=Github.OFFICIAL_NAME)\n\n    return format_str", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitlab.py", "class_name": "Gitlab", "function_name": "create_release", "parameters": ["self", "tag", "release_notes", "prerelease", "assets", "noop"], "param_types": {"tag": "str", "release_notes": "str", "prerelease": "bool", "assets": "list[str] | None", "noop": "bool"}, "return_type": "str", "param_doc": {"tag": "The tag to create the release for", "release_notes": "The changelog description for this version only", "prerelease": "This parameter has no effect in GitLab", "assets": "A list of paths to files to upload as assets (TODO: not implemented)", "noop": "If True, do not perform any actions, only logger intents"}, "return_doc": "The tag of the release", "raises_doc": [], "called_functions": ["logged_function", "logger.info", "noop_report", "self.project.releases.create"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Create a release in a remote VCS, adding any release notes and assets to it", "source_code": "def create_release(\n    self,\n    tag: str,\n    release_notes: str,\n    prerelease: bool = False,  # noqa: ARG002\n    assets: list[str] | None = None,  # noqa: ARG002\n    noop: bool = False,\n) -> str:\n    \"\"\"\n    Create a release in a remote VCS, adding any release notes and assets to it\n\n    :param tag: The tag to create the release for\n    :param release_notes: The changelog description for this version only\n    :param prerelease: This parameter has no effect in GitLab\n    :param assets: A list of paths to files to upload as assets (TODO: not implemented)\n    :param noop: If True, do not perform any actions, only logger intents\n\n    :return: The tag of the release\n\n    :raises: GitlabAuthenticationError: If authentication is not correct\n    :raises: GitlabCreateError: If the server cannot perform the request\n    \"\"\"\n    if noop:\n        noop_report(f\"would have created a release for tag {tag}\")\n        return tag\n\n    logger.info(\"Creating release for %s\", tag)\n    # ref: https://docs.gitlab.com/ee/api/releases/index.html#create-a-release\n    self.project.releases.create(\n        {\n            \"name\": tag,\n            \"tag_name\": tag,\n            \"tag_message\": tag,\n            \"description\": release_notes,\n        }\n    )\n    logger.info(\"Successfully created release for %s\", tag)\n    return tag", "loc": 38}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitlab.py", "class_name": "Gitlab", "function_name": "get_release_by_tag", "parameters": ["self", "tag"], "param_types": {"tag": "str"}, "return_type": "gitlab.v4.objects.ProjectRelease | None", "param_doc": {"tag": "The tag name to get the release for"}, "return_doc": "gitlab.v4.objects.ProjectRelease or None if not found", "raises_doc": [], "called_functions": ["UnexpectedResponse", "logged_function", "logger.debug", "self.project.releases.get"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Get a release by its tag name.", "source_code": "def get_release_by_tag(self, tag: str) -> gitlab.v4.objects.ProjectRelease | None:\n    \"\"\"\n    Get a release by its tag name.\n\n    :param tag: The tag name to get the release for\n\n    :return: gitlab.v4.objects.ProjectRelease or None if not found\n\n    :raises: gitlab.exceptions.GitlabAuthenticationError: If the user is not authenticated\n    \"\"\"\n    try:\n        return self.project.releases.get(tag)\n    except gitlab.exceptions.GitlabGetError:\n        logger.debug(\"Release %s not found\", tag)\n        return None\n    except KeyError as err:\n        raise UnexpectedResponse(\"JSON response is missing commit.id\") from err", "loc": 17}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitlab.py", "class_name": "Gitlab", "function_name": "edit_release_notes", "parameters": ["self", "release", "release_notes"], "param_types": {"release": "gitlab.v4.objects.ProjectRelease", "release_notes": "str"}, "return_type": "str", "param_doc": {"release": "The release object to update", "release_notes": "The new release notes"}, "return_doc": "The release id", "raises_doc": [], "called_functions": ["logged_function", "logger.info", "release.attributes.get", "release.attributes.get('commit', {}).get", "release.get_id", "release.save", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Update the release notes for a given release.", "source_code": "def edit_release_notes(  # type: ignore[override]\n    self,\n    release: gitlab.v4.objects.ProjectRelease,\n    release_notes: str,\n) -> str:\n    \"\"\"\n    Update the release notes for a given release.\n\n    :param release: The release object to update\n    :param release_notes: The new release notes\n\n    :return: The release id\n\n    :raises: GitlabAuthenticationError: If authentication is not correct\n    :raises: GitlabUpdateError: If the server cannot perform the request\n\n    \"\"\"\n    logger.info(\n        \"Updating release %s [%s]\",\n        release.name,\n        release.attributes.get(\"commit\", {}).get(\"id\"),\n    )\n    release.description = release_notes\n    release.save()\n    return str(release.get_id())", "loc": 25}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitlab.py", "class_name": "Gitlab", "function_name": "create_or_update_release", "parameters": ["self", "tag", "release_notes", "prerelease"], "param_types": {"tag": "str", "release_notes": "str", "prerelease": "bool"}, "return_type": "str", "param_doc": {"tag": "The tag to create or update the release for", "release_notes": "The changelog description for this version only", "prerelease": "This parameter has no effect in GitLab"}, "return_doc": "The release id", "raises_doc": [{"type": "ValueError", "desc": "If the release could not be created or updated"}, {"type": "GitlabUpdateError", "desc": "If the server cannot perform the request"}], "called_functions": ["ValueError", "logged_function", "logger.debug", "logger.info", "release_obj.commit.get", "self.create_release", "self.edit_release_notes", "self.get_release_by_tag"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Create or update a release for the given tag in a remote VCS.", "source_code": "def create_or_update_release(\n    self, tag: str, release_notes: str, prerelease: bool = False\n) -> str:\n    \"\"\"\n    Create or update a release for the given tag in a remote VCS.\n\n    :param tag: The tag to create or update the release for\n    :param release_notes: The changelog description for this version only\n    :param prerelease: This parameter has no effect in GitLab\n\n    :return: The release id\n\n    :raises ValueError: If the release could not be created or updated\n    :raises gitlab.exceptions.GitlabAuthenticationError: If the user is not authenticated\n    :raises GitlabUpdateError: If the server cannot perform the request\n    \"\"\"\n    try:\n        return self.create_release(\n            tag=tag, release_notes=release_notes, prerelease=prerelease\n        )\n    except gitlab.GitlabCreateError:\n        logger.info(\n            \"New release %s could not be created for project %s\",\n            tag,\n            self.project_namespace,\n        )\n\n    if (release_obj := self.get_release_by_tag(tag)) is None:\n        raise ValueError(\n            f\"release for tag {tag} could not be found, and could not be created\"\n        )\n\n    logger.debug(\n        \"Found existing release commit %s, updating\", release_obj.commit.get(\"id\")\n    )\n    # If this errors we let it die\n    return self.edit_release_notes(\n        release=release_obj,\n        release_notes=release_notes,\n    )", "loc": 40}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitlab.py", "class_name": "Gitlab", "function_name": "remote_url", "parameters": ["self", "use_token"], "param_types": {"use_token": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.create_server_url"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Get the remote url including the token for authentication if requested", "source_code": "def remote_url(self, use_token: bool = True) -> str:\n    \"\"\"Get the remote url including the token for authentication if requested\"\"\"\n    if not (self.token and use_token):\n        return self._remote_url\n\n    return self.create_server_url(\n        auth=f\"gitlab-ci-token:{self.token}\",\n        path=f\"{self.project_namespace}.git\",\n    )", "loc": 9}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitlab.py", "class_name": "Gitlab", "function_name": "issue_url", "parameters": ["self", "issue_num"], "param_types": {"issue_num": "str | int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "isinstance", "match.group", "regexp", "regexp('(\\\\d+)$').search", "self.create_repo_url"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def issue_url(self, issue_num: str | int) -> str:\n    # Strips off any character prefix like '#' that usually exists\n    if isinstance(issue_num, str) and (\n        match := regexp(r\"(\\d+)$\").search(issue_num)\n    ):\n        try:\n            issue_num = int(match.group(1))\n        except ValueError:\n            return \"\"\n\n    if isinstance(issue_num, int):\n        return self.create_repo_url(repo_path=f\"/-/issues/{issue_num}\")\n\n    return \"\"", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitlab.py", "class_name": "Gitlab", "function_name": "merge_request_url", "parameters": ["self", "mr_number"], "param_types": {"mr_number": "str | int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "isinstance", "match.group", "regexp", "regexp('(\\\\d+)$').search", "self.create_repo_url"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def merge_request_url(self, mr_number: str | int) -> str:\n    # Strips off any character prefix like '!' that usually exists\n    if isinstance(mr_number, str) and (\n        match := regexp(r\"(\\d+)$\").search(mr_number)\n    ):\n        try:\n            mr_number = int(match.group(1))\n        except ValueError:\n            return \"\"\n\n    if isinstance(mr_number, int):\n        return self.create_repo_url(repo_path=f\"/-/merge_requests/{mr_number}\")\n\n    return \"\"", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\gitlab.py", "class_name": "Gitlab", "function_name": "format_w_official_vcs_name", "parameters": ["format_str"], "param_types": {"format_str": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["format_str.format"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_w_official_vcs_name(format_str: str) -> str:\n    if \"%s\" in format_str:\n        return format_str % Gitlab.OFFICIAL_NAME\n\n    if \"{}\" in format_str:\n        return format_str.format(Gitlab.OFFICIAL_NAME)\n\n    if \"{vcs_name}\" in format_str:\n        return format_str.format(vcs_name=Gitlab.OFFICIAL_NAME)\n\n    return format_str", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\remote_hvcs_base.py", "class_name": "RemoteHvcsBase", "function_name": "create_server_url", "parameters": ["self", "path", "auth", "query", "fragment"], "param_types": {"path": "str", "auth": "str | None", "query": "str | None", "fragment": "str | None"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["path.startswith", "self._derive_url"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_server_url(\n    self,\n    path: str,\n    auth: str | None = None,\n    query: str | None = None,\n    fragment: str | None = None,\n) -> str:\n    # Ensure any path prefix is transferred but not doubled up on the derived url\n    normalized_path = (\n        f\"{self.hvcs_domain.path}/{path}\"\n        if self.hvcs_domain.path and not path.startswith(self.hvcs_domain.path)\n        else path\n    )\n    return self._derive_url(\n        self.hvcs_domain,\n        path=normalized_path,\n        auth=auth,\n        query=query,\n        fragment=fragment,\n    )", "loc": 20}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\remote_hvcs_base.py", "class_name": "RemoteHvcsBase", "function_name": "create_api_url", "parameters": ["self", "endpoint", "auth", "query", "fragment"], "param_types": {"endpoint": "str", "auth": "str | None", "query": "str | None", "fragment": "str | None"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["endpoint.startswith", "self._derive_url"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_api_url(\n    self,\n    endpoint: str,\n    auth: str | None = None,\n    query: str | None = None,\n    fragment: str | None = None,\n) -> str:\n    # Ensure any api path prefix is transferred but not doubled up on the derived api url\n    normalized_endpoint = (\n        f\"{self.api_url.path}/{endpoint}\"\n        if self.api_url.path and not endpoint.startswith(self.api_url.path)\n        else endpoint\n    )\n    return self._derive_url(\n        self.api_url,\n        path=normalized_endpoint,\n        auth=auth,\n        query=query,\n        fragment=fragment,\n    )", "loc": 20}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\util.py", "class_name": null, "function_name": "build_requests_session", "parameters": ["raise_for_status", "retry", "auth"], "param_types": {"raise_for_status": "bool", "retry": "bool | int | Retry", "auth": "TokenAuth | None"}, "return_type": "Session", "param_doc": {"raise_for_status": "If True, a hook to invoke raise_for_status be installed", "retry": "If true, it will use default Retry configuration. if an integer, it", "auth": "Optional TokenAuth instance to be used to provide the Authorization"}, "return_doc": "configured requests Session", "raises_doc": [], "called_functions": ["HTTPAdapter", "Retry", "Session", "ValueError", "isinstance", "logger.debug", "r.raise_for_status", "session.mount"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Create a requests session.", "source_code": "def build_requests_session(\n    raise_for_status: bool = True,\n    retry: bool | int | Retry = True,\n    auth: TokenAuth | None = None,\n) -> Session:\n    \"\"\"\n    Create a requests session.\n\n    :param raise_for_status: If True, a hook to invoke raise_for_status be installed\n    :param retry: If true, it will use default Retry configuration. if an integer, it\n        will use default Retry configuration with given integer as total retry\n        count. if Retry instance, it will use this instance.\n    :param auth: Optional TokenAuth instance to be used to provide the Authorization\n        header to the session\n\n    :return: configured requests Session\n    \"\"\"\n    session = Session()\n    if raise_for_status:\n        session.hooks = {\"response\": [lambda r, *_, **__: r.raise_for_status()]}\n\n    if retry:\n        if isinstance(retry, bool):\n            retry = Retry()\n        elif isinstance(retry, int):\n            retry = Retry(retry)\n        elif not isinstance(retry, Retry):\n            raise ValueError(\"retry should be a bool, int or Retry instance.\")\n        adapter = HTTPAdapter(max_retries=retry)\n        session.mount(\"http://\", adapter)\n        session.mount(\"https://\", adapter)\n\n    if auth:\n        logger.debug(\"setting up default session authentication\")\n        session.auth = auth\n\n    return session", "loc": 37}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\util.py", "class_name": null, "function_name": "suppress_http_error_for_codes", "parameters": [], "param_types": {}, "return_type": "Callable[[Callable[..., _R]], Callable[..., _R | None]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["func", "logger.warning", "str", "wraps"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "For the codes given, return a decorator that will suppress HTTPErrors that are raised from responses that came with one of those status codes. The function will return False instead of raising the HTTPError", "source_code": "def suppress_http_error_for_codes(\n    *codes: int,\n) -> Callable[[Callable[..., _R]], Callable[..., _R | None]]:\n    \"\"\"\n    For the codes given, return a decorator that will suppress HTTPErrors that are\n    raised from responses that came with one of those status codes. The function will\n    return False instead of raising the HTTPError\n    \"\"\"\n\n    def _suppress_http_error_for_codes(\n        func: Callable[..., _R],\n    ) -> Callable[..., _R | None]:\n        @wraps(func)\n        def _wrapper(*a: Any, **kw: Any) -> _R | None:\n            try:\n                return func(*a, **kw)\n            except HTTPError as err:\n                if err.response and err.response.status_code in codes:\n                    logger.warning(\n                        \"%s received response %s: %s\",\n                        func.__qualname__,\n                        err.response.status_code,\n                        str(err),\n                    )\n                return None\n\n        return _wrapper\n\n    return _suppress_http_error_for_codes", "loc": 29}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\_base.py", "class_name": "HvcsBase", "function_name": "repo_name", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_repository_owner_and_name"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def repo_name(self) -> str:\n    if self._name is None:\n        _, name = self._get_repository_owner_and_name()\n        self._name = name\n    return self._name", "loc": 5}
{"file": "python-semantic-release\\src\\semantic_release\\hvcs\\_base.py", "class_name": "HvcsBase", "function_name": "owner", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_repository_owner_and_name"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def owner(self) -> str:\n    if self._owner is None:\n        _owner, _ = self._get_repository_owner_and_name()\n        self._owner = _owner\n    return self._owner", "loc": 5}
{"file": "python-semantic-release\\src\\semantic_release\\version\\algorithm.py", "class_name": null, "function_name": "tags_and_versions", "parameters": ["tags", "translator"], "param_types": {"tags": "Iterable[Tag]", "translator": "VersionTranslator"}, "return_type": "list[tuple[Tag, Version]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "logger.info", "logger.isEnabledFor", "logger.warning", "sorted", "str", "translator.from_tag", "ts_and_vs.append"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Return a list of 2-tuples, where each element is a tuple (tag, version) from the tags in the Git repo and their corresponding `Version` according to `Version.from_tag`. The returned list is sorted according to semver", "source_code": "def tags_and_versions(\n    tags: Iterable[Tag], translator: VersionTranslator\n) -> list[tuple[Tag, Version]]:\n    \"\"\"\n    Return a list of 2-tuples, where each element is a tuple (tag, version)\n    from the tags in the Git repo and their corresponding `Version` according\n    to `Version.from_tag`. The returned list is sorted according to semver\n    ordering rules.\n\n    Tags which are not matched by `translator` are ignored.\n    \"\"\"\n    ts_and_vs: list[tuple[Tag, Version]] = []\n    for tag in tags:\n        try:\n            version = translator.from_tag(tag.name)\n        except (NotImplementedError, InvalidVersion) as e:\n            logger.warning(\n                \"Couldn't parse tag %s as as Version: %s\",\n                tag.name,\n                str(e),\n                exc_info=logger.isEnabledFor(logging.DEBUG),\n            )\n            continue\n\n        if version:\n            ts_and_vs.append((tag, version))\n\n    logger.info(\"found %s previous tags\", len(ts_and_vs))\n    return sorted(ts_and_vs, reverse=True, key=lambda v: v[1])", "loc": 29}
{"file": "python-semantic-release\\src\\semantic_release\\version\\algorithm.py", "class_name": null, "function_name": "dfs", "parameters": ["start_commit", "stop_nodes"], "param_types": {"start_commit": "Commit", "stop_nodes": "set[Commit]"}, "return_type": "Sequence[Commit]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["LifoQueue", "commits.append", "set", "stack.empty", "stack.get", "stack.put", "visited.add"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dfs(start_commit: Commit, stop_nodes: set[Commit]) -> Sequence[Commit]:\n    # Create a stack for DFS\n    stack: LifoQueue[Commit] = LifoQueue()\n\n    # Create a set to store visited graph nodes (commit objects in this case)\n    visited: set[Commit] = set()\n\n    # Initialize the result\n    commits: list[Commit] = []\n\n    # Add the source node in the queue to start the search\n    stack.put(start_commit)\n\n    # Traverse the git history capturing each commit found before it reaches a stop node\n    while not stack.empty():\n        if (node := stack.get()) in visited or node in stop_nodes:\n            continue\n\n        visited.add(node)\n        commits.append(node)\n\n        # Add all parent commits to the stack from left to right so that the rightmost is popped first\n        # as the left side is generally the merged into branch\n        for parent in node.parents:\n            stack.put(parent)\n\n    return commits", "loc": 27}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declaration.py", "class_name": "VersionDeclarationABC", "function_name": "content", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.debug", "self.path.read_text", "self.path.resolve"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The content of the source file in which the version is stored. This property is cached in the instance variable _content", "source_code": "def content(self) -> str:\n    \"\"\"\n    The content of the source file in which the version is stored. This property\n    is cached in the instance variable _content\n    \"\"\"\n    if self._content is None:\n        logger.debug(\n            \"No content stored, reading from source file %s\", self.path.resolve()\n        )\n        self._content = self.path.read_text()\n    return self._content", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declaration.py", "class_name": "VersionDeclarationABC", "function_name": "write", "parameters": ["self", "content"], "param_types": {"content": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.debug", "self.path.resolve", "self.path.write_text"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Write new content back to the source path. Use alongside .replace(): >>> class MyVD(VersionDeclarationABC):", "source_code": "def write(self, content: str) -> None:\n    r\"\"\"\n    Write new content back to the source path.\n    Use alongside .replace():\n    >>> class MyVD(VersionDeclarationABC):\n    ...     def parse(self): ...\n    ...     def replace(self, new_version: Version): ...\n    ...     def write(self, content: str): ...\n\n    >>> new_version = Version.parse(\"1.2.3\")\n    >>> vd = MyVD(\"path\", r\"__version__ = (?P<version>\\d+\\d+\\d+)\")\n    >>> vd.write(vd.replace(new_version))\n    \"\"\"\n    logger.debug(\"writing content to %r\", self.path.resolve())\n    self.path.write_text(content)\n    self._content = None", "loc": 16}
{"file": "python-semantic-release\\src\\semantic_release\\version\\translator.py", "class_name": "VersionTranslator", "function_name": "from_tag", "parameters": ["self", "tag"], "param_types": {"tag": "str"}, "return_type": "Version | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.from_string", "self.from_tag_re.match", "tag_match.group"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return a Version instance from a Git tag, if tag_format matches the format which would have generated the tag from a version. Otherwise return None. For example, a tag of 'v1.2.3' should be matched if `tag_format = 'v{version}`,", "source_code": "def from_tag(self, tag: str) -> Version | None:\n    \"\"\"\n    Return a Version instance from a Git tag, if tag_format matches the format\n    which would have generated the tag from a version. Otherwise return None.\n    For example, a tag of 'v1.2.3' should be matched if `tag_format = 'v{version}`,\n    but not if `tag_format = staging--v{version}`.\n    \"\"\"\n    tag_match = self.from_tag_re.match(tag)\n    if not tag_match:\n        return None\n    raw_version_str = tag_match.group(\"version\")\n    return self.from_string(raw_version_str)", "loc": 12}
{"file": "python-semantic-release\\src\\semantic_release\\version\\version.py", "class_name": "Version", "function_name": "parse", "parameters": ["cls", "version_str", "tag_format", "prerelease_token"], "param_types": {"version_str": "str", "tag_format": "str", "prerelease_token": "str"}, "return_type": "Version", "param_doc": {"prerelease_token": "will be ignored if the version string is a prerelease,"}, "return_doc": "", "raises_doc": [], "called_functions": ["InvalidVersion", "NotImplementedError", "Version", "cls._VERSION_REGEX.fullmatch", "int", "isinstance", "logger.debug", "match.group", "pm.groups", "re.match"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse version string to a Version instance. Inspired by `semver.version:VersionInfo.parse`, this implementation doesn't allow optional minor and patch versions.", "source_code": "def parse(\n    cls,\n    version_str: str,\n    tag_format: str = \"v{version}\",\n    prerelease_token: str = \"rc\",  # noqa: S107\n) -> Version:\n    \"\"\"\n    Parse version string to a Version instance.\n    Inspired by `semver.version:VersionInfo.parse`, this implementation doesn't\n    allow optional minor and patch versions.\n\n    :param prerelease_token: will be ignored if the version string is a prerelease,\n        the parsed token from `version_str` will be used instead.\n    \"\"\"\n    if not isinstance(version_str, str):\n        raise InvalidVersion(f\"{version_str!r} cannot be parsed as a Version\")\n\n    logger.debug(\"attempting to parse string %r as Version\", version_str)\n    match = cls._VERSION_REGEX.fullmatch(version_str)\n    if not match:\n        raise InvalidVersion(f\"{version_str!r} is not a valid Version\")\n\n    prerelease = match.group(\"prerelease\")\n    if prerelease:\n        pm = re.match(r\"(?P<token>[a-zA-Z0-9-\\.]+)\\.(?P<revision>\\d+)\", prerelease)\n        if not pm:\n            raise NotImplementedError(\n                f\"{cls.__qualname__} currently supports only prereleases \"\n                r\"of the format (-([a-zA-Z0-9-])\\.\\(\\d+)), for example \"\n                r\"'1.2.3-my-custom-3rc.4'.\"\n            )\n        prerelease_token, prerelease_revision = pm.groups()\n        logger.debug(\n            \"parsed prerelease_token %s, prerelease_revision %s from version \"\n            \"string %s\",\n            prerelease_token,\n            prerelease_revision,\n            version_str,\n        )\n    else:\n        prerelease_revision = None\n        logger.debug(\"version string %s parsed as a non-prerelease\", version_str)\n\n    build_metadata = match.group(\"buildmetadata\") or \"\"\n    logger.debug(\n        \"parsed build metadata %r from version string %s\",\n        build_metadata,\n        version_str,\n    )\n\n    return Version(\n        int(match.group(\"major\")),\n        int(match.group(\"minor\")),\n        int(match.group(\"patch\")),\n        prerelease_token=prerelease_token,\n        prerelease_revision=(\n            int(prerelease_revision) if prerelease_revision else None\n        ),\n        build_metadata=build_metadata,\n        tag_format=tag_format,\n    )", "loc": 61}
{"file": "python-semantic-release\\src\\semantic_release\\version\\version.py", "class_name": "Version", "function_name": "bump", "parameters": ["self", "level"], "param_types": {"level": "LevelBump"}, "return_type": "Version", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TypeError", "Version", "logger.debug", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return a new Version instance according to the level specified to bump. Note this will intentionally drop the build metadata - that should be added elsewhere for the specific build producing this version.", "source_code": "def bump(self, level: LevelBump) -> Version:\n    \"\"\"\n    Return a new Version instance according to the level specified to bump.\n    Note this will intentionally drop the build metadata - that should be added\n    elsewhere for the specific build producing this version.\n    \"\"\"\n    if type(level) != LevelBump:\n        raise TypeError(f\"Unexpected level {level!r}: expected {LevelBump!r}\")\n\n    logger.debug(\"performing a %s level bump\", level)\n    if level is LevelBump.MAJOR:\n        return Version(\n            self.major + 1,\n            0,\n            0,\n            prerelease_token=self.prerelease_token,\n            prerelease_revision=1 if self.is_prerelease else None,\n            tag_format=self.tag_format,\n        )\n    if level is LevelBump.MINOR:\n        return Version(\n            self.major,\n            self.minor + 1,\n            0,\n            prerelease_token=self.prerelease_token,\n            prerelease_revision=1 if self.is_prerelease else None,\n            tag_format=self.tag_format,\n        )\n    if level is LevelBump.PATCH:\n        return Version(\n            self.major,\n            self.minor,\n            self.patch + 1,\n            prerelease_token=self.prerelease_token,\n            prerelease_revision=1 if self.is_prerelease else None,\n            tag_format=self.tag_format,\n        )\n    if level is LevelBump.PRERELEASE_REVISION:\n        return Version(\n            self.major,\n            self.minor,\n            self.patch,\n            prerelease_token=self.prerelease_token,\n            prerelease_revision=1\n            if not self.is_prerelease\n            else (self.prerelease_revision or 0) + 1,\n            tag_format=self.tag_format,\n        )\n    # for consistency, this creates a new instance regardless\n    # only other option is level is LevelBump.NO_RELEASE\n    return Version(\n        self.major,\n        self.minor,\n        self.patch,\n        prerelease_token=self.prerelease_token,\n        prerelease_revision=self.prerelease_revision,\n        tag_format=self.tag_format,\n    )", "loc": 58}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declarations\\pattern.py", "class_name": "PatternVersionDeclaration", "function_name": "content", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FileNotFoundError", "logger.debug", "self._path.exists", "self._path.read_text"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "A cached property that stores the content of the configured source file.", "source_code": "def content(self) -> str:\n    \"\"\"A cached property that stores the content of the configured source file.\"\"\"\n    if self._content is None:\n        logger.debug(\"No content stored, reading from source file %s\", self._path)\n\n        if not self._path.exists():\n            raise FileNotFoundError(f\"path {self._path!r} does not exist\")\n\n        self._content = self._path.read_text()\n\n    return self._content", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declarations\\pattern.py", "class_name": "PatternVersionDeclaration", "function_name": "parse", "parameters": ["self"], "param_types": {}, "return_type": "set[Version]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Version.parse", "deprecated", "len", "logger.debug", "m.group", "self._path.resolve", "self._search_pattern.finditer"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Return the versions matching this pattern. Because a pattern can match in multiple places, this method returns a set of matches.  Generally, there should only be one element in this", "source_code": "def parse(self) -> set[Version]:  # pragma: no cover\n    \"\"\"\n    Return the versions matching this pattern.\n    Because a pattern can match in multiple places, this method returns a\n    set of matches.  Generally, there should only be one element in this\n    set (i.e. even if the version is specified in multiple places, it\n    should be the same version in each place), but it falls on the caller\n    to check for this condition.\n    \"\"\"\n    versions = {\n        Version.parse(m.group(self._VERSION_GROUP_NAME))\n        for m in self._search_pattern.finditer(self.content)\n    }\n\n    logger.debug(\n        \"Parsing current version: path=%r pattern=%r num_matches=%s\",\n        self._path.resolve(),\n        self._search_pattern,\n        len(versions),\n    )\n    return versions", "loc": 21}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declarations\\pattern.py", "class_name": "PatternVersionDeclaration", "function_name": "replace", "parameters": ["self", "new_version"], "param_types": {"new_version": "Version"}, "return_type": "str", "param_doc": {"new_version": "The new version number as a `Version` instance"}, "return_doc": "", "raises_doc": [], "called_functions": ["VersionSwapper", "logger.debug", "new_version.as_tag", "self._search_pattern.subn", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Replace the version in the source content with `new_version`, and return the updated content.", "source_code": "def replace(self, new_version: Version) -> str:\n    \"\"\"\n    Replace the version in the source content with `new_version`, and return\n    the updated content.\n\n    :param new_version: The new version number as a `Version` instance\n    \"\"\"\n    new_content, n_matches = self._search_pattern.subn(\n        VersionSwapper(\n            new_version_str=(\n                new_version.as_tag()\n                if self._stamp_format == VersionStampType.TAG_FORMAT\n                else str(new_version)\n            ),\n            group_match_name=self._VERSION_GROUP_NAME,\n        ),\n        self.content,\n    )\n\n    logger.debug(\n        \"path=%r pattern=%r num_matches=%r\",\n        self._path,\n        self._search_pattern,\n        n_matches,\n    )\n\n    return new_content", "loc": 27}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declarations\\pattern.py", "class_name": "PatternVersionDeclaration", "function_name": "update_file_w_version", "parameters": ["self", "new_version", "noop"], "param_types": {"new_version": "Version", "noop": "bool"}, "return_type": "Path | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "noop_report", "self._path.exists", "self._path.write_text", "self._search_pattern.findall", "self.replace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_file_w_version(\n    self, new_version: Version, noop: bool = False\n) -> Path | None:\n    if noop:\n        if not self._path.exists():\n            noop_report(\n                f\"FILE NOT FOUND: cannot stamp version in non-existent file {self._path}\",\n            )\n            return None\n\n        if len(self._search_pattern.findall(self.content)) < 1:\n            noop_report(\n                f\"VERSION PATTERN NOT FOUND: no version to stamp in file {self._path}\",\n            )\n            return None\n\n        return self._path\n\n    new_content = self.replace(new_version)\n    if new_content == self.content:\n        return None\n\n    self._path.write_text(new_content)\n    del self.content\n\n    return self._path", "loc": 26}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declarations\\pattern.py", "class_name": "PatternVersionDeclaration", "function_name": "from_string_definition", "parameters": ["cls", "replacement_def", "tag_format"], "param_types": {"replacement_def": "str", "tag_format": "str"}, "return_type": "PatternVersionDeclaration", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "VersionStampType", "cls", "len", "regex_escape", "replacement_def.split", "str.join", "tag_format.strip", "tag_format.strip().split"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "create an instance of self from a string representing one item of the \"version_variables\" list in the configuration", "source_code": "def from_string_definition(\n    cls, replacement_def: str, tag_format: str\n) -> PatternVersionDeclaration:\n    \"\"\"\n    create an instance of self from a string representing one item\n    of the \"version_variables\" list in the configuration\n    \"\"\"\n    parts = replacement_def.split(\":\", maxsplit=2)\n\n    if len(parts) <= 1:\n        raise ValueError(\n            f\"Invalid replacement definition {replacement_def!r}, missing ':'\"\n        )\n\n    if len(parts) == 2:\n        # apply default version_type of \"number_format\" (ie. \"1.2.3\")\n        parts = [*parts, VersionStampType.NUMBER_FORMAT.value]\n\n    path, variable, version_type = parts\n\n    try:\n        stamp_type = VersionStampType(version_type)\n    except ValueError as err:\n        raise ValueError(\n            str.join(\n                \" \",\n                [\n                    \"Invalid stamp type, must be one of:\",\n                    str.join(\", \", [e.value for e in VersionStampType]),\n                ],\n            )\n        ) from err\n\n    # DEFAULT: naked (no v-prefixed) semver version\n    value_replace_pattern_str = (\n        f\"(?P<{cls._VERSION_GROUP_NAME}>{SEMVER_REGEX.pattern})\"\n    )\n\n    if version_type == VersionStampType.TAG_FORMAT.value:\n        tag_parts = tag_format.strip().split(r\"{version}\", maxsplit=1)\n        value_replace_pattern_str = str.join(\n            \"\",\n            [\n                f\"(?P<{cls._VERSION_GROUP_NAME}>\",\n                regex_escape(tag_parts[0]),\n                SEMVER_REGEX.pattern,\n                (regex_escape(tag_parts[1]) if len(tag_parts) > 1 else \"\"),\n                \")\",\n            ],\n        )\n\n    search_text = str.join(\n        \"\",\n        [\n            # Supports optional matching quotations around variable name\n            # Negative lookbehind to ensure we don't match part of a variable name\n            f\"\"\"(?x)(?P<quote1>['\"])?(?<![\\\\w.-]){regex_escape(variable)}(?P=quote1)?\"\"\",\n            # Supports walrus, equals sign, double-equals, colon, or @ as assignment operator\n            # ignoring whitespace separation\n            r\"\\s*(:=|==|[:=@])\\s*\",\n            # Supports optional matching quotations around a version pattern (tag or raw format)\n            f\"\"\"(?P<quote2>['\"])?{value_replace_pattern_str}(?P=quote2)?\"\"\",\n        ],\n    )\n\n    return cls(path, search_text, stamp_type)", "loc": 66}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declarations\\toml.py", "class_name": "TomlVersionDeclaration", "function_name": "content", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FileNotFoundError", "logger.debug", "self._path.exists", "self._path.read_text"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "A cached property that stores the content of the configured source file.", "source_code": "def content(self) -> str:\n    \"\"\"A cached property that stores the content of the configured source file.\"\"\"\n    if self._content is None:\n        logger.debug(\"No content stored, reading from source file %s\", self._path)\n\n        if not self._path.exists():\n            raise FileNotFoundError(f\"path {self._path!r} does not exist\")\n\n        self._content = self._path.read_text()\n\n    return self._content", "loc": 11}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declarations\\toml.py", "class_name": "TomlVersionDeclaration", "function_name": "parse", "parameters": ["self"], "param_types": {}, "return_type": "set[Version]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Version.parse", "content.get", "deprecated", "logger.debug", "self._load", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Look for the version in the source content", "source_code": "def parse(self) -> set[Version]:  # pragma: no cover\n    \"\"\"Look for the version in the source content\"\"\"\n    content = self._load()\n    maybe_version: str = content.get(self._search_text)  # type: ignore[return-value]\n    if maybe_version is not None:\n        logger.debug(\n            \"Found a key %r that looks like a version (%r)\",\n            self._search_text,\n            maybe_version,\n        )\n        valid_version = Version.parse(maybe_version)\n        return {valid_version} if valid_version else set()\n    # Maybe in future raise error if not found?\n    return set()", "loc": 14}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declarations\\toml.py", "class_name": "TomlVersionDeclaration", "function_name": "replace", "parameters": ["self", "new_version"], "param_types": {"new_version": "Version"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "logger.info", "new_version.as_tag", "self._load", "str", "tomlkit.dumps"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Replace the version in the source content with `new_version`, and return the updated content.", "source_code": "def replace(self, new_version: Version) -> str:\n    \"\"\"\n    Replace the version in the source content with `new_version`, and return the\n    updated content.\n    \"\"\"\n    content = self._load()\n    if self._search_text in content:\n        logger.info(\n            \"found %r in source file contents, replacing with %s\",\n            self._search_text,\n            new_version,\n        )\n        content[self._search_text] = (\n            new_version.as_tag()\n            if self._stamp_format == VersionStampType.TAG_FORMAT\n            else str(new_version)\n        )\n\n    return tomlkit.dumps(cast(Dict[str, Any], content))", "loc": 19}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declarations\\toml.py", "class_name": "TomlVersionDeclaration", "function_name": "update_file_w_version", "parameters": ["self", "new_version", "noop"], "param_types": {"new_version": "Version", "noop": "bool"}, "return_type": "Path | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["noop_report", "self._load", "self._path.exists", "self._path.write_text", "self.replace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_file_w_version(\n    self, new_version: Version, noop: bool = False\n) -> Path | None:\n    if noop:\n        if not self._path.exists():\n            noop_report(\n                f\"FILE NOT FOUND: cannot stamp version in non-existent file {self._path!r}\",\n            )\n            return None\n\n        if self._search_text not in self._load():\n            noop_report(\n                f\"VERSION PATTERN NOT FOUND: no version to stamp in file {self._path!r}\",\n            )\n            return None\n\n        return self._path\n\n    new_content = self.replace(new_version)\n    if new_content == self.content:\n        return None\n\n    self._path.write_text(new_content)\n    del self.content\n\n    return self._path", "loc": 26}
{"file": "python-semantic-release\\src\\semantic_release\\version\\declarations\\toml.py", "class_name": "TomlVersionDeclaration", "function_name": "from_string_definition", "parameters": ["cls", "replacement_def"], "param_types": {"replacement_def": "str"}, "return_type": "TomlVersionDeclaration", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "VersionStampType", "cls", "len", "replacement_def.split", "str.join"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "create an instance of self from a string representing one item of the \"version_toml\" list in the configuration", "source_code": "def from_string_definition(cls, replacement_def: str) -> TomlVersionDeclaration:\n    \"\"\"\n    create an instance of self from a string representing one item\n    of the \"version_toml\" list in the configuration\n    \"\"\"\n    parts = replacement_def.split(\":\", maxsplit=2)\n\n    if len(parts) <= 1:\n        raise ValueError(\n            f\"Invalid TOML replacement definition {replacement_def!r}, missing ':'\"\n        )\n\n    if len(parts) == 2:\n        # apply default version_type of \"number_format\" (ie. \"1.2.3\")\n        parts = [*parts, VersionStampType.NUMBER_FORMAT.value]\n\n    path, search_text, version_type = parts\n\n    try:\n        stamp_type = VersionStampType(version_type)\n    except ValueError as err:\n        raise ValueError(\n            str.join(\n                \" \",\n                [\n                    \"Invalid stamp type, must be one of:\",\n                    str.join(\", \", [e.value for e in VersionStampType]),\n                ],\n            )\n        ) from err\n\n    return cls(path, search_text, stamp_type)", "loc": 32}
{"file": "sanic\\setup.py", "class_name": null, "function_name": "str_to_bool", "parameters": ["val"], "param_types": {"val": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "val.lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def str_to_bool(val: str) -> bool:\n    val = val.lower()\n    if val in {\n        \"y\",\n        \"yes\",\n        \"yep\",\n        \"yup\",\n        \"t\",\n        \"true\",\n        \"on\",\n        \"enable\",\n        \"enabled\",\n        \"1\",\n    }:\n        return True\n    elif val in {\"n\", \"no\", \"f\", \"false\", \"off\", \"disable\", \"disabled\", \"0\"}:\n        return False\n    else:\n        raise ValueError(f\"Invalid truth value {val}\")", "loc": 19}
{"file": "sanic\\setup.py", "class_name": "PyTest", "function_name": "run_tests", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["pytest.main", "shlex.split", "sys.exit"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run_tests(self):\n    import shlex\n\n    import pytest\n\n    errno = pytest.main(shlex.split(self.pytest_args))\n    sys.exit(errno)", "loc": 7}
{"file": "sanic\\examples\\amending_request_object.py", "class_name": null, "function_name": "key_exist_handler", "parameters": ["request"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["app.get", "hasattr", "text"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def key_exist_handler(request):\n    # Check the key is exist or not\n    if hasattr(request.ctx, \"num\"):\n        return text(\"num exist in request\")\n\n    return text(\"num does not exist in request\")", "loc": 6}
{"file": "sanic\\examples\\authorized_sanic.py", "class_name": null, "function_name": "authorized", "parameters": ["f"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["check_request_for_authorization_status", "f", "json", "wraps"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def authorized(f):\n    @wraps(f)\n    async def decorated_function(request, *args, **kwargs):\n        # run some method that checks the request\n        # for the client's authorization status\n        is_authorized = check_request_for_authorization_status(request)\n\n        if is_authorized:\n            # the user is authorized.\n            # run the handler method and return the response\n            response = await f(request, *args, **kwargs)\n            return response\n        else:\n            # the user is not authorized.\n            return json({\"status\": \"not_authorized\"}, 403)\n\n    return decorated_function", "loc": 17}
{"file": "sanic\\examples\\exception_monitoring.py", "class_name": "CustomHandler", "function_name": "default", "parameters": ["self", "request", "exception"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "print", "super", "super().default"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def default(self, request, exception):\n    # Here, we have access to the exception object\n    # and can do anything with it (log, send to external service, etc)\n\n    # Some exceptions are trivial and built into Sanic (404s, etc)\n    if not isinstance(exception, SanicException):\n        print(exception)\n\n    # Then, we must finish handling the exception by returning\n    # our response to the client\n    # For this we can just call the super class' default handler\n    return super().default(request, exception)", "loc": 12}
{"file": "sanic\\examples\\log_request_id.py", "class_name": "RequestIdFilter", "function_name": "filter", "parameters": ["self", "record"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["app.ctx.request_id.get"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def filter(self, record):\n    try:\n        record.request_id = app.ctx.request_id.get(None) or \"n/a\"\n    except AttributeError:\n        record.request_id = \"n/a\"\n    return True", "loc": 6}
{"file": "sanic\\examples\\modify_header_example.py", "class_name": null, "function_name": "handle_request", "parameters": ["request"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["app.route", "response.json"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_request(request):\n    return response.json(\n        {\"message\": \"Hello world!\"},\n        headers={\"X-Served-By\": \"sanic\"},\n        status=200,\n    )", "loc": 6}
{"file": "sanic\\examples\\modify_header_example.py", "class_name": null, "function_name": "handle_unauthorized_request", "parameters": ["request"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["app.route", "response.json"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_unauthorized_request(request):\n    return response.json(\n        {\"message\": \"You are not authorized\"},\n        headers={\"X-Served-By\": \"sanic\"},\n        status=404,\n    )", "loc": 6}
{"file": "sanic\\examples\\try_everything.py", "class_name": null, "function_name": "post_form_json", "parameters": ["request"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["app.route", "request.form.get", "response.json"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def post_form_json(request):\n    return response.json(\n        {\n            \"received\": True,\n            \"form_data\": request.form,\n            \"test\": request.form.get(\"test\"),\n        }\n    )", "loc": 8}
{"file": "sanic\\examples\\try_everything.py", "class_name": null, "function_name": "query_string", "parameters": ["request"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["app.route", "response.json"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def query_string(request):\n    return response.json(\n        {\n            \"parsed\": True,\n            \"args\": request.args,\n            \"url\": request.url,\n            \"query_string\": request.query_string,\n        }\n    )", "loc": 9}
{"file": "sanic\\guide\\content\\en\\migrate.py", "class_name": null, "function_name": "convert_columns", "parameters": ["content"], "param_types": {"content": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["COLUMN_PATTERN.sub", "indent", "left.strip", "match.groups", "right.strip"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def convert_columns(content: str):\n    def replacer(match: re.Match):\n        left, right = match.groups()\n        left = indent(left.strip(), \" \" * 4)\n        right = indent(right.strip(), \" \" * 4)\n        return f\"\"\"\n.. column::\n\n{left}\n\n.. column::\n\n{right}\n\"\"\"\n\n    return COLUMN_PATTERN.sub(replacer, content)", "loc": 16}
{"file": "sanic\\guide\\content\\en\\migrate.py", "class_name": null, "function_name": "convert_notifications", "parameters": ["content"], "param_types": {"content": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NOTIFICATION_PATTERN.sub", "body.strip", "indent", "match.groups"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def convert_notifications(content: str):\n    def replacer(match: re.Match):\n        type_, title, body = match.groups()\n        body = indent(body.strip(), \" \" * 4)\n        return f\"\"\"\n\n.. {type_}:: {title}\n\n{body}\n\n\"\"\"\n\n    return NOTIFICATION_PATTERN.sub(replacer, content)", "loc": 13}
{"file": "sanic\\guide\\content\\en\\migrate.py", "class_name": null, "function_name": "convert_emoji", "parameters": ["content"], "param_types": {"content": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EMOJI.get", "EMOJI_PATTERN.sub", "match.group"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def convert_emoji(content: str):\n    def replace(match):\n        return EMOJI.get(match.group(1), match.group(0))\n\n    return EMOJI_PATTERN.sub(replace, content)", "loc": 5}
{"file": "sanic\\guide\\content\\en\\migrate.py", "class_name": null, "function_name": "convert_code_blocks", "parameters": ["content"], "param_types": {"content": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["content.replace"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def convert_code_blocks(content: str):\n    for src, dest in (\n        (\"yml\", \"yaml\"),\n        (\"caddy\", \"\"),\n        (\"systemd\", \"\"),\n        (\"mermaid\", \"\\nmermaid\"),\n    ):\n        content = content.replace(f\"```{src}\", f\"```{dest}\")\n    return content", "loc": 9}
{"file": "sanic\\guide\\content\\en\\migrate.py", "class_name": null, "function_name": "convert", "parameters": ["content"], "param_types": {"content": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cleanup_highlights", "cleanup_multibreaks", "convert_code_blocks", "convert_columns", "convert_emoji", "convert_notifications"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def convert(content: str):\n    content = convert_emoji(content)\n    content = convert_columns(content)\n    content = cleanup_highlights(content)\n    content = convert_code_blocks(content)\n    content = convert_notifications(content)\n    content = cleanup_multibreaks(content)\n    return content", "loc": 8}
{"file": "sanic\\guide\\content\\en\\migrate.py", "class_name": null, "function_name": "convert_file", "parameters": ["src", "dest"], "param_types": {"src": "Path", "dest": "Path"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["convert", "dest.parent.mkdir", "dest.relative_to", "dest.touch", "dest.write_text", "print", "src.read_text", "src.relative_to"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def convert_file(src: Path, dest: Path):\n    short_src = src.relative_to(SOURCE_DIR)\n    short_dest = dest.relative_to(CURRENT_DIR)\n    print(f\"Converting {short_src} -> {short_dest}\")\n    content = src.read_text()\n    new_content = convert(content)\n    dest.parent.mkdir(parents=True, exist_ok=True)\n    dest.touch()\n    dest.write_text(new_content)", "loc": 9}
{"file": "sanic\\guide\\content\\en\\migrate.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SOURCE_DIR.glob", "convert_file", "print", "translate_path"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main():\n    print(f\"Source: {SOURCE_DIR}\")\n\n    for path in SOURCE_DIR.glob(\"**/*.md\"):\n        if path.name in (\"index.md\", \"README.md\"):\n            continue\n        dest_path = translate_path(SOURCE_DIR, path, CURRENT_DIR)\n        convert_file(path, dest_path)", "loc": 8}
{"file": "sanic\\guide\\content\\en\\migrate.py", "class_name": null, "function_name": "replacer", "parameters": ["match"], "param_types": {"match": "re.Match"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["indent", "left.strip", "match.groups", "right.strip"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "    def replacer(match: re.Match):\n        left, right = match.groups()\n        left = indent(left.strip(), \" \" * 4)\n        right = indent(right.strip(), \" \" * 4)\n        return f\"\"\"\n.. column::\n\n{left}\n\n.. column::\n\n{right}\n\"\"\"", "loc": 13}
{"file": "sanic\\guide\\content\\en\\migrate.py", "class_name": null, "function_name": "replacer", "parameters": ["match"], "param_types": {"match": "re.Match"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["body.strip", "indent", "match.groups"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "    def replacer(match: re.Match):\n        type_, title, body = match.groups()\n        body = indent(body.strip(), \" \" * 4)\n        return f\"\"\"\n\n.. {type_}:: {title}\n\n{body}\n\n\"\"\"", "loc": 10}
{"file": "sanic\\guide\\webapp\\display\\base.py", "class_name": "BaseRenderer", "function_name": "get_builder", "parameters": ["self", "full", "language"], "param_types": {"full": "bool", "language": "str"}, "return_type": "Builder", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Builder", "Document", "builder", "self._head", "self.title"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_builder(self, full: bool, language: str) -> Builder:\n    if full:\n        urls = [\n            \"/assets/code.css\",\n            \"/assets/style.css\",\n            \"/assets/docs.js\",\n            \"https://unpkg.com/htmx.org@1.9.2/dist/htmx.min.js\",\n            \"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js\",\n        ]\n        builder = Document(\n            self.title(), lang=language, _urls=urls, _viewport=True\n        )\n        builder(*self._head())\n        builder.full = True\n    else:\n        builder = Builder(name=\"Partial\")\n        builder.full = False\n    return builder", "loc": 18}
{"file": "sanic\\guide\\webapp\\display\\markdown.py", "class_name": null, "function_name": "render_markdown", "parameters": ["text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RST_CODE_BLOCK_PATTERN.sub", "_render_markdown", "dedent", "dedent(match.group(2)).strip", "match.group"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def render_markdown(text: str) -> str:\n    def replacer(match):\n        language = match.group(1)\n        code_block = dedent(match.group(2)).strip()\n        return f\"```{language}\\n{code_block}\\n```\\n\\n\"\n\n    text = RST_CODE_BLOCK_PATTERN.sub(replacer, text)\n    return _render_markdown(text)", "loc": 8}
{"file": "sanic\\guide\\webapp\\display\\markdown.py", "class_name": "DocsRenderer", "function_name": "block_code", "parameters": ["self", "code", "info"], "param_types": {"code": "str", "info": "str | None"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Builder", "E.code", "HTML", "builder", "builder.div", "builder.div(class_='code-block__rectangle code-block__filled').div", "builder.pre", "escape", "get_lexer_by_name", "highlight", "html.HtmlFormatter", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def block_code(self, code: str, info: str | None = None):\n    builder = Builder(\"Block\")\n    with builder.div(class_=\"code-block\"):\n        if info:\n            lexer = get_lexer_by_name(info, stripall=False)\n            formatter = html.HtmlFormatter(\n                style=SanicCodeStyle,\n                wrapcode=True,\n                cssclass=f\"highlight language-{info}\",\n            )\n            builder(HTML(highlight(code, lexer, formatter)))\n            with builder.div(\n                class_=\"code-block__copy\",\n                onclick=\"copyCode(this)\",\n            ):\n                builder.div(\n                    class_=\"code-block__rectangle code-block__filled\"\n                ).div(class_=\"code-block__rectangle code-block__outlined\")\n        else:\n            builder.pre(E.code(escape(code)))\n    return str(builder)", "loc": 21}
{"file": "sanic\\guide\\webapp\\display\\markdown.py", "class_name": "DocsRenderer", "function_name": "heading", "parameters": ["self", "text", "level"], "param_types": {"text": "str", "level": "int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._make_tag", "slugify"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def heading(self, text: str, level: int, **attrs) -> str:\n    ident = slugify(text)\n    if level > 1:\n        text += self._make_tag(\n            \"a\", {\"href\": f\"#{ident}\", \"class\": \"anchor\"}, \"#\"\n        )\n    return self._make_tag(\n        f\"h{level}\",\n        {\n            \"id\": ident,\n            \"class\": (\n                f\"is-size-{level}-desktop is-size-{level + 2}-touch\"\n            ),\n        },\n        text,\n    )", "loc": 16}
{"file": "sanic\\guide\\webapp\\display\\markdown.py", "class_name": "DocsRenderer", "function_name": "link", "parameters": ["self", "text", "url", "title"], "param_types": {"text": "str", "url": "str", "title": "str | None"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["safe_entity", "self._make_tag", "self.safe_url", "self.safe_url(url).replace", "url.endswith", "url.split", "url.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def link(self, text: str, url: str, title: str | None = None) -> str:\n    url = self.safe_url(url).replace(\".md\", \".html\")\n    url, anchor = url.split(\"#\", 1) if \"#\" in url else (url, None)\n    if (\n        not url.endswith(\"/\")\n        and not url.endswith(\".html\")\n        and not url.startswith(\"http\")\n    ):\n        url += \".html\"\n    if anchor:\n        url += f\"#{anchor}\"\n    attributes: dict[str, str] = {\"href\": url}\n    if title:\n        attributes[\"title\"] = safe_entity(title)\n    if url.startswith(\"http\"):\n        attributes[\"target\"] = \"_blank\"\n        attributes[\"rel\"] = \"nofollow noreferrer\"\n    else:\n        attributes[\"hx-get\"] = url\n        attributes[\"hx-target\"] = \"#content\"\n        attributes[\"hx-swap\"] = \"innerHTML\"\n        attributes[\"hx-push-url\"] = \"true\"\n    return self._make_tag(\"a\", attributes, text)", "loc": 23}
{"file": "sanic\\guide\\webapp\\display\\markdown.py", "class_name": "DocsRenderer", "function_name": "inline_directive", "parameters": ["self", "text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._make_tag", "self.codespan", "text.count", "text.rsplit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def inline_directive(self, text: str, **attrs) -> str:\n    num_dots = text.count(\".\")\n    display = self.codespan(text)\n\n    if num_dots <= 1:\n        return display\n\n    module, *_ = text.rsplit(\".\", num_dots - 1)\n    href = f\"/api/{module}.html\"\n    return self._make_tag(\n        \"a\",\n        {\"href\": href, \"class\": \"inline-directive\"},\n        display,\n    )", "loc": 14}
{"file": "sanic\\guide\\webapp\\display\\layouts\\home.py", "class_name": "HomeLayout", "function_name": "layout", "parameters": ["self", "request", "full"], "param_types": {"request": "Request", "full": "bool"}, "return_type": "Generator[None, None, None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._footer", "self._hero", "self._sponsors", "self.builder.div"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def layout(\n    self, request: Request, full: bool = True\n) -> Generator[None, None, None]:\n    self._sponsors()\n    self._hero(request.ctx.language)\n    with self.builder.div(class_=\"home container\"):\n        yield\n    self._footer(request)", "loc": 8}
{"file": "sanic\\guide\\webapp\\display\\layouts\\main.py", "class_name": "MainLayout", "function_name": "layout", "parameters": ["self", "request", "full"], "param_types": {"request": "Request", "full": "bool"}, "return_type": "Generator[None, None, None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._content_wrapper", "self._footer", "self._navbar", "self._sidebar", "self.builder.div", "self.builder.main"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def layout(\n    self, request: Request, full: bool = True\n) -> Generator[None, None, None]:\n    if full:\n        self.builder.div(class_=\"loading-bar\")\n        with self.builder.div(class_=\"is-flex\"):\n            self._sidebar(request)\n            with self.builder.main(class_=\"is-flex-grow-1\"):\n                self._navbar(request)\n                with self.builder.div(class_=\"container\", id=\"content\"):\n                    with self._content_wrapper(request):\n                        yield\n                    self._footer(request)\n    else:\n        with self._content_wrapper(request):\n            yield\n        self._footer(request)", "loc": 17}
{"file": "sanic\\guide\\webapp\\display\\layouts\\elements\\footer.py", "class_name": null, "function_name": "do_footer", "parameters": ["builder", "request", "extra_classes", "with_pagination"], "param_types": {"builder": "Builder", "request": "Request", "extra_classes": "str", "with_pagination": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_content", "_pagination", "builder.footer", "content.appendleft", "deque"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def do_footer(\n    builder: Builder,\n    request: Request,\n    extra_classes: str = \"\",\n    with_pagination: bool = True,\n) -> None:\n    content = deque([_content()])\n    if with_pagination:\n        content.appendleft(_pagination(request))\n    css_classes = \"footer\"\n    if extra_classes:\n        css_classes += f\" {extra_classes}\"\n    builder.footer(\n        *content,\n        class_=css_classes,\n    )", "loc": 16}
{"file": "sanic\\guide\\webapp\\display\\layouts\\elements\\navbar.py", "class_name": null, "function_name": "do_navbar", "parameters": ["builder", "request"], "param_types": {"builder": "Builder", "request": "Request"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["E.div", "_render_navbar_item", "_search_form", "builder.nav"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def do_navbar(builder: Builder, request: Request) -> None:\n    navbar_items = [\n        _render_navbar_item(item, request)\n        for item in request.app.config.NAVBAR\n    ]\n    container = E.div(\n        _search_form(request), *navbar_items, class_=\"navbar-end\"\n    )\n\n    builder.nav(\n        E.div(container, class_=\"navbar-menu\"),\n        class_=\"navbar is-hidden-touch\",\n    )", "loc": 13}
{"file": "sanic\\guide\\webapp\\display\\page\\docobject.py", "class_name": null, "function_name": "organize_docobjects", "parameters": ["package_name"], "param_types": {"package_name": "str"}, "return_type": "dict[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Builder", "_docobject_to_html", "_extract_docobjects", "_table_of_contents", "defaultdict", "docobjects.items", "module.count", "module.rsplit", "page_registry.items", "page_registry[ref].append", "str"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def organize_docobjects(package_name: str) -> dict[str, str]:\n    page_content: defaultdict[str, str] = defaultdict(str)\n    docobjects = _extract_docobjects(package_name)\n    page_registry: defaultdict[str, list[str]] = defaultdict(list)\n    for module, docobject in docobjects.items():\n        builder = Builder(name=\"Partial\")\n        _docobject_to_html(docobject, builder)\n        ref = module.rsplit(\".\", module.count(\".\") - 1)[0]\n        page_registry[ref].append(module)\n        page_content[f\"/api/{ref}.md\"] += str(builder)\n    for ref, objects in page_registry.items():\n        page_content[f\"/api/{ref}.md\"] = (\n            _table_of_contents(objects) + page_content[f\"/api/{ref}.md\"]\n        )\n    return page_content", "loc": 15}
{"file": "sanic\\guide\\webapp\\display\\page\\page.py", "class_name": "Page", "function_name": "get", "parameters": ["cls", "language", "path"], "param_types": {"language": "str", "path": "str"}, "return_type": "tuple[Page | None, Page | None, Page | None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_PAGE_CACHE.get", "_PAGE_CACHE.get(language, {}).get", "path.endswith", "path.removesuffix"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get(\n    cls, language: str, path: str\n) -> tuple[Page | None, Page | None, Page | None]:\n    if path.endswith(\"/\") or not path:\n        path += \"index.html\"\n    if not path.endswith(\".md\"):\n        path = path.removesuffix(\".html\") + \".md\"\n    if language == \"api\":\n        path = f\"/api/{path}\"\n    return _PAGE_CACHE.get(language, {}).get(path, (None, None, None))", "loc": 10}
{"file": "sanic\\guide\\webapp\\display\\page\\page.py", "class_name": "Page", "function_name": "load_pages", "parameters": ["cls", "base_path", "page_order"], "param_types": {"base_path": "Path", "page_order": "list[str]"}, "return_type": "list[Page]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'/'.join", "_PAGE_CACHE.items", "_PAGE_CACHE.setdefault", "base_path.glob", "cls._load_api_pages", "cls._load_page", "enumerate", "len", "output.append", "page_order.index", "pages.items", "path.relative_to"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_pages(cls, base_path: Path, page_order: list[str]) -> list[Page]:\n    output: list[Page] = []\n    for path in base_path.glob(\"**/*.md\"):\n        relative = path.relative_to(base_path)\n        language = relative.parts[0]\n        name = \"/\".join(relative.parts[1:])\n        page = cls._load_page(path)\n        output.append(page)\n        page._relative_path = relative\n        _PAGE_CACHE.setdefault(language, {})[name] = (\n            None,\n            page,\n            None,\n        )\n        _PAGE_CACHE[\"api\"] = {}\n    for language, pages in _PAGE_CACHE.items():\n        for name, (_, current, _) in pages.items():\n            previous_page = None\n            next_page = None\n            try:\n                index = page_order.index(name)\n            except ValueError:\n                continue\n            try:\n                if index > 0:\n                    previous_page = pages[page_order[index - 1]][1]\n            except KeyError:\n                pass\n            try:\n                if index < len(page_order) - 1:\n                    next_page = pages[page_order[index + 1]][1]\n            except KeyError:\n                pass\n            pages[name] = (previous_page, current, next_page)\n        previous_page = None\n        next_page = None\n\n    api_pages = cls._load_api_pages()\n    filtered_order = [ref for ref in page_order if ref in api_pages]\n    for idx, ref in enumerate(filtered_order):\n        current_page = api_pages[ref]\n        previous_page = None\n        next_page = None\n        try:\n            if idx > 0:\n                previous_page = api_pages[filtered_order[idx - 1]]\n        except KeyError:\n            pass\n        try:\n            if idx < len(filtered_order) - 1:\n                next_page = api_pages[filtered_order[idx + 1]]\n        except KeyError:\n            pass\n        _PAGE_CACHE[\"api\"][ref] = (previous_page, current_page, next_page)\n\n    return output", "loc": 56}
{"file": "sanic\\guide\\webapp\\display\\page\\renderer.py", "class_name": "PageRenderer", "function_name": "render", "parameters": ["self", "request", "language", "path"], "param_types": {"request": "Request", "language": "str", "path": "str"}, "return_type": "Builder", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["request.headers.get", "self._body", "self._setup_request", "self.get_builder"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def render(self, request: Request, language: str, path: str) -> Builder:\n    self._setup_request(request, language, path)\n    builder = self.get_builder(\n        full=request.headers.get(\"HX-Request\") is None,\n        language=language,\n    )\n    self._body(request, builder, language, path)\n    return builder", "loc": 8}
{"file": "sanic\\guide\\webapp\\display\\page\\renderer.py", "class_name": "PageRenderer", "function_name": "title", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Request.get_current", "getattr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def title(self) -> str:\n    request = Request.get_current()\n    title: str | None = None\n    if request and (\n        current_page := getattr(request.ctx, \"current_page\", None)\n    ):\n        title = f\"{self.base_title} - {current_page.meta.title}\"\n    return title or self.base_title", "loc": 8}
{"file": "sanic\\guide\\webapp\\display\\plugins\\attrs.py", "class_name": "Attributes", "function_name": "parse", "parameters": ["self", "block", "m", "state"], "param_types": {"block": "BlockParser", "m": "Match", "state": "BlockState"}, "return_type": "dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["block.parse", "block.state_cls", "dedent", "dict", "m.groupdict", "new_state.process", "options.pop", "options.setdefault", "self.parse_options"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse(\n    self, block: BlockParser, m: Match, state: BlockState\n) -> dict[str, Any]:\n    info = m.groupdict()\n    options = dict(self.parse_options(m))\n    new_state = block.state_cls()\n    new_state.process(dedent(info[\"text\"]))\n    block.parse(new_state)\n    options.setdefault(\"class_\", \"additional-attributes\")\n    classes = options.pop(\"class\", \"\")\n    if classes:\n        options[\"class_\"] += f\" {classes}\"\n\n    return {\n        \"type\": \"attrs\",\n        \"text\": info[\"text\"],\n        \"children\": new_state.tokens,\n        \"attrs\": options,\n    }", "loc": 19}
{"file": "sanic\\guide\\webapp\\display\\plugins\\columns.py", "class_name": "Column", "function_name": "parse", "parameters": ["self", "block", "m", "state"], "param_types": {"block": "BlockParser", "m": "Match", "state": "BlockState"}, "return_type": "dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["block.parse", "block.state_cls", "dedent", "m.groupdict", "new_state.process"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse(\n    self, block: BlockParser, m: Match, state: BlockState\n) -> dict[str, Any]:\n    info = m.groupdict()\n\n    new_state = block.state_cls()\n    new_state.process(dedent(info[\"text\"]))\n    block.parse(new_state)\n\n    return {\n        \"type\": \"column\",\n        \"text\": info[\"text\"],\n        \"children\": new_state.tokens,\n        \"attrs\": {},\n    }", "loc": 15}
{"file": "sanic\\guide\\webapp\\display\\plugins\\mermaid.py", "class_name": "Mermaid", "function_name": "parse", "parameters": ["self", "block", "m", "state"], "param_types": {"block": "BlockParser", "m": "Match", "state": "BlockState"}, "return_type": "dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTML", "block.parse", "block.state_cls", "dedent", "info['text'].strip", "m.groupdict", "new_state.process"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse(\n    self, block: BlockParser, m: Match, state: BlockState\n) -> dict[str, Any]:\n    info = m.groupdict()\n\n    new_state = block.state_cls()\n    new_state.process(dedent(info[\"text\"]))\n    block.parse(new_state)\n\n    text = HTML(info[\"text\"].strip())\n\n    return {\n        \"type\": \"mermaid\",\n        \"text\": text,\n        \"children\": [{\"type\": \"text\", \"text\": text}],\n        \"attrs\": {},\n    }", "loc": 17}
{"file": "sanic\\guide\\webapp\\display\\plugins\\span.py", "class_name": null, "function_name": "parse_inline_span", "parameters": ["inline", "m", "state"], "param_types": {"m": "re.Match"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["m.end", "m.group", "state.append_token"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_inline_span(inline, m: re.Match, state):\n    state.append_token(\n        {\n            \"type\": \"span\",\n            \"attrs\": {\"classes\": m.group(\"classes\")},\n            \"raw\": m.group(\"content\"),\n        }\n    )\n    return m.end()", "loc": 9}
{"file": "sanic\\guide\\webapp\\display\\plugins\\tabs.py", "class_name": "Tabs", "function_name": "parse", "parameters": ["self", "block", "m", "state"], "param_types": {"block": "BlockParser", "m": "Match", "state": "BlockState"}, "return_type": "dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["block.parse", "block.state_cls", "dedent", "m.groupdict", "new_state.process"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse(\n    self, block: BlockParser, m: Match, state: BlockState\n) -> dict[str, Any]:\n    info = m.groupdict()\n\n    new_state = block.state_cls()\n    new_state.process(dedent(info[\"text\"]))\n    block.parse(new_state)\n\n    return {\n        \"type\": \"tab\",\n        \"text\": info[\"text\"],\n        \"children\": new_state.tokens,\n        \"attrs\": {\n            \"title\": info[\"title\"],\n        },\n    }", "loc": 17}
{"file": "sanic\\guide\\webapp\\display\\search\\renderer.py", "class_name": "SearchRenderer", "function_name": "render", "parameters": ["self", "request", "language", "searcher", "full"], "param_types": {"request": "Request", "language": "str", "searcher": "Searcher", "full": "bool"}, "return_type": "Builder", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["request.headers.get", "self._body", "self.get_builder"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def render(\n    self, request: Request, language: str, searcher: Searcher, full: bool\n) -> Builder:\n    builder = self.get_builder(\n        full=request.headers.get(\"HX-Request\") is None,\n        language=language,\n    )\n    self._body(request, builder, language, searcher, full)\n    return builder", "loc": 9}
{"file": "sanic\\guide\\webapp\\display\\search\\search.py", "class_name": "Stemmer", "function_name": "stem", "parameters": ["self", "word"], "param_types": {"word": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self._stem", "word.endswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def stem(self, word: str) -> str:\n    if word in self.STOP_WORDS:\n        return word\n    if word in self.PREFIXES:\n        return word\n    for suffix in self.SUFFIXES | self.PLURALIZATION:\n        if word.endswith(suffix):\n            return self._stem(word[: -len(suffix)])\n    return word", "loc": 9}
{"file": "sanic\\guide\\webapp\\worker\\factory.py", "class_name": null, "function_name": "create_app", "parameters": ["root"], "param_types": {"root": "Path"}, "return_type": "Sanic", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Page.load_pages", "PageRenderer", "Sanic", "_compile_sidebar_order", "app.before_server_start", "app.blueprint", "app.config.PUBLIC_DIR / 'web'.glob", "app.ext.dependency", "app.get", "app.static", "html", "load_config", "load_menu", "page_renderer.render", "page_renderer.title", "redirect", "request.app.url_for", "request.match_info.get", "setup_livereload", "setup_sitemap", "setup_style", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_app(root: Path) -> Sanic:\n    app = Sanic(\"Documentation\")\n    app.config.PUBLIC_DIR = root / \"public\"\n    app.config.CONTENT_DIR = root / \"content\"\n    app.config.CONFIG_DIR = root / \"config\"\n    app.config.STYLE_DIR = root / \"style\"\n    app.config.NODE_MODULES_DIR = root / \"node_modules\"\n    app.config.LANGUAGES = [\"en\"]\n    app.config.SIDEBAR = load_menu(\n        app.config.CONFIG_DIR / \"en\" / \"sidebar.yaml\"\n    )\n    app.config.NAVBAR = load_menu(app.config.CONFIG_DIR / \"en\" / \"navbar.yaml\")\n    app.config.GENERAL = load_config(\n        app.config.CONFIG_DIR / \"en\" / \"general.yaml\"\n    )\n\n    setup_livereload(app)\n    setup_style(app)\n    setup_sitemap(app)\n    app.blueprint(bp)\n\n    app.static(\"/assets/\", app.config.PUBLIC_DIR / \"assets\", name=\"assets\")\n\n    for path in (app.config.PUBLIC_DIR / \"web\").glob(\"*\"):\n        app.static(f\"/{path.name}\", path, name=path.name)\n\n    @app.before_server_start(priority=1)\n    async def setup(app: Sanic):\n        app.ext.dependency(PageRenderer(base_title=\"Sanic User Guide\"))\n        page_order = _compile_sidebar_order(app.config.SIDEBAR)\n        app.ctx.pages = Page.load_pages(app.config.CONTENT_DIR, page_order)\n        app.ctx.get_page = Page.get\n\n    @app.get(\"/\", name=\"root\")\n    @app.get(\"/index.html\", name=\"index\")\n    async def index(request: Request):\n        return redirect(request.app.url_for(\"page\", language=\"en\", path=\"\"))\n\n    @app.get(\"/<language:str>\", name=\"page-without-path\")\n    @app.get(\"/<language:str>/<path:path>\")\n    async def page(\n        request: Request,\n        page_renderer: PageRenderer,\n        language: str,\n        path: str = \"\",\n    ):\n        # TODO: Add more language support\n        if language != \"api\" and language not in app.config.LANGUAGES:\n            return redirect(\n                request.app.url_for(\"page\", language=\"en\", path=path)\n            )\n        if path in KNOWN_REDIRECTS:\n            return redirect(\n                request.app.url_for(\n                    \"page\", language=language, path=KNOWN_REDIRECTS[path]\n                ),\n                status=301,\n            )\n        builder = page_renderer.render(request, language, path)\n        title_text = page_renderer.title()\n        return html(\n            str(builder),\n            headers={\n                \"vary\": \"hx-request\",\n                \"x-title\": title_text,\n            },\n        )\n\n    @app.on_request\n    async def set_language(request: Request):\n        request.ctx.language = request.match_info.get(\n            \"language\", Page.DEFAULT_LANGUAGE\n        )\n\n    return app", "loc": 75}
{"file": "sanic\\guide\\webapp\\worker\\reload.py", "class_name": null, "function_name": "setup_livereload", "parameters": ["app"], "param_types": {"app": "Sanic"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Manager", "app.ctx.manager.Queue", "app.ctx.manager.shutdown", "app.manager.manage", "app.shared_ctx.reload_queue.put"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def setup_livereload(app: Sanic) -> None:\n    @app.main_process_start\n    async def main_process_start(app: Sanic):\n        app.ctx.manager = Manager()\n        app.shared_ctx.reload_queue = app.ctx.manager.Queue()\n\n    @app.main_process_ready\n    async def main_process_ready(app: Sanic):\n        app.manager.manage(\n            \"Livereload\",\n            _run_reload_server,\n            {\n                \"reload_queue\": app.shared_ctx.reload_queue,\n                \"debug\": app.state.is_debug,\n                \"state\": app.manager.worker_state,\n            },\n        )\n\n    @app.main_process_stop\n    async def main_process_stop(app: Sanic):\n        app.ctx.manager.shutdown()\n\n    @app.before_server_start\n    async def before_server_start(app: Sanic):\n        app.shared_ctx.reload_queue.put(\"reload\")\n\n    @app.after_server_start\n    async def after_server_start(app: Sanic):\n        app.m.state[\"ready\"] = True\n\n    @app.before_server_stop\n    async def before_server_stop(app: Sanic):\n        app.m.state[\"ready\"] = False", "loc": 33}
{"file": "sanic\\guide\\webapp\\worker\\style.py", "class_name": null, "function_name": "setup_style", "parameters": ["app"], "param_types": {"app": "Sanic"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["code_output.write_text", "compile_scss", "formatter.get_style_defs", "html.HtmlFormatter", "index.read_text", "str", "style_output.write_text"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def setup_style(app: Sanic) -> None:\n    index = app.config.STYLE_DIR / \"index.scss\"\n    style_output = app.config.PUBLIC_DIR / \"assets\" / \"style.css\"\n    code_output = app.config.PUBLIC_DIR / \"assets\" / \"code.css\"\n\n    @app.before_server_start\n    async def setup(app: Sanic):\n        scss = compile_scss(\n            string=index.read_text(),\n            include_paths=[\n                str(app.config.NODE_MODULES_DIR),\n                str(app.config.STYLE_DIR),\n            ],\n        )\n        style_output.write_text(scss)\n        formatter = html.HtmlFormatter(\n            style=SanicCodeStyle, full=True, cssfile=code_output\n        )\n        code_output.write_text(formatter.get_style_defs())", "loc": 19}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "loop", "parameters": ["self"], "param_types": {}, "return_type": "AbstractEventLoop", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "asyncio.get_event_loop", "asyncio.get_event_loop_policy", "asyncio.get_event_loop_policy().get_event_loop", "get_running_loop"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Synonymous with asyncio.get_event_loop(). .. note:: Only supported when using the `app.run` method.", "source_code": "def loop(self) -> AbstractEventLoop:\n    \"\"\"Synonymous with asyncio.get_event_loop().\n\n    .. note::\n        Only supported when using the `app.run` method.\n\n    Returns:\n        AbstractEventLoop: The event loop for the application.\n\n    Raises:\n        SanicException: If the application is not running.\n    \"\"\"\n    if self.state.stage is ServerStage.STOPPED and self.asgi is False:\n        raise SanicException(\n            \"Loop can only be retrieved after the app has started \"\n            \"running. Not supported with `create_server` function\"\n        )\n    try:\n        return get_running_loop()\n    except RuntimeError:  # no cov\n        if sys.version_info > (3, 10):\n            return asyncio.get_event_loop_policy().get_event_loop()\n        else:\n            return asyncio.get_event_loop()", "loc": 24}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "register_listener", "parameters": ["self", "listener", "event"], "param_types": {"listener": "ListenerType[SanicVar]", "event": "str"}, "return_type": "ListenerType[SanicVar]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "BadRequest", "ListenerEvent.__members__.keys", "error_logger.warning", "event.upper", "map", "partial", "self.listeners[_event.value].append", "self.signal", "x.lower"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Register the listener for a given event.", "source_code": "def register_listener(\n    self,\n    listener: ListenerType[SanicVar],\n    event: str,\n    *,\n    priority: int = 0,\n) -> ListenerType[SanicVar]:\n    \"\"\"Register the listener for a given event.\n\n    Args:\n        listener (Callable): The listener to register.\n        event (str): The event to listen for.\n\n    Returns:\n        Callable: The listener that was registered.\n    \"\"\"\n\n    try:\n        _event = ListenerEvent[event.upper()]\n    except (ValueError, AttributeError):\n        valid = \", \".join(\n            map(lambda x: x.lower(), ListenerEvent.__members__.keys())\n        )\n        raise BadRequest(f\"Invalid event: {event}. Use one of: {valid}\")\n\n    if \".\" in _event:\n        self.signal(_event.value, priority=priority)(\n            partial(self._listener, listener=listener)\n        )\n    else:\n        if priority:\n            error_logger.warning(\n                f\"Priority is not supported for {_event.value}\"\n            )\n        self.listeners[_event.value].append(listener)\n\n    return listener", "loc": 37}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "register_middleware", "parameters": ["self", "middleware", "attach_to"], "param_types": {"middleware": "Union[MiddlewareType, Middleware]", "attach_to": "str"}, "return_type": "Union[MiddlewareType, Middleware]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Middleware", "attach_to.upper", "isinstance", "self.request_middleware.append", "self.response_middleware.appendleft"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Register a middleware to be called before a request is handled.", "source_code": "def register_middleware(\n    self,\n    middleware: Union[MiddlewareType, Middleware],\n    attach_to: str = \"request\",\n    *,\n    priority: Union[Default, int] = _default,\n) -> Union[MiddlewareType, Middleware]:\n    \"\"\"Register a middleware to be called before a request is handled.\n\n    Args:\n        middleware (Callable): A callable that takes in a request.\n        attach_to (str): Whether to attach to request or response.\n            Defaults to `'request'`.\n        priority (int): The priority level of the middleware.\n            Lower numbers are executed first. Defaults to `0`.\n\n    Returns:\n        Union[Callable, Callable[[Callable], Callable]]: The decorated\n            middleware function or a partial function depending on how\n            the method was called.\n    \"\"\"\n    retval = middleware\n    location = MiddlewareLocation[attach_to.upper()]\n\n    if not isinstance(middleware, Middleware):\n        middleware = Middleware(\n            middleware,\n            location=location,\n            priority=priority if isinstance(priority, int) else 0,\n        )\n    elif middleware.priority != priority and isinstance(priority, int):\n        middleware = Middleware(\n            middleware.func,\n            location=middleware.location,\n            priority=priority,\n        )\n\n    if location is MiddlewareLocation.REQUEST:\n        if middleware not in self.request_middleware:\n            self.request_middleware.append(middleware)\n    if location is MiddlewareLocation.RESPONSE:\n        if middleware not in self.response_middleware:\n            self.response_middleware.appendleft(middleware)\n    return retval", "loc": 44}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "register_named_middleware", "parameters": ["self", "middleware", "route_names", "attach_to"], "param_types": {"middleware": "MiddlewareType", "route_names": "Iterable[str]", "attach_to": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Middleware", "attach_to.upper", "deque", "isinstance", "self.named_request_middleware[_rn].append", "self.named_response_middleware[_rn].appendleft"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Used to register named middleqare (middleware typically on blueprints)", "source_code": "def register_named_middleware(\n    self,\n    middleware: MiddlewareType,\n    route_names: Iterable[str],\n    attach_to: str = \"request\",\n    *,\n    priority: Union[Default, int] = _default,\n):\n    \"\"\"Used to register named middleqare (middleware typically on blueprints)\n\n    Args:\n        middleware (Callable): A callable that takes in a request.\n        route_names (Iterable[str]): The route names to attach the\n            middleware to.\n        attach_to (str): Whether to attach to request or response.\n            Defaults to `'request'`.\n        priority (int): The priority level of the middleware.\n            Lower numbers are executed first. Defaults to `0`.\n\n    Returns:\n        Union[Callable, Callable[[Callable], Callable]]: The decorated\n            middleware function or a partial function depending on how\n            the method was called.\n    \"\"\"  # noqa: E501\n    retval = middleware\n    location = MiddlewareLocation[attach_to.upper()]\n\n    if not isinstance(middleware, Middleware):\n        middleware = Middleware(\n            middleware,\n            location=location,\n            priority=priority if isinstance(priority, int) else 0,\n        )\n    elif middleware.priority != priority and isinstance(priority, int):\n        middleware = Middleware(\n            middleware.func,\n            location=middleware.location,\n            priority=priority,\n        )\n\n    if location is MiddlewareLocation.REQUEST:\n        for _rn in route_names:\n            if _rn not in self.named_request_middleware:\n                self.named_request_middleware[_rn] = deque()\n            if middleware not in self.named_request_middleware[_rn]:\n                self.named_request_middleware[_rn].append(middleware)\n    if location is MiddlewareLocation.RESPONSE:\n        for _rn in route_names:\n            if _rn not in self.named_response_middleware:\n                self.named_response_middleware[_rn] = deque()\n            if middleware not in self.named_response_middleware[_rn]:\n                self.named_response_middleware[_rn].appendleft(middleware)\n    return retval", "loc": 53}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "report_exception", "parameters": ["self", "handler"], "param_types": {"handler": "Callable[[Sanic, Exception], Coroutine[Any, Any, None]]"}, "return_type": "Callable[[Exception], Coroutine[Any, Any, None]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["handler", "self.add_signal", "wraps"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Register a handler to report exceptions. A convenience method to register a handler for the signal that is emitted when an exception occurs. It is typically used to report exceptions to an external service. It is equivalent to: ```python @app.signal(Event.SERVER_EXCEPTION_REPORT) async def report(exception): await do_something_with_error(exception) ```", "source_code": "def report_exception(\n    self, handler: Callable[[Sanic, Exception], Coroutine[Any, Any, None]]\n) -> Callable[[Exception], Coroutine[Any, Any, None]]:\n    \"\"\"Register a handler to report exceptions.\n\n    A convenience method to register a handler for the signal that\n    is emitted when an exception occurs. It is typically used to\n    report exceptions to an external service.\n\n    It is equivalent to:\n\n    ```python\n    @app.signal(Event.SERVER_EXCEPTION_REPORT)\n    async def report(exception):\n        await do_something_with_error(exception)\n    ```\n\n    Args:\n        handler (Callable[[Sanic, Exception], Coroutine[Any, Any, None]]):\n            The handler to register.\n\n    Returns:\n        Callable[[Sanic, Exception], Coroutine[Any, Any, None]]: The\n            handler that was registered.\n    \"\"\"\n\n    @wraps(handler)\n    async def report(exception: Exception) -> None:\n        await handler(self, exception)\n\n    self.add_signal(\n        handler=report, event=Event.SERVER_EXCEPTION_REPORT.value\n    )\n\n    return report", "loc": 35}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "enable_websocket", "parameters": ["self", "enable"], "param_types": {"enable": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.listener"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Enable or disable the support for websocket. Websocket is enabled automatically if websocket routes are added to the application. This typically will not need to be called manually.", "source_code": "def enable_websocket(self, enable: bool = True) -> None:\n    \"\"\"Enable or disable the support for websocket.\n\n    Websocket is enabled automatically if websocket routes are\n    added to the application. This typically will not need to be\n    called manually.\n\n    Args:\n        enable (bool, optional): If set to `True`, enables websocket\n            support. If set to `False`, disables websocket support.\n            Defaults to `True`.\n\n    Returns:\n        None\n    \"\"\"\n\n    if not self.websocket_enabled:\n        # if the server is stopped, we want to cancel any ongoing\n        # websocket tasks, to allow the server to exit promptly\n        self.listener(\"before_server_stop\")(self._cancel_websocket_tasks)\n\n    self.websocket_enabled = enable", "loc": 22}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "blueprint", "parameters": ["self", "blueprint"], "param_types": {"blueprint": "Union[Blueprint, Iterable[Blueprint], BlueprintGroup]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'/'.join", "'/'.join((str(u).strip('/') for u in merge_from if u)).rstrip", "blueprint.register", "getattr", "isinstance", "merge_from.append", "options.get", "self._blueprint_order.append", "self.blueprint", "str", "str(u).strip"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Register a blueprint on the application. See [Blueprints](/en/guide/best-practices/blueprints) for more information.", "source_code": "def blueprint(\n    self,\n    blueprint: Union[Blueprint, Iterable[Blueprint], BlueprintGroup],\n    *,\n    url_prefix: Optional[str] = None,\n    version: Optional[Union[int, float, str]] = None,\n    strict_slashes: Optional[bool] = None,\n    version_prefix: Optional[str] = None,\n    name_prefix: Optional[str] = None,\n) -> None:\n    \"\"\"Register a blueprint on the application.\n\n    See [Blueprints](/en/guide/best-practices/blueprints) for more information.\n\n    Args:\n        blueprint (Union[Blueprint, Iterable[Blueprint], BlueprintGroup]): Blueprint object or (list, tuple) thereof.\n        url_prefix (Optional[str]): Prefix for all URLs bound to the blueprint. Defaults to `None`.\n        version (Optional[Union[int, float, str]]): Version prefix for URLs. Defaults to `None`.\n        strict_slashes (Optional[bool]): Enforce the trailing slashes. Defaults to `None`.\n        version_prefix (Optional[str]): Prefix for version. Defaults to `None`.\n        name_prefix (Optional[str]): Prefix for the blueprint name. Defaults to `None`.\n\n    Example:\n        ```python\n        app = Sanic(\"TestApp\")\n        bp = Blueprint('TestBP')\n\n        @bp.route('/route')\n        def handler(request):\n            return text('Hello, Blueprint!')\n\n        app.blueprint(bp, url_prefix='/blueprint')\n        ```\n    \"\"\"  # noqa: E501\n    options: dict[str, Any] = {}\n    if url_prefix is not None:\n        options[\"url_prefix\"] = url_prefix\n    if version is not None:\n        options[\"version\"] = version\n    if strict_slashes is not None:\n        options[\"strict_slashes\"] = strict_slashes\n    if version_prefix is not None:\n        options[\"version_prefix\"] = version_prefix\n    if name_prefix is not None:\n        options[\"name_prefix\"] = name_prefix\n    if isinstance(blueprint, (Iterable, BlueprintGroup)):\n        for item in blueprint:\n            params: dict[str, Any] = {**options}\n            if isinstance(blueprint, BlueprintGroup):\n                merge_from = [\n                    options.get(\"url_prefix\", \"\"),\n                    blueprint.url_prefix or \"\",\n                ]\n                if not isinstance(item, BlueprintGroup):\n                    merge_from.append(item.url_prefix or \"\")\n                merged_prefix = \"/\".join(\n                    str(u).strip(\"/\") for u in merge_from if u\n                ).rstrip(\"/\")\n                params[\"url_prefix\"] = f\"/{merged_prefix}\"\n\n                for _attr in [\"version\", \"strict_slashes\"]:\n                    if getattr(item, _attr) is None:\n                        params[_attr] = getattr(\n                            blueprint, _attr\n                        ) or options.get(_attr)\n                if item.version_prefix == \"/v\":\n                    if blueprint.version_prefix == \"/v\":\n                        params[\"version_prefix\"] = options.get(\n                            \"version_prefix\"\n                        )\n                    else:\n                        params[\"version_prefix\"] = blueprint.version_prefix\n                name_prefix = getattr(blueprint, \"name_prefix\", None)\n                if name_prefix and \"name_prefix\" not in params:\n                    params[\"name_prefix\"] = name_prefix\n            self.blueprint(item, **params)\n        return\n    if blueprint.name in self.blueprints:\n        assert self.blueprints[blueprint.name] is blueprint, (\n            'A blueprint with the name \"%s\" is already registered.  '\n            \"Blueprint names must be unique.\" % (blueprint.name,)\n        )\n    else:\n        self.blueprints[blueprint.name] = blueprint\n        self._blueprint_order.append(blueprint)\n\n    if (\n        self.strict_slashes is not None\n        and blueprint.strict_slashes is None\n    ):\n        blueprint.strict_slashes = self.strict_slashes\n    blueprint.register(self, options)", "loc": 92}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "test_client", "parameters": ["self"], "param_types": {}, "return_type": "SanicTestClient", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicTestClient"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "A testing client that uses httpx and a live running server to reach into the application to execute handlers. This property is available if the `sanic-testing` package is installed. See [Test Clients](/en/plugins/sanic-testing/clients#wsgi-client-sanictestclient) for details.", "source_code": "def test_client(self) -> SanicTestClient:  # type: ignore # noqa\n    \"\"\"A testing client that uses httpx and a live running server to reach into the application to execute handlers.\n\n    This property is available if the `sanic-testing` package is installed.\n\n    See [Test Clients](/en/plugins/sanic-testing/clients#wsgi-client-sanictestclient) for details.\n\n    Returns:\n        SanicTestClient: A testing client from the `sanic-testing` package.\n    \"\"\"  # noqa: E501\n    if self._test_client:\n        return self._test_client\n    elif self._test_manager:\n        return self._test_manager.test_client\n    from sanic_testing.testing import SanicTestClient  # type: ignore\n\n    self._test_client = SanicTestClient(self)\n    return self._test_client", "loc": 18}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "asgi_client", "parameters": ["self"], "param_types": {}, "return_type": "SanicASGITestClient", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicASGITestClient"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "A testing client that uses ASGI to reach into the application to execute handlers. This property is available if the `sanic-testing` package is installed. See [Test Clients](/en/plugins/sanic-testing/clients#asgi-async-client-sanicasgitestclient) for details.", "source_code": "def asgi_client(self) -> SanicASGITestClient:  # type: ignore # noqa\n    \"\"\"A testing client that uses ASGI to reach into the application to execute handlers.\n\n    This property is available if the `sanic-testing` package is installed.\n\n    See [Test Clients](/en/plugins/sanic-testing/clients#asgi-async-client-sanicasgitestclient) for details.\n\n    Returns:\n        SanicASGITestClient: A testing client from the `sanic-testing` package.\n    \"\"\"  # noqa: E501\n    if self._asgi_client:\n        return self._asgi_client\n    elif self._test_manager:\n        return self._test_manager.asgi_client\n    from sanic_testing.testing import SanicASGITestClient  # type: ignore\n\n    self._asgi_client = SanicASGITestClient(self)\n    return self._asgi_client", "loc": 18}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "add_task", "parameters": ["self", "task"], "param_types": {"task": "Union[Future[Any], Coroutine[Any, Any, Any], Awaitable[Any]]"}, "return_type": "Optional[Task[Any]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "hash", "partial", "self._delayed_tasks.append", "self._loop_add_task", "self.after_server_start", "self.signal"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Schedule a task to run later, after the loop has started. While this is somewhat similar to `asyncio.create_task`, it can be used before the loop has started (in which case it will run after the loop has started in the `before_server_start` listener). Naming tasks is a good practice as it allows you to cancel them later, and allows Sanic to manage them when the server is stopped, if needed. [See user guide re: background tasks](/en/guide/basics/tasks#background-tasks)", "source_code": "def add_task(\n    self,\n    task: Union[Future[Any], Coroutine[Any, Any, Any], Awaitable[Any]],\n    *,\n    name: Optional[str] = None,\n    register: bool = True,\n) -> Optional[Task[Any]]:\n    \"\"\"Schedule a task to run later, after the loop has started.\n\n    While this is somewhat similar to `asyncio.create_task`, it can be\n    used before the loop has started (in which case it will run after the\n    loop has started in the `before_server_start` listener).\n\n    Naming tasks is a good practice as it allows you to cancel them later,\n    and allows Sanic to manage them when the server is stopped, if needed.\n\n    [See user guide re: background tasks](/en/guide/basics/tasks#background-tasks)\n\n    Args:\n        task (Union[Future[Any], Coroutine[Any, Any, Any], Awaitable[Any]]):\n            The future, coroutine, or awaitable to schedule.\n        name (Optional[str], optional): The name of the task, if needed for\n            later reference. Defaults to `None`.\n        register (bool, optional): Whether to register the task. Defaults\n            to `True`.\n\n    Returns:\n        Optional[Task[Any]]: The task that was scheduled, if applicable.\n    \"\"\"  # noqa: E501\n    try:\n        loop = self.loop  # Will raise SanicError if loop is not started\n        return self._loop_add_task(\n            task, self, loop, name=name, register=register\n        )\n    except SanicException:\n        task_name = f\"sanic.delayed_task.{hash(task)}\"\n        if not self._delayed_tasks:\n            self.after_server_start(partial(self.dispatch_delayed_tasks))\n\n        if name:\n            raise RuntimeError(\n                \"Cannot name task outside of a running application\"\n            )\n\n        self.signal(task_name)(partial(self.run_delayed_task, task=task))\n        self._delayed_tasks.append(task_name)\n        return None", "loc": 47}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "get_task", "parameters": ["self", "name"], "param_types": {"name": "str"}, "return_type": "Optional[Task]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Get a named task. This method is used to get a task by its name. Optionally, you can control whether an exception should be raised if the task is not found.", "source_code": "def get_task(\n    self, name: str, *, raise_exception: bool = True\n) -> Optional[Task]:\n    \"\"\"Get a named task.\n\n    This method is used to get a task by its name. Optionally, you can\n    control whether an exception should be raised if the task is not found.\n\n    Args:\n        name (str): The name of the task to be retrieved.\n        raise_exception (bool): If `True`, an exception will be raised if\n            the task is not found. Defaults to `True`.\n\n    Returns:\n        Optional[Task]: The task, if found.\n    \"\"\"\n    try:\n        return self._task_registry[name]\n    except KeyError:\n        if raise_exception:\n            raise SanicException(\n                f'Registered task named \"{name}\" not found.'\n            )\n        return None", "loc": 24}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "purge_tasks", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._task_registry.items", "task.cancelled", "task.done"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Purges completed and cancelled tasks from the task registry. This method iterates through the task registry, identifying any tasks that are either done or cancelled, and then removes those tasks,", "source_code": "def purge_tasks(self) -> None:\n    \"\"\"Purges completed and cancelled tasks from the task registry.\n\n    This method iterates through the task registry, identifying any tasks\n    that are either done or cancelled, and then removes those tasks,\n    leaving only the pending tasks in the registry.\n    \"\"\"\n    for key, task in self._task_registry.items():\n        if task is None:\n            continue\n        if task.done() or task.cancelled():\n            self._task_registry[key] = None\n\n    self._task_registry = {\n        k: v for k, v in self._task_registry.items() if v is not None\n    }", "loc": 16}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "shutdown_tasks", "parameters": ["self", "timeout", "increment"], "param_types": {"timeout": "Optional[float]", "increment": "float"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["asyncio.sleep", "get_running_loop", "len", "running_loop.run_until_complete", "self.purge_tasks", "suppress", "task.cancel", "task.get_name"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "Cancel all tasks except the server task. This method is used to cancel all tasks except the server task. It iterates through the task registry, cancelling all tasks except the server task, and then waits for the tasks to complete. Optionally, you can provide a timeout and an increment to control how long the method will wait for the tasks to complete.", "source_code": "def shutdown_tasks(\n    self, timeout: Optional[float] = None, increment: float = 0.1\n) -> None:\n    \"\"\"Cancel all tasks except the server task.\n\n    This method is used to cancel all tasks except the server task. It\n    iterates through the task registry, cancelling all tasks except the\n    server task, and then waits for the tasks to complete. Optionally, you\n    can provide a timeout and an increment to control how long the method\n    will wait for the tasks to complete.\n\n    Args:\n        timeout (Optional[float]): The amount of time to wait for the tasks\n            to complete. Defaults to `None`.\n        increment (float): The amount of time to wait between checks for\n            whether the tasks have completed. Defaults to `0.1`.\n    \"\"\"\n    for task in self.tasks:\n        if task.get_name() != \"RunServer\":\n            task.cancel()\n\n    if timeout is None:\n        timeout = self.config.GRACEFUL_SHUTDOWN_TIMEOUT\n\n    while len(self._task_registry) and timeout:\n        with suppress(RuntimeError):\n            running_loop = get_running_loop()\n            running_loop.run_until_complete(asyncio.sleep(increment))\n        self.purge_tasks()\n        timeout -= increment", "loc": 30}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "tasks", "parameters": ["self"], "param_types": {}, "return_type": "Iterable[Task[Any]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["iter", "self._task_registry.values"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "The tasks that are currently registered with the application.", "source_code": "def tasks(self) -> Iterable[Task[Any]]:\n    \"\"\"The tasks that are currently registered with the application.\n\n    Returns:\n        Iterable[Task[Any]]: The tasks that are currently registered with\n            the application.\n    \"\"\"\n    return (\n        task\n        for task in iter(self._task_registry.values())\n        if task is not None\n    )", "loc": 12}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "ext", "parameters": ["self"], "param_types": {}, "return_type": "Extend", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "hasattr", "setup_ext"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convenience property for accessing Sanic Extensions. This property is available if the `sanic-ext` package is installed. See [Sanic Extensions](/en/plugins/sanic-ext/getting-started) for details.", "source_code": "def ext(self) -> Extend:\n    \"\"\"Convenience property for accessing Sanic Extensions.\n\n    This property is available if the `sanic-ext` package is installed.\n\n    See [Sanic Extensions](/en/plugins/sanic-ext/getting-started)\n        for details.\n\n    Returns:\n        Extend: The Sanic Extensions instance.\n\n    Examples:\n        A typical use case might be for registering a dependency injection.\n        ```python\n        app.ext.dependency(SomeObject())\n        ```\n    \"\"\"\n    if not hasattr(self, \"_ext\"):\n        setup_ext(self, fail=True)\n\n    if not hasattr(self, \"_ext\"):\n        raise RuntimeError(\n            \"Sanic Extensions is not installed. You can add it to your \"\n            \"environment using:\\n$ pip install sanic[ext]\\nor\\n$ pip \"\n            \"install sanic-ext\"\n        )\n    return self._ext  # type: ignore", "loc": 27}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "extend", "parameters": ["self"], "param_types": {}, "return_type": "Extend", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "hasattr", "setup_ext"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Extend Sanic with additional functionality using Sanic Extensions. This method enables you to add one or more Sanic Extensions to the current Sanic instance. It allows for more control over the Extend object, such as enabling or disabling built-in extensions or providing custom configuration. See [Sanic Extensions](/en/plugins/sanic-ext/getting-started) for details.", "source_code": "def extend(\n    self,\n    *,\n    extensions: Optional[list[type[Extension]]] = None,\n    built_in_extensions: bool = True,\n    config: Optional[Union[Config, dict[str, Any]]] = None,\n    **kwargs,\n) -> Extend:\n    \"\"\"Extend Sanic with additional functionality using Sanic Extensions.\n\n    This method enables you to add one or more Sanic Extensions to the\n    current Sanic instance. It allows for more control over the Extend\n    object, such as enabling or disabling built-in extensions or providing\n    custom configuration.\n\n    See [Sanic Extensions](/en/plugins/sanic-ext/getting-started)\n        for details.\n\n    Args:\n        extensions (Optional[List[Type[Extension]]], optional): A list of\n            extensions to add. Defaults to `None`, meaning only built-in\n            extensions are added.\n        built_in_extensions (bool, optional): Whether to enable built-in\n            extensions. Defaults to `True`.\n        config (Optional[Union[Config, Dict[str, Any]]], optional):\n            Optional custom configuration for the extensions. Defaults\n            to `None`.\n        **kwargs: Additional keyword arguments that might be needed by\n            specific extensions.\n\n    Returns:\n        Extend: The Sanic Extensions instance.\n\n    Raises:\n        RuntimeError: If an attempt is made to extend Sanic after Sanic\n            Extensions has already been set up.\n\n    Examples:\n        A typical use case might be to add a custom extension along with\n            built-in ones.\n        ```python\n        app.extend(\n            extensions=[MyCustomExtension],\n            built_in_extensions=True\n        )\n        ```\n    \"\"\"\n    if hasattr(self, \"_ext\"):\n        raise RuntimeError(\n            \"Cannot extend Sanic after Sanic Extensions has been setup.\"\n        )\n    setup_ext(\n        self,\n        extensions=extensions,\n        built_in_extensions=built_in_extensions,\n        config=config,\n        fail=True,\n        **kwargs,\n    )\n    return self.ext", "loc": 60}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "register_app", "parameters": ["cls", "app"], "param_types": {"app": "Sanic"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Register a Sanic instance with the class registry. This method adds a Sanic application instance to the class registry, which is used for tracking all instances of the application. It is usually used internally, but can be used to register an application that may have otherwise been created outside of the class registry.", "source_code": "def register_app(cls, app: Sanic) -> None:\n    \"\"\"Register a Sanic instance with the class registry.\n\n    This method adds a Sanic application instance to the class registry,\n    which is used for tracking all instances of the application. It is\n    usually used internally, but can be used to register an application\n    that may have otherwise been created outside of the class registry.\n\n    Args:\n        app (Sanic): The Sanic instance to be registered.\n\n    Raises:\n        SanicException: If the app is not an instance of Sanic or if the\n            name of the app is already in use (unless in test mode).\n\n    Examples:\n        ```python\n        Sanic.register_app(my_app)\n        ```\n    \"\"\"\n    if not isinstance(app, cls):\n        raise SanicException(\"Registered app must be an instance of Sanic\")\n\n    name = app.name\n    if name in cls._app_registry and not cls.test_mode:\n        raise SanicException(f'Sanic app name \"{name}\" already in use.')\n\n    cls._app_registry[name] = app", "loc": 28}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "unregister_app", "parameters": ["cls", "app"], "param_types": {"app": "Sanic"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Unregister a Sanic instance from the class registry. This method removes a previously registered Sanic application instance from the class registry. This can be useful for cleanup purposes, especially in testing or when an app instance is no longer needed. But, it is typically used internally and should not be needed in most cases.", "source_code": "def unregister_app(cls, app: Sanic) -> None:\n    \"\"\"Unregister a Sanic instance from the class registry.\n\n    This method removes a previously registered Sanic application instance\n    from the class registry. This can be useful for cleanup purposes,\n    especially in testing or when an app instance is no longer needed. But,\n    it is typically used internally and should not be needed in most cases.\n\n    Args:\n        app (Sanic): The Sanic instance to be unregistered.\n\n    Raises:\n        SanicException: If the app is not an instance of Sanic.\n\n    Examples:\n        ```python\n        Sanic.unregister_app(my_app)\n        ```\n    \"\"\"\n    if not isinstance(app, cls):\n        raise SanicException(\"Registered app must be an instance of Sanic\")\n\n    name = app.name\n    if name in cls._app_registry:\n        del cls._app_registry[name]", "loc": 25}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "get_app", "parameters": ["cls", "name"], "param_types": {"name": "Optional[str]"}, "return_type": "Sanic", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "cls", "cls._app_registry.values", "cls.get_app", "len", "list"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Retrieve an instantiated Sanic instance by name. This method is best used when needing to get access to an already defined application instance in another part of an app. .. warning:: Be careful when using this method in the global scope as it is possible that the import path running will cause it to error if the imported global scope runs before the application instance is created. It is typically best used in a function or method that is called after the application instance has been created. ```python def setup_routes(): app = Sanic.get_app() app.add_route(handler_1, '/route1') app.add_route(handler_2, '/route2') ```", "source_code": "def get_app(\n    cls, name: Optional[str] = None, *, force_create: bool = False\n) -> Sanic:\n    \"\"\"Retrieve an instantiated Sanic instance by name.\n\n    This method is best used when needing to get access to an already\n    defined application instance in another part of an app.\n\n    .. warning::\n        Be careful when using this method in the global scope as it is\n        possible that the import path running will cause it to error if\n        the imported global scope runs before the application instance\n        is created.\n\n        It is typically best used in a function or method that is called\n        after the application instance has been created.\n\n        ```python\n        def setup_routes():\n            app = Sanic.get_app()\n            app.add_route(handler_1, '/route1')\n            app.add_route(handler_2, '/route2')\n        ```\n\n    Args:\n        name (Optional[str], optional): Name of the application instance\n            to retrieve. When not specified, it will return the only\n            application instance if there is only one. If not specified\n            and there are multiple application instances, it will raise\n            an exception. Defaults to `None`.\n        force_create (bool, optional): If `True` and the named app does\n            not exist, a new instance will be created. Defaults to `False`.\n\n    Returns:\n        Sanic: The requested Sanic app instance.\n\n    Raises:\n        SanicException: If there are multiple or no Sanic apps found, or\n            if the specified name is not found.\n\n\n    Example:\n        ```python\n        app1 = Sanic(\"app1\")\n        app2 = Sanic.get_app(\"app1\")  # app2 is the same instance as app1\n        ```\n    \"\"\"\n    if name is None:\n        if len(cls._app_registry) > 1:\n            raise SanicException(\n                'Multiple Sanic apps found, use Sanic.get_app(\"app_name\")'\n            )\n        elif len(cls._app_registry) == 0:\n            raise SanicException(\"No Sanic apps have been registered.\")\n        else:\n            return list(cls._app_registry.values())[0]\n    try:\n        return cls._app_registry[name]\n    except KeyError:\n        if name == \"__main__\":\n            return cls.get_app(\"__mp_main__\", force_create=force_create)\n        if force_create:\n            return cls(name)\n        raise SanicException(\n            f\"Sanic app name '{name}' not found.\\n\"\n            \"App instantiation must occur outside \"\n            \"if __name__ == '__main__' \"\n            \"block or by using an AppLoader.\\nSee \"\n            \"https://sanic.dev/en/guide/deployment/app-loader.html\"\n            \" for more details.\"\n        )", "loc": 71}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "amend", "parameters": ["self"], "param_types": {}, "return_type": "Iterator[None]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "self.finalize", "self.router.reset", "self.signal_router.reset", "self.signalize"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Context manager to allow changes to the app after it has started. Typically, once an application has started and is running, you cannot make certain changes, like adding routes, middleware, or signals. This", "source_code": "def amend(self) -> Iterator[None]:\n    \"\"\"Context manager to allow changes to the app after it has started.\n\n    Typically, once an application has started and is running, you cannot\n    make certain changes, like adding routes, middleware, or signals. This\n    context manager allows you to make those changes, and then finalizes\n    the app again when the context manager exits.\n\n    Yields:\n        None\n\n    Example:\n        ```python\n        with app.amend():\n            app.add_route(handler, '/new_route')\n        ```\n    \"\"\"\n    if not self.state.is_started:\n        yield\n    else:\n        do_router = self.router.finalized\n        do_signal_router = self.signal_router.finalized\n        if do_router:\n            self.router.reset()\n        if do_signal_router:\n            self.signal_router.reset()\n        yield\n        if do_signal_router:\n            self.signalize(cast(bool, self.config.TOUCHUP))\n        if do_router:\n            self.finalize()", "loc": 31}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "finalize", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.finalize_middleware", "self.router.finalize"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Finalize the routing configuration for the Sanic application. This method completes the routing setup by calling the router's finalize method, and it also finalizes any middleware that has been added to the application. If the application is not in test mode, any finalization errors will be raised. Finalization consists of identifying defined routes and optimizing Sanic's performance to meet the application's specific needs. If you are manually adding routes, after Sanic has started, you will typically want to use the  `amend` context manager rather than calling this method directly. .. note:: This method is usually called internally during the server setup process and does not typically need to be invoked manually.", "source_code": "def finalize(self) -> None:\n    \"\"\"Finalize the routing configuration for the Sanic application.\n\n    This method completes the routing setup by calling the router's\n    finalize method, and it also finalizes any middleware that has been\n    added to the application. If the application is not in test mode,\n    any finalization errors will be raised.\n\n    Finalization consists of identifying defined routes and optimizing\n    Sanic's performance to meet the application's specific needs. If\n    you are manually adding routes, after Sanic has started, you will\n    typically want to use the  `amend` context manager rather than\n    calling this method directly.\n\n    .. note::\n        This method is usually called internally during the server setup\n        process and does not typically need to be invoked manually.\n\n    Raises:\n        FinalizationError: If there is an error during the finalization\n            process, and the application is not in test mode.\n\n    Example:\n        ```python\n        app.finalize()\n        ```\n    \"\"\"\n    try:\n        self.router.finalize()\n    except FinalizationError as e:\n        if not Sanic.test_mode:\n            raise e\n    self.finalize_middleware()", "loc": 33}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "signalize", "parameters": ["self", "allow_fail_builtin"], "param_types": {"allow_fail_builtin": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.signal_router.finalize"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Finalize the signal handling configuration for the Sanic application. This method completes the signal handling setup by calling the signal router's finalize method. If the application is not in test mode, any finalization errors will be raised. Finalization consists of identifying defined signaliz and optimizing Sanic's performance to meet the application's specific needs. If you are manually adding signals, after Sanic has started, you will typically want to use the  `amend` context manager rather than calling this method directly. .. note:: This method is usually called internally during the server setup process and does not typically need to be invoked manually.", "source_code": "def signalize(self, allow_fail_builtin: bool = True) -> None:\n    \"\"\"Finalize the signal handling configuration for the Sanic application.\n\n    This method completes the signal handling setup by calling the signal\n    router's finalize method. If the application is not in test mode,\n    any finalization errors will be raised.\n\n    Finalization consists of identifying defined signaliz and optimizing\n    Sanic's performance to meet the application's specific needs. If\n    you are manually adding signals, after Sanic has started, you will\n    typically want to use the  `amend` context manager rather than\n    calling this method directly.\n\n    .. note::\n        This method is usually called internally during the server setup\n        process and does not typically need to be invoked manually.\n\n    Args:\n        allow_fail_builtin (bool, optional): If set to `True`, will allow\n            built-in signals to fail during the finalization process.\n            Defaults to `True`.\n\n    Raises:\n        FinalizationError: If there is an error during the signal\n            finalization process, and the application is not in test mode.\n\n    Example:\n        ```python\n        app.signalize(allow_fail_builtin=False)\n        ```\n    \"\"\"  # noqa: E501\n    self.signal_router.allow_fail_builtin = allow_fail_builtin\n    try:\n        self.signal_router.finalize()\n    except FinalizationError as e:\n        if not Sanic.test_mode:\n            raise e", "loc": 37}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "ack", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "self.multiplexer.ack"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Shorthand to send an ack message to the Server Manager. In general, this should usually not need to be called manually. It is used to tell the Manager that a process is operational and", "source_code": "def ack(self) -> None:\n    \"\"\"Shorthand to send an ack message to the Server Manager.\n\n    In general, this should usually not need to be called manually.\n    It is used to tell the Manager that a process is operational and\n    ready to begin operation.\n    \"\"\"\n    if hasattr(self, \"multiplexer\"):\n        self.multiplexer.ack()", "loc": 9}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "set_serving", "parameters": ["self", "serving"], "param_types": {"serving": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "self.multiplexer.set_serving"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Set the serving state of the application. This method is used to set the serving state of the application. It is used internally by Sanic and should not typically be called manually.", "source_code": "def set_serving(self, serving: bool) -> None:\n    \"\"\"Set the serving state of the application.\n\n    This method is used to set the serving state of the application.\n    It is used internally by Sanic and should not typically be called\n    manually.\n\n    Args:\n        serving (bool): Whether the application is serving.\n    \"\"\"\n    self.state.is_running = serving\n    if hasattr(self, \"multiplexer\"):\n        self.multiplexer.set_serving(serving)", "loc": 13}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "refresh", "parameters": ["self", "passthru"], "param_types": {"passthru": "Optional[dict[str, Any]]"}, "return_type": "Sanic", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "hasattr", "info.items", "isinstance", "passthru.items", "self.__class__.get_app", "self.shared_ctx.lock", "setattr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Refresh the application instance. **This is used internally by Sanic**. .. warning:: This method is intended for internal use only and should not be called directly.", "source_code": "def refresh(\n    self,\n    passthru: Optional[dict[str, Any]] = None,\n) -> Sanic:\n    \"\"\"Refresh the application instance. **This is used internally by Sanic**.\n\n    .. warning::\n        This method is intended for internal use only and should not be\n        called directly.\n\n    Args:\n        passthru (Optional[Dict[str, Any]], optional): Optional dictionary\n            of attributes to pass through to the new instance. Defaults to\n            `None`.\n\n    Returns:\n        Sanic: The refreshed application instance.\n    \"\"\"  # noqa: E501\n    registered = self.__class__.get_app(self.name)\n    if self is not registered:\n        if not registered.state.server_info:\n            registered.state.server_info = self.state.server_info\n        self = registered\n    if passthru:\n        for attr, info in passthru.items():\n            if isinstance(info, dict):\n                for key, value in info.items():\n                    setattr(getattr(self, attr), key, value)\n            else:\n                setattr(self, attr, info)\n    if hasattr(self, \"multiplexer\"):\n        self.shared_ctx.lock()\n    return self", "loc": 33}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "inspector", "parameters": ["self"], "param_types": {}, "return_type": "Inspector", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "environ.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "An instance of Inspector for accessing the application's state. This can only be accessed from a worker process, and only if the inspector has been enabled. See [Inspector](/en/guide/deployment/inspector) for details.", "source_code": "def inspector(self) -> Inspector:\n    \"\"\"An instance of Inspector for accessing the application's state.\n\n    This can only be accessed from a worker process, and only if the\n    inspector has been enabled.\n\n    See [Inspector](/en/guide/deployment/inspector) for details.\n\n    Returns:\n        Inspector: An instance of Inspector.\n    \"\"\"\n    if environ.get(\"SANIC_WORKER_PROCESS\") or not self._inspector:\n        raise SanicException(\n            \"Can only access the inspector from the main process \"\n            \"after main_process_start has run. For example, you most \"\n            \"likely want to use it inside the @app.main_process_ready \"\n            \"event listener.\"\n        )\n    return self._inspector", "loc": 19}
{"file": "sanic\\sanic\\app.py", "class_name": "Sanic", "function_name": "manager", "parameters": ["self"], "param_types": {}, "return_type": "WorkerManager", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "environ.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Property to access the WorkerManager instance. This property provides access to the WorkerManager object controlling the worker processes. It can only be accessed from the main process. .. note:: Make sure to only access this property from the main process, as attempting to do so from a worker process will result in an exception. See [WorkerManager](/en/guide/deployment/manager) for details.", "source_code": "def manager(self) -> WorkerManager:\n    \"\"\"\n    Property to access the WorkerManager instance.\n\n    This property provides access to the WorkerManager object controlling\n    the worker processes. It can only be accessed from the main process.\n\n    .. note::\n        Make sure to only access this property from the main process,\n        as attempting to do so from a worker process will result\n        in an exception.\n\n    See [WorkerManager](/en/guide/deployment/manager) for details.\n\n    Returns:\n        WorkerManager: The manager responsible for managing\n            worker processes.\n\n    Raises:\n        SanicException: If an attempt is made to access the manager\n            from a worker process or if the manager is not initialized.\n\n    Example:\n        ```python\n        app.manager.manage(...)\n        ```\n    \"\"\"\n\n    if environ.get(\"SANIC_WORKER_PROCESS\") or not self._manager:\n        raise SanicException(\n            \"Can only access the manager from the main process \"\n            \"after main_process_start has run. For example, you most \"\n            \"likely want to use it inside the @app.main_process_ready \"\n            \"event listener.\"\n        )\n    return self._manager", "loc": 36}
{"file": "sanic\\sanic\\asgi.py", "class_name": "ASGIApp", "function_name": "respond", "parameters": ["self", "response"], "param_types": {"response": "BaseHTTPResponse"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def respond(self, response: BaseHTTPResponse):\n    if self.stage is not Stage.HANDLER:\n        self.stage = Stage.FAILED\n        raise RuntimeError(\"Response already started\")\n    if self.response is not None:\n        self.response.stream = None\n    response.stream, self.response = self, response\n    return response", "loc": 8}
{"file": "sanic\\sanic\\blueprints.py", "class_name": null, "function_name": "lazy", "parameters": ["func", "as_decorator"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bp.register", "func", "future", "isfunction", "wrapper", "wraps"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Decorator to register a function to be called later.", "source_code": "def lazy(func, as_decorator=True):\n    \"\"\"Decorator to register a function to be called later.\n\n    Args:\n        func (Callable): Function to be called later.\n        as_decorator (bool): Whether the function should be called\n            immediately or not.\n    \"\"\"\n\n    @wraps(func)\n    def decorator(bp, *args, **kwargs):\n        nonlocal as_decorator\n        kwargs[\"apply\"] = False\n        pass_handler = None\n\n        if args and isfunction(args[0]):\n            as_decorator = False\n\n        def wrapper(handler):\n            future = func(bp, *args, **kwargs)\n            if as_decorator:\n                future = future(handler)\n\n            if bp.registered:\n                for app in bp.apps:\n                    bp.register(app, {})\n\n            return future\n\n        return wrapper if as_decorator else wrapper(pass_handler)\n\n    return decorator", "loc": 32}
{"file": "sanic\\sanic\\blueprints.py", "class_name": null, "function_name": "decorator", "parameters": ["bp"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bp.register", "func", "future", "isfunction", "wrapper", "wraps"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def decorator(bp, *args, **kwargs):\n    nonlocal as_decorator\n    kwargs[\"apply\"] = False\n    pass_handler = None\n\n    if args and isfunction(args[0]):\n        as_decorator = False\n\n    def wrapper(handler):\n        future = func(bp, *args, **kwargs)\n        if as_decorator:\n            future = future(handler)\n\n        if bp.registered:\n            for app in bp.apps:\n                bp.register(app, {})\n\n        return future\n\n    return wrapper if as_decorator else wrapper(pass_handler)", "loc": 20}
{"file": "sanic\\sanic\\blueprints.py", "class_name": "Blueprint", "function_name": "apps", "parameters": ["self"], "param_types": {}, "return_type": "set[Sanic]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Get the set of apps that this blueprint is registered to.", "source_code": "def apps(self) -> set[Sanic]:\n    \"\"\"Get the set of apps that this blueprint is registered to.\n\n    Returns:\n        Set[Sanic]: Set of apps that this blueprint is registered to.\n\n    Raises:\n        SanicException: If the blueprint has not yet been registered to\n            an app.\n    \"\"\"\n    if not self._apps:\n        raise SanicException(\n            f\"{self} has not yet been registered to an app\"\n        )\n    return self._apps", "loc": 15}
{"file": "sanic\\sanic\\blueprints.py", "class_name": "Blueprint", "function_name": "copy", "parameters": ["self", "name", "url_prefix", "version", "version_prefix", "allow_route_overwrite", "strict_slashes", "with_registration", "with_ctx"], "param_types": {"name": "str", "url_prefix": "Optional[Union[str, Default]]", "version": "Optional[Union[int, str, float, Default]]", "version_prefix": "Union[str, Default]", "allow_route_overwrite": "Union[bool, Default]", "strict_slashes": "Optional[Union[bool, Default]]", "with_registration": "bool", "with_ctx": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "SimpleNamespace", "app.blueprint", "attrs_backup.items", "deepcopy", "isinstance", "self.reset", "setattr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Copy a blueprint instance with some optional parameters to override the values of attributes in the old instance.", "source_code": "def copy(\n    self,\n    name: str,\n    url_prefix: Optional[Union[str, Default]] = _default,\n    version: Optional[Union[int, str, float, Default]] = _default,\n    version_prefix: Union[str, Default] = _default,\n    allow_route_overwrite: Union[bool, Default] = _default,\n    strict_slashes: Optional[Union[bool, Default]] = _default,\n    with_registration: bool = True,\n    with_ctx: bool = False,\n):\n    \"\"\"Copy a blueprint instance with some optional parameters to override the values of attributes in the old instance.\n\n    Args:\n        name (str): Unique name of the blueprint.\n        url_prefix (Optional[Union[str, Default]]): URL to be prefixed before all route URLs.\n        version (Optional[Union[int, str, float, Default]]): Blueprint version.\n        version_prefix (Union[str, Default]): The prefix of the version number shown in the URL.\n        allow_route_overwrite (Union[bool, Default]): Whether to allow route overwrite or not.\n        strict_slashes (Optional[Union[bool, Default]]): Enforce the API URLs are requested with a trailing \"/*\".\n        with_registration (bool): Whether to register the new blueprint instance with Sanic apps that were registered with the old instance or not. Default is `True`.\n        with_ctx (bool): Whether the ``ctx`` will be copied or not. Default is `False`.\n\n    Returns:\n        Blueprint: A new Blueprint instance with the specified attributes.\n    \"\"\"  # noqa: E501\n\n    attrs_backup = {\n        \"_apps\": self._apps,\n        \"routes\": self.routes,\n        \"websocket_routes\": self.websocket_routes,\n        \"middlewares\": self.middlewares,\n        \"exceptions\": self.exceptions,\n        \"listeners\": self.listeners,\n        \"statics\": self.statics,\n    }\n\n    self.reset()\n    new_bp = deepcopy(self)\n    new_bp.name = name\n    new_bp.copied_from = self.name\n\n    if not isinstance(url_prefix, Default):\n        new_bp.url_prefix = url_prefix\n    if not isinstance(version, Default):\n        new_bp.version = version\n    if not isinstance(strict_slashes, Default):\n        new_bp.strict_slashes = strict_slashes\n    if not isinstance(version_prefix, Default):\n        new_bp.version_prefix = version_prefix\n    if not isinstance(allow_route_overwrite, Default):\n        new_bp._allow_route_overwrite = allow_route_overwrite\n\n    for key, value in attrs_backup.items():\n        setattr(self, key, value)\n\n    if with_registration and self._apps:\n        if new_bp._future_statics:\n            raise SanicException(\n                \"Static routes registered with the old blueprint instance,\"\n                \" cannot be registered again.\"\n            )\n        for app in self._apps:\n            app.blueprint(new_bp)\n\n    if not with_ctx:\n        new_bp.ctx = SimpleNamespace()\n\n    return new_bp", "loc": 69}
{"file": "sanic\\sanic\\blueprints.py", "class_name": "Blueprint", "function_name": "group", "parameters": [], "param_types": {}, "return_type": "BlueprintGroup", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BlueprintGroup", "bps.append", "chain", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Group multiple blueprints (or other blueprint groups) together. Gropuping blueprings is a method for modularizing and organizing your application's code. This can be a powerful tool for creating reusable components, logically structuring your application code, and easily maintaining route definitions in bulk. This is the preferred way to group multiple blueprints together.", "source_code": "def group(\n    *blueprints: Union[Blueprint, BlueprintGroup],\n    url_prefix: Optional[str] = None,\n    version: Optional[Union[int, str, float]] = None,\n    strict_slashes: Optional[bool] = None,\n    version_prefix: str = \"/v\",\n    name_prefix: Optional[str] = \"\",\n) -> BlueprintGroup:\n    \"\"\"Group multiple blueprints (or other blueprint groups) together.\n\n    Gropuping blueprings is a method for modularizing and organizing\n    your application's code. This can be a powerful tool for creating\n    reusable components, logically structuring your application code,\n    and easily maintaining route definitions in bulk.\n\n    This is the preferred way to group multiple blueprints together.\n\n    Args:\n        blueprints (Union[Blueprint, BlueprintGroup]): Blueprints to be\n            registered as a group.\n        url_prefix (Optional[str]): URL route to be prepended to all\n            sub-prefixes. Default is `None`.\n        version (Optional[Union[int, str, float]]): API Version to be\n            used for Blueprint group. Default is `None`.\n        strict_slashes (Optional[bool]): Indicate strict slash\n            termination behavior for URL. Default is `None`.\n        version_prefix (str): Prefix to be used for the version in the\n            URL. Default is \"/v\".\n        name_prefix (Optional[str]): Prefix to be used for the name of\n            the blueprints in the group. Default is an empty string.\n\n    Returns:\n        BlueprintGroup: A group of blueprints.\n\n    Example:\n        The resulting group will have the URL prefixes\n        `'/v2/bp1'` and `'/v2/bp2'` for bp1 and bp2, respectively.\n        ```python\n        bp1 = Blueprint('bp1', url_prefix='/bp1')\n        bp2 = Blueprint('bp2', url_prefix='/bp2')\n        group = group(bp1, bp2, version=2)\n        ```\n    \"\"\"\n\n    def chain(nested) -> Iterable[Blueprint]:\n        \"\"\"Iterate through nested blueprints\"\"\"\n        for i in nested:\n            if isinstance(i, (list, tuple)):\n                yield from chain(i)\n            else:\n                yield i\n\n    bps = BlueprintGroup(\n        url_prefix=url_prefix,\n        version=version,\n        strict_slashes=strict_slashes,\n        version_prefix=version_prefix,\n        name_prefix=name_prefix,\n    )\n    for bp in chain(blueprints):\n        bps.append(bp)\n    return bps", "loc": 62}
{"file": "sanic\\sanic\\blueprints.py", "class_name": "Blueprint", "function_name": "event", "parameters": ["self", "event", "timeout"], "param_types": {"event": "str", "timeout": "Optional[Union[int, float]]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotFound", "app.signal_router.get_waiter", "condition.update", "self._event", "waiters.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Wait for a signal event to be dispatched.", "source_code": "def event(\n    self,\n    event: str,\n    timeout: Optional[Union[int, float]] = None,\n    *,\n    condition: Optional[dict[str, Any]] = None,\n):\n    \"\"\"Wait for a signal event to be dispatched.\n\n    Args:\n        event (str): Name of the signal event.\n        timeout (Optional[Union[int, float]]): Timeout for the event to be\n            dispatched.\n        condition: If provided, method will only return when the signal\n            is dispatched with the given condition.\n\n    Returns:\n        Awaitable: Awaitable for the event to be dispatched.\n    \"\"\"\n    if condition is None:\n        condition = {}\n    condition.update({\"__blueprint__\": self.name})\n\n    waiters = []\n    for app in self.apps:\n        waiter = app.signal_router.get_waiter(\n            event, condition, exclusive=False\n        )\n        if not waiter:\n            raise NotFound(\"Could not find signal %s\" % event)\n        waiters.append(waiter)\n\n    return self._event(waiters, timeout)", "loc": 33}
{"file": "sanic\\sanic\\blueprints.py", "class_name": "Blueprint", "function_name": "register_futures", "parameters": ["apps", "bp", "futures"], "param_types": {"apps": "set[Sanic]", "bp": "Blueprint", "futures": "Sequence[tuple[Any, ...]]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["app._future_registry.update"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Register futures to the apps.", "source_code": "def register_futures(\n    apps: set[Sanic], bp: Blueprint, futures: Sequence[tuple[Any, ...]]\n):\n    \"\"\"Register futures to the apps.\n\n    Args:\n        apps (Set[Sanic]): Set of apps to register the futures to.\n        bp (Blueprint): Blueprint that the futures belong to.\n        futures (Sequence[Tuple[Any, ...]]): Sequence of futures to be\n            registered.\n    \"\"\"\n\n    for app in apps:\n        app._future_registry.update({(bp, item) for item in futures})", "loc": 14}
{"file": "sanic\\sanic\\blueprints.py", "class_name": "BlueprintGroup", "function_name": "exception", "parameters": ["self"], "param_types": {}, "return_type": "Callable", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["blueprint.exception"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Decorate a function to handle exceptions for all blueprints in the group. In case of nested Blueprint Groups, the same handler is applied across each of the Blueprints recursively.", "source_code": "def exception(self, *exceptions: Exception, **kwargs) -> Callable:\n    \"\"\"Decorate a function to handle exceptions for all blueprints in the group.\n\n    In case of nested Blueprint Groups, the same handler is applied\n    across each of the Blueprints recursively.\n\n    Args:\n        *exceptions (Exception): Exceptions to handle\n        **kwargs (dict): Optional Keyword arg to use with Middleware\n\n    Returns:\n        Partial function to apply the middleware\n\n    Examples:\n        ```python\n        bp1 = Blueprint(\"bp1\", url_prefix=\"/bp1\")\n        bp2 = Blueprint(\"bp2\", url_prefix=\"/bp2\")\n        group1 = Blueprint.group(bp1, bp2)\n\n        @group1.exception(Exception)\n        def handler(request, exception):\n            return text(\"Exception caught\")\n        ```\n    \"\"\"  # noqa: E501\n\n    def register_exception_handler_for_blueprints(fn):\n        for blueprint in self.blueprints:\n            blueprint.exception(*exceptions, **kwargs)(fn)\n\n    return register_exception_handler_for_blueprints", "loc": 30}
{"file": "sanic\\sanic\\blueprints.py", "class_name": "BlueprintGroup", "function_name": "middleware", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["blueprint.middleware", "callable", "list", "register_middleware_for_blueprints"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "A decorator that can be used to implement a Middleware for all blueprints in the group. In case of nested Blueprint Groups, the same middleware is applied across each of the Blueprints recursively.", "source_code": "def middleware(self, *args, **kwargs):\n    \"\"\"A decorator that can be used to implement a Middleware for all blueprints in the group.\n\n    In case of nested Blueprint Groups, the same middleware is applied\n    across each of the Blueprints recursively.\n\n    Args:\n        *args (Optional): Optional positional Parameters to be use middleware\n        **kwargs (Optional): Optional Keyword arg to use with Middleware\n\n    Returns:\n        Partial function to apply the middleware\n    \"\"\"  # noqa: E501\n\n    def register_middleware_for_blueprints(fn):\n        for blueprint in self.blueprints:\n            blueprint.middleware(fn, *args, **kwargs)\n\n    if args and callable(args[0]):\n        fn = args[0]\n        args = list(args)[1:]\n        return register_middleware_for_blueprints(fn)\n    return register_middleware_for_blueprints", "loc": 23}
{"file": "sanic\\sanic\\blueprints.py", "class_name": "BlueprintGroup", "function_name": "on_request", "parameters": ["self", "middleware"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["callable", "partial", "self.middleware"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convenience method to register a request middleware for all blueprints in the group.", "source_code": "def on_request(self, middleware=None):\n    \"\"\"Convenience method to register a request middleware for all blueprints in the group.\n\n    Args:\n        middleware (Optional): Optional positional Parameters to be use middleware\n\n    Returns:\n        Partial function to apply the middleware\n    \"\"\"  # noqa: E501\n    if callable(middleware):\n        return self.middleware(middleware, \"request\")\n    else:\n        return partial(self.middleware, attach_to=\"request\")", "loc": 13}
{"file": "sanic\\sanic\\blueprints.py", "class_name": "BlueprintGroup", "function_name": "on_response", "parameters": ["self", "middleware"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["callable", "partial", "self.middleware"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convenience method to register a response middleware for all blueprints in the group.", "source_code": "def on_response(self, middleware=None):\n    \"\"\"Convenience method to register a response middleware for all blueprints in the group.\n\n    Args:\n        middleware (Optional): Optional positional Parameters to be use middleware\n\n    Returns:\n        Partial function to apply the middleware\n    \"\"\"  # noqa: E501\n    if callable(middleware):\n        return self.middleware(middleware, \"response\")\n    else:\n        return partial(self.middleware, attach_to=\"response\")", "loc": 13}
{"file": "sanic\\sanic\\blueprints.py", "class_name": null, "function_name": "wrapper", "parameters": ["handler"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bp.register", "func", "future"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wrapper(handler):\n    future = func(bp, *args, **kwargs)\n    if as_decorator:\n        future = future(handler)\n\n    if bp.registered:\n        for app in bp.apps:\n            bp.register(app, {})\n\n    return future", "loc": 10}
{"file": "sanic\\sanic\\blueprints.py", "class_name": null, "function_name": "chain", "parameters": ["nested"], "param_types": {}, "return_type": "Iterable[Blueprint]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["chain", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Iterate through nested blueprints", "source_code": "def chain(nested) -> Iterable[Blueprint]:\n    \"\"\"Iterate through nested blueprints\"\"\"\n    for i in nested:\n        if isinstance(i, (list, tuple)):\n            yield from chain(i)\n        else:\n            yield i", "loc": 7}
{"file": "sanic\\sanic\\compat.py", "class_name": null, "function_name": "enable_windows_color_support", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["kernel.GetStdHandle", "kernel.SetConsoleMode"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def enable_windows_color_support():\n    import ctypes\n\n    kernel = ctypes.windll.kernel32\n    kernel.SetConsoleMode(kernel.GetStdHandle(-11), 7)", "loc": 5}
{"file": "sanic\\sanic\\compat.py", "class_name": null, "function_name": "pypy_os_module_patch", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["error_logger.warning", "hasattr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The PyPy os module is missing the 'readlink' function, which causes issues withaiofiles. This workaround replaces the missing 'readlink' function with 'os.path.realpath', which serves the same purpose.", "source_code": "def pypy_os_module_patch() -> None:\n    \"\"\"\n    The PyPy os module is missing the 'readlink' function, which causes issues\n    withaiofiles. This workaround replaces the missing 'readlink' function\n    with 'os.path.realpath', which serves the same purpose.\n    \"\"\"\n    if hasattr(os, \"readlink\"):\n        error_logger.warning(\n            \"PyPy: Skipping patching of the os module as it appears the \"\n            \"'readlink' function has been added.\"\n        )\n        return\n\n    module = sys.modules[\"os\"]\n    module.readlink = os.path.realpath  # type: ignore", "loc": 15}
{"file": "sanic\\sanic\\compat.py", "class_name": null, "function_name": "pypy_windows_set_console_cp_patch", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["windll.kernel32.GetConsoleOutputCP", "windll.kernel32.SetConsoleCP", "windll.kernel32.SetConsoleOutputCP"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "A patch function for PyPy on Windows that sets the console code page to UTF-8 encodingto allow for proper handling of non-ASCII characters. This function uses ctypes to call the Windows API functions SetConsoleCP and", "source_code": "def pypy_windows_set_console_cp_patch() -> None:\n    \"\"\"\n    A patch function for PyPy on Windows that sets the console code page to\n    UTF-8 encodingto allow for proper handling of non-ASCII characters. This\n    function uses ctypes to call the Windows API functions SetConsoleCP and\n    SetConsoleOutputCP to set the code page.\n    \"\"\"\n    from ctypes import windll  # type: ignore\n\n    code: int = windll.kernel32.GetConsoleOutputCP()\n    if code != 65001:\n        windll.kernel32.SetConsoleCP(65001)\n        windll.kernel32.SetConsoleOutputCP(65001)", "loc": 13}
{"file": "sanic\\sanic\\compat.py", "class_name": null, "function_name": "ctrlc_workaround_for_windows", "parameters": ["app"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["KeyboardInterrupt", "app.add_task", "app.stop", "asyncio.sleep", "signal.signal"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ctrlc_workaround_for_windows(app):\n    async def stay_active(app):\n        \"\"\"Asyncio wakeups to allow receiving SIGINT in Python\"\"\"\n        while not die:\n            # If someone else stopped the app, just exit\n            if app.state.is_stopping:\n                return\n            # Windows Python blocks signal handlers while the event loop is\n            # waiting for I/O. Frequent wakeups keep interrupts flowing.\n            await asyncio.sleep(0.1)\n        # Can't be called from signal handler, so call it from here\n        app.stop()\n\n    def ctrlc_handler(sig, frame):\n        nonlocal die\n        if die:\n            raise KeyboardInterrupt(\"Non-graceful Ctrl+C\")\n        die = True\n\n    die = False\n    signal.signal(signal.SIGINT, ctrlc_handler)\n    app.add_task(stay_active)", "loc": 22}
{"file": "sanic\\sanic\\compat.py", "class_name": null, "function_name": "ctrlc_handler", "parameters": ["sig", "frame"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["KeyboardInterrupt"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ctrlc_handler(sig, frame):\n    nonlocal die\n    if die:\n        raise KeyboardInterrupt(\"Non-graceful Ctrl+C\")\n    die = True", "loc": 5}
{"file": "sanic\\sanic\\config.py", "class_name": "Config", "function_name": "update", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dict", "dict(item).items", "kwargs.pop", "kwargs.update", "self._post_set", "setters.items", "super", "super().__setattr__", "super().update", "{**kwargs}.keys", "{**setters, **kwargs}.items"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "Update the config with new values. This method will update the config with the values from the provided `other` objects, and then update the config with the provided `kwargs`. The `other` objects can be any object that can be converted to a dictionary, such as a `dict`, `Config` object, or `str` path to a Python file. The `kwargs` must be a dictionary of key-value pairs. .. note:: Only upper case settings are considered", "source_code": "def update(self, *other: Any, **kwargs: Any) -> None:\n    \"\"\"Update the config with new values.\n\n    This method will update the config with the values from the provided\n    `other` objects, and then update the config with the provided\n    `kwargs`. The `other` objects can be any object that can be converted\n    to a dictionary, such as a `dict`, `Config` object, or `str` path to a\n    Python file. The `kwargs` must be a dictionary of key-value pairs.\n\n    .. note::\n        Only upper case settings are considered\n\n    Args:\n        *other: Any number of objects that can be converted to a\n            dictionary.\n        **kwargs: Any number of key-value pairs.\n\n    Raises:\n        AttributeError: If a key is not in the config.\n\n    Examples:\n        ```python\n        config.update(\n            {\"A\": 1, \"B\": 2},\n            {\"C\": 3, \"D\": 4},\n            E=5,\n            F=6,\n        )\n        ```\n    \"\"\"\n    kwargs.update({k: v for item in other for k, v in dict(item).items()})\n    setters: dict[str, Any] = {\n        k: kwargs.pop(k)\n        for k in {**kwargs}.keys()\n        if k in self.__class__.__setters__\n    }\n\n    for key, value in setters.items():\n        try:\n            super().__setattr__(key, value)\n        except AttributeError:\n            ...\n\n    super().update(**kwargs)\n    for attr, value in {**setters, **kwargs}.items():\n        self._post_set(attr, value)", "loc": 46}
{"file": "sanic\\sanic\\config.py", "class_name": "Config", "function_name": "FALLBACK_ERROR_FORMAT", "parameters": ["self", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["error_logger.warning", "isinstance", "self._check_error_format"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def FALLBACK_ERROR_FORMAT(self, value):\n    self._check_error_format(value)\n    if (\n        not isinstance(self._FALLBACK_ERROR_FORMAT, Default)\n        and value != self._FALLBACK_ERROR_FORMAT\n    ):\n        error_logger.warning(\n            \"Setting config.FALLBACK_ERROR_FORMAT on an already \"\n            \"configured value may have unintended consequences.\"\n        )\n    self._FALLBACK_ERROR_FORMAT = value", "loc": 11}
{"file": "sanic\\sanic\\config.py", "class_name": "Config", "function_name": "load_environment_vars", "parameters": ["self", "prefix"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["converter", "environ.items", "key.isupper", "key.split", "key.startswith", "reversed"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Load environment variables into the config. Looks for prefixed environment variables and applies them to the configuration if present. This is called automatically when Sanic starts up to load environment variables into config. Environment variables should start with the defined prefix and should only contain uppercase letters. It will automatically hydrate the following types: - ``int`` - ``float`` - ``bool`` Anything else will be imported as a ``str``. If you would like to add additional types to this list, you can use :meth:`sanic.config.Config.register_type`. Just make sure that they are registered before you instantiate your application. You likely won't need to call this method directly. See [Configuration](/en/guide/deployment/configuration) for more details.", "source_code": "def load_environment_vars(self, prefix=SANIC_PREFIX):\n    \"\"\"Load environment variables into the config.\n\n    Looks for prefixed environment variables and applies them to the\n    configuration if present. This is called automatically when Sanic\n    starts up to load environment variables into config. Environment\n    variables should start with the defined prefix and should only\n    contain uppercase letters.\n\n    It will automatically hydrate the following types:\n\n    - ``int``\n    - ``float``\n    - ``bool``\n\n    Anything else will be imported as a ``str``. If you would like to add\n    additional types to this list, you can use\n    :meth:`sanic.config.Config.register_type`. Just make sure that they\n    are registered before you instantiate your application.\n\n    You likely won't need to call this method directly.\n\n    See [Configuration](/en/guide/deployment/configuration) for more details.\n\n    Args:\n        prefix (str): The prefix to use when looking for environment\n            variables. Defaults to `SANIC_`.\n\n\n    Examples:\n        ```python\n        # Environment variables\n        # SANIC_SERVER_NAME=example.com\n        # SANIC_SERVER_PORT=9999\n        # SANIC_SERVER_AUTORELOAD=true\n\n        # Python\n        app.config.load_environment_vars()\n        ```\n    \"\"\"  # noqa: E501\n    for key, value in environ.items():\n        if not key.startswith(prefix) or not key.isupper():\n            continue\n\n        _, config_key = key.split(prefix, 1)\n\n        for converter in reversed(self._converters):\n            try:\n                self[config_key] = converter(value)\n                break\n            except ValueError:\n                pass", "loc": 52}
{"file": "sanic\\sanic\\config.py", "class_name": "Config", "function_name": "update_config", "parameters": ["self", "config"], "param_types": {"config": "Union[bytes, str, dict[str, Any], Any]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cfg.update", "config.__class__.__dict__.keys", "config.items", "config.update", "dict", "filter", "getattr", "i[0].isupper", "isclass", "isinstance", "load_module_from_file_location", "self.update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Update app.config. .. note:: Only upper case settings are considered See [Configuration](/en/guide/deployment/configuration) for more details.", "source_code": "def update_config(self, config: Union[bytes, str, dict[str, Any], Any]):\n    \"\"\"Update app.config.\n\n    .. note::\n\n        Only upper case settings are considered\n\n    See [Configuration](/en/guide/deployment/configuration) for more details.\n\n    Args:\n        config (Union[bytes, str, dict, Any]): Path to py file holding\n            settings, dict holding settings, or any object holding\n            settings.\n\n    Examples:\n        You can upload app config by providing path to py file\n        holding settings.\n\n        ```python\n        # /some/py/file\n        A = 1\n        B = 2\n        ```\n\n        ```python\n        config.update_config(\"${some}/py/file\")\n        ```\n\n        Yes you can put environment variable here, but they must be provided\n        in format: ``${some_env_var}``, and mark that ``$some_env_var`` is\n        treated as plain string.\n\n        You can upload app config by providing dict holding settings.\n\n        ```python\n        d = {\"A\": 1, \"B\": 2}\n        config.update_config(d)\n        ```\n\n        You can upload app config by providing any object holding settings,\n        but in such case config.__dict__ will be used as dict holding settings.\n\n        ```python\n        class C:\n            A = 1\n            B = 2\n\n        config.update_config(C)\n        ```\n    \"\"\"  # noqa: E501\n    if isinstance(config, (bytes, str, Path)):\n        config = load_module_from_file_location(location=config)\n\n    if not isinstance(config, dict):\n        cfg = {}\n        if not isclass(config):\n            cfg.update(\n                {\n                    key: getattr(config, key)\n                    for key in config.__class__.__dict__.keys()\n                }\n            )\n\n        config = dict(config.__dict__)\n        config.update(cfg)\n\n    config = dict(filter(lambda i: i[0].isupper(), config.items()))\n\n    self.update(config)", "loc": 69}
{"file": "sanic\\sanic\\config.py", "class_name": "Config", "function_name": "register_type", "parameters": ["self", "converter"], "param_types": {"converter": "Callable[[str], Any]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["error_logger.warning", "self._converters.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Register a custom type converter. Allows for adding custom function to cast from a string value to any other type. The function should raise ValueError if it is not the correct type.", "source_code": "def register_type(self, converter: Callable[[str], Any]) -> None:\n    \"\"\"Register a custom type converter.\n\n    Allows for adding custom function to cast from a string value to any\n    other type. The function should raise ValueError if it is not the\n    correct type.\n\n    Args:\n        converter (Callable[[str], Any]): A function that takes a string\n            and returns a value of any type.\n\n    Examples:\n        ```python\n        def my_converter(value: str) -> Any:\n            # Do something to convert the value\n            return value\n\n        config.register_type(my_converter)\n        ```\n    \"\"\"\n    if converter in self._converters:\n        error_logger.warning(\n            f\"Configuration value converter '{converter.__name__}' has \"\n            \"already been registered\"\n        )\n        return\n    self._converters.append(converter)", "loc": 27}
{"file": "sanic\\sanic\\errorpages.py", "class_name": null, "function_name": "exception_response", "parameters": ["request", "exception", "debug", "fallback", "base", "renderer"], "param_types": {"request": "Request", "exception": "Exception", "debug": "bool", "fallback": "str", "base": "t.Type[BaseRenderer]", "renderer": "t.Optional[t.Type[BaseRenderer]]"}, "return_type": "HTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RENDERERS_BY_CONTENT_TYPE.get", "guess_mime", "renderer", "renderer(request, exception, debug).render", "t.cast"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Render a response for the default FALLBACK exception handler.", "source_code": "def exception_response(\n    request: Request,\n    exception: Exception,\n    debug: bool,\n    fallback: str,\n    base: t.Type[BaseRenderer],\n    renderer: t.Optional[t.Type[BaseRenderer]] = None,\n) -> HTTPResponse:\n    \"\"\"Render a response for the default FALLBACK exception handler.\"\"\"\n    if not renderer:\n        mt = guess_mime(request, fallback)\n        renderer = RENDERERS_BY_CONTENT_TYPE.get(mt, base)\n\n    renderer = t.cast(t.Type[BaseRenderer], renderer)\n    return renderer(request, exception, debug).render()", "loc": 15}
{"file": "sanic\\sanic\\errorpages.py", "class_name": null, "function_name": "guess_mime", "parameters": ["req", "fallback"], "param_types": {"req": "Request", "fallback": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["deprecation", "logger.debug", "repr", "req.accept.match", "req.headers.getone"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Guess the MIME type for the response based upon the request.", "source_code": "def guess_mime(req: Request, fallback: str) -> str:\n    \"\"\"Guess the MIME type for the response based upon the request.\"\"\"\n    # Attempt to find a suitable MIME format for the response.\n    # Insertion-ordered map of formats[\"html\"] = \"source of that suggestion\"\n    formats = {}\n    name = \"\"\n    # Route error_format (by magic from handler code if auto, the default)\n    if req.route:\n        name = req.route.name\n        f = req.route.extra.error_format\n        if f in MIME_BY_CONFIG:\n            formats[f] = name\n\n    if not formats and fallback in MIME_BY_CONFIG:\n        formats[fallback] = \"FALLBACK_ERROR_FORMAT\"\n\n    # If still not known, check for the request for clues of JSON\n    if not formats and fallback == \"auto\" and req.accept.match(JSON):\n        if JSON in req.accept:  # Literally, not wildcard\n            formats[\"json\"] = \"request.accept\"\n        elif JSON in req.headers.getone(\"content-type\", \"\"):\n            formats[\"json\"] = \"content-type\"\n        # DEPRECATION: Remove this block in 24.3\n        else:\n            c = None\n            try:\n                c = req.json\n            except BadRequest:\n                pass\n            if c:\n                formats[\"json\"] = \"request.json\"\n                deprecation(\n                    \"Response type was determined by the JSON content of \"\n                    \"the request. This behavior is deprecated and will be \"\n                    \"removed in v24.3. Please specify the format either by\\n\"\n                    f'  error_format=\"json\" on route {name}, by\\n'\n                    '  FALLBACK_ERROR_FORMAT = \"json\", or by adding header\\n'\n                    \"  accept: application/json to your requests.\",\n                    24.3,\n                )\n\n    # Any other supported formats\n    if fallback == \"auto\":\n        for k in MIME_BY_CONFIG:\n            if k not in formats:\n                formats[k] = \"any\"\n\n    mimes = [MIME_BY_CONFIG[k] for k in formats]\n    m = req.accept.match(*mimes)\n    if m:\n        format = CONFIG_BY_MIME[m.mime]\n        source = formats[format]\n        logger.debug(\n            \"Error Page: The client accepts %s, using '%s' from %s\",\n            m.header,\n            format,\n            source,\n        )\n    else:\n        logger.debug(\n            \"Error Page: No format found, the client accepts %s\",\n            repr(req.accept),\n        )\n    return m.mime", "loc": 64}
{"file": "sanic\\sanic\\errorpages.py", "class_name": "BaseRenderer", "function_name": "headers", "parameters": ["self"], "param_types": {}, "return_type": "t.Dict[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The headers to be used for the response.", "source_code": "def headers(self) -> t.Dict[str, str]:\n    \"\"\"The headers to be used for the response.\"\"\"\n    if isinstance(self.exception, SanicException):\n        return getattr(self.exception, \"headers\", {})\n    return {}", "loc": 5}
{"file": "sanic\\sanic\\errorpages.py", "class_name": "BaseRenderer", "function_name": "status", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The status code to be used for the response.", "source_code": "def status(self):\n    \"\"\"The status code to be used for the response.\"\"\"\n    if isinstance(self.exception, SanicException):\n        return getattr(self.exception, \"status_code\", FALLBACK_STATUS)\n    return FALLBACK_STATUS", "loc": 5}
{"file": "sanic\\sanic\\errorpages.py", "class_name": "BaseRenderer", "function_name": "text", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The text to be used for the response.", "source_code": "def text(self):\n    \"\"\"The text to be used for the response.\"\"\"\n    if self.debug or isinstance(self.exception, SanicException):\n        return str(self.exception)\n    return FALLBACK_TEXT", "loc": 5}
{"file": "sanic\\sanic\\errorpages.py", "class_name": "BaseRenderer", "function_name": "render", "parameters": ["self"], "param_types": {}, "return_type": "HTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "output.headers.update"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Outputs the exception as a response.", "source_code": "def render(self) -> HTTPResponse:\n    \"\"\"Outputs the exception as a response.\n\n    Returns:\n        HTTPResponse: The response object.\n    \"\"\"\n    output = (\n        self.full\n        if self.debug and not getattr(self.exception, \"quiet\", False)\n        else self.minimal\n    )()\n    output.status = self.status\n    output.headers.update(self.headers)\n    return output", "loc": 14}
{"file": "sanic\\sanic\\errorpages.py", "class_name": "HTMLRenderer", "function_name": "full", "parameters": ["self"], "param_types": {}, "return_type": "HTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ErrorPage", "html", "page.render", "super"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def full(self) -> HTTPResponse:\n    page = ErrorPage(\n        debug=self.debug,\n        title=super().title,\n        text=super().text,\n        request=self.request,\n        exc=self.exception,\n    )\n    return html(page.render())", "loc": 9}
{"file": "sanic\\sanic\\errorpages.py", "class_name": "TextRenderer", "function_name": "full", "parameters": ["self"], "param_types": {}, "return_type": "HTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.OUTPUT_TEXT.format", "self._generate_body", "text"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def full(self) -> HTTPResponse:\n    return text(\n        self.OUTPUT_TEXT.format(\n            title=self.title,\n            text=self.text,\n            bar=(\"=\" * len(self.title)),\n            body=self._generate_body(full=True),\n        )\n    )", "loc": 9}
{"file": "sanic\\sanic\\errorpages.py", "class_name": "TextRenderer", "function_name": "minimal", "parameters": ["self"], "param_types": {}, "return_type": "HTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.OUTPUT_TEXT.format", "self._generate_body", "text"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def minimal(self) -> HTTPResponse:\n    return text(\n        self.OUTPUT_TEXT.format(\n            title=self.title,\n            text=self.text,\n            bar=(\"=\" * len(self.title)),\n            body=self._generate_body(full=False),\n        )\n    )", "loc": 9}
{"file": "sanic\\sanic\\headers.py", "class_name": null, "function_name": "parse_accept", "parameters": ["accept"], "param_types": {"accept": "Optional[str]"}, "return_type": "AcceptList", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AcceptList", "InvalidHeader", "MediaType._parse", "accept.split", "sorted"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Parse an Accept header and order the acceptable media types according to RFC 7231, s. 5.3.2 https://datatracker.ietf.org/doc/html/rfc7231#section-5.3.2", "source_code": "def parse_accept(accept: Optional[str]) -> AcceptList:\n    \"\"\"Parse an Accept header and order the acceptable media types according to RFC 7231, s. 5.3.2\n\n    https://datatracker.ietf.org/doc/html/rfc7231#section-5.3.2\n\n    Args:\n        accept (str): The Accept header value to parse.\n\n    Returns:\n        AcceptList: A list of MediaType objects, ordered by preference.\n\n    Raises:\n        InvalidHeader: If the header value is invalid.\n    \"\"\"  # noqa: E501\n    if not accept:\n        if accept == \"\":\n            return AcceptList()  # Empty header, accept nothing\n        accept = \"*/*\"  # No header means that all types are accepted\n    try:\n        a = [\n            mt\n            for mt in [MediaType._parse(mtype) for mtype in accept.split(\",\")]\n            if mt\n        ]\n        if not a:\n            raise ValueError\n        return AcceptList(sorted(a, key=lambda x: x.key))\n    except ValueError:\n        raise InvalidHeader(f\"Invalid header value in Accept: {accept}\")", "loc": 29}
{"file": "sanic\\sanic\\headers.py", "class_name": null, "function_name": "parse_content_header", "parameters": ["value"], "param_types": {"value": "str"}, "return_type": "tuple[str, Options]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["(m.group(2) or m.group(3)).replace('%22', '\"').replace", "_param.finditer", "m.group", "m.group(1).lower", "m.group(2) or m.group(3).replace", "value.find", "value.strip", "value.strip().lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse content-type and content-disposition header values. E.g. `form-data; name=upload; filename=\"file.txt\"` to ('form-data', {'name': 'upload', 'filename': 'file.txt'}) Mostly identical to cgi.parse_header and werkzeug.parse_options_header but runs faster and handles special characters better. Unescapes %22 to `\"` and %0D%0A to ` ` in field values.", "source_code": "def parse_content_header(value: str) -> tuple[str, Options]:\n    \"\"\"Parse content-type and content-disposition header values.\n\n    E.g. `form-data; name=upload; filename=\"file.txt\"` to\n    ('form-data', {'name': 'upload', 'filename': 'file.txt'})\n\n    Mostly identical to cgi.parse_header and werkzeug.parse_options_header\n    but runs faster and handles special characters better.\n\n    Unescapes %22 to `\"` and %0D%0A to `\\n` in field values.\n\n    Args:\n        value (str): The header value to parse.\n\n    Returns:\n        Tuple[str, Options]: The header value and a dict of options.\n    \"\"\"\n    pos = value.find(\";\")\n    if pos == -1:\n        options: dict[str, Union[int, str]] = {}\n    else:\n        options = {\n            m.group(1).lower(): (m.group(2) or m.group(3))\n            .replace(\"%22\", '\"')\n            .replace(\"%0D%0A\", \"\\n\")\n            for m in _param.finditer(value[pos:])\n        }\n        value = value[:pos]\n    return value.strip().lower(), options", "loc": 29}
{"file": "sanic\\sanic\\headers.py", "class_name": null, "function_name": "parse_forwarded", "parameters": ["headers", "config"], "param_types": {}, "return_type": "Optional[Options]", "param_doc": {}, "return_doc": "dict with keys and values, or None if nothing matched", "raises_doc": [], "called_functions": ["','.join", "_rparam.finditer", "fwd_normalize", "headers.getall", "key.lower", "m.end", "m.groups", "m.start", "options.append", "reversed", "val_quoted.replace"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Parse RFC 7239 Forwarded headers. The value of `by` or `secret` must match `config.FORWARDED_SECRET`", "source_code": "def parse_forwarded(headers, config) -> Optional[Options]:\n    \"\"\"Parse RFC 7239 Forwarded headers.\n    The value of `by` or `secret` must match `config.FORWARDED_SECRET`\n    :return: dict with keys and values, or None if nothing matched\n    \"\"\"\n    header = headers.getall(\"forwarded\", None)\n    secret = config.FORWARDED_SECRET\n    if header is None or not secret:\n        return None\n    header = \",\".join(header)  # Join multiple header lines\n    if secret not in header:\n        return None\n    # Loop over <separator><key>=<value> elements from right to left\n    sep = pos = None\n    options: list[tuple[str, str]] = []\n    found = False\n    for m in _rparam.finditer(header[::-1]):\n        # Start of new element? (on parser skips and non-semicolon right sep)\n        if m.start() != pos or sep != \";\":\n            # Was the previous element (from right) what we wanted?\n            if found:\n                break\n            # Clear values and parse as new element\n            del options[:]\n        pos = m.end()\n        val_token, val_quoted, key, sep = m.groups()\n        key = key.lower()[::-1]\n        val = (val_token or val_quoted.replace('\"\\\\', '\"'))[::-1]\n        options.append((key, val))\n        if key in (\"secret\", \"by\") and val == secret:\n            found = True\n        # Check if we would return on next round, to avoid useless parse\n        if found and sep != \";\":\n            break\n    # If secret was found, return the matching options in left-to-right order\n    return fwd_normalize(reversed(options)) if found else None", "loc": 36}
{"file": "sanic\\sanic\\headers.py", "class_name": null, "function_name": "parse_xforwarded", "parameters": ["headers", "config"], "param_types": {}, "return_type": "Optional[Options]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fwd_normalize", "h.split", "headers.getall", "headers.getone", "options", "p.strip"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Parse traditional proxy headers.", "source_code": "def parse_xforwarded(headers, config) -> Optional[Options]:\n    \"\"\"Parse traditional proxy headers.\"\"\"\n    real_ip_header = config.REAL_IP_HEADER\n    proxies_count = config.PROXIES_COUNT\n    addr = real_ip_header and headers.getone(real_ip_header, None)\n    if not addr and proxies_count:\n        assert proxies_count > 0\n        try:\n            # Combine, split and filter multiple headers' entries\n            forwarded_for = headers.getall(config.FORWARDED_FOR_HEADER)\n            proxies = [\n                p\n                for p in (\n                    p.strip() for h in forwarded_for for p in h.split(\",\")\n                )\n                if p\n            ]\n            addr = proxies[-proxies_count]\n        except (KeyError, IndexError):\n            pass\n    # No processing of other headers if no address is found\n    if not addr:\n        return None\n\n    def options():\n        yield \"for\", addr\n        for key, header in (\n            (\"proto\", \"x-scheme\"),\n            (\"proto\", \"x-forwarded-proto\"),  # Overrides X-Scheme if present\n            (\"host\", \"x-forwarded-host\"),\n            (\"port\", \"x-forwarded-port\"),\n            (\"path\", \"x-forwarded-path\"),\n        ):\n            yield key, headers.getone(header, None)\n\n    return fwd_normalize(options())", "loc": 36}
{"file": "sanic\\sanic\\headers.py", "class_name": null, "function_name": "fwd_normalize", "parameters": ["fwd"], "param_types": {"fwd": "OptionsIterable"}, "return_type": "Options", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fwd_normalize_address", "int", "unquote", "val.lower"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Normalize and convert values extracted from forwarded headers.", "source_code": "def fwd_normalize(fwd: OptionsIterable) -> Options:\n    \"\"\"Normalize and convert values extracted from forwarded headers.\n\n    Args:\n        fwd (OptionsIterable): An iterable of key-value pairs.\n\n    Returns:\n        Options: A dict of normalized key-value pairs.\n    \"\"\"\n    ret: dict[str, Union[int, str]] = {}\n    for key, val in fwd:\n        if val is not None:\n            try:\n                if key in (\"by\", \"for\"):\n                    ret[key] = fwd_normalize_address(val)\n                elif key in (\"host\", \"proto\"):\n                    ret[key] = val.lower()\n                elif key == \"port\":\n                    ret[key] = int(val)\n                elif key == \"path\":\n                    ret[key] = unquote(val)\n                else:\n                    ret[key] = val\n            except ValueError:\n                pass\n    return ret", "loc": 26}
{"file": "sanic\\sanic\\headers.py", "class_name": null, "function_name": "fwd_normalize_address", "parameters": ["addr"], "param_types": {"addr": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "_ipv6_re.fullmatch", "addr.lower", "addr.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Normalize address fields of proxy headers.", "source_code": "def fwd_normalize_address(addr: str) -> str:\n    \"\"\"Normalize address fields of proxy headers.\n\n    Args:\n        addr (str): An address string.\n\n    Returns:\n        str: A normalized address string.\n    \"\"\"\n    if addr == \"unknown\":\n        raise ValueError()  # omit unknown value identifiers\n    if addr.startswith(\"_\"):\n        return addr  # do not lower-case obfuscated strings\n    if _ipv6_re.fullmatch(addr):\n        addr = f\"[{addr}]\"  # bracket IPv6\n    return addr.lower()", "loc": 16}
{"file": "sanic\\sanic\\headers.py", "class_name": null, "function_name": "parse_host", "parameters": ["host"], "param_types": {"host": "str"}, "return_type": "tuple[Optional[str], Optional[int]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_host_re.fullmatch", "host.lower", "int", "m.groups"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Split host:port into hostname and port.", "source_code": "def parse_host(host: str) -> tuple[Optional[str], Optional[int]]:\n    \"\"\"Split host:port into hostname and port.\n\n    Args:\n        host (str): A host string.\n\n    Returns:\n        Tuple[Optional[str], Optional[int]]: A tuple of hostname and port.\n    \"\"\"\n    m = _host_re.fullmatch(host)\n    if not m:\n        return None, None\n    host, port = m.groups()\n    return host.lower(), int(port) if port is not None else None", "loc": 14}
{"file": "sanic\\sanic\\headers.py", "class_name": null, "function_name": "format_http1_response", "parameters": ["status", "headers"], "param_types": {"status": "int", "headers": "HeaderBytesIterable"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Format a HTTP/1.1 response header.", "source_code": "def format_http1_response(status: int, headers: HeaderBytesIterable) -> bytes:\n    \"\"\"Format a HTTP/1.1 response header.\n\n    Args:\n        status (int): The HTTP status code.\n        headers (HeaderBytesIterable): An iterable of header tuples.\n\n    Returns:\n        bytes: The formatted response header.\n    \"\"\"\n    # Note: benchmarks show that here bytes concat is faster than bytearray,\n    # b\"\".join() or %-formatting. %timeit any changes you make.\n    ret = _HTTP1_STATUSLINES[status]\n    for h in headers:\n        ret += b\"%b: %b\\r\\n\" % h\n    ret += b\"\\r\\n\"\n    return ret", "loc": 17}
{"file": "sanic\\sanic\\headers.py", "class_name": null, "function_name": "parse_credentials", "parameters": ["header", "prefixes"], "param_types": {"header": "Optional[str]", "prefixes": "Optional[Union[list, tuple, set]]"}, "return_type": "tuple[Optional[str], Optional[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["header.partition", "header.partition(prefix)[-1].strip", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Parses any header with the aim to retrieve any credentials from it.", "source_code": "def parse_credentials(\n    header: Optional[str],\n    prefixes: Optional[Union[list, tuple, set]] = None,\n) -> tuple[Optional[str], Optional[str]]:\n    \"\"\"Parses any header with the aim to retrieve any credentials from it.\n\n    Args:\n        header (Optional[str]): The header to parse.\n        prefixes (Optional[Union[List, Tuple, Set]], optional): The prefixes to look for. Defaults to None.\n\n    Returns:\n        Tuple[Optional[str], Optional[str]]: The prefix and the credentials.\n    \"\"\"  # noqa: E501\n    if not prefixes or not isinstance(prefixes, (list, tuple, set)):\n        prefixes = (\"Basic\", \"Bearer\", \"Token\")\n    if header is not None:\n        for prefix in prefixes:\n            if prefix in header:\n                return prefix, header.partition(prefix)[-1].strip()\n    return None, header", "loc": 20}
{"file": "sanic\\sanic\\headers.py", "class_name": "MediaType", "function_name": "match", "parameters": ["self", "mime_with_params"], "param_types": {"mime_with_params": "Union[str, MediaType]"}, "return_type": "Optional[MediaType]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["MediaType._parse", "all", "isinstance", "mt.params.items", "self.params.get"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Match this media type against another media type. Check if this media type matches the given mime type/subtype. Wildcards are supported both ways on both type and subtype. If mime contains a semicolon, optionally followed by parameters, the parameters of the two media types must match exactly. .. note:: Use the `==` operator instead to check for literal matches without expanding wildcards.", "source_code": "def match(\n    self,\n    mime_with_params: Union[str, MediaType],\n) -> Optional[MediaType]:\n    \"\"\"Match this media type against another media type.\n\n    Check if this media type matches the given mime type/subtype.\n    Wildcards are supported both ways on both type and subtype.\n    If mime contains a semicolon, optionally followed by parameters,\n    the parameters of the two media types must match exactly.\n\n    .. note::\n        Use the `==` operator instead to check for literal matches\n        without expanding wildcards.\n\n\n    Args:\n        media_type (str): A type/subtype string to match.\n\n    Returns:\n        MediaType: Returns `self` if the media types are compatible.\n        None: Returns `None` if the media types are not compatible.\n    \"\"\"\n    mt = (\n        MediaType._parse(mime_with_params)\n        if isinstance(mime_with_params, str)\n        else mime_with_params\n    )\n    return (\n        self\n        if (\n            mt\n            # All parameters given in the other media type must match\n            and all(self.params.get(k) == v for k, v in mt.params.items())\n            # Subtype match\n            and (\n                self.subtype == mt.subtype\n                or self.subtype == \"*\"\n                or mt.subtype == \"*\"\n            )\n            # Type match\n            and (\n                self.type == mt.type or self.type == \"*\" or mt.type == \"*\"\n            )\n        )\n        else None\n    )", "loc": 47}
{"file": "sanic\\sanic\\headers.py", "class_name": "Matched", "function_name": "match", "parameters": ["self", "other"], "param_types": {"other": "Union[str, Matched]"}, "return_type": "Optional[Matched]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Matched.parse", "isinstance", "self.header.match"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Match this MIME string against another MIME string. Check if this MIME string matches the given MIME string. Wildcards are supported both ways on both type and subtype.", "source_code": "def match(self, other: Union[str, Matched]) -> Optional[Matched]:\n    \"\"\"Match this MIME string against another MIME string.\n\n    Check if this MIME string matches the given MIME string. Wildcards are supported both ways on both type and subtype.\n\n    Args:\n        other (str): A MIME string to match.\n\n    Returns:\n        Matched: Returns `self` if the MIME strings are compatible.\n        None: Returns `None` if the MIME strings are not compatible.\n    \"\"\"  # noqa: E501\n    accept = Matched.parse(other) if isinstance(other, str) else other\n    if not self.header or not accept.header:\n        return None\n    if self.header.match(accept.header):\n        return accept\n    return None", "loc": 18}
{"file": "sanic\\sanic\\headers.py", "class_name": "AcceptList", "function_name": "match", "parameters": ["self"], "param_types": {}, "return_type": "Matched", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Matched", "acc.match", "enumerate", "sorted"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Find a media type accepted by the client. This method can be used to find which of the media types requested by the client is most preferred against the ones given as arguments. The ordering of preference is set by: 1. The order set by RFC 7231, s. 5.3.2, giving a higher priority to q values and more specific type definitions, 2. The order of the arguments (first is most preferred), and 3. The first matching entry on the Accept header. Wildcards are matched both ways. A match is usually found, as the Accept headers typically include `*/*`, in particular if the header is missing, is not manually set, or if the client is a browser. Note: the returned object behaves as a string of the mime argument that matched, and is empty/falsy if no match was found. The matched header entry `MediaType` or `None` is available as the `m` attribute.", "source_code": "def match(self, *mimes: str, accept_wildcards=True) -> Matched:\n    \"\"\"Find a media type accepted by the client.\n\n    This method can be used to find which of the media types requested by\n    the client is most preferred against the ones given as arguments.\n\n    The ordering of preference is set by:\n    1. The order set by RFC 7231, s. 5.3.2, giving a higher priority\n        to q values and more specific type definitions,\n    2. The order of the arguments (first is most preferred), and\n    3. The first matching entry on the Accept header.\n\n    Wildcards are matched both ways. A match is usually found, as the\n    Accept headers typically include `*/*`, in particular if the header\n    is missing, is not manually set, or if the client is a browser.\n\n    Note: the returned object behaves as a string of the mime argument\n    that matched, and is empty/falsy if no match was found. The matched\n    header entry `MediaType` or `None` is available as the `m` attribute.\n\n    Args:\n        mimes (List[str]): Any MIME types to search for in order of preference.\n        accept_wildcards (bool): Match Accept entries with wildcards in them.\n\n    Returns:\n        Match: A match object with the mime string and the MediaType object.\n    \"\"\"  # noqa: E501\n    a = sorted(\n        (-acc.q, i, j, mime, acc)\n        for j, acc in enumerate(self)\n        if accept_wildcards or not acc.has_wildcard\n        for i, mime in enumerate(mimes)\n        if acc.match(mime)\n    )\n    return Matched(*(a[0][-2:] if a else (\"\", None)))", "loc": 35}
{"file": "sanic\\sanic\\headers.py", "class_name": null, "function_name": "options", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["headers.getone"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def options():\n    yield \"for\", addr\n    for key, header in (\n        (\"proto\", \"x-scheme\"),\n        (\"proto\", \"x-forwarded-proto\"),  # Overrides X-Scheme if present\n        (\"host\", \"x-forwarded-host\"),\n        (\"port\", \"x-forwarded-port\"),\n        (\"path\", \"x-forwarded-path\"),\n    ):\n        yield key, headers.getone(header, None)", "loc": 10}
{"file": "sanic\\sanic\\helpers.py", "class_name": null, "function_name": "import_string", "parameters": ["module_name", "package"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "a module object or one instance from class if", "raises_doc": [], "called_functions": ["getattr", "import_module", "ismodule", "module_name.rsplit", "obj"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "import a module or class by string path. :module_name: str with path of module or path to import and instantiate a class", "source_code": "def import_string(module_name, package=None):\n    \"\"\"\n    import a module or class by string path.\n\n    :module_name: str with path of module or path to import and\n    instantiate a class\n    :returns: a module object or one instance from class if\n    module_name is a valid path to class\n\n    \"\"\"\n    module, klass = module_name.rsplit(\".\", 1)\n    module = import_module(module, package=package)\n    obj = getattr(module, klass)\n    if ismodule(obj):\n        return obj\n    return obj()", "loc": 16}
{"file": "sanic\\sanic\\middleware.py", "class_name": "Middleware", "function_name": "convert", "parameters": ["cls"], "param_types": {}, "return_type": "Deque[Middleware]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Middleware", "deque", "isinstance"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Convert middleware collections to a deque of Middleware objects.", "source_code": "def convert(\n    cls,\n    *middleware_collections: Sequence[Union[Middleware, MiddlewareType]],\n    location: MiddlewareLocation,\n) -> Deque[Middleware]:\n    \"\"\"Convert middleware collections to a deque of Middleware objects.\n\n    Args:\n        *middleware_collections (Sequence[Union[Middleware, MiddlewareType]]):\n            The middleware collections to convert.\n        location (MiddlewareLocation): The location of the middleware.\n\n    Returns:\n        Deque[Middleware]: The converted middleware.\n    \"\"\"  # noqa: E501\n    return deque(\n        [\n            middleware\n            if isinstance(middleware, Middleware)\n            else Middleware(middleware, location)\n            for collection in middleware_collections\n            for middleware in collection\n        ]\n    )", "loc": 24}
{"file": "sanic\\sanic\\middleware.py", "class_name": "Middleware", "function_name": "reset_count", "parameters": ["cls"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["count", "next"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Reset the counter for the middleware definition order. This is used for testing.", "source_code": "def reset_count(cls) -> None:\n    \"\"\"Reset the counter for the middleware definition order.\n\n    This is used for testing.\n\n    Returns:\n        None\n    \"\"\"\n    cls._counter = count()\n    cls.count = next(cls._counter)", "loc": 10}
{"file": "sanic\\sanic\\router.py", "class_name": "Router", "function_name": "get", "parameters": ["self", "path", "method", "host"], "param_types": {"path": "str", "method": "str", "host": "Optional[str]"}, "return_type": "tuple[Route, RouteHandler, dict[str, Any]]", "param_doc": {"request": "the incoming request object"}, "return_doc": "details needed for handling the request and returning the", "raises_doc": [], "called_functions": ["lru_cache", "self._get"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Retrieve a `Route` object containing the details about how to handle a response for a given request", "source_code": "def get(  # type: ignore\n    self, path: str, method: str, host: Optional[str]\n) -> tuple[Route, RouteHandler, dict[str, Any]]:\n    \"\"\"Retrieve a `Route` object containing the details about how to handle a response for a given request\n\n    :param request: the incoming request object\n    :type request: Request\n    :return: details needed for handling the request and returning the\n        correct response\n    :rtype: Tuple[ Route, RouteHandler, Dict[str, Any]]\n\n    Args:\n        path (str): the path of the route\n        method (str): the HTTP method of the route\n        host (Optional[str]): the host of the route\n\n    Raises:\n        NotFound: if the route is not found\n        MethodNotAllowed: if the method is not allowed for the route\n\n    Returns:\n        Tuple[Route, RouteHandler, Dict[str, Any]]: the route, handler, and match info\n    \"\"\"  # noqa: E501\n    __tracebackhide__ = True\n    return self._get(path, method, host)", "loc": 25}
{"file": "sanic\\sanic\\router.py", "class_name": "Router", "function_name": "add", "parameters": ["self", "uri", "methods", "handler", "host", "strict_slashes", "stream", "ignore_body", "version", "name", "unquote", "static", "version_prefix", "overwrite", "error_format"], "param_types": {"uri": "str", "methods": "Iterable[str]", "handler": "RouteHandler", "host": "Optional[Union[str, Iterable[str]]]", "strict_slashes": "bool", "stream": "bool", "ignore_body": "bool", "version": "Optional[Union[str, float, int]]", "name": "Optional[str]", "unquote": "bool", "static": "bool", "version_prefix": "str", "overwrite": "bool", "error_format": "Optional[str]"}, "return_type": "Union[Route, list[Route]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'/'.join", "check_error_format", "dict", "frozenset", "host.replace", "isinstance", "len", "map", "params.update", "routes.append", "self._normalize", "str", "str(version).strip", "str(version).strip('/').lstrip", "super", "super().add", "uri.lstrip"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Add a handler to the router", "source_code": "def add(  # type: ignore\n    self,\n    uri: str,\n    methods: Iterable[str],\n    handler: RouteHandler,\n    host: Optional[Union[str, Iterable[str]]] = None,\n    strict_slashes: bool = False,\n    stream: bool = False,\n    ignore_body: bool = False,\n    version: Optional[Union[str, float, int]] = None,\n    name: Optional[str] = None,\n    unquote: bool = False,\n    static: bool = False,\n    version_prefix: str = \"/v\",\n    overwrite: bool = False,\n    error_format: Optional[str] = None,\n) -> Union[Route, list[Route]]:\n    \"\"\"Add a handler to the router\n\n    Args:\n        uri (str): The path of the route.\n        methods (Iterable[str]): The types of HTTP methods that should be attached,\n            example: [\"GET\", \"POST\", \"OPTIONS\"].\n        handler (RouteHandler): The sync or async function to be executed.\n        host (Optional[str], optional): Host that the route should be on. Defaults to None.\n        strict_slashes (bool, optional): Whether to apply strict slashes. Defaults to False.\n        stream (bool, optional): Whether to stream the response. Defaults to False.\n        ignore_body (bool, optional): Whether the incoming request body should be read.\n            Defaults to False.\n        version (Union[str, float, int], optional): A version modifier for the uri. Defaults to None.\n        name (Optional[str], optional): An identifying name of the route. Defaults to None.\n\n    Returns:\n        Route: The route object.\n    \"\"\"  # noqa: E501\n\n    if version is not None:\n        version = str(version).strip(\"/\").lstrip(\"v\")\n        uri = \"/\".join([f\"{version_prefix}{version}\", uri.lstrip(\"/\")])\n\n    uri = self._normalize(uri, handler)\n\n    params = dict(\n        path=uri,\n        handler=handler,\n        methods=frozenset(map(str, methods)) if methods else None,\n        name=name,\n        strict=strict_slashes,\n        unquote=unquote,\n        overwrite=overwrite,\n    )\n\n    if isinstance(host, str):\n        hosts = [host]\n    else:\n        hosts = host or [None]  # type: ignore\n\n    routes = []\n\n    for host in hosts:\n        if host:\n            params.update({\"requirements\": {\"host\": host}})\n\n        ident = name\n        if len(hosts) > 1:\n            ident = (\n                f\"{name}_{host.replace('.', '_')}\"\n                if name\n                else \"__unnamed__\"\n            )\n\n        route = super().add(**params)  # type: ignore\n        route.extra.ident = ident\n        route.extra.ignore_body = ignore_body\n        route.extra.stream = stream\n        route.extra.hosts = hosts\n        route.extra.static = static\n        route.extra.error_format = error_format\n\n        if error_format:\n            check_error_format(route.extra.error_format)\n\n        routes.append(route)\n\n    if len(routes) == 1:\n        return routes[0]\n    return routes", "loc": 87}
{"file": "sanic\\sanic\\router.py", "class_name": "Router", "function_name": "find_route_by_view_name", "parameters": ["self", "view_name", "name"], "param_types": {"view_name": "str", "name": "Optional[str]"}, "return_type": "Optional[Route]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["lru_cache", "self.ctx.app.generate_name", "self.name_index.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Find a route in the router based on the specified view name.", "source_code": "def find_route_by_view_name(\n    self, view_name: str, name: Optional[str] = None\n) -> Optional[Route]:\n    \"\"\"Find a route in the router based on the specified view name.\n\n    Args:\n        view_name (str): the name of the view to search for\n        name (Optional[str], optional): the name of the route. Defaults to `None`.\n\n    Returns:\n        Optional[Route]: the route object\n    \"\"\"  # noqa: E501\n    if not view_name:\n        return None\n\n    route = self.name_index.get(view_name)\n    if not route:\n        full_name = self.ctx.app.generate_name(view_name)\n        route = self.name_index.get(full_name)\n\n    if not route:\n        return None\n\n    return route", "loc": 24}
{"file": "sanic\\sanic\\router.py", "class_name": "Router", "function_name": "finalize", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "any", "label.startswith", "self.dynamic_routes.values", "super", "super().finalize"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Finalize the router.", "source_code": "def finalize(self, *args, **kwargs) -> None:\n    \"\"\"Finalize the router.\n\n    Raises:\n        SanicException: if a route contains a parameter name that starts with \"__\" and is not in ALLOWED_LABELS\n    \"\"\"  # noqa: E501\n    super().finalize(*args, **kwargs)\n\n    for route in self.dynamic_routes.values():\n        if any(\n            label.startswith(\"__\") and label not in ALLOWED_LABELS\n            for label in route.labels\n        ):\n            raise SanicException(\n                f\"Invalid route: {route}. Parameter names cannot use '__'.\"\n            )", "loc": 16}
{"file": "sanic\\sanic\\signals.py", "class_name": "SignalRouter", "function_name": "format_event", "parameters": ["event"], "param_types": {"event": "Union[str, Enum]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Ensure event strings in proper format", "source_code": "def format_event(event: Union[str, Enum]) -> str:\n    \"\"\"Ensure event strings in proper format\n\n    Args:\n        event (str): event string\n\n    Returns:\n        str: formatted event string\n    \"\"\"\n    if isinstance(event, Enum):\n        event = str(event.value)\n    if \".\" not in event:\n        event = GENERIC_SIGNAL_FORMAT % event\n    return event", "loc": 14}
{"file": "sanic\\sanic\\signals.py", "class_name": "SignalRouter", "function_name": "get", "parameters": ["self", "event", "condition"], "param_types": {"event": "Union[str, Enum]", "condition": "Optional[dict[str, str]]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotFound", "group.params.items", "self.find_route", "self.format_event", "terms.append", "tuple"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Get the handlers for a signal", "source_code": "def get(  # type: ignore\n    self,\n    event: Union[str, Enum],\n    condition: Optional[dict[str, str]] = None,\n):\n    \"\"\"Get the handlers for a signal\n\n    Args:\n        event (str): The event to get the handlers for\n        condition (Optional[Dict[str, str]], optional): A dictionary of conditions to match against the handlers. Defaults to `None`.\n\n    Returns:\n        Tuple[SignalGroup, List[SignalHandler], Dict[str, Any]]: A tuple of the `SignalGroup` that matched, a list of the handlers that matched, and a dictionary of the params that matched\n\n    Raises:\n        NotFound: If no handlers are found\n    \"\"\"  # noqa: E501\n    event = self.format_event(event)\n    extra = condition or {}\n    try:\n        group, param_basket = self.find_route(\n            f\".{event}\",\n            self.DEFAULT_METHOD,\n            self,\n            {\"__params__\": {}, \"__matches__\": {}},\n            extra=extra,\n        )\n    except NotFound:\n        message = \"Could not find signal %s\"\n        terms: list[Union[str, Optional[dict[str, str]]]] = [event]\n        if extra:\n            message += \" with %s\"\n            terms.append(extra)\n        raise NotFound(message % tuple(terms))\n\n    # Regex routes evaluate and can extract params directly. They are set\n    # on param_basket[\"__params__\"]\n    params = param_basket[\"__params__\"]\n    if not params:\n        # If param_basket[\"__params__\"] does not exist, we might have\n        # param_basket[\"__matches__\"], which are indexed based matches\n        # on path segments. They should already be cast types.\n        params = {\n            param.name: param_basket[\"__matches__\"][idx]\n            for idx, param in group.params.items()\n        }\n\n    return group, [route.handler for route in group], params", "loc": 48}
{"file": "sanic\\sanic\\signals.py", "class_name": "SignalRouter", "function_name": "get_waiter", "parameters": ["self", "event", "condition", "exclusive"], "param_types": {"event": "Union[str, Enum]", "condition": "Optional[dict[str, Any]]", "exclusive": "bool"}, "return_type": "Optional[SignalWaiter]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SignalWaiter", "bool", "cast", "event_definition.endswith", "self._get_event_parts", "self.format_event", "self.name_index.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_waiter(\n    self,\n    event: Union[str, Enum],\n    condition: Optional[dict[str, Any]] = None,\n    exclusive: bool = True,\n) -> Optional[SignalWaiter]:\n    event_definition = self.format_event(event)\n    name, trigger, _ = self._get_event_parts(event_definition)\n    signal = cast(Signal, self.name_index.get(name))\n    if not signal:\n        return None\n\n    if event_definition.endswith(\".*\") and not trigger:\n        trigger = \"*\"\n    return SignalWaiter(\n        signal=signal,\n        event_definition=event_definition,\n        trigger=trigger,\n        requirements=condition,\n        exclusive=bool(exclusive),\n    )", "loc": 21}
{"file": "sanic\\sanic\\signals.py", "class_name": "SignalRouter", "function_name": "add", "parameters": ["self", "handler", "event", "condition", "exclusive"], "param_types": {"handler": "SignalHandler", "event": "Union[str, Enum]", "condition": "Optional[dict[str, Any]]", "exclusive": "bool"}, "return_type": "Signal", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "self._get_event_parts", "self.format_event", "super", "super().add"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add(  # type: ignore\n    self,\n    handler: SignalHandler,\n    event: Union[str, Enum],\n    condition: Optional[dict[str, Any]] = None,\n    exclusive: bool = True,\n    *,\n    priority: int = 0,\n) -> Signal:\n    event_definition = self.format_event(event)\n    name, trigger, event_string = self._get_event_parts(event_definition)\n\n    signal = super().add(\n        event_string,\n        handler,\n        name=name,\n        append=True,\n        priority=priority,\n    )  # type: ignore\n\n    signal.ctx.exclusive = exclusive\n    signal.ctx.trigger = trigger\n    signal.ctx.definition = event_definition\n    signal.extra.requirements = condition\n\n    return cast(Signal, signal)", "loc": 26}
{"file": "sanic\\sanic\\signals.py", "class_name": "SignalRouter", "function_name": "finalize", "parameters": ["self", "do_compile", "do_optimize"], "param_types": {"do_compile": "bool", "do_optimize": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "asyncio.get_running_loop", "deque", "self.add", "super", "super().finalize"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "Finalize the router and compile the routes", "source_code": "def finalize(self, do_compile: bool = True, do_optimize: bool = False):\n    \"\"\"Finalize the router and compile the routes\n\n    Args:\n        do_compile (bool, optional): Whether to compile the routes. Defaults to `True`.\n        do_optimize (bool, optional): Whether to optimize the routes. Defaults to `False`.\n\n    Returns:\n        SignalRouter: The router\n\n    Raises:\n        RuntimeError: If the router is finalized outside of an event loop\n    \"\"\"  # noqa: E501\n    self.add(_blank, \"sanic.__signal__.__init__\")\n\n    try:\n        self.ctx.loop = asyncio.get_running_loop()\n    except RuntimeError:\n        raise RuntimeError(\"Cannot finalize signals outside of event loop\")\n\n    for signal in self.routes:\n        signal.ctx.waiters = deque()\n\n    return super().finalize(do_compile=do_compile, do_optimize=do_optimize)", "loc": 24}
{"file": "sanic\\sanic\\simple.py", "class_name": null, "function_name": "create_simple_server", "parameters": ["directory"], "param_types": {"directory": "Path"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Sanic", "SanicException", "app.static", "directory.is_dir"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_simple_server(directory: Path):\n    if not directory.is_dir():\n        raise SanicException(\n            \"Cannot setup Sanic Simple Server without a path to a directory\"\n        )\n\n    app = Sanic(\"SimpleServer\")\n    app.static(\n        \"/\", directory, name=\"main\", directory_view=True, index=\"index.html\"\n    )\n\n    return app", "loc": 12}
{"file": "sanic\\sanic\\utils.py", "class_name": null, "function_name": "str_to_bool", "parameters": ["val"], "param_types": {"val": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "val.lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Takes string and tries to turn it into bool as human would do. If val is in case insensitive ( \"y\", \"yes\", \"yep\", \"yup\", \"t\",", "source_code": "def str_to_bool(val: str) -> bool:\n    \"\"\"Takes string and tries to turn it into bool as human would do.\n\n    If val is in case insensitive (\n        \"y\", \"yes\", \"yep\", \"yup\", \"t\",\n        \"true\", \"on\", \"enable\", \"enabled\", \"1\"\n    ) returns True.\n    If val is in case insensitive (\n        \"n\", \"no\", \"f\", \"false\", \"off\", \"disable\", \"disabled\", \"0\"\n    ) returns False.\n    Else Raise ValueError.\"\"\"\n\n    val = val.lower()\n    if val in {\n        \"y\",\n        \"yes\",\n        \"yep\",\n        \"yup\",\n        \"t\",\n        \"true\",\n        \"on\",\n        \"enable\",\n        \"enabled\",\n        \"1\",\n    }:\n        return True\n    elif val in {\"n\", \"no\", \"f\", \"false\", \"off\", \"disable\", \"disabled\", \"0\"}:\n        return False\n    else:\n        raise ValueError(f\"Invalid truth value {val}\")", "loc": 30}
{"file": "sanic\\sanic\\views.py", "class_name": "HTTPMethodView", "function_name": "dispatch_request", "parameters": ["self", "request"], "param_types": {"request": "Request"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "getattr", "handler", "request.method.lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Dispatch request to appropriate handler method.", "source_code": "def dispatch_request(self, request: Request, *args, **kwargs):\n    \"\"\"Dispatch request to appropriate handler method.\"\"\"\n    method = request.method.lower()\n    handler = getattr(self, method, None)\n\n    if not handler and method == \"head\":\n        handler = getattr(self, \"get\")\n    if not handler:\n        # The router will never allow us to get here, but this is\n        # included as a fallback and for completeness.\n        raise NotImplementedError(\n            f\"{request.method} is not supported for this endpoint.\"\n        )\n    return handler(request, *args, **kwargs)", "loc": 14}
{"file": "sanic\\sanic\\views.py", "class_name": "HTTPMethodView", "function_name": "as_view", "parameters": ["cls"], "param_types": {}, "return_type": "RouteHandler", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["decorator", "self.dispatch_request", "view.view_class"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Return view function for use with the routing system, that dispatches request to appropriate handler method. If you need to pass arguments to the class's constructor, you can pass the arguments to `as_view` and they will be passed to the class `__init__` method.", "source_code": "def as_view(cls, *class_args: Any, **class_kwargs: Any) -> RouteHandler:\n    \"\"\"Return view function for use with the routing system, that dispatches request to appropriate handler method.\n\n    If you need to pass arguments to the class's constructor, you can\n    pass the arguments to `as_view` and they will be passed to the class\n    `__init__` method.\n\n    Args:\n        *class_args: Variable length argument list for the class instantiation.\n        **class_kwargs: Arbitrary keyword arguments for the class instantiation.\n\n    Returns:\n        RouteHandler: The view function.\n\n    Examples:\n        ```python\n        class DummyView(HTTPMethodView):\n            def __init__(self, foo: MyFoo):\n                self.foo = foo\n\n            async def get(self, request: Request):\n                return text(self.foo.bar)\n\n        app.add_route(DummyView.as_view(foo=MyFoo()), \"/\")\n        ```\n    \"\"\"  # noqa: E501\n\n    def view(*args, **kwargs):\n        self = view.view_class(*class_args, **class_kwargs)\n        return self.dispatch_request(*args, **kwargs)\n\n    if cls.decorators:\n        view.__module__ = cls.__module__\n        for decorator in cls.decorators:\n            view = decorator(view)\n\n    view.view_class = cls  # type: ignore\n    view.__doc__ = cls.__doc__\n    view.__module__ = cls.__module__\n    view.__name__ = cls.__name__\n    return view", "loc": 41}
{"file": "sanic\\sanic\\views.py", "class_name": "HTTPMethodView", "function_name": "attach", "parameters": ["cls", "to", "uri", "methods", "host", "strict_slashes", "version", "name", "stream", "version_prefix"], "param_types": {"to": "Union[Sanic, Blueprint]", "uri": "str", "methods": "Iterable[str]", "host": "Optional[str]", "strict_slashes": "Optional[bool]", "version": "Optional[int]", "name": "Optional[str]", "stream": "bool", "version_prefix": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls.as_view", "frozenset", "to.add_route"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Attaches the view to a Sanic app or Blueprint at the specified URI.", "source_code": "def attach(\n    cls,\n    to: Union[Sanic, Blueprint],\n    uri: str,\n    methods: Iterable[str] = frozenset({\"GET\"}),\n    host: Optional[str] = None,\n    strict_slashes: Optional[bool] = None,\n    version: Optional[int] = None,\n    name: Optional[str] = None,\n    stream: bool = False,\n    version_prefix: str = \"/v\",\n) -> None:\n    \"\"\"Attaches the view to a Sanic app or Blueprint at the specified URI.\n\n    Args:\n        cls: The class that this method is part of.\n        to (Union[Sanic, Blueprint]): The Sanic application or Blueprint to attach to.\n        uri (str): The URI to bind the view to.\n        methods (Iterable[str], optional): A collection of HTTP methods that the view should respond to. Defaults to `frozenset({\"GET\"})`.\n        host (Optional[str], optional): A specific host or hosts to bind the view to. Defaults to `None`.\n        strict_slashes (Optional[bool], optional): Enforce or not the trailing slash. Defaults to `None`.\n        version (Optional[int], optional): Version of the API if versioning is used. Defaults to `None`.\n        name (Optional[str], optional): Unique name for the route. Defaults to `None`.\n        stream (bool, optional): Enable or disable streaming for the view. Defaults to `False`.\n        version_prefix (str, optional): The prefix for the version, if versioning is used. Defaults to `\"/v\"`.\n    \"\"\"  # noqa: E501\n    to.add_route(\n        cls.as_view(),\n        uri=uri,\n        methods=methods,\n        host=host,\n        strict_slashes=strict_slashes,\n        version=version,\n        name=name,\n        stream=stream,\n        version_prefix=version_prefix,\n    )", "loc": 37}
{"file": "sanic\\sanic\\application\\ext.py", "class_name": null, "function_name": "setup_ext", "parameters": ["app"], "param_types": {"app": "Sanic"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Ext", "RuntimeError", "getattr", "import_module", "suppress"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Setup Sanic Extensions. Requires Sanic Extensions to be installed.", "source_code": "def setup_ext(app: Sanic, *, fail: bool = False, **kwargs):\n    \"\"\"Setup Sanic Extensions.\n\n    Requires Sanic Extensions to be installed.\n\n    Args:\n        app (Sanic): Sanic application.\n        fail (bool, optional): Raise an error if Sanic Extensions is not\n            installed. Defaults to `False`.\n        **kwargs: Keyword arguments to pass to `sanic_ext.Extend`.\n\n    Returns:\n        sanic_ext.Extend: Sanic Extensions instance.\n    \"\"\"\n\n    if not app.config.AUTO_EXTEND:\n        return\n\n    sanic_ext = None\n    with suppress(ModuleNotFoundError):\n        sanic_ext = import_module(\"sanic_ext\")\n\n    if not sanic_ext:  # no cov\n        if fail:\n            raise RuntimeError(\n                \"Sanic Extensions is not installed. You can add it to your \"\n                \"environment using:\\n$ pip install sanic[ext]\\nor\\n$ pip \"\n                \"install sanic-ext\"\n            )\n\n        return\n\n    if not getattr(app, \"_ext\", None):\n        Ext = getattr(sanic_ext, \"Extend\")\n        app._ext = Ext(app, **kwargs)\n\n        return app.ext", "loc": 37}
{"file": "sanic\\sanic\\application\\logo.py", "class_name": null, "function_name": "get_logo", "parameters": ["full", "coffee"], "param_types": {"full": "bool", "coffee": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ansi_pattern.sub", "environ.get", "is_atty"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Get the Sanic logo. Will return the full color logo if the terminal supports it.", "source_code": "def get_logo(full: bool = False, coffee: bool = False) -> str:\n    \"\"\"Get the Sanic logo.\n\n    Will return the full color logo if the terminal supports it.\n\n    Args:\n        full (bool, optional): Use the full color logo. Defaults to `False`.\n        coffee (bool, optional): Use the coffee logo. Defaults to `False`.\n\n    Returns:\n        str: Sanic logo.\n    \"\"\"\n    logo = (\n        (FULL_COLOR_LOGO if full else (COFFEE_LOGO if coffee else COLOR_LOGO))\n        if is_atty()\n        else BASE_LOGO\n    )\n\n    if (\n        sys.platform == \"darwin\"\n        and environ.get(\"TERM_PROGRAM\") == \"Apple_Terminal\"\n    ):\n        logo = ansi_pattern.sub(\"\", logo)\n\n    return logo", "loc": 25}
{"file": "sanic\\sanic\\application\\motd.py", "class_name": "MOTD", "function_name": "output", "parameters": ["cls", "logo", "serve_location", "data", "extra"], "param_types": {"logo": "Optional[str]", "serve_location": "str", "data": "dict[str, str]", "extra": "dict[str, str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_atty", "motd_class", "motd_class(logo, serve_location, data, extra).display"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Output the MOTD.", "source_code": "def output(\n    cls,\n    logo: Optional[str],\n    serve_location: str,\n    data: dict[str, str],\n    extra: dict[str, str],\n) -> None:\n    \"\"\"Output the MOTD.\n\n    Args:\n        logo (Optional[str]): Logo to display.\n        serve_location (str): Location to serve.\n        data (Dict[str, str]): Data to display.\n        extra (Dict[str, str]): Extra data to display.\n    \"\"\"\n    motd_class = MOTDTTY if is_atty() else MOTDBasic\n    motd_class(logo, serve_location, data, extra).display()", "loc": 17}
{"file": "sanic\\sanic\\application\\motd.py", "class_name": "MOTDBasic", "function_name": "display", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["lines.append", "logger.debug", "logger.info", "self.data.items", "self.extra.items"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def display(self):\n    if self.logo:\n        logger.debug(self.logo)\n    lines = [f\"Sanic v{__version__}\"]\n    if self.serve_location:\n        lines.append(f\"Goin' Fast @ {self.serve_location}\")\n    lines += [\n        *(f\"{key}: {value}\" for key, value in self.data.items()),\n        *(f\"{key}: {value}\" for key, value in self.extra.items()),\n    ]\n    for line in lines:\n        logger.info(line)", "loc": 12}
{"file": "sanic\\sanic\\application\\motd.py", "class_name": "MOTDTTY", "function_name": "set_variables", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_terminal_size", "map", "max", "min", "self.data.keys", "self.data.values", "self.extra.keys", "self.extra.values", "self.logo.split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Set the variables used for display.", "source_code": "def set_variables(self):  # no  cov\n    \"\"\"Set the variables used for display.\"\"\"\n    fallback = (108, 24)\n    terminal_width = max(\n        get_terminal_size(fallback=fallback).columns, fallback[0]\n    )\n    self.max_value_width = terminal_width - fallback[0] + 36\n\n    self.key_width = 4\n    self.value_width = self.max_value_width\n    if self.data:\n        self.key_width = max(map(len, self.data.keys()))\n        self.value_width = min(\n            max(map(len, self.data.values())), self.max_value_width\n        )\n    if self.extra:\n        self.key_width = max(\n            self.key_width, max(map(len, self.extra.keys()))\n        )\n        self.value_width = min(\n            max((*map(len, self.extra.values()), self.value_width)),\n            self.max_value_width,\n        )\n    self.logo_lines = self.logo.split(\"\\n\") if self.logo else []\n    self.logo_line_length = 24\n    self.centering_length = (\n        self.key_width + self.value_width + 2 + self.logo_line_length\n    )\n    self.display_length = self.key_width + self.value_width + 2", "loc": 29}
{"file": "sanic\\sanic\\application\\motd.py", "class_name": "MOTDTTY", "function_name": "display", "parameters": ["self", "version", "action", "out"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "f'{action} @ {self.serve_location}' if self.serve_location else ''.center", "header.center", "indent", "len", "lines.append", "out", "self._get_logo_part", "self._render_data", "self._render_fill"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Display the MOTD.", "source_code": "def display(self, version=True, action=\"Goin' Fast\", out=None):\n    \"\"\"Display the MOTD.\n\n    Args:\n        version (bool, optional): Display the version. Defaults to `True`.\n        action (str, optional): Action to display. Defaults to\n            `\"Goin' Fast\"`.\n        out (Optional[Callable], optional): Output function. Defaults to\n            `None`.\n    \"\"\"\n    if not out:\n        out = logger.info\n    header = \"Sanic\"\n    if version:\n        header += f\" v{__version__}\"\n    header = header.center(self.centering_length)\n    running = (\n        f\"{action} @ {self.serve_location}\" if self.serve_location else \"\"\n    ).center(self.centering_length)\n    length = len(header) + 2 - self.logo_line_length\n    first_filler = \"\" * (self.logo_line_length - 1)\n    second_filler = \"\" * length\n    display_filler = \"\" * (self.display_length + 2)\n    lines = [\n        f\"\\n{first_filler}{second_filler}\",\n        f\" {header} \",\n        f\" {running} \",\n        f\"{first_filler}{second_filler}\",\n    ]\n\n    self._render_data(lines, self.data, 0)\n    if self.extra:\n        logo_part = self._get_logo_part(len(lines) - 4)\n        lines.append(f\" {logo_part} {display_filler}\")\n        self._render_data(lines, self.extra, len(lines) - 4)\n\n    self._render_fill(lines)\n\n    lines.append(f\"{first_filler}{second_filler}\\n\")\n    out(indent(\"\\n\".join(lines), \"  \"))", "loc": 40}
{"file": "sanic\\sanic\\application\\spinner.py", "class_name": null, "function_name": "loading", "parameters": ["message"], "param_types": {"message": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Spinner", "spinner.start", "spinner.stop"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def loading(message: str = \"Loading\"):  # noqa\n    spinner = Spinner(message)\n    spinner.start()\n    yield\n    spinner.stop()", "loc": 5}
{"file": "sanic\\sanic\\application\\spinner.py", "class_name": "Spinner", "function_name": "run", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["next", "self.queue.get", "self.queue.put", "sys.stdout.flush", "sys.stdout.write", "time.sleep"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run(self):\n    while self.queue.get():\n        output = f\"\\r{self.message} [{next(self.spinner)}]\"\n        sys.stdout.write(output)\n        sys.stdout.flush()\n        time.sleep(0.1)\n        self.queue.put(1)", "loc": 7}
{"file": "sanic\\sanic\\application\\spinner.py", "class_name": "Spinner", "function_name": "hide", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_CursorInfo", "ctypes.byref", "ctypes.windll.kernel32.GetConsoleCursorInfo", "ctypes.windll.kernel32.GetStdHandle", "ctypes.windll.kernel32.SetConsoleCursorInfo", "sys.stdout.flush", "sys.stdout.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def hide():\n    if os.name == \"nt\":\n        ci = _CursorInfo()\n        handle = ctypes.windll.kernel32.GetStdHandle(-11)\n        ctypes.windll.kernel32.GetConsoleCursorInfo(\n            handle, ctypes.byref(ci)\n        )\n        ci.visible = False\n        ctypes.windll.kernel32.SetConsoleCursorInfo(\n            handle, ctypes.byref(ci)\n        )\n    elif os.name == \"posix\":\n        sys.stdout.write(\"\\033[?25l\")\n        sys.stdout.flush()", "loc": 14}
{"file": "sanic\\sanic\\application\\spinner.py", "class_name": "Spinner", "function_name": "show", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_CursorInfo", "ctypes.byref", "ctypes.windll.kernel32.GetConsoleCursorInfo", "ctypes.windll.kernel32.GetStdHandle", "ctypes.windll.kernel32.SetConsoleCursorInfo", "sys.stdout.flush", "sys.stdout.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show():\n    if os.name == \"nt\":\n        ci = _CursorInfo()\n        handle = ctypes.windll.kernel32.GetStdHandle(-11)\n        ctypes.windll.kernel32.GetConsoleCursorInfo(\n            handle, ctypes.byref(ci)\n        )\n        ci.visible = True\n        ctypes.windll.kernel32.SetConsoleCursorInfo(\n            handle, ctypes.byref(ci)\n        )\n    elif os.name == \"posix\":\n        sys.stdout.write(\"\\033[?25h\")\n        sys.stdout.flush()", "loc": 14}
{"file": "sanic\\sanic\\application\\state.py", "class_name": "ApplicationState", "function_name": "set_mode", "parameters": ["self", "value"], "param_types": {"value": "Union[str, Mode]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "hasattr", "logger.setLevel"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_mode(self, value: Union[str, Mode]):\n    if hasattr(self.app, \"error_handler\"):\n        self.app.error_handler.debug = self.app.debug\n    if getattr(self.app, \"configure_logging\", False) and self.app.debug:\n        logger.setLevel(logging.DEBUG)", "loc": 5}
{"file": "sanic\\sanic\\application\\state.py", "class_name": "ApplicationState", "function_name": "stage", "parameters": ["self"], "param_types": {}, "return_type": "ServerStage", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["all", "any"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Get the server stage.", "source_code": "def stage(self) -> ServerStage:\n    \"\"\"Get the server stage.\n\n    Returns:\n        ServerStage: Server stage.\n    \"\"\"\n    if not self.server_info:\n        return ServerStage.STOPPED\n\n    if all(info.stage is ServerStage.SERVING for info in self.server_info):\n        return ServerStage.SERVING\n    elif any(\n        info.stage is ServerStage.SERVING for info in self.server_info\n    ):\n        return ServerStage.PARTIAL\n\n    return ServerStage.STOPPED", "loc": 17}
{"file": "sanic\\sanic\\cli\\app.py", "class_name": "SanicCLI", "function_name": "attach", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_logo", "group.create", "instance.attach", "len", "make_executor_parser", "make_inspector_parser", "self.groups.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def attach(self):\n    if len(sys.argv) > 1 and sys.argv[1] == \"inspect\":\n        self.run_mode = \"inspect\"\n        self.parser.description = get_logo(True)\n        make_inspector_parser(self.parser)\n        return\n\n    for group in Group._registry:\n        instance = group.create(self.parser)\n        instance.attach()\n        self.groups.append(instance)\n\n    if len(sys.argv) > 2 and sys.argv[2] == \"exec\":\n        self.run_mode = \"exec\"\n        self.parser.description = get_logo(True)\n        make_executor_parser(self.parser)", "loc": 16}
{"file": "sanic\\sanic\\cli\\app.py", "class_name": "SanicCLI", "function_name": "run", "parameters": ["self", "parse_args"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'-h --help'.split", "AppLoader", "ValueError", "app.prepare", "arg.split", "arg.startswith", "error_logger.exception", "len", "partial", "self._build_run_kwargs", "self._executor", "self._get_app", "self._inspector", "self._precheck", "self._repl", "self.parser.add_argument", "self.parser.parse_args", "self.parser.parse_known_args", "serve"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run(self, parse_args=None):\n    if self.run_mode == \"inspect\":\n        self._inspector()\n        return\n\n    legacy_version = False\n    if not parse_args:\n        # This is to provide backwards compat -v to display version\n        legacy_version = len(sys.argv) == 2 and sys.argv[-1] == \"-v\"\n        parse_args = [\"--version\"] if legacy_version else None\n    elif parse_args == [\"-v\"]:\n        parse_args = [\"--version\"]\n\n    if not legacy_version:\n        if self.run_mode == \"exec\":\n            parse_args = [\n                a\n                for a in (parse_args or sys.argv[1:])\n                if a not in \"-h --help\".split()\n            ]\n        parsed, unknown = self.parser.parse_known_args(args=parse_args)\n        if unknown and parsed.factory:\n            for arg in unknown:\n                if arg.startswith(\"--\"):\n                    self.parser.add_argument(arg.split(\"=\")[0])\n\n    if self.run_mode == \"exec\":\n        self.args, _ = self.parser.parse_known_args(args=parse_args)\n    else:\n        self.args = self.parser.parse_args(args=parse_args)\n    self._precheck()\n    app_loader = AppLoader(\n        self.args.target, self.args.factory, self.args.simple, self.args\n    )\n\n    try:\n        app = self._get_app(app_loader)\n        kwargs = self._build_run_kwargs()\n    except ValueError as e:\n        error_logger.exception(f\"Failed to run app: {e}\")\n    else:\n        if self.run_mode == \"exec\":\n            self._executor(app, kwargs)\n            return\n        elif self.run_mode != \"serve\":\n            raise ValueError(f\"Unknown run mode: {self.run_mode}\")\n\n        if self.args.repl:\n            self._repl(app)\n        for http_version in self.args.http:\n            app.prepare(**kwargs, version=http_version)\n        if self.args.single:\n            serve = Sanic.serve_single\n        else:\n            serve = partial(Sanic.serve, app_loader=app_loader)\n        serve(app)", "loc": 56}
{"file": "sanic\\sanic\\cli\\arguments.py", "class_name": "Group", "function_name": "add_bool_arguments", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["args[0][2:].replace", "f\"no {kwargs['help'].lower()}\".capitalize", "group.add_argument", "group.set_defaults", "kwargs['help'].capitalize", "kwargs['help'].lower", "self.container.add_mutually_exclusive_group"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_bool_arguments(self, *args, nullable=False, **kwargs):\n    group = self.container.add_mutually_exclusive_group()\n    kwargs[\"help\"] = kwargs[\"help\"].capitalize()\n    group.add_argument(*args, action=\"store_true\", **kwargs)\n    kwargs[\"help\"] = f\"no {kwargs['help'].lower()}\".capitalize()\n    group.add_argument(\n        \"--no-\" + args[0][2:], *args[1:], action=\"store_false\", **kwargs\n    )\n    if nullable:\n        params = {args[0][2:].replace(\"-\", \"_\"): None}\n        group.set_defaults(**params)", "loc": 11}
{"file": "sanic\\sanic\\cli\\arguments.py", "class_name": "ApplicationGroup", "function_name": "attach", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["group.add_argument", "self.add_bool_arguments", "self.container.add_mutually_exclusive_group"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def attach(self):\n    group = self.container.add_mutually_exclusive_group()\n    group.add_argument(\n        \"--factory\",\n        action=\"store_true\",\n        help=(\n            \"Treat app as an application factory, \"\n            \"i.e. a () -> <Sanic app> callable\"\n        ),\n    )\n    group.add_argument(\n        \"-s\",\n        \"--simple\",\n        dest=\"simple\",\n        action=\"store_true\",\n        help=(\n            \"Run Sanic as a Simple Server, and serve the contents of \"\n            \"a directory\\n(module arg should be a path)\"\n        ),\n    )\n    self.add_bool_arguments(\n        \"--repl\",\n        help=\"Run the server with an interactive shell session\",\n    )", "loc": 24}
{"file": "sanic\\sanic\\cli\\arguments.py", "class_name": "HTTPVersionGroup", "function_name": "attach", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTTP.__members__.values", "self.container.add_argument"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def attach(self):\n    http_values = [http.value for http in HTTP.__members__.values()]\n\n    self.container.add_argument(\n        \"--http\",\n        dest=\"http\",\n        action=\"append\",\n        choices=http_values,\n        type=int,\n        help=(\n            \"Which HTTP version to use: HTTP/1.1 or HTTP/3. Value should\\n\"\n            \"be either 1, or 3. [default 1]\"\n        ),\n    )\n    self.container.add_argument(\n        \"-1\",\n        dest=\"http\",\n        action=\"append_const\",\n        const=1,\n        help=(\"Run Sanic server using HTTP/1.1\"),\n    )\n    self.container.add_argument(\n        \"-3\",\n        dest=\"http\",\n        action=\"append_const\",\n        const=3,\n        help=(\"Run Sanic server using HTTP/3\"),\n    )", "loc": 28}
{"file": "sanic\\sanic\\cli\\arguments.py", "class_name": "WorkerGroup", "function_name": "attach", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["group.add_argument", "self.add_bool_arguments", "self.container.add_mutually_exclusive_group"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def attach(self):\n    group = self.container.add_mutually_exclusive_group()\n    group.add_argument(\n        \"-w\",\n        \"--workers\",\n        dest=\"workers\",\n        type=int,\n        default=1,\n        help=\"Number of worker processes [default 1]\",\n    )\n    group.add_argument(\n        \"--fast\",\n        dest=\"fast\",\n        action=\"store_true\",\n        help=\"Set the number of workers to max allowed\",\n    )\n    group.add_argument(\n        \"--single-process\",\n        dest=\"single\",\n        action=\"store_true\",\n        help=\"Do not use multiprocessing, run server in a single process\",\n    )\n    self.add_bool_arguments(\n        \"--access-logs\",\n        dest=\"access_log\",\n        help=\"display access logs\",\n        default=None,\n    )", "loc": 28}
{"file": "sanic\\sanic\\cli\\arguments.py", "class_name": "OutputGroup", "function_name": "attach", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.add_bool_arguments", "self.container.add_argument"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def attach(self):\n    self.add_bool_arguments(\n        \"--coffee\",\n        dest=\"coffee\",\n        default=False,\n        help=\"Uhm, coffee?\",\n    )\n    self.add_bool_arguments(\n        \"--motd\",\n        dest=\"motd\",\n        default=True,\n        help=\"Show the startup display\",\n    )\n    self.container.add_argument(\n        \"-v\",\n        \"--verbosity\",\n        action=\"count\",\n        help=\"Control logging noise, eg. -vv or --verbosity=2 [default 0]\",\n    )\n    self.add_bool_arguments(\n        \"--noisy-exceptions\",\n        dest=\"noisy_exceptions\",\n        help=\"Output stack traces for all exceptions\",\n        default=None,\n    )", "loc": 25}
{"file": "sanic\\sanic\\cli\\base.py", "class_name": "SanicHelpFormatter", "function_name": "add_usage", "parameters": ["self", "usage", "actions", "groups", "prefix"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.add_text", "super", "super().add_usage"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_usage(self, usage, actions, groups, prefix=None):\n    if not usage:\n        usage = SUPPRESS\n        # Add one linebreak, but not two\n        self.add_text(\"\\x1b[1A\")\n    super().add_usage(usage, actions, groups, prefix)", "loc": 6}
{"file": "sanic\\sanic\\cli\\console.py", "class_name": null, "function_name": "make_request", "parameters": ["url", "headers", "method", "body"], "param_types": {"url": "str", "headers": "Optional[Union[dict[str, Any], Sequence[tuple[str, str]]]]", "method": "str", "body": "Optional[str]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Header", "REPLProtocol", "Request", "body.encode", "url.encode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_request(\n    url: str = \"/\",\n    headers: Optional[Union[dict[str, Any], Sequence[tuple[str, str]]]] = None,\n    method: str = \"GET\",\n    body: Optional[str] = None,\n):\n    assert repl_app, \"No Sanic app has been registered.\"\n    headers = headers or {}\n    protocol = REPLProtocol()\n    request = Request(  # type: ignore\n        url.encode(),\n        Header(headers),\n        \"1.1\",\n        method,\n        protocol,\n        repl_app,\n    )\n    if body is not None:\n        request.body = body.encode()\n    request.stream = protocol  # type: ignore\n    request.conn_info = None\n    return request", "loc": 22}
{"file": "sanic\\sanic\\cli\\console.py", "class_name": "SanicREPL", "function_name": "runsource", "parameters": ["self", "source", "filename", "symbol"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["print", "self._shutdown", "self.is_paused", "source.strip", "super", "super().runsource"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def runsource(self, source, filename=\"<input>\", symbol=\"single\"):\n    if source.strip() == \"exit()\":\n        self._shutdown()\n        return False\n\n    if self.is_paused():\n        print(\"Console is paused. Please wait for it to be resumed.\")\n        return False\n\n    return super().runsource(source, filename, symbol)", "loc": 10}
{"file": "sanic\\sanic\\cli\\console.py", "class_name": "SanicREPL", "function_name": "runcode", "parameters": ["self", "code"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FunctionType", "callback", "concurrent.futures.Future", "func", "future.result", "future.set_result", "iscoroutine", "self.loop.call_soon_threadsafe", "traceback.print_exc"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def runcode(self, code):\n    future = concurrent.futures.Future()\n\n    async def callback():\n        func = FunctionType(code, self.locals)\n        try:\n            result = func()\n            if iscoroutine(result):\n                result = await result\n        except BaseException:\n            traceback.print_exc()\n            result = False\n        future.set_result(result)\n\n    self.loop.call_soon_threadsafe(self.loop.create_task, callback())\n    return future.result()", "loc": 16}
{"file": "sanic\\sanic\\cli\\executor.py", "class_name": "Executor", "function_name": "run", "parameters": ["self", "command", "args"], "param_types": {"command": "str", "args": "list[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "parsed_kwargs.pop", "run", "self.parser.parse_args", "vars"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run(self, command: str, args: list[str]) -> None:\n    if command == \"exec\":\n        args = [\"--help\"]\n    parsed_args = self.parser.parse_args(args)\n    if command not in self.commands:\n        raise ValueError(f\"Unknown command: {command}\")\n    parsed_kwargs = vars(parsed_args)\n    parsed_kwargs.pop(\"command\")\n    run(self.commands[command](**parsed_kwargs))", "loc": 9}
{"file": "sanic\\sanic\\cli\\inspector.py", "class_name": null, "function_name": "make_inspector_parser", "parameters": ["parser"], "param_types": {"parser": "ArgumentParser"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_add_shared", "custom.add_argument", "parser.add_subparsers", "reloader.add_argument", "scale.add_argument", "subparsers.add_parser"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def make_inspector_parser(parser: ArgumentParser) -> None:\n    _add_shared(parser)\n    subparsers = parser.add_subparsers(\n        action=SanicSubParsersAction,\n        dest=\"action\",\n        description=(\n            \"Run one or none of the below subcommands. Using inspect without \"\n            \"a subcommand will fetch general information about the state \"\n            \"of the application instance.\\n\\n\"\n            \"Or, you can optionally follow inspect with a subcommand. \"\n            \"If you have created a custom \"\n            \"Inspector instance, then you can run custom commands. See \"\n            \"https://sanic.dev/en/guide/deployment/inspector.html \"\n            \"for more details.\"\n        ),\n        title=\"  Subcommands\",\n        parser_class=InspectorSubParser,\n    )\n    reloader = subparsers.add_parser(\n        \"reload\",\n        help=\"Trigger a reload of the server workers\",\n        formatter_class=SanicHelpFormatter,\n    )\n    reloader.add_argument(\n        \"--zero-downtime\",\n        action=\"store_true\",\n        help=(\n            \"Whether to wait for the new process to be online before \"\n            \"terminating the old\"\n        ),\n    )\n    subparsers.add_parser(\n        \"shutdown\",\n        help=\"Shutdown the application and all processes\",\n        formatter_class=SanicHelpFormatter,\n    )\n    scale = subparsers.add_parser(\n        \"scale\",\n        help=\"Scale the number of workers\",\n        formatter_class=SanicHelpFormatter,\n    )\n    scale.add_argument(\n        \"replicas\",\n        type=int,\n        help=\"Number of workers requested\",\n    )\n\n    custom = subparsers.add_parser(\n        \"<custom>\",\n        help=\"Run a custom command\",\n        description=(\n            \"keyword arguments:\\n  When running a custom command, you can \"\n            \"add keyword arguments by appending them to your command\\n\\n\"\n            \"\\tsanic inspect foo --one=1 --two=2\"\n        ),\n        formatter_class=SanicHelpFormatter,\n    )\n    custom.add_argument(\n        \"positional\",\n        nargs=\"*\",\n        help=\"Add one or more non-keyword args to your custom command\",\n    )", "loc": 62}
{"file": "sanic\\sanic\\cli\\inspector_client.py", "class_name": "InspectorClient", "function_name": "do", "parameters": ["self", "action"], "param_types": {"action": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dumps", "isinstance", "self.info", "self.request", "self.request(action, **kwargs).get", "str", "sys.stdout.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def do(self, action: str, **kwargs: Any) -> None:\n    if action == \"info\":\n        self.info()\n        return\n    result = self.request(action, **kwargs).get(\"result\")\n    if result:\n        out = (\n            dumps(result)\n            if isinstance(result, (list, dict))\n            else str(result)\n        )\n        sys.stdout.write(out + \"\\n\")", "loc": 12}
{"file": "sanic\\sanic\\cli\\inspector_client.py", "class_name": "InspectorClient", "function_name": "info", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "'\\n'.join", "MOTDTTY", "MOTDTTY(get_logo(), self.base_url, display, extra).display", "data.pop", "data['workers'].items", "display.pop", "get_logo", "indent", "info.items", "out", "self.request"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def info(self) -> None:\n    out = sys.stdout.write\n    response = self.request(\"\", \"GET\")\n    if self.raw or not response:\n        return\n    data = response[\"result\"]\n    display = data.pop(\"info\")\n    extra = display.pop(\"extra\", {})\n    display[\"packages\"] = \", \".join(display[\"packages\"])\n    MOTDTTY(get_logo(), self.base_url, display, extra).display(\n        version=False,\n        action=\"Inspecting\",\n        out=out,\n    )\n    for name, info in data[\"workers\"].items():\n        info = \"\\n\".join(\n            f\"\\t{key}: {Colors.BLUE}{value}{Colors.END}\"\n            for key, value in info.items()\n        )\n        out(\n            \"\\n\"\n            + indent(\n                \"\\n\".join(\n                    [\n                        f\"{Colors.BOLD}{Colors.SANIC}{name}{Colors.END}\",\n                        info,\n                    ]\n                ),\n                \"  \",\n            )\n            + \"\\n\"\n        )", "loc": 32}
{"file": "sanic\\sanic\\cookies\\request.py", "class_name": null, "function_name": "parse_cookie", "parameters": ["raw"], "param_types": {"raw": "str"}, "return_type": "dict[str, list[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["COOKIE_NAME_RESERVED_CHARS.search", "_unquote", "cookies[name].append", "len", "name.strip", "raw.split", "token.partition", "value.strip"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Parses a raw cookie string into a dictionary. The function takes a raw cookie string (usually from HTTP headers) and returns a dictionary where each key is a cookie name and the value is a list of values for that cookie. The function handles quoted values and skips invalid cookie names.", "source_code": "def parse_cookie(raw: str) -> dict[str, list[str]]:\n    \"\"\"Parses a raw cookie string into a dictionary.\n\n    The function takes a raw cookie string (usually from HTTP headers) and\n    returns a dictionary where each key is a cookie name and the value is a\n    list of values for that cookie. The function handles quoted values and\n    skips invalid cookie names.\n\n    Args:\n        raw (str): The raw cookie string to be parsed.\n\n    Returns:\n        Dict[str, List[str]]: A dictionary containing the cookie names as keys\n        and a list of values for each cookie.\n\n    Example:\n        ```python\n        raw = 'name1=value1; name2=\"value2\"; name3=value3'\n        cookies = parse_cookie(raw)\n        # cookies will be {'name1': ['value1'], 'name2': ['value2'], 'name3': ['value3']}\n        ```\n    \"\"\"  # noqa: E501\n    cookies: dict[str, list[str]] = {}\n\n    for token in raw.split(\";\"):\n        name, sep, value = token.partition(\"=\")\n        name = name.strip()\n        value = value.strip()\n\n        # Support cookies =value or plain value with no name\n        # https://github.com/httpwg/http-extensions/issues/159\n        if not sep:\n            if not name:\n                # Empty value like ;; or a cookie header with no value\n                continue\n            name, value = \"\", name\n\n        if COOKIE_NAME_RESERVED_CHARS.search(name):  # no cov\n            continue\n\n        if len(value) > 2 and value[0] == '\"' and value[-1] == '\"':  # no cov\n            value = _unquote(value)\n\n        if name in cookies:\n            cookies[name].append(value)\n        else:\n            cookies[name] = [value]\n\n    return cookies", "loc": 49}
{"file": "sanic\\sanic\\cookies\\request.py", "class_name": "CookieRequestParameters", "function_name": "get", "parameters": ["self", "name", "default"], "param_types": {"name": "str", "default": "Optional[Any]"}, "return_type": "Optional[Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_prefixed_cookie", "super", "super().get"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get(self, name: str, default: Optional[Any] = None) -> Optional[Any]:\n    try:\n        return self._get_prefixed_cookie(name)[0]\n    except KeyError:\n        return super().get(name, default)", "loc": 5}
{"file": "sanic\\sanic\\cookies\\request.py", "class_name": "CookieRequestParameters", "function_name": "getlist", "parameters": ["self", "name", "default"], "param_types": {"name": "str", "default": "Optional[list[Any]]"}, "return_type": "list[Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_prefixed_cookie", "super", "super().getlist"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def getlist(\n    self, name: str, default: Optional[list[Any]] = None\n) -> list[Any]:\n    try:\n        return self._get_prefixed_cookie(name)\n    except KeyError:\n        return super().getlist(name, default)", "loc": 7}
{"file": "sanic\\sanic\\cookies\\response.py", "class_name": "CookieJar", "function_name": "get_cookie", "parameters": ["self", "key", "path", "domain", "host_prefix", "secure_prefix"], "param_types": {"key": "str", "path": "str", "domain": "str | None", "host_prefix": "bool", "secure_prefix": "bool"}, "return_type": "Cookie | None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Cookie.make_key"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Fetch a cookie from the CookieJar.", "source_code": "def get_cookie(\n    self,\n    key: str,\n    path: str = \"/\",\n    domain: str | None = None,\n    host_prefix: bool = False,\n    secure_prefix: bool = False,\n) -> Cookie | None:\n    \"\"\"Fetch a cookie from the CookieJar.\n\n    Args:\n        key (str): The key of the cookie to fetch.\n        path (str, optional): The path of the cookie. Defaults to `\"/\"`.\n        domain (Optional[str], optional): The domain of the cookie.\n            Defaults to `None`.\n        host_prefix (bool, optional): Whether to add __Host- as a prefix to the key.\n            This requires that path=\"/\", domain=None, and secure=True.\n            Defaults to `False`.\n        secure_prefix (bool, optional): Whether to add __Secure- as a prefix to the key.\n            This requires that secure=True. Defaults to `False`.\n\n    Returns:\n        Optional[Cookie]: The cookie if it exists, otherwise `None`.\n    \"\"\"  # noqa: E501\n    for cookie in self.cookies:\n        if (\n            cookie.key == Cookie.make_key(key, host_prefix, secure_prefix)\n            and cookie.path == path\n            and cookie.domain == domain\n        ):\n            return cookie\n    return None", "loc": 32}
{"file": "sanic\\sanic\\cookies\\response.py", "class_name": "CookieJar", "function_name": "has_cookie", "parameters": ["self", "key", "path", "domain", "host_prefix", "secure_prefix"], "param_types": {"key": "str", "path": "str", "domain": "str | None", "host_prefix": "bool", "secure_prefix": "bool"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Cookie.make_key"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Check if a cookie exists in the CookieJar.", "source_code": "def has_cookie(\n    self,\n    key: str,\n    path: str = \"/\",\n    domain: str | None = None,\n    host_prefix: bool = False,\n    secure_prefix: bool = False,\n) -> bool:\n    \"\"\"Check if a cookie exists in the CookieJar.\n\n    Args:\n        key (str): The key of the cookie to check.\n        path (str, optional): The path of the cookie. Defaults to `\"/\"`.\n        domain (Optional[str], optional): The domain of the cookie.\n            Defaults to `None`.\n        host_prefix (bool, optional): Whether to add __Host- as a prefix to the key.\n            This requires that path=\"/\", domain=None, and secure=True.\n            Defaults to `False`.\n        secure_prefix (bool, optional): Whether to add __Secure- as a prefix to the key.\n            This requires that secure=True. Defaults to `False`.\n\n    Returns:\n        bool: Whether the cookie exists.\n    \"\"\"  # noqa: E501\n    for cookie in self.cookies:\n        if (\n            cookie.key == Cookie.make_key(key, host_prefix, secure_prefix)\n            and cookie.path == path\n            and cookie.domain == domain\n        ):\n            return True\n    return False", "loc": 32}
{"file": "sanic\\sanic\\cookies\\response.py", "class_name": "CookieJar", "function_name": "add_cookie", "parameters": ["self", "key", "value"], "param_types": {"key": "str", "value": "str"}, "return_type": "Cookie", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Cookie", "self.headers.add"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Add a cookie to the CookieJar.", "source_code": "def add_cookie(\n    self,\n    key: str,\n    value: str,\n    *,\n    path: str = \"/\",\n    domain: str | None = None,\n    secure: bool = True,\n    max_age: int | None = None,\n    expires: datetime | None = None,\n    httponly: bool = False,\n    samesite: SameSite | None = \"Lax\",\n    partitioned: bool = False,\n    comment: str | None = None,\n    host_prefix: bool = False,\n    secure_prefix: bool = False,\n) -> Cookie:\n    \"\"\"Add a cookie to the CookieJar.\n\n    Args:\n        key (str): Key of the cookie.\n        value (str): Value of the cookie.\n        path (str, optional): Path of the cookie. Defaults to \"/\".\n        domain (Optional[str], optional): Domain of the cookie. Defaults to None.\n        secure (bool, optional): Whether to set it as a secure cookie. Defaults to True.\n        max_age (Optional[int], optional): Max age of the cookie in seconds; if set to 0 a\n            browser should delete it. Defaults to None.\n        expires (Optional[datetime], optional): When the cookie expires; if set to None browsers\n            should set it as a session cookie. Defaults to None.\n        httponly (bool, optional): Whether to set it as HTTP only. Defaults to False.\n        samesite (Optional[SameSite], optional): How to set the samesite property, should be\n            strict, lax, or none (case insensitive). Defaults to \"Lax\".\n        partitioned (bool, optional): Whether to set it as partitioned. Defaults to False.\n        comment (Optional[str], optional): A cookie comment. Defaults to None.\n        host_prefix (bool, optional): Whether to add __Host- as a prefix to the key.\n            This requires that path=\"/\", domain=None, and secure=True. Defaults to False.\n        secure_prefix (bool, optional): Whether to add __Secure- as a prefix to the key.\n            This requires that secure=True. Defaults to False.\n\n    Returns:\n        Cookie: The instance of the created cookie.\n\n    Raises:\n        ServerError: If host_prefix is set without secure=True.\n        ServerError: If host_prefix is set without path=\"/\" and domain=None.\n        ServerError: If host_prefix is set with domain.\n        ServerError: If secure_prefix is set without secure=True.\n        ServerError: If partitioned is set without host_prefix=True.\n\n    Examples:\n        Basic usage\n        ```python\n        cookie = add_cookie('name', 'value')\n        ```\n\n        Adding a cookie with a custom path and domain\n        ```python\n        cookie = add_cookie('name', 'value', path='/custom', domain='example.com')\n        ```\n\n        Adding a secure, HTTP-only cookie with a comment\n        ```python\n        cookie = add_cookie('name', 'value', secure=True, httponly=True, comment='My Cookie')\n        ```\n\n        Adding a cookie with a max age of 60 seconds\n        ```python\n        cookie = add_cookie('name', 'value', max_age=60)\n        ```\n    \"\"\"  # noqa: E501\n    cookie = Cookie(\n        key,\n        value,\n        path=path,\n        expires=expires,\n        comment=comment,\n        domain=domain,\n        max_age=max_age,\n        secure=secure,\n        httponly=httponly,\n        samesite=samesite,\n        partitioned=partitioned,\n        host_prefix=host_prefix,\n        secure_prefix=secure_prefix,\n    )\n    self.headers.add(self.HEADER_KEY, cookie)\n\n    return cookie", "loc": 88}
{"file": "sanic\\sanic\\cookies\\response.py", "class_name": "CookieJar", "function_name": "delete_cookie", "parameters": ["self", "key"], "param_types": {"key": "str"}, "return_type": "None", "param_doc": {"key": "The key to be deleted", "path": "Path of the cookie, defaults to None", "domain": "Domain of the cookie, defaults to None", "secure": "bool", "host_prefix": "Whether to add __Host- as a prefix to the key.", "secure_prefix": "Whether to add __Secure- as a prefix to the key."}, "return_doc": "", "raises_doc": [], "called_functions": ["Cookie.make_key", "ServerError", "self.add_cookie", "self.headers.add", "self.headers.popall"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Delete a cookie This will effectively set it as Max-Age: 0, which a browser should interpret it to mean: \"delete the cookie\". Since it is a browser/client implementation, your results may vary depending upon which client is being used.", "source_code": "def delete_cookie(\n    self,\n    key: str,\n    *,\n    path: str = \"/\",\n    domain: str | None = None,\n    secure: bool = True,\n    host_prefix: bool = False,\n    secure_prefix: bool = False,\n) -> None:\n    \"\"\"\n    Delete a cookie\n\n    This will effectively set it as Max-Age: 0, which a browser should\n    interpret it to mean: \"delete the cookie\".\n\n    Since it is a browser/client implementation, your results may vary\n    depending upon which client is being used.\n\n    :param key: The key to be deleted\n    :type key: str\n    :param path: Path of the cookie, defaults to None\n    :type path: Optional[str], optional\n    :param domain: Domain of the cookie, defaults to None\n    :type domain: Optional[str], optional\n    :param secure: Whether to delete a secure cookie. Defaults to True.\n    :param secure: bool\n    :param host_prefix: Whether to add __Host- as a prefix to the key.\n        This requires that path=\"/\", domain=None, and secure=True,\n        defaults to False\n    :type host_prefix: bool\n    :param secure_prefix: Whether to add __Secure- as a prefix to the key.\n        This requires that secure=True, defaults to False\n    :type secure_prefix: bool\n    \"\"\"\n    if host_prefix and not (secure and path == \"/\" and domain is None):\n        raise ServerError(\n            \"Cannot set host_prefix on a cookie without \"\n            \"path='/', domain=None, and secure=True\"\n        )\n    if secure_prefix and not secure:\n        raise ServerError(\n            \"Cannot set secure_prefix on a cookie without secure=True\"\n        )\n\n    cookies: list[Cookie] = self.headers.popall(self.HEADER_KEY, [])\n    existing_cookie = None\n    for cookie in cookies:\n        if (\n            cookie.key != Cookie.make_key(key, host_prefix, secure_prefix)\n            or cookie.path != path\n            or cookie.domain != domain\n        ):\n            self.headers.add(self.HEADER_KEY, cookie)\n        elif existing_cookie is None:\n            existing_cookie = cookie\n\n    if existing_cookie is not None:\n        # Use all the same values as the cookie to be deleted\n        # except value=\"\" and max_age=0\n        self.add_cookie(\n            key=key,\n            value=\"\",\n            path=existing_cookie.path,\n            domain=existing_cookie.domain,\n            secure=existing_cookie.secure,\n            max_age=0,\n            httponly=existing_cookie.httponly,\n            partitioned=existing_cookie.partitioned,\n            samesite=existing_cookie.samesite,\n            host_prefix=host_prefix,\n            secure_prefix=secure_prefix,\n        )\n    else:\n        self.add_cookie(\n            key=key,\n            value=\"\",\n            path=path,\n            domain=domain,\n            secure=secure,\n            max_age=0,\n            samesite=None,\n            host_prefix=host_prefix,\n            secure_prefix=secure_prefix,\n        )", "loc": 85}
{"file": "sanic\\sanic\\cookies\\response.py", "class_name": "Cookie", "function_name": "samesite", "parameters": ["self", "value"], "param_types": {"value": "SameSite"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["','.join", "TypeError", "value.lower", "value.title"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def samesite(self, value: SameSite) -> None:  # no cov\n    if value.lower() not in SAMESITE_VALUES:\n        raise TypeError(\n            \"Cookie 'samesite' property must \"\n            f\"be one of: {','.join(SAMESITE_VALUES)}\"\n        )\n    self._samesite = value.title()", "loc": 7}
{"file": "sanic\\sanic\\cookies\\response.py", "class_name": "Cookie", "function_name": "make_key", "parameters": ["cls", "key", "host_prefix", "secure_prefix"], "param_types": {"key": "str", "host_prefix": "bool", "secure_prefix": "bool"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ServerError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Create a cookie key with the appropriate prefix. Cookies can have one ow two prefixes. The first is `__Host-` which requires that the cookie be set with `path=\"/\", domain=None, and secure=True`. The second is `__Secure-` which requires that `secure=True`. They cannot be combined.", "source_code": "def make_key(\n    cls, key: str, host_prefix: bool = False, secure_prefix: bool = False\n) -> str:\n    \"\"\"Create a cookie key with the appropriate prefix.\n\n    Cookies can have one ow two prefixes. The first is `__Host-` which\n    requires that the cookie be set with `path=\"/\", domain=None, and\n    secure=True`. The second is `__Secure-` which requires that\n    `secure=True`.\n\n    They cannot be combined.\n\n    Args:\n        key (str): The key (name) of the cookie.\n        host_prefix (bool, optional): Whether to add __Host- as a prefix to the key.\n            This requires that path=\"/\", domain=None, and secure=True.\n            Defaults to `False`.\n        secure_prefix (bool, optional): Whether to add __Secure- as a prefix to the key.\n            This requires that secure=True. Defaults to `False`.\n\n    Raises:\n        ServerError: If both host_prefix and secure_prefix are set.\n\n    Returns:\n        str: The key with the appropriate prefix.\n    \"\"\"  # noqa: E501\n    if host_prefix and secure_prefix:\n        raise ServerError(\n            \"Both host_prefix and secure_prefix were requested. \"\n            \"A cookie should have only one prefix.\"\n        )\n    elif host_prefix:\n        key = cls.HOST_PREFIX + key\n    elif secure_prefix:\n        key = cls.SECURE_PREFIX + key\n    return key", "loc": 36}
{"file": "sanic\\sanic\\handlers\\error.py", "class_name": "ErrorHandler", "function_name": "add", "parameters": ["self", "exception", "handler", "route_names"], "param_types": {"route_names": "Optional[list[str]]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._add"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Add a new exception handler to an already existing handler object.", "source_code": "def add(self, exception, handler, route_names: Optional[list[str]] = None):\n    \"\"\"Add a new exception handler to an already existing handler object.\n\n    Args:\n        exception (sanic.exceptions.SanicException or Exception): Type\n            of exception that needs to be handled.\n        handler (function): Reference to the function that will\n            handle the exception.\n\n    Returns:\n        None\n\n    \"\"\"  # noqa: E501\n    if route_names:\n        for route in route_names:\n            self._add((exception, route), handler)\n    else:\n        self._add((exception, None), handler)", "loc": 18}
{"file": "sanic\\sanic\\handlers\\error.py", "class_name": "ErrorHandler", "function_name": "lookup", "parameters": ["self", "exception", "route_name"], "param_types": {"route_name": "Optional[str]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.cached_handlers.get", "type", "type.mro"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Lookup the existing instance of `ErrorHandler` and fetch the registered handler for a specific type of exception. This method leverages a dict lookup to speedup the retrieval process.", "source_code": "def lookup(self, exception, route_name: Optional[str] = None):\n    \"\"\"Lookup the existing instance of `ErrorHandler` and fetch the registered handler for a specific type of exception.\n\n    This method leverages a dict lookup to speedup the retrieval process.\n\n    Args:\n        exception (sanic.exceptions.SanicException or Exception): Type\n            of exception.\n\n    Returns:\n        Registered function if found, ``None`` otherwise.\n\n    \"\"\"  # noqa: E501\n    exception_class = type(exception)\n\n    for name in (route_name, None):\n        exception_key = (exception_class, name)\n        handler = self.cached_handlers.get(exception_key)\n        if handler:\n            return handler\n\n    for name in (route_name, None):\n        for ancestor in type.mro(exception_class):\n            exception_key = (ancestor, name)\n            if exception_key in self.cached_handlers:\n                handler = self.cached_handlers[exception_key]\n                self.cached_handlers[(exception_class, route_name)] = (\n                    handler\n                )\n                return handler\n\n            if ancestor is BaseException:\n                break\n    self.cached_handlers[(exception_class, route_name)] = None\n    handler = None\n    return handler", "loc": 36}
{"file": "sanic\\sanic\\handlers\\error.py", "class_name": "ErrorHandler", "function_name": "response", "parameters": ["self", "request", "exception"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["error_logger.exception", "handler", "repr", "self._lookup", "self.default", "text"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Fetch and executes an exception handler and returns a response object.", "source_code": "def response(self, request, exception):\n    \"\"\"Fetch and executes an exception handler and returns a response object.\n\n    Args:\n        request (sanic.request.Request): Instance of the request.\n        exception (sanic.exceptions.SanicException or Exception): Exception to handle.\n\n    Returns:\n        Wrap the return value obtained from the `default` function or the registered handler for that type of exception.\n\n    \"\"\"  # noqa: E501\n    route_name = request.name if request else None\n    handler = self._lookup(exception, route_name)\n    response = None\n    try:\n        if handler:\n            response = handler(request, exception)\n        if response is None:\n            response = self.default(request, exception)\n    except Exception:\n        try:\n            url = repr(request.url)\n        except AttributeError:  # no cov\n            url = \"unknown\"\n        response_message = (\n            'Exception raised in exception handler \"%s\" for uri: %s'\n        )\n        error_logger.exception(response_message, handler.__name__, url)\n\n        if self.debug:\n            return text(response_message % (handler.__name__, url), 500)\n        else:\n            return text(\"An error occurred while handling an error\", 500)\n    return response", "loc": 34}
{"file": "sanic\\sanic\\handlers\\error.py", "class_name": "ErrorHandler", "function_name": "default", "parameters": ["self", "request", "exception"], "param_types": {"request": "Request", "exception": "Exception"}, "return_type": "HTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["exception_response", "self.log"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Provide a default behavior for the objects of ErrorHandler. If a developer chooses to extend the ErrorHandler, they can provide a custom implementation for this method to behave in a way they see fit.", "source_code": "def default(self, request: Request, exception: Exception) -> HTTPResponse:\n    \"\"\"Provide a default behavior for the objects of ErrorHandler.\n\n    If a developer chooses to extend the ErrorHandler, they can\n    provide a custom implementation for this method to behave in a way\n    they see fit.\n\n    Args:\n        request (sanic.request.Request): Incoming request.\n        exception (sanic.exceptions.SanicException or Exception): Exception object.\n\n    Returns:\n        HTTPResponse: The response object.\n\n    Examples:\n        ```python\n        class CustomErrorHandler(ErrorHandler):\n            def default(self, request: Request, exception: Exception) -> HTTPResponse:\n                # Custom logic for handling the exception and creating a response\n                custom_response = my_custom_logic(request, exception)\n                return custom_response\n\n        app = Sanic(\"MyApp\", error_handler=CustomErrorHandler())\n        ```\n    \"\"\"  # noqa: E501\n    self.log(request, exception)\n    fallback = request.app.config.FALLBACK_ERROR_FORMAT\n    return exception_response(\n        request,\n        exception,\n        debug=self.debug,\n        base=self.base,\n        fallback=fallback,\n    )", "loc": 34}
{"file": "sanic\\sanic\\handlers\\error.py", "class_name": "ErrorHandler", "function_name": "log", "parameters": ["request", "exception"], "param_types": {"request": "Request", "exception": "Exception"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["error_logger.exception", "getattr", "repr"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Logs information about an incoming request and the associated exception.", "source_code": "def log(request: Request, exception: Exception) -> None:\n    \"\"\"Logs information about an incoming request and the associated exception.\n\n    Args:\n        request (Request): The incoming request to be logged.\n        exception (Exception): The exception that occurred during the handling of the request.\n\n    Returns:\n        None\n    \"\"\"  # noqa: E501\n    quiet = getattr(exception, \"quiet\", False)\n    noisy = getattr(request.app.config, \"NOISY_EXCEPTIONS\", False)\n    if quiet is False or noisy is True:\n        try:\n            url = repr(request.url)\n        except AttributeError:  # no cov\n            url = \"unknown\"\n\n        error_logger.exception(\n            \"Exception occurred while handling uri: %s\", url\n        )", "loc": 21}
{"file": "sanic\\sanic\\http\\http1.py", "class_name": "Http", "function_name": "head_response_ignored", "parameters": ["self", "data", "end_stream"], "param_types": {"data": "bytes", "end_stream": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "HEAD response: body data silently ignored.", "source_code": "def head_response_ignored(self, data: bytes, end_stream: bool) -> None:\n    \"\"\"HEAD response: body data silently ignored.\"\"\"\n    if end_stream:\n        self.response_func = None\n        self.stage = Stage.IDLE", "loc": 5}
{"file": "sanic\\sanic\\http\\http1.py", "class_name": "Http", "function_name": "create_empty_request", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Header", "self.protocol.request_class", "self.url.encode", "self.url.encode(errors='surrogateescape').decode", "self.url.encode(errors='surrogateescape').decode('ASCII', errors='backslashreplace').encode"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Create an empty request object for error handling use. Current error handling code needs a request object that won't exist if an error occurred during before a request was received. Create a", "source_code": "def create_empty_request(self) -> None:\n    \"\"\"Create an empty request object for error handling use.\n\n    Current error handling code needs a request object that won't exist\n    if an error occurred during before a request was received. Create a\n    bogus response for error handling use.\n    \"\"\"\n\n    # Reformat any URL already received with \\xHH escapes for better logs\n    url_bytes = (\n        self.url.encode(errors=\"surrogateescape\")\n        .decode(\"ASCII\", errors=\"backslashreplace\")\n        .encode(\"ASCII\")\n        if self.url\n        else b\"*\"\n    )\n\n    # FIXME: Avoid this by refactoring error handling and response code\n    self.request = self.protocol.request_class(\n        url_bytes=url_bytes,\n        headers=Header({}),\n        version=\"1.1\",\n        method=\"NONE\",\n        transport=self.protocol.transport,\n        app=self.protocol.app,\n    )\n    self.request.stream = self", "loc": 27}
{"file": "sanic\\sanic\\http\\http1.py", "class_name": "Http", "function_name": "log_response", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["access_logger.info", "getattr", "id", "perf_counter", "res.headers.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Helper method provided to enable the logging of responses in case if the `HttpProtocol.access_log` is enabled.", "source_code": "def log_response(self) -> None:\n    \"\"\"Helper method provided to enable the logging of responses in case if the `HttpProtocol.access_log` is enabled.\"\"\"  # noqa: E501\n    req, res = self.request, self.response\n    extra = {\n        \"status\": getattr(res, \"status\", 0),\n        \"byte\": res.headers.get(\"content-length\", 0)\n        if res.headers.get(\"transfer-encoding\") != \"chunked\"\n        else \"chunked\",\n        \"host\": f\"{id(self.protocol.transport):X}\"[-5:-1] + \"unx\",\n        \"request\": \"nil\",\n        \"duration\": (\n            f\" {1000 * (perf_counter() - self.perft0):.1f}ms\"\n            if self.perft0 is not None\n            else \"\"\n        ),\n    }\n    if ip := req.client_ip:\n        extra[\"host\"] = f\"{ip}:{req.port}\"\n    extra[\"request\"] = f\"{req.method} {req.url}\"\n    access_logger.info(\"\", extra=extra)", "loc": 20}
{"file": "sanic\\sanic\\http\\http1.py", "class_name": "Http", "function_name": "respond", "parameters": ["self", "response"], "param_types": {"response": "BaseHTTPResponse"}, "return_type": "BaseHTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Initiate new streaming response. Nothing is sent until the first send() call on the returned object, and calling this function multiple times will just alter the response to be", "source_code": "def respond(self, response: BaseHTTPResponse) -> BaseHTTPResponse:\n    \"\"\"Initiate new streaming response.\n\n    Nothing is sent until the first send() call on the returned object, and\n    calling this function multiple times will just alter the response to be\n    given.\n    \"\"\"\n    if self.stage is not Stage.HANDLER:\n        self.stage = Stage.FAILED\n        raise RuntimeError(\"Response already started\")\n\n    # Disconnect any earlier but unused response object\n    if self.response is not None:\n        self.response.stream = None\n\n    # Connect and return the response\n    self.response, response.stream = response, self\n    return response", "loc": 18}
{"file": "sanic\\sanic\\http\\http3.py", "class_name": null, "function_name": "get_config", "parameters": ["app", "ssl"], "param_types": {"app": "Sanic", "ssl": "Union[SanicSSLContext, CertSelector, SSLContext]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["QuicConfiguration", "SanicException", "cast", "config.load_cert_chain", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_config(\n    app: Sanic, ssl: Union[SanicSSLContext, CertSelector, SSLContext]\n):\n    # TODO:\n    # - proper selection needed if service with multiple certs insted of\n    #   just taking the first\n    if isinstance(ssl, CertSelector):\n        ssl = cast(SanicSSLContext, ssl.sanic_select[0])\n    if app.config.LOCAL_CERT_CREATOR is LocalCertCreator.TRUSTME:\n        raise SanicException(\n            \"Sorry, you cannot currently use trustme as a local certificate \"\n            \"generator for an HTTP/3 server. This is not yet supported. You \"\n            \"should be able to use mkcert instead. For more information, see: \"\n            \"https://github.com/aiortc/aioquic/issues/295.\"\n        )\n    if not isinstance(ssl, SanicSSLContext):\n        raise SanicException(\"SSLContext is not SanicSSLContext\")\n\n    config = QuicConfiguration(\n        alpn_protocols=H3_ALPN + H0_ALPN + [\"siduck\"],\n        is_client=False,\n        max_datagram_frame_size=65536,\n    )\n    password = app.config.TLS_CERT_PASSWORD or None\n\n    config.load_cert_chain(\n        ssl.sanic[\"cert\"], ssl.sanic[\"key\"], password=password\n    )\n\n    return config", "loc": 30}
{"file": "sanic\\sanic\\http\\http3.py", "class_name": "HTTP3Transport", "function_name": "get_extra_info", "parameters": ["self", "info", "default"], "param_types": {"info": "str", "default": "Any"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._protocol._transport.get_extra_info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_extra_info(self, info: str, default: Any = None) -> Any:\n    if (\n        info in (\"socket\", \"sockname\", \"peername\")\n        and self._protocol._transport\n    ):\n        return self._protocol._transport.get_extra_info(info, default)\n    elif info == \"network_paths\":\n        return self._protocol._quic._network_paths\n    elif info == \"ssl_context\":\n        return self._protocol.app.state.ssl\n    return default", "loc": 11}
{"file": "sanic\\sanic\\http\\http3.py", "class_name": "HTTPReceiver", "function_name": "send_headers", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "logger.debug", "self._prepare_headers", "self._send", "self.future.cancel", "self.protocol.connection.send_headers"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Send response headers to client", "source_code": "def send_headers(self) -> None:\n    \"\"\"Send response headers to client\"\"\"\n    logger.debug(  # no cov\n        f\"{Colors.BLUE}[send]: {Colors.GREEN}HEADERS{Colors.END}\",\n        extra={\"verbosity\": 2},\n    )\n    if not self.response:\n        raise RuntimeError(\"no response\")\n\n    response = self.response\n    headers = self._prepare_headers(response)\n\n    self.protocol.connection.send_headers(\n        stream_id=self.request.stream_id,\n        headers=headers,\n    )\n    self.headers_sent = True\n    self.stage = Stage.RESPONSE\n\n    if self.response.body and not self.head_only:\n        self._send(self.response.body, False)\n    elif self.head_only:\n        self.future.cancel()", "loc": 23}
{"file": "sanic\\sanic\\http\\http3.py", "class_name": "HTTPReceiver", "function_name": "respond", "parameters": ["self", "response"], "param_types": {"response": "BaseHTTPResponse"}, "return_type": "BaseHTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "logger.debug"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Prepare response to client", "source_code": "def respond(self, response: BaseHTTPResponse) -> BaseHTTPResponse:\n    \"\"\"Prepare response to client\"\"\"\n    logger.debug(  # no cov\n        f\"{Colors.BLUE}[respond]:{Colors.END} {response}\",\n        extra={\"verbosity\": 2},\n    )\n\n    if self.stage is not Stage.HANDLER:\n        self.stage = Stage.FAILED\n        raise RuntimeError(\"Response already started\")\n\n    # Disconnect any earlier but unused response object\n    if self.response is not None:\n        self.response.stream = None\n\n    self.response, response.stream = response, self\n\n    return response", "loc": 18}
{"file": "sanic\\sanic\\http\\http3.py", "class_name": "HTTPReceiver", "function_name": "receive_body", "parameters": ["self", "data"], "param_types": {"data": "bytes"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PayloadTooLarge", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Receive request body from client", "source_code": "def receive_body(self, data: bytes) -> None:\n    \"\"\"Receive request body from client\"\"\"\n    self.request_bytes += len(data)\n    if self.request_bytes > self.request_max_size:\n        raise PayloadTooLarge(\"Request body exceeds the size limit\")\n\n    self.request.body += data", "loc": 7}
{"file": "sanic\\sanic\\http\\http3.py", "class_name": "Http3", "function_name": "http_event_received", "parameters": ["self", "event"], "param_types": {"event": "H3Event"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["asyncio.ensure_future", "cast", "isinstance", "logger.debug", "receiver.future.cancel", "receiver.receive_body", "receiver.run", "self.get_or_make_receiver"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def http_event_received(self, event: H3Event) -> None:\n    logger.debug(  # no cov\n        f\"{Colors.BLUE}[http_event_received]: \"\n        f\"{Colors.YELLOW}{event}{Colors.END}\",\n        extra={\"verbosity\": 2},\n    )\n    receiver, created_new = self.get_or_make_receiver(event)\n    receiver = cast(HTTPReceiver, receiver)\n\n    if isinstance(event, HeadersReceived) and created_new:\n        receiver.future = asyncio.ensure_future(receiver.run())\n    elif isinstance(event, DataReceived):\n        try:\n            receiver.receive_body(event.data)\n        except Exception as e:\n            receiver.future.cancel()\n            receiver.future = asyncio.ensure_future(receiver.run(e))\n    else:\n        ...  # Intentionally here to help out Touchup\n        logger.debug(  # no cov\n            f\"{Colors.RED}DOING NOTHING{Colors.END}\",\n            extra={\"verbosity\": 2},\n        )", "loc": 23}
{"file": "sanic\\sanic\\http\\http3.py", "class_name": "Http3", "function_name": "get_or_make_receiver", "parameters": ["self", "event"], "param_types": {"event": "H3Event"}, "return_type": "tuple[Receiver, bool]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTTPReceiver", "getattr", "isinstance", "self._make_request", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_or_make_receiver(self, event: H3Event) -> tuple[Receiver, bool]:\n    if (\n        isinstance(event, HeadersReceived)\n        and event.stream_id not in self.receivers\n    ):\n        request = self._make_request(event)\n        receiver = HTTPReceiver(self.transmit, self.protocol, request)\n        request.stream = receiver\n\n        self.receivers[event.stream_id] = receiver\n        return receiver, True\n    else:\n        ident = getattr(event, self.HANDLER_PROPERTY_MAPPING[type(event)])\n        return self.receivers[ident], False", "loc": 14}
{"file": "sanic\\sanic\\http\\tls\\context.py", "class_name": null, "function_name": "create_context", "parameters": ["certfile", "keyfile", "password", "purpose"], "param_types": {"certfile": "Optional[str]", "keyfile": "Optional[str]", "password": "Optional[str]", "purpose": "ssl.Purpose"}, "return_type": "ssl.SSLContext", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["':'.join", "context.load_cert_chain", "context.set_alpn_protocols", "context.set_ciphers", "ssl.create_default_context"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Create a context with secure crypto and HTTP/1.1 in protocols.", "source_code": "def create_context(\n    certfile: Optional[str] = None,\n    keyfile: Optional[str] = None,\n    password: Optional[str] = None,\n    purpose: ssl.Purpose = ssl.Purpose.CLIENT_AUTH,\n) -> ssl.SSLContext:\n    \"\"\"Create a context with secure crypto and HTTP/1.1 in protocols.\"\"\"\n    context = ssl.create_default_context(purpose=purpose)\n    context.minimum_version = ssl.TLSVersion.TLSv1_2\n    context.set_ciphers(\":\".join(CIPHERS_TLS12))\n    context.set_alpn_protocols([\"http/1.1\"])\n    if purpose is ssl.Purpose.CLIENT_AUTH:\n        context.sni_callback = server_name_callback\n    if certfile and keyfile:\n        context.load_cert_chain(certfile, keyfile, password)\n    return context", "loc": 16}
{"file": "sanic\\sanic\\http\\tls\\context.py", "class_name": null, "function_name": "shorthand_to_ctx", "parameters": ["ctxdef"], "param_types": {"ctxdef": "Union[None, ssl.SSLContext, dict, str]"}, "return_type": "Optional[ssl.SSLContext]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CertSimple", "ValueError", "isinstance", "load_cert_dir", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Convert an ssl argument shorthand to an SSLContext object.", "source_code": "def shorthand_to_ctx(\n    ctxdef: Union[None, ssl.SSLContext, dict, str],\n) -> Optional[ssl.SSLContext]:\n    \"\"\"Convert an ssl argument shorthand to an SSLContext object.\"\"\"\n    if ctxdef is None or isinstance(ctxdef, ssl.SSLContext):\n        return ctxdef\n    if isinstance(ctxdef, str):\n        return load_cert_dir(ctxdef)\n    if isinstance(ctxdef, dict):\n        return CertSimple(**ctxdef)\n    raise ValueError(\n        f\"Invalid ssl argument {type(ctxdef)}.\"\n        \" Expecting a list of certdirs, a dict or an SSLContext.\"\n    )", "loc": 14}
{"file": "sanic\\sanic\\http\\tls\\context.py", "class_name": null, "function_name": "process_to_context", "parameters": ["ssldef"], "param_types": {"ssldef": "Union[None, ssl.SSLContext, dict, str, list, tuple]"}, "return_type": "Optional[ssl.SSLContext]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CertSelector", "isinstance", "map", "shorthand_to_ctx"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Process app.run ssl argument from easy formats to full SSLContext.", "source_code": "def process_to_context(\n    ssldef: Union[None, ssl.SSLContext, dict, str, list, tuple],\n) -> Optional[ssl.SSLContext]:\n    \"\"\"Process app.run ssl argument from easy formats to full SSLContext.\"\"\"\n    return (\n        CertSelector(map(shorthand_to_ctx, ssldef))\n        if isinstance(ssldef, (list, tuple))\n        else shorthand_to_ctx(ssldef)\n    )", "loc": 9}
{"file": "sanic\\sanic\\http\\tls\\context.py", "class_name": null, "function_name": "find_cert", "parameters": ["self", "server_name"], "param_types": {"self": "CertSelector", "server_name": "str"}, "return_type": null, "param_doc": {}, "return_doc": "A matching ssl.SSLContext object if found.", "raises_doc": [], "called_functions": ["ValueError", "match_hostname"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Find the first certificate that matches the given SNI.", "source_code": "def find_cert(self: CertSelector, server_name: str):\n    \"\"\"Find the first certificate that matches the given SNI.\n\n    :raises ssl.CertificateError: No matching certificate found.\n    :return: A matching ssl.SSLContext object if found.\"\"\"\n    if not server_name:\n        if self.sanic_fallback:\n            return self.sanic_fallback\n        raise ValueError(\n            \"The client provided no SNI to match for certificate.\"\n        )\n    for ctx in self.sanic_select:\n        if match_hostname(ctx, server_name):\n            return ctx\n    if self.sanic_fallback:\n        return self.sanic_fallback\n    raise ValueError(f\"No certificate found matching hostname {server_name!r}\")", "loc": 17}
{"file": "sanic\\sanic\\http\\tls\\context.py", "class_name": null, "function_name": "match_hostname", "parameters": ["ctx", "hostname"], "param_types": {"ctx": "Union[ssl.SSLContext, CertSelector]", "hostname": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dict", "dict(getattr(ctx, 'sanic', {})).get", "getattr", "hostname.lower", "hostname.split", "name.startswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Match names from CertSelector against a received hostname.", "source_code": "def match_hostname(\n    ctx: Union[ssl.SSLContext, CertSelector], hostname: str\n) -> bool:\n    \"\"\"Match names from CertSelector against a received hostname.\"\"\"\n    # Local certs are considered trusted, so this can be less pedantic\n    # and thus faster than the deprecated ssl.match_hostname function is.\n    names = dict(getattr(ctx, \"sanic\", {})).get(\"names\", [])\n    hostname = hostname.lower()\n    for name in names:\n        if name.startswith(\"*.\"):\n            if hostname.split(\".\", 1)[-1] == name[2:]:\n                return True\n        elif name == hostname:\n            return True\n    return False", "loc": 15}
{"file": "sanic\\sanic\\http\\tls\\context.py", "class_name": null, "function_name": "selector_sni_callback", "parameters": ["sslobj", "server_name", "ctx"], "param_types": {"sslobj": "ssl.SSLObject", "server_name": "str", "ctx": "CertSelector"}, "return_type": "Optional[int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["find_cert", "logger.warning", "server_name_callback"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Select a certificate matching the SNI.", "source_code": "def selector_sni_callback(\n    sslobj: ssl.SSLObject, server_name: str, ctx: CertSelector\n) -> Optional[int]:\n    \"\"\"Select a certificate matching the SNI.\"\"\"\n    # Call server_name_callback to store the SNI on sslobj\n    server_name_callback(sslobj, server_name, ctx)\n    # Find a new context matching the hostname\n    try:\n        sslobj.context = find_cert(ctx, server_name)\n    except ValueError as e:\n        logger.warning(f\"Rejecting TLS connection: {e}\")\n        # This would show ERR_SSL_UNRECOGNIZED_NAME_ALERT on client side if\n        # asyncio/uvloop did proper SSL shutdown. They don't.\n        return ssl.ALERT_DESCRIPTION_UNRECOGNIZED_NAME\n    return None  # mypy complains without explicit return", "loc": 15}
{"file": "sanic\\sanic\\http\\tls\\creators.py", "class_name": null, "function_name": "get_ssl_context", "parameters": ["app", "ssl"], "param_types": {"app": "Sanic", "ssl": "Optional[ssl.SSLContext]"}, "return_type": "ssl.SSLContext", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CertCreator.select", "SanicException", "cast", "creator.generate_cert"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_ssl_context(\n    app: Sanic, ssl: Optional[ssl.SSLContext]\n) -> ssl.SSLContext:\n    if ssl:\n        return ssl\n\n    if app.state.mode is Mode.PRODUCTION:\n        raise SanicException(\n            \"Cannot run Sanic as an HTTPS server in PRODUCTION mode \"\n            \"without passing a TLS certificate. If you are developing \"\n            \"locally, please enable DEVELOPMENT mode and Sanic will \"\n            \"generate a localhost TLS certificate. For more information \"\n            \"please see: https://sanic.dev/en/guide/deployment/development.\"\n            \"html#automatic-tls-certificate.\"\n        )\n\n    creator = CertCreator.select(\n        app,\n        cast(LocalCertCreator, app.config.LOCAL_CERT_CREATOR),\n        app.config.LOCAL_TLS_KEY,\n        app.config.LOCAL_TLS_CERT,\n    )\n    context = creator.generate_cert(app.config.LOCALHOST)\n    return context", "loc": 24}
{"file": "sanic\\sanic\\http\\tls\\creators.py", "class_name": "CertCreator", "function_name": "select", "parameters": ["cls", "app", "cert_creator", "local_tls_key", "local_tls_cert"], "param_types": {"app": "Sanic", "cert_creator": "LocalCertCreator"}, "return_type": "CertCreator", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "cls._try_select"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select(\n    cls,\n    app: Sanic,\n    cert_creator: LocalCertCreator,\n    local_tls_key,\n    local_tls_cert,\n) -> CertCreator:\n    creator: Optional[CertCreator] = None\n\n    cert_creator_options: tuple[\n        tuple[type[CertCreator], LocalCertCreator], ...\n    ] = (\n        (MkcertCreator, LocalCertCreator.MKCERT),\n        (TrustmeCreator, LocalCertCreator.TRUSTME),\n    )\n    for creator_class, local_creator in cert_creator_options:\n        creator = cls._try_select(\n            app,\n            creator,\n            creator_class,\n            local_creator,\n            cert_creator,\n            local_tls_key,\n            local_tls_cert,\n        )\n        if creator:\n            break\n\n    if not creator:\n        raise SanicException(\n            \"Sanic could not find package to create a TLS certificate. \"\n            \"You must have either mkcert or trustme installed. See \"\n            \"https://sanic.dev/en/guide/deployment/development.html\"\n            \"#automatic-tls-certificate for more details.\"\n        )\n\n    return creator", "loc": 37}
{"file": "sanic\\sanic\\http\\tls\\creators.py", "class_name": "MkcertCreator", "function_name": "check_supported", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "subprocess.run"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_supported(self) -> None:\n    try:\n        subprocess.run(  # nosec B603 B607\n            [\"mkcert\", \"-help\"],\n            check=True,\n            stderr=subprocess.DEVNULL,\n            stdout=subprocess.DEVNULL,\n        )\n    except Exception as e:\n        raise SanicException(\n            \"Sanic is attempting to use mkcert to generate local TLS \"\n            \"certificates since you did not supply a certificate, but \"\n            \"one is required. Sanic cannot proceed since mkcert does not \"\n            \"appear to be installed. Alternatively, you can use trustme. \"\n            \"Please install mkcert, trustme, or supply TLS certificates \"\n            \"to proceed. Installation instructions can be found here: \"\n            \"https://github.com/FiloSottile/mkcert.\\n\"\n            \"Find out more information about your options here: \"\n            \"https://sanic.dev/en/guide/deployment/development.html#\"\n            \"automatic-tls-certificate\"\n        ) from e", "loc": 21}
{"file": "sanic\\sanic\\http\\tls\\creators.py", "class_name": "MkcertCreator", "function_name": "generate_cert", "parameters": ["self", "localhost"], "param_types": {"localhost": "str"}, "return_type": "ssl.SSLContext", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CertSimple", "SanicSSLContext.create_from_ssl_context", "len", "loading", "self.cert_path.exists", "self.cert_path.unlink", "self.key_path.unlink", "self.tmpdir.rmdir", "str", "subprocess.run", "suppress", "sys.stdout.flush", "sys.stdout.write"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def generate_cert(self, localhost: str) -> ssl.SSLContext:\n    try:\n        if not self.cert_path.exists():\n            message = \"Generating TLS certificate\"\n            # TODO: Validate input for security\n            with loading(message):\n                cmd = [\n                    \"mkcert\",\n                    \"-key-file\",\n                    str(self.key_path),\n                    \"-cert-file\",\n                    str(self.cert_path),\n                    localhost,\n                ]\n                resp = subprocess.run(  # nosec B603\n                    cmd,\n                    check=True,\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.STDOUT,\n                    text=True,\n                )\n            sys.stdout.write(\"\\r\" + \" \" * (len(message) + 4))\n            sys.stdout.flush()\n            sys.stdout.write(resp.stdout)\n    finally:\n\n        @self.app.main_process_stop\n        async def cleanup(*_):  # no cov\n            if self.tmpdir:\n                with suppress(FileNotFoundError):\n                    self.key_path.unlink()\n                    self.cert_path.unlink()\n                self.tmpdir.rmdir()\n\n    context = CertSimple(self.cert_path, self.key_path)\n    context.sanic[\"creator\"] = \"mkcert\"\n    context.sanic[\"localhost\"] = localhost\n    SanicSSLContext.create_from_ssl_context(context)\n\n    return context", "loc": 40}
{"file": "sanic\\sanic\\http\\tls\\creators.py", "class_name": "TrustmeCreator", "function_name": "check_supported", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_supported(self) -> None:\n    if not TRUSTME_INSTALLED:\n        raise SanicException(\n            \"Sanic is attempting to use trustme to generate local TLS \"\n            \"certificates since you did not supply a certificate, but \"\n            \"one is required. Sanic cannot proceed since trustme does not \"\n            \"appear to be installed. Alternatively, you can use mkcert. \"\n            \"Please install mkcert, trustme, or supply TLS certificates \"\n            \"to proceed. Installation instructions can be found here: \"\n            \"https://github.com/python-trio/trustme.\\n\"\n            \"Find out more information about your options here: \"\n            \"https://sanic.dev/en/guide/deployment/development.html#\"\n            \"automatic-tls-certificate\"\n        )", "loc": 14}
{"file": "sanic\\sanic\\http\\tls\\creators.py", "class_name": "TrustmeCreator", "function_name": "generate_cert", "parameters": ["self", "localhost"], "param_types": {"localhost": "str"}, "return_type": "ssl.SSLContext", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicSSLContext.create_from_ssl_context", "ca.cert_pem.write_to_path", "ca.configure_trust", "ca.issue_cert", "self.cert_path.absolute", "self.key_path.absolute", "server_cert.configure_cert", "server_cert.private_key_and_cert_chain_pem.write_to_path", "ssl.SSLContext", "str", "trustme.CA"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def generate_cert(self, localhost: str) -> ssl.SSLContext:\n    context = SanicSSLContext.create_from_ssl_context(\n        ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n    )\n    context.sanic = {\n        \"cert\": self.cert_path.absolute(),\n        \"key\": self.key_path.absolute(),\n    }\n    ca = trustme.CA()\n    server_cert = ca.issue_cert(localhost)\n    server_cert.configure_cert(context)\n    ca.configure_trust(context)\n\n    ca.cert_pem.write_to_path(str(self.cert_path.absolute()))\n    server_cert.private_key_and_cert_chain_pem.write_to_path(\n        str(self.key_path.absolute())\n    )\n    context.sanic[\"creator\"] = \"trustme\"\n    context.sanic[\"localhost\"] = localhost\n\n    return context", "loc": 21}
{"file": "sanic\\sanic\\logging\\deprecation.py", "class_name": null, "function_name": "deprecation", "parameters": ["message", "version"], "param_types": {"message": "str", "version": "float"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_atty", "warn"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Add a deprecation notice Example when a feature is being removed. In this case, version should be AT LEAST next version + 2 .. code-block:: python deprecation(\"Helpful message\", 99.9) Example when a feature is deprecated but not being removed: .. code-block:: python deprecation(\"Helpful message\", 0)", "source_code": "def deprecation(message: str, version: float):  # no cov\n    \"\"\"\n    Add a deprecation notice\n\n    Example when a feature is being removed. In this case, version\n    should be AT LEAST next version + 2\n\n    .. code-block:: python\n\n        deprecation(\"Helpful message\", 99.9)\n\n    Example when a feature is deprecated but not being removed:\n\n    .. code-block:: python\n\n        deprecation(\"Helpful message\", 0)\n\n    Args:\n        message (str): Deprecation message\n        version (float): Version when the feature will be removed\n    \"\"\"\n    version_display = f\" v{version}\" if version else \"\"\n    version_info = f\"[DEPRECATION{version_display}] \"\n    if is_atty():\n        version_info = f\"{Colors.RED}{version_info}\"\n        message = f\"{Colors.YELLOW}{message}{Colors.END}\"\n    warn(version_info + message, DeprecationWarning)", "loc": 27}
{"file": "sanic\\sanic\\logging\\formatter.py", "class_name": "AutoFormatter", "function_name": "format", "parameters": ["self", "record"], "param_types": {"record": "logging.LogRecord"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._log_extra", "self._set_levelname", "super", "super().format"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format(self, record: logging.LogRecord) -> str:\n    record.ident = self.IDENT\n    self._set_levelname(record)\n    output = super().format(record)\n    if self.LOG_EXTRA:\n        output += self._log_extra(record)\n    return output", "loc": 7}
{"file": "sanic\\sanic\\logging\\formatter.py", "class_name": "DebugFormatter", "function_name": "formatException", "parameters": ["self", "ei"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "colored_traceback.append", "enumerate", "len", "line.startswith", "orig.splitlines", "self._color_code_line", "self._color_exception_line", "self._color_file_line", "super", "super().formatException"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def formatException(self, ei):  # no cov\n    orig = super().formatException(ei)\n    if not self.ATTY or self.NO_COLOR:\n        return orig\n    colored_traceback = []\n    lines = orig.splitlines()\n    for idx, line in enumerate(lines):\n        if line.startswith(\"  File\"):\n            line = self._color_file_line(line)\n        elif line.startswith(\"    \"):\n            line = self._color_code_line(line)\n        elif (\n            \"Error\" in line or \"Exception\" in line or len(lines) - 1 == idx\n        ):\n            line = self._color_exception_line(line)\n        colored_traceback.append(line)\n    return \"\\n\".join(colored_traceback)", "loc": 17}
{"file": "sanic\\sanic\\logging\\formatter.py", "class_name": "AutoAccessFormatter", "function_name": "format", "parameters": ["self", "record"], "param_types": {"record": "logging.LogRecord"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CONTROL_LIMIT_END.format", "getattr", "len", "str", "super", "super().format"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format(self, record: logging.LogRecord) -> str:\n    status = len(str(getattr(record, \"status\", \"\")))\n    byte = len(str(getattr(record, \"byte\", \"\")))\n    duration = len(str(getattr(record, \"duration\", \"\")))\n    record.right = (\n        CONTROL_LIMIT_END.format(right=status + byte + duration + 1)\n        if self.ATTY\n        else \"\"\n    )\n    return super().format(record)", "loc": 10}
{"file": "sanic\\sanic\\logging\\formatter.py", "class_name": "JSONFormatter", "function_name": "to_dict", "parameters": ["self", "record"], "param_types": {"record": "logging.LogRecord"}, "return_type": "dict", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "record.__dict__.items", "record.getMessage", "self.formatException", "self.formatStack", "self.formatTime"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def to_dict(self, record: logging.LogRecord) -> dict:\n    base = {field: getattr(record, field, None) for field in self.FIELDS}\n    extra = {\n        key: value\n        for key, value in record.__dict__.items()\n        if key not in DEFAULT_FIELDS\n    }\n    info = {}\n    if record.exc_info:\n        info[\"exc_info\"] = self.formatException(record.exc_info)\n    if record.stack_info:\n        info[\"stack_info\"] = self.formatStack(record.stack_info)\n    return {\n        \"timestamp\": self.formatTime(record, self.datefmt),\n        \"level\": record.levelname,\n        \"message\": record.getMessage(),\n        **base,\n        **info,\n        **extra,\n    }", "loc": 20}
{"file": "sanic\\sanic\\logging\\formatter.py", "class_name": "JSONAccessFormatter", "function_name": "to_dict", "parameters": ["self", "record"], "param_types": {"record": "logging.LogRecord"}, "return_type": "dict", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "record.getMessage", "self.formatTime"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def to_dict(self, record: logging.LogRecord) -> dict:\n    base = {field: getattr(record, field, None) for field in self.FIELDS}\n    return {\n        \"timestamp\": self.formatTime(record, self.datefmt),\n        \"level\": record.levelname,\n        \"message\": record.getMessage(),\n        **base,\n    }", "loc": 8}
{"file": "sanic\\sanic\\logging\\setup.py", "class_name": null, "function_name": "setup_logging", "parameters": ["debug", "no_color", "log_extra"], "param_types": {"debug": "bool", "no_color": "bool", "log_extra": "Union[bool, Default]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_auto_format", "isinstance", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def setup_logging(\n    debug: bool,\n    no_color: bool = False,\n    log_extra: Union[bool, Default] = _default,\n) -> None:\n    if AutoFormatter.SETUP:\n        return\n\n    if isinstance(log_extra, Default):\n        log_extra = debug\n        os.environ[\"SANIC_LOG_EXTRA\"] = str(log_extra)\n    AutoFormatter.LOG_EXTRA = log_extra\n\n    if no_color:\n        os.environ[\"SANIC_NO_COLOR\"] = str(no_color)\n        AutoFormatter.NO_COLOR = no_color\n\n    AutoFormatter.SETUP = True\n\n    for lggr in (logger, server_logger, error_logger, websockets_logger):\n        _auto_format(\n            lggr,\n            AutoFormatter,\n            DebugFormatter if debug else ProdFormatter,\n        )\n    _auto_format(\n        access_logger,\n        AutoAccessFormatter,\n        DebugAccessFormatter if debug else ProdAccessFormatter,\n    )", "loc": 30}
{"file": "sanic\\sanic\\mixins\\commands.py", "class_name": "CommandMixin", "function_name": "command", "parameters": ["self", "maybe_func"], "param_types": {"maybe_func": "Optional[Callable]"}, "return_type": "Union[Callable, Callable[[Callable], Callable]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FutureCommand", "decorator", "f", "isawaitable", "self._future_commands.add", "wraps"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def command(\n    self, maybe_func: Optional[Callable] = None, *, name: str = \"\"\n) -> Union[Callable, Callable[[Callable], Callable]]:\n    def decorator(f):\n        @wraps(f)\n        async def decorated_function(*args, **kwargs):\n            response = f(*args, **kwargs)\n            if isawaitable(response):\n                response = await response\n            return response\n\n        self._future_commands.add(\n            FutureCommand(name or f.__name__, decorated_function)\n        )\n        return decorated_function\n\n    return decorator(maybe_func) if maybe_func else decorator", "loc": 17}
{"file": "sanic\\sanic\\mixins\\commands.py", "class_name": null, "function_name": "decorator", "parameters": ["f"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FutureCommand", "f", "isawaitable", "self._future_commands.add", "wraps"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def decorator(f):\n    @wraps(f)\n    async def decorated_function(*args, **kwargs):\n        response = f(*args, **kwargs)\n        if isawaitable(response):\n            response = await response\n        return response\n\n    self._future_commands.add(\n        FutureCommand(name or f.__name__, decorated_function)\n    )\n    return decorated_function", "loc": 12}
{"file": "sanic\\sanic\\mixins\\exceptions.py", "class_name": "ExceptionMixin", "function_name": "exception", "parameters": ["self"], "param_types": {}, "return_type": "Callable", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FutureException", "isinstance", "self._apply_exception_handler", "self._future_exceptions.add", "tuple"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Decorator used to register an exception handler for the current application or blueprint instance. This method allows you to define a handler for specific exceptions that may be raised within the routes of this blueprint. You can specify one or more exception types to catch, and the handler will be applied to those exceptions. When used on a Blueprint, the handler will only be applied to routes registered under that blueprint. That means they only apply to requests that have been matched, and the exception is raised within the handler function (or middleware) for that route. A general exception like `NotFound` should only be registered on the application instance, not on a blueprint. See [Exceptions](/en/guide/best-practices/exceptions.html) for more information.", "source_code": "def exception(\n    self,\n    *exceptions: Union[type[Exception], list[type[Exception]]],\n    apply: bool = True,\n) -> Callable:\n    \"\"\"Decorator used to register an exception handler for the current application or blueprint instance.\n\n    This method allows you to define a handler for specific exceptions that\n    may be raised within the routes of this blueprint. You can specify one\n    or more exception types to catch, and the handler will be applied to\n    those exceptions.\n\n    When used on a Blueprint, the handler will only be applied to routes\n    registered under that blueprint. That means they only apply to\n    requests that have been matched, and the exception is raised within\n    the handler function (or middleware) for that route.\n\n    A general exception like `NotFound` should only be registered on the\n    application instance, not on a blueprint.\n\n    See [Exceptions](/en/guide/best-practices/exceptions.html) for more information.\n\n    Args:\n        exceptions (Union[Type[Exception], List[Type[Exception]]]): List of\n            Python exceptions to be caught by the handler.\n        apply (bool, optional): Whether the exception handler should be\n            applied. Defaults to True.\n\n    Returns:\n        Callable: A decorated method to handle global exceptions for any route\n            registered under this blueprint.\n\n    Example:\n        ```python\n        from sanic import Blueprint, text\n\n        bp = Blueprint('my_blueprint')\n\n        @bp.exception(Exception)\n        def handle_exception(request, exception):\n            return text(\"Oops, something went wrong!\", status=500)\n        ```\n\n        ```python\n        from sanic import Sanic, NotFound, text\n\n        app = Sanic('MyApp')\n\n        @app.exception(NotFound)\n        def ignore_404s(request, exception):\n            return text(f\"Yep, I totally found the page: {request.url}\")\n    \"\"\"  # noqa: E501\n\n    def decorator(handler):\n        nonlocal apply\n        nonlocal exceptions\n\n        if isinstance(exceptions[0], list):\n            exceptions = tuple(*exceptions)\n\n        future_exception = FutureException(handler, exceptions)\n        self._future_exceptions.add(future_exception)\n        if apply:\n            self._apply_exception_handler(future_exception)\n        return handler\n\n    return decorator", "loc": 67}
{"file": "sanic\\sanic\\mixins\\exceptions.py", "class_name": null, "function_name": "decorator", "parameters": ["handler"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FutureException", "isinstance", "self._apply_exception_handler", "self._future_exceptions.add", "tuple"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def decorator(handler):\n    nonlocal apply\n    nonlocal exceptions\n\n    if isinstance(exceptions[0], list):\n        exceptions = tuple(*exceptions)\n\n    future_exception = FutureException(handler, exceptions)\n    self._future_exceptions.add(future_exception)\n    if apply:\n        self._apply_exception_handler(future_exception)\n    return handler", "loc": 12}
{"file": "sanic\\sanic\\mixins\\listeners.py", "class_name": "ListenerMixin", "function_name": "listener", "parameters": ["self", "listener_or_event", "event_or_none", "apply"], "param_types": {"listener_or_event": "Union[ListenerType[Sanic], str]", "event_or_none": "Optional[str]", "apply": "bool"}, "return_type": "Union[ListenerType[Sanic], Callable[[ListenerType[Sanic]], ListenerType[Sanic]]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BadRequest", "FutureListener", "callable", "partial", "register_listener", "self._apply_listener", "self._future_listeners.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Create a listener for a specific event in the application's lifecycle. See [Listeners](/en/guide/basics/listeners) for more details. .. note:: Overloaded signatures allow for different ways of calling this method, depending on the types of the arguments. Usually, it is prederred to use one of the convenience methods such as `before_server_start` or `after_server_stop` instead of calling this method directly. ```python @app.before_server_start async def prefered_method(_): ... @app.listener(\"before_server_start\") async def not_prefered_method(_): ...", "source_code": "def listener(\n    self,\n    listener_or_event: Union[ListenerType[Sanic], str],\n    event_or_none: Optional[str] = None,\n    apply: bool = True,\n    *,\n    priority: int = 0,\n) -> Union[\n    ListenerType[Sanic],\n    Callable[[ListenerType[Sanic]], ListenerType[Sanic]],\n]:\n    \"\"\"Create a listener for a specific event in the application's lifecycle.\n\n    See [Listeners](/en/guide/basics/listeners) for more details.\n\n    .. note::\n        Overloaded signatures allow for different ways of calling this method, depending on the types of the arguments.\n\n        Usually, it is prederred to use one of the convenience methods such as `before_server_start` or `after_server_stop` instead of calling this method directly.\n\n        ```python\n        @app.before_server_start\n        async def prefered_method(_):\n            ...\n\n        @app.listener(\"before_server_start\")\n        async def not_prefered_method(_):\n            ...\n\n    Args:\n        listener_or_event (Union[ListenerType[Sanic], str]): A listener function or an event name.\n        event_or_none (Optional[str]): The event name to listen for if `listener_or_event` is a function. Defaults to `None`.\n        apply (bool): Whether to apply the listener immediately. Defaults to `True`.\n        priority (int): The priority of the listener. Defaults to `0`.\n\n    Returns:\n        Union[ListenerType[Sanic], Callable[[ListenerType[Sanic]], ListenerType[Sanic]]]: The listener or a callable that takes a listener.\n\n    Example:\n        The following code snippet shows how you can use this method as a decorator:\n\n        ```python\n        @bp.listener(\"before_server_start\")\n        async def before_server_start(app, loop):\n            ...\n        ```\n    \"\"\"  # noqa: E501\n\n    def register_listener(\n        listener: ListenerType[Sanic], event: str, priority: int = 0\n    ) -> ListenerType[Sanic]:\n        \"\"\"A helper function to register a listener for an event.\n\n        Typically will not be called directly.\n\n        Args:\n            listener (ListenerType[Sanic]): The listener function to\n                register.\n            event (str): The event name to listen for.\n\n        Returns:\n            ListenerType[Sanic]: The listener function that was registered.\n        \"\"\"\n        nonlocal apply\n\n        future_listener = FutureListener(listener, event, priority)\n        self._future_listeners.append(future_listener)\n        if apply:\n            self._apply_listener(future_listener)\n        return listener\n\n    if callable(listener_or_event):\n        if event_or_none is None:\n            raise BadRequest(\n                \"Invalid event registration: Missing event name.\"\n            )\n        return register_listener(\n            listener_or_event, event_or_none, priority\n        )\n    else:\n        return partial(\n            register_listener, event=listener_or_event, priority=priority\n        )", "loc": 83}
{"file": "sanic\\sanic\\mixins\\listeners.py", "class_name": null, "function_name": "register_listener", "parameters": ["listener", "event", "priority"], "param_types": {"listener": "ListenerType[Sanic]", "event": "str", "priority": "int"}, "return_type": "ListenerType[Sanic]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FutureListener", "self._apply_listener", "self._future_listeners.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "A helper function to register a listener for an event. Typically will not be called directly.", "source_code": "def register_listener(\n    listener: ListenerType[Sanic], event: str, priority: int = 0\n) -> ListenerType[Sanic]:\n    \"\"\"A helper function to register a listener for an event.\n\n    Typically will not be called directly.\n\n    Args:\n        listener (ListenerType[Sanic]): The listener function to\n            register.\n        event (str): The event name to listen for.\n\n    Returns:\n        ListenerType[Sanic]: The listener function that was registered.\n    \"\"\"\n    nonlocal apply\n\n    future_listener = FutureListener(listener, event, priority)\n    self._future_listeners.append(future_listener)\n    if apply:\n        self._apply_listener(future_listener)\n    return listener", "loc": 22}
{"file": "sanic\\sanic\\mixins\\middleware.py", "class_name": "MiddlewareMixin", "function_name": "middleware", "parameters": ["self", "middleware_or_request", "attach_to", "apply"], "param_types": {"middleware_or_request": "Union[MiddlewareType, str]", "attach_to": "str", "apply": "bool"}, "return_type": "Union[MiddlewareType, Callable[[MiddlewareType], MiddlewareType]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FutureMiddleware", "Middleware", "callable", "partial", "register_middleware", "self._apply_middleware", "self._future_middleware.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Decorator for registering middleware. Decorate and register middleware to be called before a request is handled or after a response is created. Can either be called as *@app.middleware* or *@app.middleware('request')*. Although, it is recommended to use *@app.on_request* or *@app.on_response* instead for clarity and convenience. See [Middleware](/guide/basics/middleware) for more information.", "source_code": "def middleware(\n    self,\n    middleware_or_request: Union[MiddlewareType, str],\n    attach_to: str = \"request\",\n    apply: bool = True,\n    *,\n    priority: int = 0,\n) -> Union[MiddlewareType, Callable[[MiddlewareType], MiddlewareType]]:\n    \"\"\"Decorator for registering middleware.\n\n    Decorate and register middleware to be called before a request is\n    handled or after a response is created. Can either be called as\n    *@app.middleware* or *@app.middleware('request')*. Although, it is\n    recommended to use *@app.on_request* or *@app.on_response* instead\n    for clarity and convenience.\n\n    See [Middleware](/guide/basics/middleware) for more information.\n\n    Args:\n        middleware_or_request (Union[Callable, str]): Middleware function\n            or the keyword 'request' or 'response'.\n        attach_to (str, optional): When to apply the middleware;\n            either 'request' (before the request is handled) or 'response'\n            (after the response is created). Defaults to `'request'`.\n        apply (bool, optional): Whether the middleware should be applied.\n            Defaults to `True`.\n        priority (int, optional): The priority level of the middleware.\n            Lower numbers are executed first. Defaults to `0`.\n\n    Returns:\n        Union[Callable, Callable[[Callable], Callable]]: The decorated\n            middleware function or a partial function depending on how\n            the method was called.\n\n    Example:\n        ```python\n        @app.middleware('request')\n        async def custom_middleware(request):\n            ...\n        ```\n    \"\"\"\n\n    def register_middleware(middleware, attach_to=\"request\"):\n        nonlocal apply\n\n        location = (\n            MiddlewareLocation.REQUEST\n            if attach_to == \"request\"\n            else MiddlewareLocation.RESPONSE\n        )\n        middleware = Middleware(middleware, location, priority=priority)\n        future_middleware = FutureMiddleware(middleware, attach_to)\n        self._future_middleware.append(future_middleware)\n        if apply:\n            self._apply_middleware(future_middleware)\n        return middleware\n\n    # Detect which way this was called, @middleware or @middleware('AT')\n    if callable(middleware_or_request):\n        return register_middleware(\n            middleware_or_request, attach_to=attach_to\n        )\n    else:\n        return partial(\n            register_middleware, attach_to=middleware_or_request\n        )", "loc": 66}
{"file": "sanic\\sanic\\mixins\\middleware.py", "class_name": "MiddlewareMixin", "function_name": "on_request", "parameters": ["self", "middleware"], "param_types": {}, "return_type": "MiddlewareType", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["callable", "partial", "self.middleware"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Register a middleware to be called before a request is handled. This is the same as *@app.middleware('request')*.", "source_code": "def on_request(self, middleware=None, *, priority=0) -> MiddlewareType:\n    \"\"\"Register a middleware to be called before a request is handled.\n\n    This is the same as *@app.middleware('request')*.\n\n    Args:\n        middleware (Callable, optional): A callable that takes in a\n            request. Defaults to `None`.\n\n    Returns:\n        Callable: The decorated middleware function or a partial function\n            depending on how the method was called.\n\n    Examples:\n        ```python\n        @app.on_request\n        async def custom_middleware(request):\n            request.ctx.custom = 'value'\n        ```\n    \"\"\"\n    if callable(middleware):\n        return self.middleware(middleware, \"request\", priority=priority)\n    else:\n        return partial(  # type: ignore\n            self.middleware, attach_to=\"request\", priority=priority\n        )", "loc": 26}
{"file": "sanic\\sanic\\mixins\\middleware.py", "class_name": "MiddlewareMixin", "function_name": "on_response", "parameters": ["self", "middleware"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["callable", "partial", "self.middleware"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Register a middleware to be called after a response is created. This is the same as *@app.middleware('response')*.", "source_code": "def on_response(self, middleware=None, *, priority=0):\n    \"\"\"Register a middleware to be called after a response is created.\n\n    This is the same as *@app.middleware('response')*.\n\n    Args:\n        middleware (Callable, optional): A callable that takes in a\n            request and response. Defaults to `None`.\n\n    Returns:\n        Callable: The decorated middleware function or a partial function\n            depending on how the method was called.\n\n    Examples:\n        ```python\n        @app.on_response\n        async def custom_middleware(request, response):\n            response.headers['X-Server'] = 'Sanic'\n        ```\n    \"\"\"\n    if callable(middleware):\n        return self.middleware(middleware, \"response\", priority=priority)\n    else:\n        return partial(\n            self.middleware, attach_to=\"response\", priority=priority\n        )", "loc": 26}
{"file": "sanic\\sanic\\mixins\\middleware.py", "class_name": "MiddlewareMixin", "function_name": "finalize_middleware", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Middleware.convert", "attrgetter", "deque", "self.named_request_middleware.get", "self.named_response_middleware.get", "sorted"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Finalize the middleware configuration for the Sanic application. This method completes the middleware setup for the application. Middleware in Sanic is used to process requests globally before they", "source_code": "def finalize_middleware(self) -> None:\n    \"\"\"Finalize the middleware configuration for the Sanic application.\n\n    This method completes the middleware setup for the application.\n    Middleware in Sanic is used to process requests globally before they\n    reach individual routes or after routes have been processed.\n\n    Finalization consists of identifying defined routes and optimizing\n    Sanic's performance to meet the application's specific needs. If\n    you are manually adding routes, after Sanic has started, you will\n    typically want to use the `amend` context manager rather than\n    calling this method directly.\n\n    .. note::\n        This method is usually called internally during the server setup\n        process and does not typically need to be invoked manually.\n\n    Example:\n        ```python\n        app.finalize_middleware()\n        ```\n    \"\"\"\n    for route in self.router.routes:\n        request_middleware = Middleware.convert(\n            self.request_middleware,  # type: ignore\n            self.named_request_middleware.get(route.name, deque()),  # type: ignore  # noqa: E501\n            location=MiddlewareLocation.REQUEST,\n        )\n        response_middleware = Middleware.convert(\n            self.response_middleware,  # type: ignore\n            self.named_response_middleware.get(route.name, deque()),  # type: ignore  # noqa: E501\n            location=MiddlewareLocation.RESPONSE,\n        )\n        route.extra.request_middleware = deque(\n            sorted(\n                request_middleware,\n                key=attrgetter(\"order\"),\n                reverse=True,\n            )\n        )\n        route.extra.response_middleware = deque(\n            sorted(\n                response_middleware,\n                key=attrgetter(\"order\"),\n                reverse=True,\n            )[::-1]\n        )\n    request_middleware = Middleware.convert(\n        self.request_middleware,  # type: ignore\n        location=MiddlewareLocation.REQUEST,\n    )\n    response_middleware = Middleware.convert(\n        self.response_middleware,  # type: ignore\n        location=MiddlewareLocation.RESPONSE,\n    )\n    self.request_middleware = deque(\n        sorted(\n            request_middleware,\n            key=attrgetter(\"order\"),\n            reverse=True,\n        )\n    )\n    self.response_middleware = deque(\n        sorted(\n            response_middleware,\n            key=attrgetter(\"order\"),\n            reverse=True,\n        )[::-1]\n    )", "loc": 69}
{"file": "sanic\\sanic\\mixins\\middleware.py", "class_name": null, "function_name": "register_middleware", "parameters": ["middleware", "attach_to"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FutureMiddleware", "Middleware", "self._apply_middleware", "self._future_middleware.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def register_middleware(middleware, attach_to=\"request\"):\n    nonlocal apply\n\n    location = (\n        MiddlewareLocation.REQUEST\n        if attach_to == \"request\"\n        else MiddlewareLocation.RESPONSE\n    )\n    middleware = Middleware(middleware, location, priority=priority)\n    future_middleware = FutureMiddleware(middleware, attach_to)\n    self._future_middleware.append(future_middleware)\n    if apply:\n        self._apply_middleware(future_middleware)\n    return middleware", "loc": 14}
{"file": "sanic\\sanic\\mixins\\routes.py", "class_name": "RouteMixin", "function_name": "add_route", "parameters": ["self", "handler", "uri", "methods", "host", "strict_slashes", "version", "name", "stream", "version_prefix", "error_format", "unquote"], "param_types": {"handler": "RouteHandler", "uri": "str", "methods": "Iterable[str]", "host": "Optional[Union[str, list[str]]]", "strict_slashes": "Optional[bool]", "version": "Optional[Union[int, str, float]]", "name": "Optional[str]", "stream": "bool", "version_prefix": "str", "error_format": "Optional[str]", "unquote": "bool"}, "return_type": "RouteHandler", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["frozenset", "getattr", "hasattr", "method.lower", "methods.add", "self.route", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "A helper method to register class-based view or functions as a handler to the application url routes.", "source_code": "def add_route(\n    self,\n    handler: RouteHandler,\n    uri: str,\n    methods: Iterable[str] = frozenset({\"GET\"}),\n    host: Optional[Union[str, list[str]]] = None,\n    strict_slashes: Optional[bool] = None,\n    version: Optional[Union[int, str, float]] = None,\n    name: Optional[str] = None,\n    stream: bool = False,\n    version_prefix: str = \"/v\",\n    error_format: Optional[str] = None,\n    unquote: bool = False,\n    **ctx_kwargs: Any,\n) -> RouteHandler:\n    \"\"\"A helper method to register class-based view or functions as a handler to the application url routes.\n\n    Args:\n        handler (RouteHandler): Function or class-based view used as a route handler.\n        uri (str): Path of the URL.\n        methods (Iterable[str]): List or tuple of methods allowed; these are overridden if using an HTTPMethodView.\n        host (Optional[Union[str, List[str]]]): Hostname or hostnames to match for this route.\n        strict_slashes (Optional[bool]): If set, a route's slashes will be strict. E.g. `/foo` will not match `/foo/`.\n        version (Optional[Union[int, str, float]]): Version of the API for this route.\n        name (Optional[str]): User-defined route name for `url_for`.\n        stream (bool): Boolean specifying if the handler is a stream handler.\n        version_prefix (str): URL path that should be before the version value; default: ``/v``.\n        error_format (Optional[str]): Custom error format string.\n        unquote (bool): Boolean specifying if the handler requires unquoting.\n        ctx_kwargs (Any): Keyword arguments that begin with a `ctx_*` prefix will be appended to the route context (``route.ctx``). See below for examples.\n\n    Returns:\n        RouteHandler: The route handler.\n\n    Examples:\n        ```python\n        from sanic import Sanic, text\n\n        app = Sanic(\"test\")\n\n        async def handler(request):\n            return text(\"OK\")\n\n        app.add_route(handler, \"/test\", methods=[\"GET\", \"POST\"])\n        ```\n\n        You can use `ctx_kwargs` to add custom context to the route. This\n        can often be useful when wanting to add metadata to a route that\n        can be used by other parts of the application (like middleware).\n\n        ```python\n        from sanic import Sanic, text\n\n        app = Sanic(\"test\")\n\n        async def handler(request):\n            return text(\"OK\")\n\n        async def custom_middleware(request):\n            if request.route.ctx.monitor:\n                do_some_monitoring()\n\n        app.add_route(handler, \"/test\", methods=[\"GET\", \"POST\"], ctx_monitor=True)\n        app.register_middleware(custom_middleware)\n    \"\"\"  # noqa: E501\n    # Handle HTTPMethodView differently\n    if hasattr(handler, \"view_class\"):\n        methods = set()\n\n        for method in HTTP_METHODS:\n            view_class = getattr(handler, \"view_class\")\n            _handler = getattr(view_class, method.lower(), None)\n            if _handler:\n                methods.add(method)\n                if hasattr(_handler, \"is_stream\"):\n                    stream = True\n\n    if strict_slashes is None:\n        strict_slashes = self.strict_slashes\n\n    self.route(\n        uri=uri,\n        methods=methods,\n        host=host,\n        strict_slashes=strict_slashes,\n        stream=stream,\n        version=version,\n        name=name,\n        version_prefix=version_prefix,\n        error_format=error_format,\n        unquote=unquote,\n        **ctx_kwargs,\n    )(handler)\n    return handler", "loc": 94}
{"file": "sanic\\sanic\\mixins\\routes.py", "class_name": "RouteMixin", "function_name": "get", "parameters": ["self", "uri", "host", "strict_slashes", "version", "name", "ignore_body", "version_prefix", "error_format"], "param_types": {"uri": "str", "host": "Optional[Union[str, list[str]]]", "strict_slashes": "Optional[bool]", "version": "Optional[Union[int, str, float]]", "name": "Optional[str]", "ignore_body": "bool", "version_prefix": "str", "error_format": "Optional[str]"}, "return_type": "RouteHandler", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "frozenset", "self.route"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Decorate a function handler to create a route definition using the **GET** HTTP method.", "source_code": "def get(\n    self,\n    uri: str,\n    host: Optional[Union[str, list[str]]] = None,\n    strict_slashes: Optional[bool] = None,\n    version: Optional[Union[int, str, float]] = None,\n    name: Optional[str] = None,\n    ignore_body: bool = True,\n    version_prefix: str = \"/v\",\n    error_format: Optional[str] = None,\n    **ctx_kwargs: Any,\n) -> RouteHandler:\n    \"\"\"Decorate a function handler to create a route definition using the **GET** HTTP method.\n\n    Args:\n        uri (str): URL to be tagged to GET method of HTTP.\n        host (Optional[Union[str, List[str]]]): Host IP or FQDN for\n            the service to use.\n        strict_slashes (Optional[bool]): Instruct Sanic to check if the\n            request URLs need to terminate with a `/`.\n        version (Optional[Union[int, str, float]]): API Version.\n        name (Optional[str]): Unique name that can be used to identify\n            the route.\n        ignore_body (bool): Whether the handler should ignore request\n            body. This means the body of the request, if sent, will not\n            be consumed. In that instance, you will see a warning in\n            the logs. Defaults to `True`, meaning do not consume the body.\n        version_prefix (str): URL path that should be before the version\n            value. Defaults to `\"/v\"`.\n        error_format (Optional[str]): Custom error format string.\n        **ctx_kwargs (Any): Keyword arguments that begin with a\n            `ctx_* prefix` will be appended to the route\n            context (`route.ctx`).\n\n    Returns:\n        RouteHandler: Object decorated with route method.\n    \"\"\"  # noqa: E501\n    return cast(\n        RouteHandler,\n        self.route(\n            uri,\n            methods=frozenset({\"GET\"}),\n            host=host,\n            strict_slashes=strict_slashes,\n            version=version,\n            name=name,\n            ignore_body=ignore_body,\n            version_prefix=version_prefix,\n            error_format=error_format,\n            **ctx_kwargs,\n        ),\n    )", "loc": 52}
{"file": "sanic\\sanic\\mixins\\routes.py", "class_name": "RouteMixin", "function_name": "post", "parameters": ["self", "uri", "host", "strict_slashes", "stream", "version", "name", "version_prefix", "error_format"], "param_types": {"uri": "str", "host": "Optional[Union[str, list[str]]]", "strict_slashes": "Optional[bool]", "stream": "bool", "version": "Optional[Union[int, str, float]]", "name": "Optional[str]", "version_prefix": "str", "error_format": "Optional[str]"}, "return_type": "RouteHandler", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "frozenset", "self.route"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Decorate a function handler to create a route definition using the **POST** HTTP method.", "source_code": "def post(\n    self,\n    uri: str,\n    host: Optional[Union[str, list[str]]] = None,\n    strict_slashes: Optional[bool] = None,\n    stream: bool = False,\n    version: Optional[Union[int, str, float]] = None,\n    name: Optional[str] = None,\n    version_prefix: str = \"/v\",\n    error_format: Optional[str] = None,\n    **ctx_kwargs: Any,\n) -> RouteHandler:\n    \"\"\"Decorate a function handler to create a route definition using the **POST** HTTP method.\n\n    Args:\n        uri (str): URL to be tagged to POST method of HTTP.\n        host (Optional[Union[str, List[str]]]): Host IP or FQDN for\n            the service to use.\n        strict_slashes (Optional[bool]): Instruct Sanic to check if the\n            request URLs need to terminate with a `/`.\n        stream (bool): Whether or not to stream the request body.\n            Defaults to `False`.\n        version (Optional[Union[int, str, float]]): API Version.\n        name (Optional[str]): Unique name that can be used to identify\n            the route.\n        version_prefix (str): URL path that should be before the version\n            value. Defaults to `\"/v\"`.\n        error_format (Optional[str]): Custom error format string.\n        **ctx_kwargs (Any): Keyword arguments that begin with a\n            `ctx_*` prefix will be appended to the route\n            context (`route.ctx`).\n\n    Returns:\n        RouteHandler: Object decorated with route method.\n    \"\"\"  # noqa: E501\n    return cast(\n        RouteHandler,\n        self.route(\n            uri,\n            methods=frozenset({\"POST\"}),\n            host=host,\n            strict_slashes=strict_slashes,\n            stream=stream,\n            version=version,\n            name=name,\n            version_prefix=version_prefix,\n            error_format=error_format,\n            **ctx_kwargs,\n        ),\n    )", "loc": 50}
{"file": "sanic\\sanic\\mixins\\routes.py", "class_name": "RouteMixin", "function_name": "put", "parameters": ["self", "uri", "host", "strict_slashes", "stream", "version", "name", "version_prefix", "error_format"], "param_types": {"uri": "str", "host": "Optional[Union[str, list[str]]]", "strict_slashes": "Optional[bool]", "stream": "bool", "version": "Optional[Union[int, str, float]]", "name": "Optional[str]", "version_prefix": "str", "error_format": "Optional[str]"}, "return_type": "RouteHandler", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "frozenset", "self.route"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Decorate a function handler to create a route definition using the **PUT** HTTP method.", "source_code": "def put(\n    self,\n    uri: str,\n    host: Optional[Union[str, list[str]]] = None,\n    strict_slashes: Optional[bool] = None,\n    stream: bool = False,\n    version: Optional[Union[int, str, float]] = None,\n    name: Optional[str] = None,\n    version_prefix: str = \"/v\",\n    error_format: Optional[str] = None,\n    **ctx_kwargs: Any,\n) -> RouteHandler:\n    \"\"\"Decorate a function handler to create a route definition using the **PUT** HTTP method.\n\n    Args:\n        uri (str): URL to be tagged to PUT method of HTTP.\n        host (Optional[Union[str, List[str]]]): Host IP or FQDN for\n            the service to use.\n        strict_slashes (Optional[bool]): Instruct Sanic to check if the\n            request URLs need to terminate with a `/`.\n        stream (bool): Whether or not to stream the request body.\n            Defaults to `False`.\n        version (Optional[Union[int, str, float]]): API Version.\n        name (Optional[str]): Unique name that can be used to identify\n            the route.\n        version_prefix (str): URL path that should be before the version\n            value. Defaults to `\"/v\"`.\n        error_format (Optional[str]): Custom error format string.\n        **ctx_kwargs (Any): Keyword arguments that begin with a\n            `ctx_*` prefix will be appended to the route\n            context (`route.ctx`).\n\n    Returns:\n        RouteHandler: Object decorated with route method.\n    \"\"\"  # noqa: E501\n    return cast(\n        RouteHandler,\n        self.route(\n            uri,\n            methods=frozenset({\"PUT\"}),\n            host=host,\n            strict_slashes=strict_slashes,\n            stream=stream,\n            version=version,\n            name=name,\n            version_prefix=version_prefix,\n            error_format=error_format,\n            **ctx_kwargs,\n        ),\n    )", "loc": 50}
{"file": "sanic\\sanic\\mixins\\routes.py", "class_name": "RouteMixin", "function_name": "head", "parameters": ["self", "uri", "host", "strict_slashes", "version", "name", "ignore_body", "version_prefix", "error_format"], "param_types": {"uri": "str", "host": "Optional[Union[str, list[str]]]", "strict_slashes": "Optional[bool]", "version": "Optional[Union[int, str, float]]", "name": "Optional[str]", "ignore_body": "bool", "version_prefix": "str", "error_format": "Optional[str]"}, "return_type": "RouteHandler", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "frozenset", "self.route"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Decorate a function handler to create a route definition using the **HEAD** HTTP method.", "source_code": "def head(\n    self,\n    uri: str,\n    host: Optional[Union[str, list[str]]] = None,\n    strict_slashes: Optional[bool] = None,\n    version: Optional[Union[int, str, float]] = None,\n    name: Optional[str] = None,\n    ignore_body: bool = True,\n    version_prefix: str = \"/v\",\n    error_format: Optional[str] = None,\n    **ctx_kwargs: Any,\n) -> RouteHandler:\n    \"\"\"Decorate a function handler to create a route definition using the **HEAD** HTTP method.\n\n    Args:\n        uri (str): URL to be tagged to HEAD method of HTTP.\n        host (Optional[Union[str, List[str]]]): Host IP or FQDN for\n            the service to use.\n        strict_slashes (Optional[bool]): Instruct Sanic to check if the\n            request URLs need to terminate with a `/`.\n        version (Optional[Union[int, str, float]]): API Version.\n        name (Optional[str]): Unique name that can be used to identify\n            the route.\n        ignore_body (bool): Whether the handler should ignore request\n            body. This means the body of the request, if sent, will not\n            be consumed. In that instance, you will see a warning in\n            the logs. Defaults to `True`, meaning do not consume the body.\n        version_prefix (str): URL path that should be before the version\n            value. Defaults to `\"/v\"`.\n        error_format (Optional[str]): Custom error format string.\n        **ctx_kwargs (Any): Keyword arguments that begin with a\n            `ctx_*` prefix will be appended to the route\n            context (`route.ctx`).\n\n    Returns:\n        RouteHandler: Object decorated with route method.\n    \"\"\"  # noqa: E501\n    return cast(\n        RouteHandler,\n        self.route(\n            uri,\n            methods=frozenset({\"HEAD\"}),\n            host=host,\n            strict_slashes=strict_slashes,\n            version=version,\n            name=name,\n            ignore_body=ignore_body,\n            version_prefix=version_prefix,\n            error_format=error_format,\n            **ctx_kwargs,\n        ),\n    )", "loc": 52}
{"file": "sanic\\sanic\\mixins\\routes.py", "class_name": "RouteMixin", "function_name": "options", "parameters": ["self", "uri", "host", "strict_slashes", "version", "name", "ignore_body", "version_prefix", "error_format"], "param_types": {"uri": "str", "host": "Optional[Union[str, list[str]]]", "strict_slashes": "Optional[bool]", "version": "Optional[Union[int, str, float]]", "name": "Optional[str]", "ignore_body": "bool", "version_prefix": "str", "error_format": "Optional[str]"}, "return_type": "RouteHandler", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "frozenset", "self.route"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Decorate a function handler to create a route definition using the **OPTIONS** HTTP method.", "source_code": "def options(\n    self,\n    uri: str,\n    host: Optional[Union[str, list[str]]] = None,\n    strict_slashes: Optional[bool] = None,\n    version: Optional[Union[int, str, float]] = None,\n    name: Optional[str] = None,\n    ignore_body: bool = True,\n    version_prefix: str = \"/v\",\n    error_format: Optional[str] = None,\n    **ctx_kwargs: Any,\n) -> RouteHandler:\n    \"\"\"Decorate a function handler to create a route definition using the **OPTIONS** HTTP method.\n\n    Args:\n        uri (str): URL to be tagged to OPTIONS method of HTTP.\n        host (Optional[Union[str, List[str]]]): Host IP or FQDN for\n            the service to use.\n        strict_slashes (Optional[bool]): Instruct Sanic to check if the\n            request URLs need to terminate with a `/`.\n        version (Optional[Union[int, str, float]]): API Version.\n        name (Optional[str]): Unique name that can be used to identify\n            the route.\n        ignore_body (bool): Whether the handler should ignore request\n            body. This means the body of the request, if sent, will not\n            be consumed. In that instance, you will see a warning in\n            the logs. Defaults to `True`, meaning do not consume the body.\n        version_prefix (str): URL path that should be before the version\n            value. Defaults to `\"/v\"`.\n        error_format (Optional[str]): Custom error format string.\n        **ctx_kwargs (Any): Keyword arguments that begin with a\n            `ctx_*` prefix will be appended to the route\n            context (`route.ctx`).\n\n    Returns:\n        RouteHandler: Object decorated with route method.\n    \"\"\"  # noqa: E501\n    return cast(\n        RouteHandler,\n        self.route(\n            uri,\n            methods=frozenset({\"OPTIONS\"}),\n            host=host,\n            strict_slashes=strict_slashes,\n            version=version,\n            name=name,\n            ignore_body=ignore_body,\n            version_prefix=version_prefix,\n            error_format=error_format,\n            **ctx_kwargs,\n        ),\n    )", "loc": 52}
{"file": "sanic\\sanic\\mixins\\routes.py", "class_name": "RouteMixin", "function_name": "patch", "parameters": ["self", "uri", "host", "strict_slashes", "stream", "version", "name", "version_prefix", "error_format"], "param_types": {"uri": "str", "host": "Optional[Union[str, list[str]]]", "strict_slashes": "Optional[bool]", "version": "Optional[Union[int, str, float]]", "name": "Optional[str]", "version_prefix": "str", "error_format": "Optional[str]"}, "return_type": "RouteHandler", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "frozenset", "self.route"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Decorate a function handler to create a route definition using the **PATCH** HTTP method.", "source_code": "def patch(\n    self,\n    uri: str,\n    host: Optional[Union[str, list[str]]] = None,\n    strict_slashes: Optional[bool] = None,\n    stream=False,\n    version: Optional[Union[int, str, float]] = None,\n    name: Optional[str] = None,\n    version_prefix: str = \"/v\",\n    error_format: Optional[str] = None,\n    **ctx_kwargs: Any,\n) -> RouteHandler:\n    \"\"\"Decorate a function handler to create a route definition using the **PATCH** HTTP method.\n\n    Args:\n        uri (str): URL to be tagged to PATCH method of HTTP.\n        host (Optional[Union[str, List[str]]]): Host IP or FQDN for\n            the service to use.\n        strict_slashes (Optional[bool]): Instruct Sanic to check if the\n            request URLs need to terminate with a `/`.\n        stream (bool): Set to `True` if full request streaming is needed,\n            `False` otherwise. Defaults to `False`.\n        version (Optional[Union[int, str, float]]): API Version.\n        name (Optional[str]): Unique name that can be used to identify\n            the route.\n        version_prefix (str): URL path that should be before the version\n            value. Defaults to `\"/v\"`.\n        error_format (Optional[str]): Custom error format string.\n        **ctx_kwargs (Any): Keyword arguments that begin with a\n            `ctx_*` prefix will be appended to the route\n            context (`route.ctx`).\n\n    Returns:\n        RouteHandler: Object decorated with route method.\n    \"\"\"  # noqa: E501\n    return cast(\n        RouteHandler,\n        self.route(\n            uri,\n            methods=frozenset({\"PATCH\"}),\n            host=host,\n            strict_slashes=strict_slashes,\n            stream=stream,\n            version=version,\n            name=name,\n            version_prefix=version_prefix,\n            error_format=error_format,\n            **ctx_kwargs,\n        ),\n    )", "loc": 50}
{"file": "sanic\\sanic\\mixins\\routes.py", "class_name": "RouteMixin", "function_name": "delete", "parameters": ["self", "uri", "host", "strict_slashes", "version", "name", "ignore_body", "version_prefix", "error_format"], "param_types": {"uri": "str", "host": "Optional[Union[str, list[str]]]", "strict_slashes": "Optional[bool]", "version": "Optional[Union[int, str, float]]", "name": "Optional[str]", "ignore_body": "bool", "version_prefix": "str", "error_format": "Optional[str]"}, "return_type": "RouteHandler", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "frozenset", "self.route"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Decorate a function handler to create a route definition using the **DELETE** HTTP method.", "source_code": "def delete(\n    self,\n    uri: str,\n    host: Optional[Union[str, list[str]]] = None,\n    strict_slashes: Optional[bool] = None,\n    version: Optional[Union[int, str, float]] = None,\n    name: Optional[str] = None,\n    ignore_body: bool = False,\n    version_prefix: str = \"/v\",\n    error_format: Optional[str] = None,\n    **ctx_kwargs: Any,\n) -> RouteHandler:\n    \"\"\"Decorate a function handler to create a route definition using the **DELETE** HTTP method.\n\n    Args:\n        uri (str): URL to be tagged to the DELETE method of HTTP.\n        host (Optional[Union[str, List[str]]]): Host IP or FQDN for the\n            service to use.\n        strict_slashes (Optional[bool]): Instruct Sanic to check if the\n            request URLs need to terminate with a */*.\n        version (Optional[Union[int, str, float]]): API Version.\n        name (Optional[str]): Unique name that can be used to identify\n            the Route.\n        ignore_body (bool): Whether or not to ignore the body in the\n            request. Defaults to `False`.\n        version_prefix (str): URL path that should be before the version\n            value. Defaults to `\"/v\"`.\n        error_format (Optional[str]): Custom error format string.\n        **ctx_kwargs (Any): Keyword arguments that begin with a `ctx_*`\n            prefix will be appended to the route context (`route.ctx`).\n\n    Returns:\n        RouteHandler: Object decorated with route method.\n    \"\"\"  # noqa: E501\n    return cast(\n        RouteHandler,\n        self.route(\n            uri,\n            methods=frozenset({\"DELETE\"}),\n            host=host,\n            strict_slashes=strict_slashes,\n            version=version,\n            name=name,\n            ignore_body=ignore_body,\n            version_prefix=version_prefix,\n            error_format=error_format,\n            **ctx_kwargs,\n        ),\n    )", "loc": 49}
{"file": "sanic\\sanic\\mixins\\routes.py", "class_name": null, "function_name": "decorator", "parameters": ["handler"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FutureRoute", "ValueError", "filter", "frozenset", "getattr", "isinstance", "len", "list", "self._apply_route", "self._determine_error_format", "self._future_routes.add", "self.generate_name", "set", "signature", "signature(handler).parameters.keys", "tuple", "x.upper"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def decorator(handler):\n    nonlocal uri\n    nonlocal methods\n    nonlocal host\n    nonlocal strict_slashes\n    nonlocal stream\n    nonlocal version\n    nonlocal name\n    nonlocal ignore_body\n    nonlocal subprotocols\n    nonlocal websocket\n    nonlocal static\n    nonlocal version_prefix\n    nonlocal error_format\n\n    if isinstance(handler, tuple):\n        # if a handler fn is already wrapped in a route, the handler\n        # variable will be a tuple of (existing routes, handler fn)\n        _, handler = handler\n\n    name = self.generate_name(name, handler)\n\n    if isinstance(host, str):\n        host = frozenset([host])\n    elif host and not isinstance(host, frozenset):\n        try:\n            host = frozenset(host)\n        except TypeError:\n            raise ValueError(\n                \"Expected either string or Iterable of host strings, \"\n                \"not %s\" % host\n            )\n    if isinstance(subprotocols, list):\n        # Ordered subprotocols, maintain order\n        subprotocols = tuple(subprotocols)\n    elif isinstance(subprotocols, set):\n        # subprotocol is unordered, keep it unordered\n        subprotocols = frozenset(subprotocols)\n\n    if not error_format or error_format == \"auto\":\n        error_format = self._determine_error_format(handler)\n\n    route = FutureRoute(\n        handler,\n        uri,\n        None if websocket else frozenset([x.upper() for x in methods]),\n        host,\n        strict_slashes,\n        stream,\n        version,\n        name,\n        ignore_body,\n        websocket,\n        subprotocols,\n        unquote,\n        static,\n        version_prefix,\n        error_format,\n        route_context,\n    )\n    overwrite = getattr(self, \"_allow_route_overwrite\", False)\n    if overwrite:\n        self._future_routes = set(\n            filter(lambda x: x.uri != uri, self._future_routes)\n        )\n    self._future_routes.add(route)\n\n    args = list(signature(handler).parameters.keys())\n    if websocket and len(args) < 2:\n        handler_name = handler.__name__\n\n        raise ValueError(\n            f\"Required parameter `request` and/or `ws` missing \"\n            f\"in the {handler_name}() route?\"\n        )\n    elif not args:\n        handler_name = handler.__name__\n\n        raise ValueError(\n            f\"Required parameter `request` missing \"\n            f\"in the {handler_name}() route?\"\n        )\n\n    if not websocket and stream:\n        handler.is_stream = stream\n\n    if apply:\n        self._apply_route(route, overwrite=overwrite)\n\n    if static:\n        return route, handler\n    return handler", "loc": 92}
{"file": "sanic\\sanic\\mixins\\routes.py", "class_name": "HttpResponseVisitor", "function_name": "visit_Return", "parameters": ["self", "node"], "param_types": {"node": "Return"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["suppress", "types.add"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_Return(self, node: Return) -> Any:\n    nonlocal types\n\n    with suppress(AttributeError):\n        checks = [node.value.func.id]  # type: ignore\n        if node.value.keywords:  # type: ignore\n            checks += [\n                k.value\n                for k in node.value.keywords  # type: ignore\n                if k.arg == \"content_type\"\n            ]\n\n        for check in checks:\n            if check in RESPONSE_MAPPING:\n                types.add(RESPONSE_MAPPING[check])", "loc": 15}
{"file": "sanic\\sanic\\mixins\\signals.py", "class_name": "SignalMixin", "function_name": "signal", "parameters": ["self", "event"], "param_types": {"event": "Union[str, Enum]"}, "return_type": "Callable[[SignalHandler], SignalHandler]", "param_doc": {"event": "Representation of the event in ``one.two.three`` form", "apply": "For lazy evaluation, defaults to ``True``", "condition": "For use with the ``condition`` argument in dispatch", "exclusive": "When ``True``, the signal can only be dispatched"}, "return_doc": "", "raises_doc": [], "called_functions": ["FutureSignal", "HashableDict", "isinstance", "self._apply_signal", "self._future_signals.add", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "For creating a signal handler, used similar to a route handler: .. code-block:: python @app.signal(\"foo.bar.<thing>\") async def signal_handler(thing, **kwargs): print(f\"[signal_handler] {thing=}\", kwargs)", "source_code": "def signal(\n    self,\n    event: Union[str, Enum],\n    *,\n    apply: bool = True,\n    condition: Optional[dict[str, Any]] = None,\n    exclusive: bool = True,\n    priority: int = 0,\n) -> Callable[[SignalHandler], SignalHandler]:\n    \"\"\"\n    For creating a signal handler, used similar to a route handler:\n\n    .. code-block:: python\n\n        @app.signal(\"foo.bar.<thing>\")\n        async def signal_handler(thing, **kwargs):\n            print(f\"[signal_handler] {thing=}\", kwargs)\n\n    :param event: Representation of the event in ``one.two.three`` form\n    :type event: str\n    :param apply: For lazy evaluation, defaults to ``True``\n    :type apply: bool, optional\n    :param condition: For use with the ``condition`` argument in dispatch\n        filtering, defaults to ``None``\n    :param exclusive: When ``True``, the signal can only be dispatched\n        when the condition has been met. When ``False``, the signal can\n        be dispatched either with or without it. *THIS IS INAPPLICABLE TO\n        BLUEPRINT SIGNALS. THEY ARE ALWAYS NON-EXCLUSIVE*, defaults\n        to ``True``\n    :type condition: Dict[str, Any], optional\n    \"\"\"\n    event_value = str(event.value) if isinstance(event, Enum) else event\n\n    def decorator(handler: SignalHandler):\n        future_signal = FutureSignal(\n            handler,\n            event_value,\n            HashableDict(condition or {}),\n            exclusive,\n            priority,\n        )\n        self._future_signals.add(future_signal)\n\n        if apply:\n            self._apply_signal(future_signal)\n\n        return handler\n\n    return decorator", "loc": 49}
{"file": "sanic\\sanic\\mixins\\signals.py", "class_name": "SignalMixin", "function_name": "add_signal", "parameters": ["self", "handler", "event", "condition", "exclusive"], "param_types": {"handler": "Optional[Callable[..., Any]]", "event": "Union[str, Enum]", "condition": "Optional[dict[str, Any]]", "exclusive": "bool"}, "return_type": "Callable[..., Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.signal"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Registers a signal handler for a specific event.", "source_code": "def add_signal(\n    self,\n    handler: Optional[Callable[..., Any]],\n    event: Union[str, Enum],\n    condition: Optional[dict[str, Any]] = None,\n    exclusive: bool = True,\n) -> Callable[..., Any]:\n    \"\"\"Registers a signal handler for a specific event.\n\n    Args:\n        handler (Optional[Callable[..., Any]]): The function to be called\n            when the event occurs. Defaults to a noop if not provided.\n        event (str): The name of the event to listen for.\n        condition (Optional[Dict[str, Any]]): Optional condition to filter\n            the event triggering. Defaults to `None`.\n        exclusive (bool): Whether or not the handler is exclusive. When\n            `True`, the signal can only be dispatched when the\n            `condition` has been met. *This is inapplicable to blueprint\n            signals, which are **ALWAYS** non-exclusive.* Defaults\n            to `True`.\n\n    Returns:\n        Callable[..., Any]: The handler that was registered.\n    \"\"\"\n    if not handler:\n\n        async def noop(**context): ...\n\n        handler = noop\n    self.signal(event=event, condition=condition, exclusive=exclusive)(\n        handler\n    )\n    return handler", "loc": 33}
{"file": "sanic\\sanic\\mixins\\signals.py", "class_name": "SignalMixin", "function_name": "catch_exception", "parameters": ["self", "handler"], "param_types": {"handler": "Callable[[SignalMixin, Exception], Coroutine[Any, Any, None]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["handler", "self.signal"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Register an exception handler for logging or processing. This method allows the registration of a custom exception handler to catch and process exceptions that occur in the application. Unlike a typical exception handler that might modify the response to the client, this is intended to capture exceptions for logging or other internal processing, such as sending them to an error reporting utility.", "source_code": "def catch_exception(\n    self,\n    handler: Callable[[SignalMixin, Exception], Coroutine[Any, Any, None]],\n) -> None:\n    \"\"\"Register an exception handler for logging or processing.\n\n    This method allows the registration of a custom exception handler to\n    catch and process exceptions that occur in the application. Unlike a\n    typical exception handler that might modify the response to the client,\n    this is intended to capture exceptions for logging or other internal\n    processing, such as sending them to an error reporting utility.\n\n    Args:\n        handler (Callable): A coroutine function that takes the application\n            instance and the exception as arguments. It will be called when\n            an exception occurs within the application's lifecycle.\n\n    Example:\n        ```python\n        app = Sanic(\"TestApp\")\n\n        @app.catch_exception\n        async def report_exception(app: Sanic, exception: Exception):\n            logging.error(f\"An exception occurred: {exception}\")\n\n            # Send to an error reporting service\n            await error_service.report(exception)\n\n        # Any unhandled exceptions within the application will now be\n        # logged and reported to the error service.\n        ```\n    \"\"\"  # noqa: E501\n\n    async def signal_handler(exception: Exception):\n        await handler(self, exception)\n\n    self.signal(Event.SERVER_EXCEPTION_REPORT)(signal_handler)", "loc": 37}
{"file": "sanic\\sanic\\mixins\\signals.py", "class_name": null, "function_name": "decorator", "parameters": ["handler"], "param_types": {"handler": "SignalHandler"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FutureSignal", "HashableDict", "self._apply_signal", "self._future_signals.add"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def decorator(handler: SignalHandler):\n    future_signal = FutureSignal(\n        handler,\n        event_value,\n        HashableDict(condition or {}),\n        exclusive,\n        priority,\n    )\n    self._future_signals.add(future_signal)\n\n    if apply:\n        self._apply_signal(future_signal)\n\n    return handler", "loc": 14}
{"file": "sanic\\sanic\\mixins\\startup.py", "class_name": "StartupMixin", "function_name": "setup_loop", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "try_use_uvloop", "try_windows_loop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Set up the event loop. An internal method that sets up the event loop to uvloop if possible, or a Windows selector loop if on Windows.", "source_code": "def setup_loop(self) -> None:\n    \"\"\"Set up the event loop.\n\n    An internal method that sets up the event loop to uvloop if\n    possible, or a Windows selector loop if on Windows.\n\n    Returns:\n        None\n    \"\"\"\n    if not self.asgi:\n        if self.config.USE_UVLOOP is True or (\n            isinstance(self.config.USE_UVLOOP, Default)\n            and not OS_IS_WINDOWS\n        ):\n            try_use_uvloop()\n        elif OS_IS_WINDOWS:\n            try_windows_loop()", "loc": 17}
{"file": "sanic\\sanic\\mixins\\startup.py", "class_name": "StartupMixin", "function_name": "stop", "parameters": ["self", "terminate", "unregister"], "param_types": {"terminate": "bool", "unregister": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["all_tasks", "get_event_loop", "get_event_loop().stop", "hasattr", "self.__class__.unregister_app", "self.multiplexer.terminate", "self.shutdown_tasks", "suppress", "task.cancel", "task.get_name"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "This kills the Sanic server, cleaning up after itself.", "source_code": "def stop(self, terminate: bool = True, unregister: bool = False) -> None:\n    \"\"\"This kills the Sanic server, cleaning up after itself.\n\n    Args:\n        terminate (bool): Force kill all requests immediately without\n            allowing them to finish processing.\n        unregister (bool): Unregister the app from the global registry.\n\n    Returns:\n        None\n    \"\"\"\n    if terminate and hasattr(self, \"multiplexer\"):\n        self.multiplexer.terminate()\n    if self.state.stage is not ServerStage.STOPPED:\n        self.shutdown_tasks(timeout=0)  # type: ignore\n        for task in all_tasks():\n            with suppress(AttributeError):\n                if task.get_name() == \"RunServer\":\n                    task.cancel()\n        get_event_loop().stop()\n\n    if unregister:\n        self.__class__.unregister_app(self)  # type: ignore", "loc": 23}
{"file": "sanic\\sanic\\mixins\\startup.py", "class_name": "StartupMixin", "function_name": "motd", "parameters": ["self", "server_settings"], "param_types": {"server_settings": "Optional[dict[str, Any]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["MOTD.output", "get_logo", "os.environ.get", "self.get_motd_data", "self.get_server_location"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Outputs the message of the day (MOTD). It generally can only be called once per process, and is usually called by the `run` method in the main process.", "source_code": "def motd(\n    self,\n    server_settings: Optional[dict[str, Any]] = None,\n) -> None:\n    \"\"\"Outputs the message of the day (MOTD).\n\n    It generally can only be called once per process, and is usually\n    called by the `run` method in the main process.\n\n    Args:\n        server_settings (Optional[Dict[str, Any]], optional): Settings for\n            the server. Defaults to `None`.\n\n    Returns:\n        None\n    \"\"\"\n    if (\n        os.environ.get(\"SANIC_WORKER_NAME\")\n        or os.environ.get(\"SANIC_MOTD_OUTPUT\")\n        or os.environ.get(\"SANIC_WORKER_PROCESS\")\n        or os.environ.get(\"SANIC_SERVER_RUNNING\")\n    ):\n        return\n    serve_location = self.get_server_location(server_settings)\n    if self.config.MOTD:\n        logo = get_logo(coffee=self.state.coffee)\n        display, extra = self.get_motd_data(server_settings)\n\n        MOTD.output(logo, serve_location, display, extra)", "loc": 29}
{"file": "sanic\\sanic\\mixins\\startup.py", "class_name": "StartupMixin", "function_name": "get_motd_data", "parameters": ["self", "server_settings"], "param_types": {"server_settings": "Optional[dict[str, Any]]"}, "return_type": "tuple[dict[str, Any], dict[str, Any]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "', '.join", "extra.update", "import_module", "mode.append", "package_name.replace", "packages.append", "path.absolute", "platform.platform", "platform.python_version", "server_settings['version'].display", "str"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Retrieves the message of the day (MOTD) data.", "source_code": "def get_motd_data(\n    self, server_settings: Optional[dict[str, Any]] = None\n) -> tuple[dict[str, Any], dict[str, Any]]:\n    \"\"\"Retrieves the message of the day (MOTD) data.\n\n    Args:\n        server_settings (Optional[Dict[str, Any]], optional): Settings for\n            the server. Defaults to `None`.\n\n    Returns:\n        Tuple[Dict[str, Any], Dict[str, Any]]: A tuple containing two\n            dictionaries with the relevant MOTD data.\n    \"\"\"\n\n    mode = [f\"{self.state.mode},\"]\n    if self.state.fast:\n        mode.append(\"goin' fast\")\n    if self.state.asgi:\n        mode.append(\"ASGI\")\n    else:\n        if self.state.workers == 1:\n            mode.append(\"single worker\")\n        else:\n            mode.append(f\"w/ {self.state.workers} workers\")\n\n    if server_settings:\n        server = \", \".join(\n            (\n                self.state.server,\n                server_settings[\"version\"].display(),  # type: ignore\n            )\n        )\n    else:\n        server = \"ASGI\" if self.asgi else \"unknown\"  # type: ignore\n\n    display = {\n        \"app\": self.name,\n        \"mode\": \" \".join(mode),\n        \"server\": server,\n        \"python\": platform.python_version(),\n        \"platform\": platform.platform(),\n    }\n    extra = {}\n    if self.config.AUTO_RELOAD:\n        reload_display = \"enabled\"\n        if self.state.reload_dirs:\n            reload_display += \", \".join(\n                [\n                    \"\",\n                    *(\n                        str(path.absolute())\n                        for path in self.state.reload_dirs\n                    ),\n                ]\n            )\n        display[\"auto-reload\"] = reload_display\n\n    packages = []\n    for package_name in SANIC_PACKAGES:\n        module_name = package_name.replace(\"-\", \"_\")\n        try:\n            module = import_module(module_name)\n            packages.append(f\"{package_name}=={module.__version__}\")  # type: ignore\n        except ImportError:  # no cov\n            ...\n\n    if packages:\n        display[\"packages\"] = \", \".join(packages)\n\n    if self.config.MOTD_DISPLAY:\n        extra.update(self.config.MOTD_DISPLAY)\n\n    return display, extra", "loc": 73}
{"file": "sanic\\sanic\\mixins\\startup.py", "class_name": "StartupMixin", "function_name": "serve_location", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.get_server_location"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Retrieve the server location.", "source_code": "def serve_location(self) -> str:\n    \"\"\"Retrieve the server location.\n\n    Returns:\n        str: The server location.\n    \"\"\"\n    try:\n        server_settings = self.state.server_info[0].settings\n        return self.get_server_location(server_settings)\n    except IndexError:\n        location = \"ASGI\" if self.asgi else \"unknown\"  # type: ignore\n        return f\"http://<{location}>\"", "loc": 12}
{"file": "sanic\\sanic\\mixins\\startup.py", "class_name": "StartupMixin", "function_name": "get_server_location", "parameters": ["server_settings"], "param_types": {"server_settings": "Optional[dict[str, Any]]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["server_settings.get", "server_settings['sock'].getsockname"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Using the server settings, retrieve the server location.", "source_code": "def get_server_location(\n    server_settings: Optional[dict[str, Any]] = None,\n) -> str:\n    \"\"\"Using the server settings, retrieve the server location.\n\n    Args:\n        server_settings (Optional[Dict[str, Any]], optional): Settings for\n            the server. Defaults to `None`.\n\n    Returns:\n        str: The server location.\n    \"\"\"\n    serve_location = \"\"\n    proto = \"http\"\n    if not server_settings:\n        return serve_location\n\n    host = server_settings[\"host\"]\n    port = server_settings[\"port\"]\n\n    if server_settings.get(\"ssl\") is not None:\n        proto = \"https\"\n    if server_settings.get(\"unix\"):\n        serve_location = f\"{server_settings['unix']} {proto}://...\"\n    elif server_settings.get(\"sock\"):\n        host, port, *_ = server_settings[\"sock\"].getsockname()\n\n    if not serve_location and host and port:\n        # colon(:) is legal for a host only in an ipv6 address\n        display_host = f\"[{host}]\" if \":\" in host else host\n        serve_location = f\"{proto}://{display_host}:{port}\"\n\n    return serve_location", "loc": 33}
{"file": "sanic\\sanic\\mixins\\startup.py", "class_name": "StartupMixin", "function_name": "should_auto_reload", "parameters": ["cls"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "cls._app_registry.values"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Check if any applications have auto-reload enabled.", "source_code": "def should_auto_reload(cls) -> bool:\n    \"\"\"Check if any applications have auto-reload enabled.\n\n    Returns:\n        bool: `True` if any applications have auto-reload enabled, else\n            `False`.\n    \"\"\"\n    return any(app.state.auto_reload for app in cls._app_registry.values())", "loc": 8}
{"file": "sanic\\sanic\\mixins\\startup.py", "class_name": "StartupMixin", "function_name": "serve_single", "parameters": ["cls", "primary"], "param_types": {"primary": "Optional[Sanic]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "app.router.reset", "app.signal_router.reset", "app.state.server_info.clear", "cls._app_registry.values", "cls._cleanup_apps", "cls._cleanup_env_vars", "configure_socket", "error_logger.exception", "kwargs['server_info'][primary.name].append", "list", "logger.info", "partial", "primary.before_server_start", "primary_server_info.settings.items", "server_info.settings.items", "sock.close", "worker_serve"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Serve a single process of a Sanic application. Similar to `serve`, but only serves a single process. When used, certain features are disabled, such as `fast`, `workers`, `multiplexer`, `auto_reload`, and the Inspector. It is almost never needed to use this method directly. Instead, you should use the CLI: ```sh sanic app.sanic:app --single-process ``` Or, if you need to do it programmatically, you should use the `single_process` argument of `run`: ```python app.run(single_process=True) ```", "source_code": "def serve_single(cls, primary: Optional[Sanic] = None) -> None:\n    \"\"\"Serve a single process of a Sanic application.\n\n    Similar to `serve`, but only serves a single process. When used,\n    certain features are disabled, such as `fast`, `workers`,\n    `multiplexer`, `auto_reload`, and the Inspector. It is almost\n    never needed to use this method directly. Instead, you should\n    use the CLI:\n\n    ```sh\n    sanic app.sanic:app --single-process\n    ```\n\n    Or, if you need to do it programmatically, you should use the\n    `single_process` argument of `run`:\n\n    ```python\n    app.run(single_process=True)\n    ```\n\n    Args:\n        primary (Optional[Sanic], optional): The primary Sanic application\n            to serve. Defaults to `None`.\n\n    Raises:\n        RuntimeError: Raised when no applications are found.\n        RuntimeError: Raised when no server information is found for the\n            primary application.\n        RuntimeError: Raised when attempting to serve HTTP/3 as a\n            secondary server.\n        RuntimeError: Raised when attempting to use both `fast` and\n            `workers`.\n        ValueError: Raised when `PROXIES_COUNT` is negative.\n    \"\"\"\n    os.environ[\"SANIC_MOTD_OUTPUT\"] = \"true\"\n    apps = list(cls._app_registry.values())\n\n    if not primary:\n        try:\n            primary = apps[0]\n        except IndexError:\n            raise RuntimeError(\"Did not find any applications.\")\n\n    # This exists primarily for unit testing\n    if not primary.state.server_info:  # no cov\n        for app in apps:\n            app.state.server_info.clear()\n        return\n\n    primary_server_info = primary.state.server_info[0]\n    primary.before_server_start(partial(primary._start_servers, apps=apps))\n    kwargs = {\n        k: v\n        for k, v in primary_server_info.settings.items()\n        if k\n        not in (\n            \"main_start\",\n            \"main_stop\",\n            \"app\",\n        )\n    }\n    kwargs[\"app_name\"] = primary.name\n    kwargs[\"app_loader\"] = None\n    sock = configure_socket(kwargs)\n\n    kwargs[\"server_info\"] = {}\n    kwargs[\"server_info\"][primary.name] = []\n    for server_info in primary.state.server_info:\n        server_info.settings = {\n            k: v\n            for k, v in server_info.settings.items()\n            if k not in (\"main_start\", \"main_stop\", \"app\")\n        }\n        kwargs[\"server_info\"][primary.name].append(server_info)\n\n    try:\n        worker_serve(monitor_publisher=None, **kwargs)\n    except BaseException:\n        error_logger.exception(\n            \"Experienced exception while trying to serve\"\n        )\n        raise\n    finally:\n        logger.info(\"Server Stopped\")\n        for app in apps:\n            app.state.server_info.clear()\n            app.router.reset()\n            app.signal_router.reset()\n\n        if sock:\n            sock.close()\n\n        cls._cleanup_env_vars()\n        cls._cleanup_apps()", "loc": 94}
{"file": "sanic\\sanic\\models\\asgi.py", "class_name": "MockTransport", "function_name": "get_extra_info", "parameters": ["self", "info", "default"], "param_types": {"info": "str"}, "return_type": "Optional[Union[str, bool]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.scope.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_extra_info(\n    self, info: str, default=None\n) -> Optional[Union[str, bool]]:\n    if info == \"peername\":\n        return self.scope.get(\"client\")\n    elif info == \"sslcontext\":\n        return self.scope.get(\"scheme\") in [\"https\", \"wss\"]\n    return default", "loc": 8}
{"file": "sanic\\sanic\\models\\asgi.py", "class_name": "MockTransport", "function_name": "get_websocket_connection", "parameters": ["self"], "param_types": {}, "return_type": "WebSocketConnection", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BadRequest"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_websocket_connection(self) -> WebSocketConnection:\n    try:\n        return self._websocket_connection\n    except AttributeError:\n        raise BadRequest(\"Improper websocket connection.\")", "loc": 5}
{"file": "sanic\\sanic\\models\\asgi.py", "class_name": "MockTransport", "function_name": "create_websocket_connection", "parameters": ["self", "send", "receive"], "param_types": {"send": "ASGISend", "receive": "ASGIReceive"}, "return_type": "WebSocketConnection", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["WebSocketConnection", "self.scope.get"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_websocket_connection(\n    self, send: ASGISend, receive: ASGIReceive\n) -> WebSocketConnection:\n    self._websocket_connection = WebSocketConnection(\n        send, receive, self.scope.get(\"subprotocols\", [])\n    )\n    return self._websocket_connection", "loc": 7}
{"file": "sanic\\sanic\\models\\ctx_types.py", "class_name": "REPLContext", "function_name": "add", "parameters": ["self", "var", "name", "desc"], "param_types": {"var": "Any", "name": "Optional[str]", "desc": "Optional[str]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["REPLLocal", "ValueError", "isinstance", "self._locals.add", "self._truncate", "str", "type"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Add a local variable to be available in REPL context.", "source_code": "def add(\n    self,\n    var: Any,\n    name: Optional[str] = None,\n    desc: Optional[str] = None,\n):\n    \"\"\"Add a local variable to be available in REPL context.\n\n    Args:\n        var (Any): A module, class, object or a class.\n        name (Optional[str], optional): An alias for the local. Defaults to None.\n        desc (Optional[str], optional): A brief description for the local. Defaults to None.\n    \"\"\"  # noqa: E501\n    if name is None:\n        try:\n            name = var.__name__\n        except AttributeError:\n            name = var.__class__.__name__\n\n    if desc is None:\n        try:\n            desc = var.__doc__ or \"\"\n        except AttributeError:\n            desc = str(type(var))\n\n    assert isinstance(desc, str) and isinstance(\n        name, str\n    )  # Just to make mypy happy\n\n    if name in self.BUILTINS:\n        raise ValueError(f\"Cannot override built-in variable: {name}\")\n\n    desc = self._truncate(desc)\n\n    self._locals.add(REPLLocal(var, name, desc))", "loc": 35}
{"file": "sanic\\sanic\\pages\\base.py", "class_name": "BasePage", "function_name": "render", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Document", "self._body", "self._foot", "self._head", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Renders the page.", "source_code": "def render(self) -> str:\n    \"\"\"Renders the page.\n\n    Returns:\n        str: The rendered page.\n    \"\"\"\n    self.doc = Document(self.TITLE, lang=\"en\", id=\"sanic\")\n    self._head()\n    self._body()\n    self._foot()\n    return str(self.doc)", "loc": 11}
{"file": "sanic\\sanic\\request\\form.py", "class_name": null, "function_name": "parse_multipart_form", "parameters": ["body", "boundary"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["File", "RequestParameters", "body.split", "email.utils.decode_rfc2231", "fields[field_name].append", "files[field_name].append", "form_line.index", "form_line[0:colon_index].lower", "form_parameters.get", "form_part.find", "form_part[line_index:line_end_index].decode", "logger.debug", "parse_content_header", "post_data.decode", "unicodedata.normalize", "unquote"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "Parse a request body and returns fields and files", "source_code": "def parse_multipart_form(body, boundary):\n    \"\"\"Parse a request body and returns fields and files\n\n    Args:\n        body (bytes): Bytes request body.\n        boundary (bytes): Bytes multipart boundary.\n\n    Returns:\n        Tuple[RequestParameters, RequestParameters]: A tuple containing fields and files as `RequestParameters`.\n    \"\"\"  # noqa: E501\n    files = {}\n    fields = {}\n\n    form_parts = body.split(boundary)\n    for form_part in form_parts[1:-1]:\n        file_name = None\n        content_type = \"text/plain\"\n        content_charset = \"utf-8\"\n        field_name = None\n        line_index = 2\n        line_end_index = 0\n        while not line_end_index == -1:\n            line_end_index = form_part.find(b\"\\r\\n\", line_index)\n            form_line = form_part[line_index:line_end_index].decode(\"utf-8\")\n            line_index = line_end_index + 2\n\n            if not form_line:\n                break\n\n            colon_index = form_line.index(\":\")\n            idx = colon_index + 2\n            form_header_field = form_line[0:colon_index].lower()\n            form_header_value, form_parameters = parse_content_header(\n                form_line[idx:]\n            )\n\n            if form_header_field == \"content-disposition\":\n                field_name = form_parameters.get(\"name\")\n                file_name = form_parameters.get(\"filename\")\n\n                # non-ASCII filenames in RFC2231, \"filename*\" format\n                if file_name is None and form_parameters.get(\"filename*\"):\n                    encoding, _, value = email.utils.decode_rfc2231(\n                        form_parameters[\"filename*\"]\n                    )\n                    file_name = unquote(value, encoding=encoding)\n\n                # Normalize to NFC (Apple MacOS/iOS send NFD)\n                # Notes:\n                # - No effect for Windows, Linux or Android clients which\n                #   already send NFC\n                # - Python open() is tricky (creates files in NFC no matter\n                #   which form you use)\n                if file_name is not None:\n                    file_name = unicodedata.normalize(\"NFC\", file_name)\n\n            elif form_header_field == \"content-type\":\n                content_type = form_header_value\n                content_charset = form_parameters.get(\"charset\", \"utf-8\")\n\n        if field_name:\n            post_data = form_part[line_index:-4]\n            if file_name is None:\n                value = post_data.decode(content_charset)\n                if field_name in fields:\n                    fields[field_name].append(value)\n                else:\n                    fields[field_name] = [value]\n            else:\n                form_file = File(\n                    type=content_type, name=file_name, body=post_data\n                )\n                if field_name in files:\n                    files[field_name].append(form_file)\n                else:\n                    files[field_name] = [form_file]\n        else:\n            logger.debug(\n                \"Form-data field does not have a 'name' parameter \"\n                \"in the Content-Disposition header\"\n            )\n\n    return RequestParameters(fields), RequestParameters(files)", "loc": 83}
{"file": "sanic\\sanic\\request\\parameters.py", "class_name": "RequestParameters", "function_name": "get", "parameters": ["self", "name", "default"], "param_types": {"name": "str", "default": "Optional[Any]"}, "return_type": "Optional[Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["super", "super().get"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Return the first value, either the default or actual", "source_code": "def get(self, name: str, default: Optional[Any] = None) -> Optional[Any]:\n    \"\"\"Return the first value, either the default or actual\n\n    Args:\n        name (str): The name of the parameter\n        default (Optional[Any], optional): The default value. Defaults to None.\n\n    Returns:\n        Optional[Any]: The first value of the list\n    \"\"\"  # noqa: E501\n    return super().get(name, [default])[0]", "loc": 11}
{"file": "sanic\\sanic\\request\\parameters.py", "class_name": "RequestParameters", "function_name": "getlist", "parameters": ["self", "name", "default"], "param_types": {"name": "str", "default": "Optional[list[Any]]"}, "return_type": "list[Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["super", "super().get"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Return the entire list", "source_code": "def getlist(\n    self, name: str, default: Optional[list[Any]] = None\n) -> list[Any]:\n    \"\"\"Return the entire list\n\n    Args:\n        name (str): The name of the parameter\n        default (Optional[List[Any]], optional): The default value. Defaults to None.\n\n    Returns:\n        list[Any]: The entire list of values or [] if not found\n    \"\"\"  # noqa: E501\n    return super().get(name, default) or []", "loc": 13}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "make_context", "parameters": [], "param_types": {}, "return_type": "ctx_type", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SimpleNamespace", "cast"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Create a new context object. This method is called when a new request context is pushed. It is a great candidate for overriding in a subclass if you want to control the type of context object that is created. By default, it returns a `types.SimpleNamespace` instance.", "source_code": "def make_context() -> ctx_type:\n    \"\"\"Create a new context object.\n\n    This method is called when a new request context is pushed. It is\n    a great candidate for overriding in a subclass if you want to\n    control the type of context object that is created.\n\n    By default, it returns a `types.SimpleNamespace` instance.\n\n    Returns:\n        ctx_type: A new context object.\n    \"\"\"\n    return cast(ctx_type, SimpleNamespace())", "loc": 13}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "get_current", "parameters": ["cls"], "param_types": {}, "return_type": "Request", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ServerError", "cls._current.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Retrieve the current request object This implements [Context Variables](https://docs.python.org/3/library/contextvars.html) to allow for accessing the current request from anywhere. A typical usecase is when you want to access the current request from a function that is not a handler, such as a logging function: ```python import logging class LoggingFormater(logging.Formatter): def format(self, record): request = Request.get_current() record.url = request.url record.ip = request.ip return super().format(record) ```", "source_code": "def get_current(cls) -> Request:\n    \"\"\"Retrieve the current request object\n\n    This implements [Context Variables](https://docs.python.org/3/library/contextvars.html)\n    to allow for accessing the current request from anywhere.\n\n    A typical usecase is when you want to access the current request\n    from a function that is not a handler, such as a logging function:\n\n    ```python\n    import logging\n\n    class LoggingFormater(logging.Formatter):\n        def format(self, record):\n            request = Request.get_current()\n            record.url = request.url\n            record.ip = request.ip\n            return super().format(record)\n    ```\n\n    Returns:\n        Request: The current request object\n\n    Raises:\n        sanic.exceptions.ServerError: If it is outside of a request\n            lifecycle.\n    \"\"\"  # noqa: E501\n    request = cls._current.get(None)\n    if not request:\n        raise ServerError(\"No current request\")\n    return request", "loc": 31}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "ctx", "parameters": ["self"], "param_types": {}, "return_type": "ctx_type", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.make_context"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The current request context. This is a context object for the current request. It is created by `Request.make_context` and is a great place to store data that you want to be accessible during the request lifecycle.", "source_code": "def ctx(self) -> ctx_type:\n    \"\"\"The current request context.\n\n    This is a context object for the current request. It is created\n    by `Request.make_context` and is a great place to store data\n    that you want to be accessible during the request lifecycle.\n\n    Returns:\n        ctx_type: The current request context.\n    \"\"\"\n    if not self._ctx:\n        self._ctx = self.make_context()\n    return self._ctx", "loc": 13}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "stream_id", "parameters": ["self"], "param_types": {}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ServerError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Access the HTTP/3 stream ID.", "source_code": "def stream_id(self) -> int:\n    \"\"\"Access the HTTP/3 stream ID.\n\n    Raises:\n        sanic.exceptions.ServerError: If the request is not HTTP/3.\n\n    Returns:\n        int: The HTTP/3 stream ID.\n    \"\"\"\n    if self.protocol.version is not HTTP.VERSION_3:\n        raise ServerError(\n            \"Stream ID is only a property of a HTTP/3 request\"\n        )\n    return self._stream_id", "loc": 14}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "reset_response", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ServerError"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Reset the response object. This clears much of the state of the object. It should generally not be called directly, but is called automatically as part of the request lifecycle.", "source_code": "def reset_response(self) -> None:\n    \"\"\"Reset the response object.\n\n    This clears much of the state of the object. It should\n    generally not be called directly, but is called automatically as\n    part of the request lifecycle.\n\n    Raises:\n        sanic.exceptions.ServerError: If the response has already been\n            sent.\n    \"\"\"\n    try:\n        if (\n            self.stream is not None\n            and self.stream.stage is not Stage.HANDLER\n        ):\n            raise ServerError(\n                \"Cannot reset response because previous response was sent.\"\n            )\n        self.stream.response.stream = None  # type: ignore\n        self.stream.response = None  # type: ignore\n        self.responded = False\n    except AttributeError:\n        pass", "loc": 24}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "name", "parameters": ["self"], "param_types": {}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The route name In the following pattern: ``` <AppName>.[<BlueprintName>.]<HandlerName> ```", "source_code": "def name(self) -> Optional[str]:\n    \"\"\"The route name\n\n    In the following pattern:\n\n    ```\n    <AppName>.[<BlueprintName>.]<HandlerName>\n    ```\n\n    Returns:\n        Optional[str]: The route name\n    \"\"\"\n    if self._name:\n        return self._name\n    elif self.route:\n        return self.route.name\n    return None", "loc": 17}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "uri_template", "parameters": ["self"], "param_types": {}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The defined URI template", "source_code": "def uri_template(self) -> Optional[str]:\n    \"\"\"The defined URI template\n\n    Returns:\n        Optional[str]: The defined URI template\n    \"\"\"\n    if self.route:\n        return f\"/{self.route.path}\"\n    return None", "loc": 9}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "protocol", "parameters": ["self"], "param_types": {}, "return_type": "TransportProtocol", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.transport.get_protocol"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The HTTP protocol instance", "source_code": "def protocol(self) -> TransportProtocol:\n    \"\"\"The HTTP protocol instance\n\n    Returns:\n        Protocol: The HTTP protocol instance\n    \"\"\"\n    if not self._protocol:\n        self._protocol = self.transport.get_protocol()\n    return self._protocol  # type: ignore", "loc": 9}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "raw_headers", "parameters": ["self"], "param_types": {}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytes", "self.head.split"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "The unparsed HTTP headers", "source_code": "def raw_headers(self) -> bytes:\n    \"\"\"The unparsed HTTP headers\n\n    Returns:\n        bytes: The unparsed HTTP headers\n    \"\"\"\n    _, headers = self.head.split(b\"\\r\\n\", 1)\n    return bytes(headers)", "loc": 8}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "request_line", "parameters": ["self"], "param_types": {}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytes", "self.head.split"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "The first line of a HTTP request", "source_code": "def request_line(self) -> bytes:\n    \"\"\"The first line of a HTTP request\n\n    Returns:\n        bytes: The first line of a HTTP request\n    \"\"\"\n    reqline, _ = self.head.split(b\"\\r\\n\", 1)\n    return bytes(reqline)", "loc": 8}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "id", "parameters": ["self"], "param_types": {}, "return_type": "Optional[Union[uuid.UUID, str, int]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "isinstance", "self.__class__.generate_id", "self.headers.getone", "uuid.UUID"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "A request ID passed from the client, or generated from the backend. By default, this will look in a request header defined at: `self.app.config.REQUEST_ID_HEADER`. It defaults to `X-Request-ID`. Sanic will try to cast the ID into a `UUID` or an `int`. If there is not a UUID from the client, then Sanic will try to generate an ID by calling `Request.generate_id()`. The default behavior is to generate a `UUID`. You can customize this behavior by subclassing `Request` and overwriting that method. ```python from sanic import Request, Sanic from itertools import count class IntRequest(Request): counter = count() def generate_id(self): return next(self.counter) app = Sanic(\"MyApp\", request_class=IntRequest) ```", "source_code": "def id(self) -> Optional[Union[uuid.UUID, str, int]]:\n    \"\"\"A request ID passed from the client, or generated from the backend.\n\n    By default, this will look in a request header defined at:\n    `self.app.config.REQUEST_ID_HEADER`. It defaults to\n    `X-Request-ID`. Sanic will try to cast the ID into a `UUID` or an\n    `int`.\n\n    If there is not a UUID from the client, then Sanic will try\n    to generate an ID by calling `Request.generate_id()`. The default\n    behavior is to generate a `UUID`. You can customize this behavior\n    by subclassing `Request` and overwriting that method.\n\n    ```python\n    from sanic import Request, Sanic\n    from itertools import count\n\n    class IntRequest(Request):\n        counter = count()\n\n        def generate_id(self):\n            return next(self.counter)\n\n    app = Sanic(\"MyApp\", request_class=IntRequest)\n    ```\n\n    Returns:\n        Optional[Union[uuid.UUID, str, int]]: A request ID passed from the\n            client, or generated from the backend.\n    \"\"\"\n    if not self._id:\n        self._id = self.headers.getone(\n            self.app.config.REQUEST_ID_HEADER,\n            self.__class__.generate_id(self),  # type: ignore\n        )\n\n        # Try casting to a UUID or an integer\n        if isinstance(self._id, str):\n            try:\n                self._id = uuid.UUID(self._id)\n            except ValueError:\n                try:\n                    self._id = int(self._id)  # type: ignore\n                except ValueError:\n                    ...\n\n    return self._id  # type: ignore", "loc": 47}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "json", "parameters": ["self"], "param_types": {}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.load_json"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The request body parsed as JSON", "source_code": "def json(self) -> Any:\n    \"\"\"The request body parsed as JSON\n\n    Returns:\n        Any: The request body parsed as JSON\n    \"\"\"\n    if self.parsed_json is None:\n        self.load_json()\n\n    return self.parsed_json", "loc": 10}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "load_json", "parameters": ["self", "loads"], "param_types": {}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BadRequest", "loads"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Load the request body as JSON", "source_code": "def load_json(self, loads=None) -> Any:\n    \"\"\"Load the request body as JSON\n\n    Args:\n        loads (Callable, optional): A custom JSON loader. Defaults to None.\n\n    Raises:\n        BadRequest: If the request body cannot be parsed as JSON\n\n    Returns:\n        Any: The request body parsed as JSON\n    \"\"\"\n    try:\n        if not loads:\n            loads = self.__class__._loads\n\n        self.parsed_json = loads(self.body)\n    except Exception:\n        if not self.body:\n            return None\n        raise BadRequest(\"Failed when parsing body as json\")\n\n    return self.parsed_json", "loc": 23}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "accept", "parameters": ["self"], "param_types": {}, "return_type": "AcceptList", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_accept", "self.headers.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Accepted response content types. A convenience handler for easier RFC-compliant matching of MIME types, parsed as a list that can match wildcards and includes */* by default.", "source_code": "def accept(self) -> AcceptList:\n    \"\"\"Accepted response content types.\n\n    A convenience handler for easier RFC-compliant matching of MIME types,\n    parsed as a list that can match wildcards and includes */* by default.\n\n    Returns:\n        AcceptList: Accepted response content types\n    \"\"\"\n    if self.parsed_accept is None:\n        self.parsed_accept = parse_accept(self.headers.get(\"accept\"))\n    return self.parsed_accept", "loc": 12}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "token", "parameters": ["self"], "param_types": {}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_credentials", "self.headers.getone"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Attempt to return the auth header token.", "source_code": "def token(self) -> Optional[str]:\n    \"\"\"Attempt to return the auth header token.\n\n    Returns:\n        Optional[str]: The auth header token\n    \"\"\"\n    if self.parsed_token is None:\n        prefixes = (\"Bearer\", \"Token\")\n        _, token = parse_credentials(\n            self.headers.getone(\"authorization\", None), prefixes\n        )\n        self.parsed_token = token\n    return self.parsed_token", "loc": 13}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "credentials", "parameters": ["self"], "param_types": {}, "return_type": "Optional[Credentials]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Credentials", "parse_credentials", "self.headers.getone"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Attempt to return the auth header value. Covers NoAuth, Basic Auth, Bearer Token, Api Token authentication schemas.", "source_code": "def credentials(self) -> Optional[Credentials]:\n    \"\"\"Attempt to return the auth header value.\n\n    Covers NoAuth, Basic Auth, Bearer Token, Api Token authentication\n    schemas.\n\n    Returns:\n        Optional[Credentials]: A Credentials object with token, or username\n            and password related to the request\n    \"\"\"\n    if self.parsed_credentials is None:\n        try:\n            prefix, credentials = parse_credentials(\n                self.headers.getone(\"authorization\", None)\n            )\n            if credentials:\n                self.parsed_credentials = Credentials(\n                    auth_type=prefix, token=credentials\n                )\n        except ValueError:\n            pass\n    return self.parsed_credentials", "loc": 22}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "get_form", "parameters": ["self", "keep_blank_values"], "param_types": {"keep_blank_values": "bool"}, "return_type": "Optional[RequestParameters]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RequestParameters", "error_logger.exception", "parameters['boundary'].encode", "parse_content_header", "parse_multipart_form", "parse_qs", "self.body.decode", "self.headers.getone"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Method to extract and parse the form data from a request.", "source_code": "def get_form(\n    self, keep_blank_values: bool = False\n) -> Optional[RequestParameters]:\n    \"\"\"Method to extract and parse the form data from a request.\n\n    Args:\n        keep_blank_values (bool): Whether to discard blank values from the form data.\n\n    Returns:\n        Optional[RequestParameters]: The parsed form data.\n    \"\"\"  # noqa: E501\n    self.parsed_form = RequestParameters()\n    self.parsed_files = RequestParameters()\n    content_type = self.headers.getone(\n        \"content-type\", DEFAULT_HTTP_CONTENT_TYPE\n    )\n    content_type, parameters = parse_content_header(content_type)\n    try:\n        if content_type == \"application/x-www-form-urlencoded\":\n            self.parsed_form = RequestParameters(\n                parse_qs(\n                    self.body.decode(\"utf-8\"),\n                    keep_blank_values=keep_blank_values,\n                )\n            )\n        elif content_type == \"multipart/form-data\":\n            # TODO: Stream this instead of reading to/from memory\n            boundary = parameters[\"boundary\"].encode(  # type: ignore\n                \"utf-8\"\n            )  # type: ignore\n            self.parsed_form, self.parsed_files = parse_multipart_form(\n                self.body, boundary\n            )\n    except Exception:\n        error_logger.exception(\"Failed when parsing form\")\n\n    return self.parsed_form", "loc": 37}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "form", "parameters": ["self"], "param_types": {}, "return_type": "Optional[RequestParameters]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.get_form"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The request body parsed as form data", "source_code": "def form(self) -> Optional[RequestParameters]:\n    \"\"\"The request body parsed as form data\n\n    Returns:\n        Optional[RequestParameters]: The request body parsed as form data\n    \"\"\"\n    if self.parsed_form is None:\n        self.get_form()\n\n    return self.parsed_form", "loc": 10}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "files", "parameters": ["self"], "param_types": {}, "return_type": "Optional[RequestParameters]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The request body parsed as uploaded files", "source_code": "def files(self) -> Optional[RequestParameters]:\n    \"\"\"The request body parsed as uploaded files\n\n    Returns:\n        Optional[RequestParameters]: The request body parsed as uploaded files\n    \"\"\"  # noqa: E501\n    if self.parsed_files is None:\n        self.form  # compute form to get files\n\n    return self.parsed_files", "loc": 10}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "get_args", "parameters": ["self", "keep_blank_values", "strict_parsing", "encoding", "errors"], "param_types": {"keep_blank_values": "bool", "strict_parsing": "bool", "encoding": "str", "errors": "str"}, "return_type": "RequestParameters", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RequestParameters", "parse_qs"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse `query_string` using `urllib.parse.parse_qs`. This methods is used by the `args` property, but it also can be used directly if you need to change default parameters.", "source_code": "def get_args(\n    self,\n    keep_blank_values: bool = False,\n    strict_parsing: bool = False,\n    encoding: str = \"utf-8\",\n    errors: str = \"replace\",\n) -> RequestParameters:\n    \"\"\"Parse `query_string` using `urllib.parse.parse_qs`.\n\n    This methods is used by the `args` property, but it also\n    can be used directly if you need to change default parameters.\n\n    Args:\n        keep_blank_values (bool): Flag indicating whether blank values in\n            percent-encoded queries should be treated as blank strings.\n            A `True` value indicates that blanks should be retained as\n            blank strings. The default `False` value indicates that\n            blank values are to be ignored and treated as if they were\n            not included.\n        strict_parsing (bool): Flag indicating what to do with parsing\n            errors. If `False` (the default), errors are silently ignored.\n            If `True`, errors raise a `ValueError` exception.\n        encoding (str): Specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the\n            `bytes.decode()` method.\n        errors (str): Specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the\n            `bytes.decode()` method.\n\n    Returns:\n        RequestParameters: A dictionary containing the parsed arguments.\n    \"\"\"\n    if (\n        keep_blank_values,\n        strict_parsing,\n        encoding,\n        errors,\n    ) not in self.parsed_args:\n        if self.query_string:\n            self.parsed_args[\n                (keep_blank_values, strict_parsing, encoding, errors)\n            ] = RequestParameters(\n                parse_qs(\n                    qs=self.query_string,\n                    keep_blank_values=keep_blank_values,\n                    strict_parsing=strict_parsing,\n                    encoding=encoding,\n                    errors=errors,\n                )\n            )\n\n    return self.parsed_args[\n        (keep_blank_values, strict_parsing, encoding, errors)\n    ]", "loc": 54}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "get_query_args", "parameters": ["self", "keep_blank_values", "strict_parsing", "encoding", "errors"], "param_types": {"keep_blank_values": "bool", "strict_parsing": "bool", "encoding": "str", "errors": "str"}, "return_type": "list", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_qsl"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Parse `query_string` using `urllib.parse.parse_qsl`. This methods is used by `query_args` propertyn but can be used directly if you need to change default parameters.", "source_code": "def get_query_args(\n    self,\n    keep_blank_values: bool = False,\n    strict_parsing: bool = False,\n    encoding: str = \"utf-8\",\n    errors: str = \"replace\",\n) -> list:\n    \"\"\"Parse `query_string` using `urllib.parse.parse_qsl`.\n\n    This methods is used by `query_args` propertyn but can be used\n    directly if you need to change default parameters.\n\n    Args:\n        keep_blank_values (bool): Flag indicating whether blank values in\n            percent-encoded queries should be treated as blank strings.\n            A `True` value indicates that blanks should be retained as\n            blank strings. The default `False` value indicates that\n            blank values are to be ignored and treated as if they were\n            not included.\n        strict_parsing (bool): Flag indicating what to do with\n            parsing errors. If `False` (the default), errors are\n            silently ignored. If `True`, errors raise a\n            `ValueError` exception.\n        encoding (str): Specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the\n            `bytes.decode()` method.\n        errors (str): Specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the\n            `bytes.decode()` method.\n\n    Returns:\n        list: A list of tuples containing the parsed arguments.\n    \"\"\"\n    if (\n        keep_blank_values,\n        strict_parsing,\n        encoding,\n        errors,\n    ) not in self.parsed_not_grouped_args:\n        if self.query_string:\n            self.parsed_not_grouped_args[\n                (keep_blank_values, strict_parsing, encoding, errors)\n            ] = parse_qsl(\n                qs=self.query_string,\n                keep_blank_values=keep_blank_values,\n                strict_parsing=strict_parsing,\n                encoding=encoding,\n                errors=errors,\n            )\n    return self.parsed_not_grouped_args[\n        (keep_blank_values, strict_parsing, encoding, errors)\n    ]", "loc": 52}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "cookies", "parameters": ["self"], "param_types": {}, "return_type": "RequestParameters", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "self.get_cookies"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Incoming cookies on the request", "source_code": "def cookies(self) -> RequestParameters:\n    \"\"\"Incoming cookies on the request\n\n    Returns:\n        RequestParameters: Incoming cookies on the request\n    \"\"\"\n\n    if self.parsed_cookies is None:\n        self.get_cookies()\n    return cast(CookieRequestParameters, self.parsed_cookies)", "loc": 10}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "network_paths", "parameters": ["self"], "param_types": {}, "return_type": "Optional[list[Any]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Access the network paths if available", "source_code": "def network_paths(self) -> Optional[list[Any]]:\n    \"\"\"Access the network paths if available\n\n    Returns:\n        Optional[List[Any]]: Access the network paths if available\n    \"\"\"\n    if self.conn_info is None:\n        return None\n    return self.conn_info.network_paths", "loc": 9}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "forwarded", "parameters": ["self"], "param_types": {}, "return_type": "Options", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_forwarded", "parse_xforwarded"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Active proxy information obtained from request headers, as specified in Sanic configuration. Field names by, for, proto, host, port and path are normalized. - for and by IPv6 addresses are bracketed - port (int) is only set by port headers, not from host. - path is url-unencoded Additional values may be available from new style Forwarded headers.", "source_code": "def forwarded(self) -> Options:\n    \"\"\"Active proxy information obtained from request headers, as specified in Sanic configuration.\n\n    Field names by, for, proto, host, port and path are normalized.\n    - for and by IPv6 addresses are bracketed\n    - port (int) is only set by port headers, not from host.\n    - path is url-unencoded\n\n    Additional values may be available from new style Forwarded headers.\n\n    Returns:\n        Options: proxy information from request headers\n    \"\"\"  # noqa: E501\n    if self.parsed_forwarded is None:\n        self.parsed_forwarded = (\n            parse_forwarded(self.headers, self.app.config)\n            or parse_xforwarded(self.headers, self.app.config)\n            or {}\n        )\n    return self.parsed_forwarded", "loc": 20}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "remote_addr", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "self.forwarded.get", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Client IP address, if available from proxy.", "source_code": "def remote_addr(self) -> str:\n    \"\"\"Client IP address, if available from proxy.\n\n    Returns:\n        str: IPv4, bracketed IPv6, UNIX socket name or arbitrary string\n    \"\"\"\n    if not hasattr(self, \"_remote_addr\"):\n        self._remote_addr = str(self.forwarded.get(\"for\", \"\"))\n    return self._remote_addr", "loc": 9}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "scheme", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "len", "proto.replace", "self.app.config.get", "self.app.config.get('SERVER_NAME', '').split", "self.headers.upgrade.lower", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Determine request scheme. 1. `config.SERVER_NAME` if in full URL format 2. proxied proto/scheme 3. local connection protocol", "source_code": "def scheme(self) -> str:\n    \"\"\"Determine request scheme.\n\n    1. `config.SERVER_NAME` if in full URL format\n    2. proxied proto/scheme\n    3. local connection protocol\n\n    Returns:\n        str: http|https|ws|wss or arbitrary value given by the headers.\n    \"\"\"\n    if not hasattr(self, \"_scheme\"):\n        if (\n            self.app.websocket_enabled\n            and self.headers.upgrade.lower() == \"websocket\"\n        ):\n            scheme = \"ws\"\n        else:\n            scheme = \"http\"\n        proto = None\n        sp = self.app.config.get(\"SERVER_NAME\", \"\").split(\"://\", 1)\n        if len(sp) == 2:\n            proto = sp[0]\n        elif \"proto\" in self.forwarded:\n            proto = str(self.forwarded[\"proto\"])\n        if proto:\n            # Give ws/wss if websocket, otherwise keep the same\n            scheme = proto.replace(\"http\", scheme)\n        elif self.conn_info and self.conn_info.ssl:\n            scheme += \"s\"\n        self._scheme = scheme\n\n    return self._scheme", "loc": 32}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "host", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.app.config.get", "self.forwarded.get", "self.headers.getone", "server_name.split", "server_name.split('//', 1)[-1].split", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The currently effective server 'host' (hostname or hostname:port). 1. `config.SERVER_NAME` overrides any client headers 2. proxied host of original request 3. request host header hostname and port may be separated by `sanic.headers.parse_host(request.host)`.", "source_code": "def host(self) -> str:\n    \"\"\"The currently effective server 'host' (hostname or hostname:port).\n\n    1. `config.SERVER_NAME` overrides any client headers\n    2. proxied host of original request\n    3. request host header\n    hostname and port may be separated by\n    `sanic.headers.parse_host(request.host)`.\n\n    Returns:\n        str: the first matching host found, or empty string\n    \"\"\"\n    server_name = self.app.config.get(\"SERVER_NAME\")\n    if server_name:\n        return server_name.split(\"//\", 1)[-1].split(\"/\", 1)[0]\n    return str(\n        self.forwarded.get(\"host\") or self.headers.getone(\"host\", \"\")\n    )", "loc": 18}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "server_port", "parameters": ["self"], "param_types": {}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "parse_host", "self.forwarded.get"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "The port the client connected to, by forwarded `port` or `request.host`. Default port is returned as 80 and 443 based on `request.scheme`.", "source_code": "def server_port(self) -> int:\n    \"\"\"The port the client connected to, by forwarded `port` or `request.host`.\n\n    Default port is returned as 80 and 443 based on `request.scheme`.\n\n    Returns:\n        int: The port the client connected to, by forwarded `port` or `request.host`.\n    \"\"\"  # noqa: E501\n    port = self.forwarded.get(\"port\") or parse_host(self.host)[1]\n    return int(port or (80 if self.scheme in (\"http\", \"ws\") else 443))", "loc": 10}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "server_path", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.forwarded.get", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Full path of current URL; uses proxied or local path", "source_code": "def server_path(self) -> str:\n    \"\"\"Full path of current URL; uses proxied or local path\n\n    Returns:\n        str: Full path of current URL; uses proxied or local path\n    \"\"\"\n    return str(self.forwarded.get(\"path\") or self.path)", "loc": 7}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "query_string", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._parsed_url.query.decode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Representation of the requested query", "source_code": "def query_string(self) -> str:\n    \"\"\"Representation of the requested query\n\n    Returns:\n        str: Representation of the requested query\n    \"\"\"\n    if self._parsed_url.query:\n        return self._parsed_url.query.decode(\"utf-8\")\n    else:\n        return \"\"", "loc": 10}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "url_for", "parameters": ["self", "view_name"], "param_types": {"view_name": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "scheme.lower", "self.app.config.get", "self.app.config.get('SERVER_NAME', '').split", "self.app.url_for"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Retrieve a URL for a given view name. Same as `sanic.Sanic.url_for`, but automatically determine `scheme` and `netloc` base on the request. Since this method is aiming to generate correct schema & netloc, `_external` is implied.", "source_code": "def url_for(self, view_name: str, **kwargs) -> str:\n    \"\"\"Retrieve a URL for a given view name.\n\n    Same as `sanic.Sanic.url_for`, but automatically determine `scheme`\n    and `netloc` base on the request. Since this method is aiming\n    to generate correct schema & netloc, `_external` is implied.\n\n    Args:\n        view_name (str): The view name to generate URL for.\n        **kwargs: Arbitrary keyword arguments to build URL query string.\n\n    Returns:\n        str: The generated URL.\n    \"\"\"\n    # Full URL SERVER_NAME can only be handled in app.url_for\n    try:\n        sp = self.app.config.get(\"SERVER_NAME\", \"\").split(\"://\", 1)\n        if len(sp) == 2:\n            return self.app.url_for(view_name, _external=True, **kwargs)\n    except AttributeError:\n        pass\n\n    scheme = self.scheme\n    host = self.server_name\n    port = self.server_port\n\n    if (scheme.lower() in (\"http\", \"ws\") and port == 80) or (\n        scheme.lower() in (\"https\", \"wss\") and port == 443\n    ):\n        netloc = host\n    else:\n        netloc = f\"{host}:{port}\"\n\n    return self.app.url_for(\n        view_name, _external=True, _scheme=scheme, _server=netloc, **kwargs\n    )", "loc": 36}
{"file": "sanic\\sanic\\request\\types.py", "class_name": "Request", "function_name": "scope", "parameters": ["self"], "param_types": {}, "return_type": "ASGIScope", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The ASGI scope of the request.", "source_code": "def scope(self) -> ASGIScope:\n    \"\"\"The ASGI scope of the request.\n\n    Returns:\n        ASGIScope: The ASGI scope of the request.\n\n    Raises:\n        NotImplementedError: If the app isn't an ASGI app.\n    \"\"\"\n    if not self.app.asgi:\n        raise NotImplementedError(\n            \"App isn't running in ASGI mode. \"\n            \"Scope is only available for ASGI apps.\"\n        )\n\n    return self.transport.scope", "loc": 16}
{"file": "sanic\\sanic\\response\\convenience.py", "class_name": null, "function_name": "text", "parameters": ["body", "status", "headers", "content_type"], "param_types": {"body": "str", "status": "int", "headers": "Optional[dict[str, str]]", "content_type": "str"}, "return_type": "HTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTTPResponse", "TypeError", "isinstance", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def text(\n    body: str,\n    status: int = 200,\n    headers: Optional[dict[str, str]] = None,\n    content_type: str = \"text/plain; charset=utf-8\",\n) -> HTTPResponse:\n    \"\"\"Returns response object with body in text format.\n\n    Args:\n        body (str): Response data.\n        status (int, optional): HTTP response code. Defaults to `200`.\n        headers (Dict[str, str], optional): Custom HTTP headers. Defaults to `None`.\n        content_type (str, optional): The content type (string) of the response. Defaults to `\"text/plain; charset=utf-8\"`.\n\n    Returns:\n        HTTPResponse: A response object with body in text format.\n\n    Raises:\n        TypeError: If the body is not a string.\n    \"\"\"  # noqa: E501\n    if not isinstance(body, str):\n        raise TypeError(\n            f\"Bad body type. Expected str, got {type(body).__name__})\"\n        )\n\n    return HTTPResponse(\n        body, status=status, headers=headers, content_type=content_type\n    )", "loc": 28}
{"file": "sanic\\sanic\\response\\convenience.py", "class_name": null, "function_name": "html", "parameters": ["body", "status", "headers"], "param_types": {"body": "Union[str, bytes, HTMLProtocol]", "status": "int", "headers": "Optional[dict[str, str]]"}, "return_type": "HTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTTPResponse", "body.__html__", "body._repr_html_", "hasattr", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def html(\n    body: Union[str, bytes, HTMLProtocol],\n    status: int = 200,\n    headers: Optional[dict[str, str]] = None,\n) -> HTTPResponse:\n    \"\"\"Returns response object with body in html format.\n\n    Body should be a `str` or `bytes` like object, or an object with `__html__` or `_repr_html_`.\n\n    Args:\n        body (Union[str, bytes, HTMLProtocol]): Response data.\n        status (int, optional): HTTP response code. Defaults to `200`.\n        headers (Dict[str, str], optional): Custom HTTP headers. Defaults to `None`.\n\n    Returns:\n        HTTPResponse: A response object with body in html format.\n    \"\"\"  # noqa: E501\n    if not isinstance(body, (str, bytes)):\n        if hasattr(body, \"__html__\"):\n            body = body.__html__()\n        elif hasattr(body, \"_repr_html_\"):\n            body = body._repr_html_()\n\n    return HTTPResponse(\n        body,\n        status=status,\n        headers=headers,\n        content_type=\"text/html; charset=utf-8\",\n    )", "loc": 29}
{"file": "sanic\\sanic\\response\\convenience.py", "class_name": null, "function_name": "redirect", "parameters": ["to", "headers", "status", "content_type"], "param_types": {"to": "str", "headers": "Optional[dict[str, str]]", "status": "int", "content_type": "str"}, "return_type": "HTTPResponse", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HTTPResponse", "quote_plus"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Cause a HTTP redirect (302 by default) by setting a Location header.", "source_code": "def redirect(\n    to: str,\n    headers: Optional[dict[str, str]] = None,\n    status: int = 302,\n    content_type: str = \"text/html; charset=utf-8\",\n) -> HTTPResponse:\n    \"\"\"Cause a HTTP redirect (302 by default) by setting a Location header.\n\n    Args:\n        to (str): path or fully qualified URL to redirect to\n        headers (Optional[Dict[str, str]], optional): optional dict of headers to include in the new request. Defaults to None.\n        status (int, optional): status code (int) of the new request, defaults to 302. Defaults to 302.\n        content_type (str, optional): the content type (string) of the response. Defaults to \"text/html; charset=utf-8\".\n\n    Returns:\n        HTTPResponse: A response object with the redirect.\n    \"\"\"  # noqa: E501\n    headers = headers or {}\n\n    # URL Quote the URL before redirecting\n    safe_to = quote_plus(to, safe=\":/%#?&=@[]!$&'()*+,;\")\n\n    # According to RFC 7231, a relative URI is now permitted.\n    headers[\"Location\"] = safe_to\n\n    return HTTPResponse(\n        status=status, headers=headers, content_type=content_type\n    )", "loc": 28}
{"file": "sanic\\sanic\\response\\types.py", "class_name": "BaseHTTPResponse", "function_name": "cookies", "parameters": ["self"], "param_types": {}, "return_type": "CookieJar", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CookieJar"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The response cookies. See [Cookies](/en/guide/basics/cookies.html)", "source_code": "def cookies(self) -> CookieJar:\n    \"\"\"The response cookies.\n\n    See [Cookies](/en/guide/basics/cookies.html)\n\n    Returns:\n        CookieJar: The response cookies\n    \"\"\"\n    if self._cookies is None:\n        self._cookies = CookieJar(self.headers)\n    return self._cookies", "loc": 11}
{"file": "sanic\\sanic\\response\\types.py", "class_name": "BaseHTTPResponse", "function_name": "processed_headers", "parameters": ["self"], "param_types": {}, "return_type": "Iterator[tuple[bytes, bytes]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["f'{value}'.encode", "has_message_body", "name.encode", "self.headers.items", "self.headers.setdefault"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Obtain a list of header tuples encoded in bytes for sending. Add and remove headers based on status and content_type.", "source_code": "def processed_headers(self) -> Iterator[tuple[bytes, bytes]]:\n    \"\"\"Obtain a list of header tuples encoded in bytes for sending.\n\n    Add and remove headers based on status and content_type.\n\n    Returns:\n        Iterator[Tuple[bytes, bytes]]: A list of header tuples encoded in bytes for sending\n    \"\"\"  # noqa: E501\n    if has_message_body(self.status):\n        self.headers.setdefault(\"content-type\", self.content_type)\n    # Encode headers into bytes\n    return (\n        (name.encode(\"ascii\"), f\"{value}\".encode(errors=\"surrogateescape\"))\n        for name, value in self.headers.items()\n    )", "loc": 15}
{"file": "sanic\\sanic\\response\\types.py", "class_name": "JSONResponse", "function_name": "raw_body", "parameters": ["self", "value"], "param_types": {"value": "Any"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._encode_body", "self._use_dumps"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def raw_body(self, value: Any):\n    self._body_manually_set = False\n    self._body = self._encode_body(\n        self._use_dumps(value, **self._use_dumps_kwargs)\n    )\n    self._raw_body = value", "loc": 6}
{"file": "sanic\\sanic\\response\\types.py", "class_name": "JSONResponse", "function_name": "body", "parameters": ["self", "value"], "param_types": {"value": "Optional[bytes]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def body(self, value: Optional[bytes]):\n    self._body = value\n    if not self._initialized:\n        return\n    self._body_manually_set = True", "loc": 5}
{"file": "sanic\\sanic\\response\\types.py", "class_name": "JSONResponse", "function_name": "set_body", "parameters": ["self", "body", "dumps"], "param_types": {"body": "Any", "dumps": "Optional[Callable[..., AnyStr]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._encode_body", "use_dumps"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Set the response body to the given value, using the given dumps function Sets a new response body using the given dumps function and kwargs, or falling back to the defaults given when creating the object if none are specified.", "source_code": "def set_body(\n    self,\n    body: Any,\n    dumps: Optional[Callable[..., AnyStr]] = None,\n    **dumps_kwargs: Any,\n) -> None:\n    \"\"\"Set the response body to the given value, using the given dumps function\n\n    Sets a new response body using the given dumps function\n    and kwargs, or falling back to the defaults given when\n    creating the object if none are specified.\n\n    Args:\n        body (Any): The body to set\n        dumps (Optional[Callable[..., AnyStr]], optional): The function to use for json encoding. Defaults to `None`.\n        **dumps_kwargs (Any, optional): The kwargs to pass to the json encoding function. Defaults to `{}`.\n\n    Examples:\n        ```python\n        response = JSONResponse({\"foo\": \"bar\"})\n        response.set_body({\"bar\": \"baz\"})\n        assert response.body == b'{\"bar\": \"baz\"}'\n        ```\n    \"\"\"  # noqa: E501\n    self._body_manually_set = False\n    self._raw_body = body\n\n    use_dumps = dumps or self._use_dumps\n    use_dumps_kwargs = dumps_kwargs if dumps else self._use_dumps_kwargs\n\n    self._body = self._encode_body(use_dumps(body, **use_dumps_kwargs))", "loc": 31}
{"file": "sanic\\sanic\\response\\types.py", "class_name": "JSONResponse", "function_name": "append", "parameters": ["self", "value"], "param_types": {"value": "Any"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "isinstance", "self._check_body_not_manually_set", "self._raw_body.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Appends a value to the response raw_body, ensuring that body is kept up to date. This can only be used if raw_body is a list.", "source_code": "def append(self, value: Any) -> None:\n    \"\"\"Appends a value to the response raw_body, ensuring that body is kept up to date.\n\n    This can only be used if raw_body is a list.\n\n    Args:\n        value (Any): The value to append\n\n    Raises:\n        SanicException: If the body is not a list\n    \"\"\"  # noqa: E501\n\n    self._check_body_not_manually_set()\n\n    if not isinstance(self._raw_body, list):\n        raise SanicException(\"Cannot append to a non-list object.\")\n\n    self._raw_body.append(value)\n    self.raw_body = self._raw_body", "loc": 19}
{"file": "sanic\\sanic\\response\\types.py", "class_name": "JSONResponse", "function_name": "extend", "parameters": ["self", "value"], "param_types": {"value": "Any"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "isinstance", "self._check_body_not_manually_set", "self._raw_body.extend"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Extends the response's raw_body with the given values, ensuring that body is kept up to date. This can only be used if raw_body is a list.", "source_code": "def extend(self, value: Any) -> None:\n    \"\"\"Extends the response's raw_body with the given values, ensuring that body is kept up to date.\n\n    This can only be used if raw_body is a list.\n\n    Args:\n        value (Any): The values to extend with\n\n    Raises:\n        SanicException: If the body is not a list\n    \"\"\"  # noqa: E501\n\n    self._check_body_not_manually_set()\n\n    if not isinstance(self._raw_body, list):\n        raise SanicException(\"Cannot extend a non-list object.\")\n\n    self._raw_body.extend(value)\n    self.raw_body = self._raw_body", "loc": 19}
{"file": "sanic\\sanic\\response\\types.py", "class_name": "JSONResponse", "function_name": "update", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "isinstance", "self._check_body_not_manually_set", "self._raw_body.update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Updates the response's raw_body with the given values, ensuring that body is kept up to date. This can only be used if raw_body is a dict.", "source_code": "def update(self, *args, **kwargs) -> None:\n    \"\"\"Updates the response's raw_body with the given values, ensuring that body is kept up to date.\n\n    This can only be used if raw_body is a dict.\n\n    Args:\n        *args: The args to update with\n        **kwargs: The kwargs to update with\n\n    Raises:\n        SanicException: If the body is not a dict\n    \"\"\"  # noqa: E501\n\n    self._check_body_not_manually_set()\n\n    if not isinstance(self._raw_body, dict):\n        raise SanicException(\"Cannot update a non-dict object.\")\n\n    self._raw_body.update(*args, **kwargs)\n    self.raw_body = self._raw_body", "loc": 20}
{"file": "sanic\\sanic\\response\\types.py", "class_name": "JSONResponse", "function_name": "pop", "parameters": ["self", "key", "default"], "param_types": {"key": "Any", "default": "Any"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SanicException", "TypeError", "isinstance", "self._check_body_not_manually_set", "self._raw_body.pop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Pops a key from the response's raw_body, ensuring that body is kept up to date. This can only be used if raw_body is a dict or a list.", "source_code": "def pop(self, key: Any, default: Any = _default) -> Any:\n    \"\"\"Pops a key from the response's raw_body, ensuring that body is kept up to date.\n\n    This can only be used if raw_body is a dict or a list.\n\n    Args:\n        key (Any): The key to pop\n        default (Any, optional): The default value to return if the key is not found. Defaults to `_default`.\n\n    Raises:\n        SanicException: If the body is not a dict or a list\n        TypeError: If the body is a list and a default value is provided\n\n    Returns:\n        Any: The value that was popped\n    \"\"\"  # noqa: E501\n\n    self._check_body_not_manually_set()\n\n    if not isinstance(self._raw_body, (list, dict)):\n        raise SanicException(\n            \"Cannot pop from a non-list and non-dict object.\"\n        )\n\n    if isinstance(default, Default):\n        value = self._raw_body.pop(key)\n    elif isinstance(self._raw_body, list):\n        raise TypeError(\"pop doesn't accept a default argument for lists\")\n    else:\n        value = self._raw_body.pop(key, default)\n\n    self.raw_body = self._raw_body\n\n    return value", "loc": 34}
{"file": "sanic\\sanic\\server\\async_server.py", "class_name": "AsyncioServer", "function_name": "is_serving", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.server.is_serving"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_serving(self) -> bool:\n    \"\"\"Returns True if the server is running, False otherwise\"\"\"\n    if self.server:\n        return self.server.is_serving()\n    return False", "loc": 5}
{"file": "sanic\\sanic\\server\\async_server.py", "class_name": "AsyncioServer", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["asyncio.ensure_future", "self.server.close", "self.wait_closed"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Close the server", "source_code": "def close(self):\n    \"\"\"Close the server\"\"\"\n    if self.server:\n        self.server.close()\n        coro = self.wait_closed()\n        task = asyncio.ensure_future(coro, loop=self.loop)\n        return task", "loc": 7}
{"file": "sanic\\sanic\\server\\events.py", "class_name": null, "function_name": "trigger_events", "parameters": ["events", "loop", "app"], "param_types": {"events": "Optional[Iterable[Callable[..., Any]]]", "app": "Optional[Sanic]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["event", "isawaitable", "loop.run_until_complete"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Trigger event callbacks (functions or async)", "source_code": "def trigger_events(\n    events: Optional[Iterable[Callable[..., Any]]],\n    loop,\n    app: Optional[Sanic] = None,\n    **kwargs,\n):\n    \"\"\"Trigger event callbacks (functions or async)\n\n    Args:\n        events (Optional[Iterable[Callable[..., Any]]]): [description]\n        loop ([type]): [description]\n        app (Optional[Sanic], optional): [description]. Defaults to None.\n    \"\"\"\n    if events:\n        for event in events:\n            try:\n                result = event(**kwargs) if not app else event(app, **kwargs)\n            except TypeError:\n                result = (\n                    event(loop, **kwargs)\n                    if not app\n                    else event(app, loop, **kwargs)\n                )\n            if isawaitable(result):\n                loop.run_until_complete(result)", "loc": 25}
{"file": "sanic\\sanic\\server\\loop.py", "class_name": null, "function_name": "try_use_uvloop", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["asyncio.get_event_loop_policy", "asyncio.set_event_loop_policy", "error_logger.info", "error_logger.warning", "getenv", "isinstance", "str_to_bool", "uvloop.EventLoopPolicy"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Use uvloop instead of the default asyncio loop.", "source_code": "def try_use_uvloop() -> None:\n    \"\"\"Use uvloop instead of the default asyncio loop.\"\"\"\n    if OS_IS_WINDOWS:\n        error_logger.warning(\n            \"You are trying to use uvloop, but uvloop is not compatible \"\n            \"with your system. You can disable uvloop completely by setting \"\n            \"the 'USE_UVLOOP' configuration value to false, or simply not \"\n            \"defining it and letting Sanic handle it for you. Sanic will now \"\n            \"continue to run using the default event loop.\"\n        )\n        return\n\n    try:\n        import uvloop  # type: ignore\n    except ImportError:\n        error_logger.warning(\n            \"You are trying to use uvloop, but uvloop is not \"\n            \"installed in your system. In order to use uvloop \"\n            \"you must first install it. Otherwise, you can disable \"\n            \"uvloop completely by setting the 'USE_UVLOOP' \"\n            \"configuration value to false. Sanic will now continue \"\n            \"to run with the default event loop.\"\n        )\n        return\n\n    uvloop_install_removed = str_to_bool(getenv(\"SANIC_NO_UVLOOP\", \"no\"))\n    if uvloop_install_removed:\n        error_logger.info(\n            \"You are requesting to run Sanic using uvloop, but the \"\n            \"install-time 'SANIC_NO_UVLOOP' environment variable (used to \"\n            \"opt-out of installing uvloop with Sanic) is set to true. If \"\n            \"you want to prevent Sanic from overriding the event loop policy \"\n            \"during runtime, set the 'USE_UVLOOP' configuration value to \"\n            \"false.\"\n        )\n\n    if not isinstance(asyncio.get_event_loop_policy(), uvloop.EventLoopPolicy):\n        asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())", "loc": 38}
{"file": "sanic\\sanic\\server\\loop.py", "class_name": null, "function_name": "try_windows_loop", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["asyncio.WindowsSelectorEventLoopPolicy", "asyncio.get_event_loop_policy", "asyncio.set_event_loop_policy", "error_logger.warning", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Try to use the WindowsSelectorEventLoopPolicy instead of the default", "source_code": "def try_windows_loop():\n    \"\"\"Try to use the WindowsSelectorEventLoopPolicy instead of the default\"\"\"\n    if not OS_IS_WINDOWS:\n        error_logger.warning(\n            \"You are trying to use an event loop policy that is not \"\n            \"compatible with your system. You can simply let Sanic handle \"\n            \"selecting the best loop for you. Sanic will now continue to run \"\n            \"using the default event loop.\"\n        )\n        return\n\n    if not isinstance(\n        asyncio.get_event_loop_policy(), asyncio.WindowsSelectorEventLoopPolicy\n    ):\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())", "loc": 15}
{"file": "sanic\\sanic\\server\\socket.py", "class_name": null, "function_name": "bind_socket", "parameters": ["host", "port"], "param_types": {"host": "str", "port": "int"}, "return_type": "socket.socket", "param_doc": {"host": "IPv4, IPv6 or hostname may be specified", "port": "TCP port number", "backlog": "Maximum number of connections to queue"}, "return_doc": "socket.socket object", "raises_doc": [], "called_functions": ["ip_address", "sock.bind", "sock.listen", "sock.set_inheritable", "sock.setsockopt", "socket.socket", "str"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Create TCP server socket.", "source_code": "def bind_socket(host: str, port: int, *, backlog=100) -> socket.socket:\n    \"\"\"Create TCP server socket.\n    :param host: IPv4, IPv6 or hostname may be specified\n    :param port: TCP port number\n    :param backlog: Maximum number of connections to queue\n    :return: socket.socket object\n    \"\"\"\n    location = (host, port)\n    # socket.share, socket.fromshare\n    try:  # IP address: family must be specified for IPv6 at least\n        ip = ip_address(host)\n        host = str(ip)\n        sock = socket.socket(\n            socket.AF_INET6 if ip.version == 6 else socket.AF_INET\n        )\n    except ValueError:  # Hostname, may become AF_INET or AF_INET6\n        sock = socket.socket()\n    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    sock.bind(location)\n    sock.listen(backlog)\n    sock.set_inheritable(True)\n    return sock", "loc": 22}
{"file": "sanic\\sanic\\server\\socket.py", "class_name": null, "function_name": "bind_unix_socket", "parameters": ["path"], "param_types": {"path": "Union[Path, str]"}, "return_type": "socket.socket", "param_doc": {"path": "filesystem path", "backlog": "Maximum number of connections to queue"}, "return_doc": "socket.socket object", "raises_doc": [], "called_functions": ["FileExistsError", "FileNotFoundError", "Path", "folder.is_dir", "path.lstat", "path.with_name", "secrets.token_urlsafe", "sock.bind", "sock.close", "sock.listen", "socket.socket", "stat.S_ISSOCK", "tmp_path.as_posix", "tmp_path.chmod", "tmp_path.rename", "tmp_path.unlink"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Create unix socket.", "source_code": "def bind_unix_socket(\n    path: Union[Path, str], *, mode=0o666, backlog=100\n) -> socket.socket:\n    \"\"\"Create unix socket.\n    :param path: filesystem path\n    :param backlog: Maximum number of connections to queue\n    :return: socket.socket object\n    \"\"\"\n\n    # Sanitise and pre-verify socket path\n    path = Path(path)\n    folder = path.parent\n    if not folder.is_dir():\n        raise FileNotFoundError(f\"Socket folder does not exist: {folder}\")\n    try:\n        if not stat.S_ISSOCK(path.lstat().st_mode):\n            raise FileExistsError(f\"Existing file is not a socket: {path}\")\n    except FileNotFoundError:\n        pass\n    # Create new socket with a random temporary name\n    tmp_path = path.with_name(f\"{path.name}.{secrets.token_urlsafe()}\")\n    sock = socket.socket(socket.AF_UNIX)\n    try:\n        # Critical section begins (filename races)\n        sock.bind(tmp_path.as_posix())\n        try:\n            tmp_path.chmod(mode)\n            # Start listening before rename to avoid connection failures\n            sock.listen(backlog)\n            tmp_path.rename(path)\n        except:  # noqa: E722\n            try:\n                tmp_path.unlink()\n            finally:\n                raise\n    except:  # noqa: E722\n        try:\n            sock.close()\n        finally:\n            raise\n    return sock", "loc": 41}
{"file": "sanic\\sanic\\server\\socket.py", "class_name": null, "function_name": "remove_unix_socket", "parameters": ["path"], "param_types": {"path": "Optional[Union[Path, str]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "path.as_posix", "path.lstat", "path.unlink", "socket.socket", "stat.S_ISSOCK", "testsock.connect"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Remove dead unix socket during server exit.", "source_code": "def remove_unix_socket(path: Optional[Union[Path, str]]) -> None:\n    \"\"\"Remove dead unix socket during server exit.\"\"\"\n    if not path:\n        return\n    try:\n        path = Path(path)\n        if stat.S_ISSOCK(path.lstat().st_mode):\n            # Is it actually dead (doesn't belong to a new server instance)?\n            with socket.socket(socket.AF_UNIX) as testsock:\n                try:\n                    testsock.connect(path.as_posix())\n                except ConnectionRefusedError:\n                    path.unlink()\n    except FileNotFoundError:\n        pass", "loc": 15}
{"file": "sanic\\sanic\\server\\socket.py", "class_name": null, "function_name": "configure_socket", "parameters": ["server_settings"], "param_types": {"server_settings": "dict[str, Any]"}, "return_type": "Optional[socket.SocketType]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Path", "Path(unix).absolute", "ServerError", "bind_socket", "bind_unix_socket", "server_settings.get", "sock.set_inheritable"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def configure_socket(\n    server_settings: dict[str, Any],\n) -> Optional[socket.SocketType]:\n    # Create a listening socket or use the one in settings\n    if server_settings.get(\"version\") is HTTP.VERSION_3:\n        return None\n    sock = server_settings.get(\"sock\")\n    unix = server_settings[\"unix\"]\n    backlog = server_settings[\"backlog\"]\n    if unix:\n        unix = Path(unix).absolute()\n        sock = bind_unix_socket(unix, backlog=backlog)\n        server_settings[\"unix\"] = unix\n    if sock is None:\n        try:\n            sock = bind_socket(\n                server_settings[\"host\"],\n                server_settings[\"port\"],\n                backlog=backlog,\n            )\n        except OSError as e:  # no cov\n            error = ServerError(\n                f\"Sanic server could not start: {e}.\\n\\n\"\n                \"This may have happened if you are running Sanic in the \"\n                \"global scope and not inside of a \"\n                '`if __name__ == \"__main__\"` block.\\n\\nSee more information: '\n                \"https://sanic.dev/en/guide/deployment/manager.html#\"\n                \"how-sanic-server-starts-processes\\n\"\n            )\n            error.quiet = True\n            raise error\n        sock.set_inheritable(True)\n        server_settings[\"sock\"] = sock\n        server_settings[\"host\"] = None\n        server_settings[\"port\"] = None\n    return sock", "loc": 36}
{"file": "sanic\\sanic\\server\\protocols\\base_protocol.py", "class_name": "SanicProtocol", "function_name": "ctx", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ctx(self):\n    if self.conn_info is not None:\n        return self.conn_info.ctx\n    else:\n        return None", "loc": 5}
{"file": "sanic\\sanic\\server\\protocols\\base_protocol.py", "class_name": "SanicProtocol", "function_name": "close", "parameters": ["self", "timeout"], "param_types": {"timeout": "Optional[float]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._can_write.is_set", "self.loop.call_soon", "self.transport.close", "self.transport.get_write_buffer_size", "self.transport.is_closing"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Attempt close the connection.", "source_code": "def close(self, timeout: Optional[float] = None):\n    \"\"\"\n    Attempt close the connection.\n    \"\"\"\n    if self.transport is None or self.transport.is_closing():\n        # do not attempt to close again, already aborted or closing\n        return\n\n    # Check if write is already paused _before_ close() is called.\n    write_was_paused = not self._can_write.is_set()\n    # Trigger the UVLoop Stream Transport Close routine\n    # Causes a call to connection_lost where further cleanup occurs\n    # Close may fully close the connection now, but if there is still\n    # data in the libuv buffer, then close becomes an async operation\n    self.transport.close()\n    try:\n        # Check write-buffer data left _after_ close is called.\n        # in UVLoop, get the data in the libuv transport write-buffer\n        data_left = self.transport.get_write_buffer_size()\n    # Some asyncio implementations don't support get_write_buffer_size\n    except (AttributeError, NotImplementedError):\n        data_left = 0\n    if write_was_paused or data_left > 0:\n        # don't call resume_writing here, it gets called by the transport\n        # to unpause the protocol when it is ready for more data\n\n        # Schedule the async close checker, to close the connection\n        # after the transport is done, and clean everything up.\n        if timeout is None:\n            # This close timeout needs to be less than the graceful\n            # shutdown timeout. The graceful shutdown _could_ be waiting\n            # for this transport to close before shutting down the app.\n            timeout = self.app.config.GRACEFUL_TCP_CLOSE_TIMEOUT\n            # This is 5s by default.\n    else:\n        # Schedule the async close checker but with no timeout,\n        # this will ensure abort() is called if required.\n        if timeout is None:\n            timeout = 0\n    self.loop.call_soon(\n        _async_protocol_transport_close,\n        self,\n        self.loop,\n        timeout,\n    )", "loc": 45}
{"file": "sanic\\sanic\\server\\protocols\\base_protocol.py", "class_name": "SanicProtocol", "function_name": "abort", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.transport.abort"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Force close the connection.", "source_code": "def abort(self):\n    \"\"\"\n    Force close the connection.\n    \"\"\"\n    # Cause a call to connection_lost where further cleanup occurs\n    if self.transport:\n        self.transport.abort()\n        self.transport = None", "loc": 8}
{"file": "sanic\\sanic\\server\\protocols\\base_protocol.py", "class_name": "SanicProtocol", "function_name": "connection_made", "parameters": ["self", "transport"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ConnInfo", "error_logger.exception", "self.connections.add", "transport.set_write_buffer_limits"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Generic connection-made, with no connection_task, and no recv_buffer. Override this for protocol-specific connection implementations.", "source_code": "def connection_made(self, transport):\n    \"\"\"\n    Generic connection-made, with no connection_task, and no recv_buffer.\n    Override this for protocol-specific connection implementations.\n    \"\"\"\n    try:\n        transport.set_write_buffer_limits(low=16384, high=65536)\n        self.connections.add(self)\n        self.transport = transport\n        self.conn_info = ConnInfo(self.transport, unix=self._unix)\n    except Exception:\n        error_logger.exception(\"protocol.connect_made\")", "loc": 12}
{"file": "sanic\\sanic\\server\\protocols\\base_protocol.py", "class_name": "SanicProtocol", "function_name": "connection_lost", "parameters": ["self", "exc"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["error_logger.exception", "self._task.cancel", "self.connections.discard", "self.resume_writing"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "This is a callback handler that is called from the asyncio transport layer implementation (eg, UVLoop's UVStreamTransport). It is scheduled to be called async after the transport has closed.", "source_code": "def connection_lost(self, exc):\n    \"\"\"\n    This is a callback handler that is called from the asyncio\n    transport layer implementation (eg, UVLoop's UVStreamTransport).\n    It is scheduled to be called async after the transport has closed.\n    When data is still in the send buffer, this call to connection_lost\n    will be delayed until _after_ the buffer is finished being sent.\n\n    So we can use this callback as a confirmation callback\n    that the async write-buffer transfer is finished.\n    \"\"\"\n    try:\n        self.connections.discard(self)\n        # unblock the send queue if it is paused,\n        # this allows the route handler to see\n        # the CancelledError exception\n        self.resume_writing()\n        self.conn_info.lost = True\n        if self._task:\n            self._task.cancel()\n    except BaseException:\n        error_logger.exception(\"protocol.connection_lost\")", "loc": 22}
{"file": "sanic\\sanic\\server\\protocols\\base_protocol.py", "class_name": "SanicProtocol", "function_name": "data_received", "parameters": ["self", "data"], "param_types": {"data": "bytes"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["current_time", "error_logger.exception", "self._data_received.set", "self.close"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def data_received(self, data: bytes):\n    try:\n        self._time = current_time()\n        if not data:\n            return self.close()\n\n        if self._data_received:\n            self._data_received.set()\n    except BaseException:\n        error_logger.exception(\"protocol.data_received\")", "loc": 10}
{"file": "sanic\\sanic\\server\\protocols\\http_protocol.py", "class_name": "HttpProtocol", "function_name": "log_disconnect", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["access_logger.info", "id", "self.transport.get_extra_info", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def log_disconnect(self):\n    ip = self.transport.get_extra_info(\"peername\")\n\n    req = self._http.request\n    res = self._http.response\n    extra = {\n        \"status\": res.status if res else str(self._http.stage),\n        \"byte\": \"DISCONNECTED\",\n        \"host\": f\"{id(self):X}\"[-5:-1] + \"unx\",\n        \"request\": \"nil\",\n        \"duration\": \"\",\n    }\n    if req is not None:\n        if ip := req.client_ip:\n            extra[\"host\"] = f\"{ip}:{req.port}\"\n        extra[\"request\"] = f\"{req.method} {req.url}\"\n    access_logger.info(\"\", extra=extra)", "loc": 17}
{"file": "sanic\\sanic\\server\\protocols\\http_protocol.py", "class_name": "HttpProtocol", "function_name": "check_timeouts", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RequestTimeout", "ServiceUnavailable", "current_time", "error_logger.exception", "logger.debug", "max", "min", "self._task.cancel", "self.loop.call_later", "websockets_logger.debug"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Runs itself periodically to enforce any expired timeouts.", "source_code": "def check_timeouts(self):\n    \"\"\"\n    Runs itself periodically to enforce any expired timeouts.\n    \"\"\"\n    try:\n        if not self._task:\n            return\n        duration = current_time() - self._time\n        stage = self._http.stage\n        if stage is Stage.IDLE and duration > self.keep_alive_timeout:\n            logger.debug(\"KeepAlive Timeout. Closing connection.\")\n        elif stage is Stage.REQUEST and duration > self.request_timeout:\n            logger.debug(\"Request Timeout. Closing connection.\")\n            self._http.exception = RequestTimeout(\"Request Timeout\")\n        elif stage is Stage.HANDLER and self._http.upgrade_websocket:\n            websockets_logger.debug(\n                \"Handling websocket. Timeouts disabled.\"\n            )\n            return\n        elif (\n            stage in (Stage.HANDLER, Stage.RESPONSE, Stage.FAILED)\n            and duration > self.response_timeout\n        ):\n            logger.debug(\"Response Timeout. Closing connection.\")\n            self._http.exception = ServiceUnavailable(\"Response Timeout\")\n        else:\n            interval = (\n                min(\n                    self.keep_alive_timeout,\n                    self.request_timeout,\n                    self.response_timeout,\n                )\n                / 2\n            )\n            _interval = max(0.1, interval)\n            self._callback_check_timeouts = self.loop.call_later(\n                _interval, self.check_timeouts\n            )\n            return\n        cancel_msg_args = ()\n        cancel_msg_args = (\"Cancel connection task with a timeout\",)\n        self._task.cancel(*cancel_msg_args)\n    except Exception:\n        error_logger.exception(\"protocol.check_timeouts\")", "loc": 44}
{"file": "sanic\\sanic\\server\\protocols\\http_protocol.py", "class_name": "HttpProtocol", "function_name": "close", "parameters": ["self", "timeout"], "param_types": {"timeout": "Optional[float]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._callback_check_timeouts.cancel", "super", "super().close"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Requires to prevent checking timeouts for closed connections", "source_code": "def close(self, timeout: Optional[float] = None):\n    \"\"\"\n    Requires to prevent checking timeouts for closed connections\n    \"\"\"\n\n    if self._callback_check_timeouts:\n        self._callback_check_timeouts.cancel()\n    return super().close(timeout=timeout)", "loc": 8}
{"file": "sanic\\sanic\\server\\protocols\\http_protocol.py", "class_name": "HttpProtocol", "function_name": "close_if_idle", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "boolean - True if closed, false if staying open", "raises_doc": [], "called_functions": ["self.close"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Close the connection if a request is not being sent or received", "source_code": "def close_if_idle(self) -> bool:\n    \"\"\"\n    Close the connection if a request is not being sent or received\n\n    :return: boolean - True if closed, false if staying open\n    \"\"\"\n    if self._http is None or self._http.stage is Stage.IDLE:\n        self.close()\n        return True\n    return False", "loc": 10}
{"file": "sanic\\sanic\\server\\protocols\\http_protocol.py", "class_name": "HttpProtocol", "function_name": "connection_made", "parameters": ["self", "transport"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ConnInfo", "bytearray", "error_logger.exception", "self.connection_task", "self.connections.add", "self.loop.create_task", "transport.set_write_buffer_limits"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "HTTP-protocol-specific new connection handler", "source_code": "def connection_made(self, transport):\n    \"\"\"\n    HTTP-protocol-specific new connection handler\n    \"\"\"\n    try:\n        # TODO: Benchmark to find suitable write buffer limits\n        transport.set_write_buffer_limits(low=16384, high=65536)\n        self.connections.add(self)\n        self.transport = transport\n        self._task = self.loop.create_task(self.connection_task())\n        self.recv_buffer = bytearray()\n        self.conn_info = ConnInfo(self.transport, unix=self._unix)\n    except Exception:\n        error_logger.exception(\"protocol.connect_made\")", "loc": 14}
{"file": "sanic\\sanic\\server\\protocols\\http_protocol.py", "class_name": "HttpProtocol", "function_name": "data_received", "parameters": ["self", "data"], "param_types": {"data": "bytes"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["current_time", "error_logger.exception", "len", "self._data_received.set", "self.close", "self.transport.pause_reading"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def data_received(self, data: bytes):\n    try:\n        self._time = current_time()\n        if not data:\n            return self.close()\n        self.recv_buffer += data\n\n        if (\n            len(self.recv_buffer) >= self.app.config.REQUEST_BUFFER_SIZE\n            and self.transport\n        ):\n            self.transport.pause_reading()\n\n        if self._data_received:\n            self._data_received.set()\n    except Exception:\n        error_logger.exception(\"protocol.data_received\")", "loc": 17}
{"file": "sanic\\sanic\\server\\protocols\\websocket_protocol.py", "class_name": "WebSocketProtocol", "function_name": "connection_lost", "parameters": ["self", "exc"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.log_websocket", "self.websocket.connection_lost", "super", "super().connection_lost"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def connection_lost(self, exc):\n    if self.websocket is not None:\n        self.websocket.connection_lost(exc)\n    super().connection_lost(exc)\n    self.log_websocket(\"CLOSE\")\n    self.websocket_url = None\n    self.websocket_peer = None", "loc": 7}
{"file": "sanic\\sanic\\server\\protocols\\websocket_protocol.py", "class_name": "WebSocketProtocol", "function_name": "data_received", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.websocket.data_received", "super", "super().data_received"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def data_received(self, data):\n    if self.websocket is not None:\n        self.websocket.data_received(data)\n    else:\n        # Pass it to HttpProtocol handler first\n        # That will (hopefully) upgrade it to a websocket.\n        super().data_received(data)", "loc": 7}
{"file": "sanic\\sanic\\server\\protocols\\websocket_protocol.py", "class_name": "WebSocketProtocol", "function_name": "eof_received", "parameters": ["self"], "param_types": {}, "return_type": "Optional[bool]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.websocket.eof_received"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def eof_received(self) -> Optional[bool]:\n    if self.websocket is not None:\n        return self.websocket.eof_received()\n    else:\n        return False", "loc": 5}
{"file": "sanic\\sanic\\server\\protocols\\websocket_protocol.py", "class_name": "WebSocketProtocol", "function_name": "close", "parameters": ["self", "timeout"], "param_types": {"timeout": "Optional[float]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.websocket.end_connection", "super", "super().close"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self, timeout: Optional[float] = None):\n    # Called by HttpProtocol at the end of connection_task\n    # If we've upgraded to websocket, we do our own closing\n    if self.websocket is not None:\n        # Note, we don't want to use websocket.close()\n        # That is used for user's application code to send a\n        # websocket close packet. This is different.\n        self.websocket.end_connection(1001)\n    else:\n        super().close()", "loc": 10}
{"file": "sanic\\sanic\\server\\protocols\\websocket_protocol.py", "class_name": "WebSocketProtocol", "function_name": "close_if_idle", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.websocket.close", "self.websocket.end_connection", "self.websocket.loop.create_task", "super", "super().close_if_idle"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close_if_idle(self):\n    # Called by Sanic Server when shutting down\n    # If we've upgraded to websocket, shut it down\n    if self.websocket is not None:\n        if self.websocket.ws_proto.state in (CLOSING, CLOSED):\n            return True\n        elif self.websocket.loop is not None:\n            self.websocket.loop.create_task(self.websocket.close(1001))\n        else:\n            self.websocket.end_connection(1001)\n    else:\n        return super().close_if_idle()", "loc": 12}
{"file": "sanic\\sanic\\server\\protocols\\websocket_protocol.py", "class_name": "WebSocketProtocol", "function_name": "log_websocket", "parameters": ["self", "message"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["access_logger.info", "codes.get", "repr"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def log_websocket(self, message):\n    if not self.access_log or not self.websocket_url:\n        return\n    status = \"\"\n    close = \"\"\n    try:\n        # Can we get some useful statistics?\n        p = self.websocket.ws_proto\n        state = p.state\n        if state == CLOSED:\n            codes = {\n                1000: \"NORMAL\",\n                1001: \"GOING AWAY\",\n                1005: \"NO STATUS\",\n                1006: \"ABNORMAL\",\n                1011: \"SERVER ERR\",\n            }\n            if p.close_code == 1006:\n                message = \"CLOSE_ABN\"\n            scode = rcode = 1006  # Abnormal closure (disconnection)\n            sdesc = rdesc = \"\"\n            if p.close_sent:\n                scode = p.close_sent.code\n                sdesc = p.close_sent.reason\n            if p.close_rcvd:\n                rcode = p.close_rcvd.code\n                rdesc = p.close_rcvd.reason\n            # Use repr() to escape any control characters\n            sdesc = repr(sdesc[:256]) if sdesc else codes.get(scode, \"\")\n            rdesc = repr(rdesc[:256]) if rdesc else codes.get(rcode, \"\")\n            if p.close_rcvd_then_sent or scode == 1006:\n                status = rcode\n                close = (\n                    f\"{rdesc} from client\"\n                    if scode in (rcode, 1006)\n                    else f\"{rdesc}  {scode} {sdesc}\"\n                )\n            else:\n                status = scode\n                close = (\n                    f\"{sdesc} from server\"\n                    if rcode in (scode, 1006)\n                    else f\"{sdesc}  {rcode} {rdesc}\"\n                )\n\n    except AttributeError:\n        ...\n    extra = {\n        \"status\": status,\n        \"byte\": close,\n        \"host\": self.websocket_peer,\n        \"request\": f\"  {self.websocket_url}\",\n        \"duration\": \"\",\n    }\n    access_logger.info(message, extra=extra)", "loc": 55}
{"file": "sanic\\sanic\\server\\websockets\\impl.py", "class_name": "WebsocketImplProtocol", "function_name": "pause_frames", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.io_proto.transport.pause_reading", "self.loop.create_future", "websockets_logger.debug"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def pause_frames(self):\n    if not self.can_pause:\n        return False\n    if self.pause_frame_fut:\n        websockets_logger.debug(\"Websocket connection already paused.\")\n        return False\n    if (not self.loop) or (not self.io_proto):\n        return False\n    if self.io_proto.transport:\n        self.io_proto.transport.pause_reading()\n    self.pause_frame_fut = self.loop.create_future()\n    websockets_logger.debug(\"Websocket connection paused.\")\n    return True", "loc": 13}
{"file": "sanic\\sanic\\server\\websockets\\impl.py", "class_name": "WebsocketImplProtocol", "function_name": "resume_frames", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.io_proto.transport.resume_reading", "self.pause_frame_fut.set_result", "websockets_logger.debug"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def resume_frames(self):\n    if not self.pause_frame_fut:\n        websockets_logger.debug(\"Websocket connection not paused.\")\n        return False\n    if (not self.loop) or (not self.io_proto):\n        websockets_logger.debug(\n            \"Websocket attempting to resume reading frames, \"\n            \"but connection is gone.\"\n        )\n        return False\n    if self.io_proto.transport:\n        self.io_proto.transport.resume_reading()\n    self.pause_frame_fut.set_result(None)\n    self.pause_frame_fut = None\n    websockets_logger.debug(\"Websocket connection unpaused.\")\n    return True", "loc": 16}
{"file": "sanic\\sanic\\server\\websockets\\impl.py", "class_name": "WebsocketImplProtocol", "function_name": "fail_connection", "parameters": ["self", "code", "reason"], "param_types": {"code": "int", "reason": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data_to_send.pop", "len", "self._force_disconnect", "self.auto_closer_task.done", "self.data_finished_fut.cancel", "self.data_finished_fut.done", "self.io_proto.transport.pause_reading", "self.io_proto.transport.write", "self.ws_proto.data_to_send", "self.ws_proto.fail", "self.ws_proto.send_close"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Fail the WebSocket Connection This requires: 1. Stopping all processing of incoming data, which means cancelling", "source_code": "def fail_connection(self, code: int = 1006, reason: str = \"\") -> bool:\n    \"\"\"\n    Fail the WebSocket Connection\n    This requires:\n    1. Stopping all processing of incoming data, which means cancelling\n       pausing the underlying io protocol. The close code will be 1006\n       unless a close frame was received earlier.\n    2. Sending a close frame with an appropriate code if the opening\n       handshake succeeded and the other side is likely to process it.\n    3. Closing the connection. :meth:`auto_close_connection` takes care\n       of this.\n    (The specification describes these steps in the opposite order.)\n    \"\"\"\n    if self.io_proto and self.io_proto.transport:\n        # Stop new data coming in\n        # In Python Version 3.7: pause_reading is idempotent\n        # ut can be called when the transport is already paused or closed\n        self.io_proto.transport.pause_reading()\n\n        # Keeping fail_connection() synchronous guarantees it can't\n        # get stuck and simplifies the implementation of the callers.\n        # Not draining the write buffer is acceptable in this context.\n\n        # clear the send buffer\n        _ = self.ws_proto.data_to_send()\n        # If we're not already CLOSED or CLOSING, then send the close.\n        if self.ws_proto.state is OPEN:\n            if code in (1000, 1001):\n                self.ws_proto.send_close(code, reason)\n            else:\n                self.ws_proto.fail(code, reason)\n            try:\n                data_to_send = self.ws_proto.data_to_send()\n                while (\n                    len(data_to_send)\n                    and self.io_proto\n                    and self.io_proto.transport\n                ):\n                    frame_data = data_to_send.pop(0)\n                    self.io_proto.transport.write(frame_data)\n            except Exception:\n                # sending close frames may fail if the\n                # transport closes during this period\n                ...\n    if code == 1006:\n        # Special case: 1006 consider the transport already closed\n        self.ws_proto.state = CLOSED\n    if self.data_finished_fut and not self.data_finished_fut.done():\n        # We have a graceful auto-closer. Use it to close the connection.\n        self.data_finished_fut.cancel()\n        self.data_finished_fut = None\n    if (not self.auto_closer_task) or self.auto_closer_task.done():\n        return self._force_disconnect()\n    return False", "loc": 54}
{"file": "sanic\\sanic\\server\\websockets\\impl.py", "class_name": "WebsocketImplProtocol", "function_name": "end_connection", "parameters": ["self", "code", "reason"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data_to_send.extend", "data_to_send.pop", "len", "self._force_disconnect", "self.auto_closer_task.done", "self.data_finished_fut.cancel", "self.data_finished_fut.done", "self.fail_connection", "self.io_proto.transport.pause_reading", "self.io_proto.transport.write", "self.ws_proto.data_to_send", "self.ws_proto.send_close"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def end_connection(self, code=1000, reason=\"\"):\n    # This is like slightly more graceful form of fail_connection\n    # Use this instead of close() when you need an immediate\n    # close and cannot await websocket.close() handshake.\n\n    if code == 1006 or not self.io_proto or not self.io_proto.transport:\n        return self.fail_connection(code, reason)\n\n    # Stop new data coming in\n    # In Python Version 3.7: pause_reading is idempotent\n    # i.e. it can be called when the transport is already paused or closed.\n    self.io_proto.transport.pause_reading()\n    if self.ws_proto.state == OPEN:\n        data_to_send = self.ws_proto.data_to_send()\n        self.ws_proto.send_close(code, reason)\n        data_to_send.extend(self.ws_proto.data_to_send())\n        try:\n            while (\n                len(data_to_send)\n                and self.io_proto\n                and self.io_proto.transport\n            ):\n                frame_data = data_to_send.pop(0)\n                self.io_proto.transport.write(frame_data)\n        except Exception:\n            # sending close frames may fail if the\n            # transport closes during this period\n            # But that doesn't matter at this point\n            ...\n    if self.data_finished_fut and not self.data_finished_fut.done():\n        # We have the ability to signal the auto-closer\n        # try to trigger it to auto-close the connection\n        self.data_finished_fut.cancel()\n        self.data_finished_fut = None\n    if (not self.auto_closer_task) or self.auto_closer_task.done():\n        # Auto-closer is not running, do force disconnect\n        return self._force_disconnect()\n    return False", "loc": 38}
{"file": "sanic\\sanic\\server\\websockets\\impl.py", "class_name": "WebsocketImplProtocol", "function_name": "abort_pings", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ConnectionClosedError", "ServerError", "ping.cancel", "ping.set_exception", "self.pings.values"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Raise ConnectionClosed in pending keepalive pings. They'll never receive a pong once the connection is closed.", "source_code": "def abort_pings(self) -> None:\n    \"\"\"\n    Raise ConnectionClosed in pending keepalive pings.\n    They'll never receive a pong once the connection is closed.\n    \"\"\"\n    if self.ws_proto.state is not CLOSED:\n        raise ServerError(\n            \"Webscoket about_pings should only be called \"\n            \"after connection state is changed to CLOSED\"\n        )\n\n    for ping in self.pings.values():\n        ping.set_exception(ConnectionClosedError(None, None))\n        # If the exception is never retrieved, it will be logged when ping\n        # is garbage-collected. This is confusing for users.\n        # Given that ping is done (with an exception), canceling it does\n        # nothing, but it prevents logging the exception.\n        ping.cancel()", "loc": 18}
{"file": "sanic\\sanic\\server\\websockets\\impl.py", "class_name": "WebsocketImplProtocol", "function_name": "data_received", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["asyncio.create_task", "len", "self.async_data_received", "self.ws_proto.data_to_send", "self.ws_proto.events_received", "self.ws_proto.receive_data"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def data_received(self, data):\n    self.ws_proto.receive_data(data)\n    data_to_send = self.ws_proto.data_to_send()\n    events_to_process = self.ws_proto.events_received()\n    if len(data_to_send) > 0 or len(events_to_process) > 0:\n        asyncio.create_task(\n            self.async_data_received(data_to_send, events_to_process)\n        )", "loc": 8}
{"file": "sanic\\sanic\\server\\websockets\\impl.py", "class_name": "WebsocketImplProtocol", "function_name": "eof_received", "parameters": ["self"], "param_types": {}, "return_type": "Optional[bool]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["asyncio.create_task", "self.async_eof_received", "self.ws_proto.data_to_send", "self.ws_proto.events_received", "self.ws_proto.receive_eof"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def eof_received(self) -> Optional[bool]:\n    self.ws_proto.receive_eof()\n    data_to_send = self.ws_proto.data_to_send()\n    events_to_process = self.ws_proto.events_received()\n    asyncio.create_task(\n        self.async_eof_received(data_to_send, events_to_process)\n    )\n    return False", "loc": 8}
{"file": "sanic\\sanic\\server\\websockets\\impl.py", "class_name": "WebsocketImplProtocol", "function_name": "connection_lost", "parameters": ["self", "exc"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.abort_pings", "self.connection_lost_waiter.set_result", "self.ws_proto.fail"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "The WebSocket Connection is Closed.", "source_code": "def connection_lost(self, exc):\n    \"\"\"\n    The WebSocket Connection is Closed.\n    \"\"\"\n    if not self.ws_proto.state == CLOSED:\n        # signal to the websocket connection handler\n        # we've lost the connection\n        self.ws_proto.fail(code=1006)\n        self.ws_proto.state = CLOSED\n\n    self.abort_pings()\n    if self.connection_lost_waiter:\n        self.connection_lost_waiter.set_result(None)", "loc": 13}
{"file": "sanic\\sanic\\touchup\\service.py", "class_name": "TouchUp", "function_name": "run", "parameters": ["cls", "app"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BaseScheme.build", "dict", "getattr", "getmembers", "getmodule", "hasattr", "setattr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run(cls, app):\n    for target, method_name in cls._registry:\n        method = getattr(target, method_name)\n\n        if app.test_mode:\n            placeholder = f\"_{method_name}\"\n            if hasattr(target, placeholder):\n                method = getattr(target, placeholder)\n            else:\n                setattr(target, placeholder, method)\n\n        module = getmodule(target)\n        module_globals = dict(getmembers(module))\n        modified = BaseScheme.build(method, module_globals, app)\n        setattr(target, method_name, modified)\n\n        target.__touched__ = True", "loc": 17}
{"file": "sanic\\sanic\\touchup\\schemes\\altsvc.py", "class_name": "RemoveAltSvc", "function_name": "visit_Assign", "parameters": ["self", "node"], "param_types": {"node": "Assign"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "isinstance", "self._matches", "self._should_remove", "self.value"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_Assign(self, node: Assign) -> Any:\n    if any(self._matches(target) for target in node.targets):\n        if self._should_remove():\n            return None\n        assert isinstance(node.value, Constant)\n        node.value.value = self.value()\n    return node", "loc": 7}
{"file": "sanic\\sanic\\touchup\\schemes\\altsvc.py", "class_name": "RemoveAltSvc", "function_name": "value", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "values.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def value(self):\n    values = []\n    for info in self._app.state.server_info:\n        port = info.settings[\"port\"]\n        version = info.settings[\"version\"]\n        if version is HTTP.VERSION_3:\n            values.append(f'h3=\":{port}\"')\n    return \", \".join(values)", "loc": 8}
{"file": "sanic\\sanic\\touchup\\schemes\\base.py", "class_name": "BaseScheme", "function_name": "build", "parameters": ["cls", "method", "module_globals", "app"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["compile", "dedent", "exec", "getsource", "parse", "scheme", "visitor.visit"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def build(cls, method, module_globals, app):\n    raw_source = getsource(method)\n    src = dedent(raw_source)\n    node = parse(src)\n\n    for scheme in cls._registry:\n        for visitor in scheme(app)():\n            node = visitor.visit(node)\n\n    compiled_src = compile(node, method.__name__, \"exec\")\n    exec_locals: dict[str, Any] = {}\n    exec(compiled_src, module_globals, exec_locals)  # nosec\n    return exec_locals[method.__name__]", "loc": 13}
{"file": "sanic\\sanic\\touchup\\schemes\\ode.py", "class_name": "RemoveDispatch", "function_name": "visit_Expr", "parameters": ["self", "node"], "param_types": {"node": "Expr"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "isinstance", "logger.debug", "self._not_registered"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_Expr(self, node: Expr) -> Any:\n    call = node.value\n    if isinstance(call, Await):\n        call = call.value\n\n    func = getattr(call, \"func\", None)\n    args = getattr(call, \"args\", None)\n    if not func or not args:\n        return node\n\n    if isinstance(func, Attribute) and func.attr == \"dispatch\":\n        event = args[0]\n        if event_name := getattr(event, \"value\", None):\n            if self._not_registered(event_name):\n                logger.debug(\n                    f\"Disabling event: {event_name}\",\n                    extra={\"verbosity\": 2},\n                )\n                return None\n    return node", "loc": 20}
{"file": "sanic\\sanic\\worker\\inspector.py", "class_name": "Inspector", "function_name": "reload", "parameters": ["self", "zero_downtime"], "param_types": {"zero_downtime": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._publisher.send"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Reload the workers", "source_code": "def reload(self, zero_downtime: bool = False) -> None:\n    \"\"\"Reload the workers\n\n    Args:\n        zero_downtime (bool, optional): Whether to use zero downtime\n            reload. Defaults to `False`.\n    \"\"\"\n    message = \"__ALL_PROCESSES__:\"\n    if zero_downtime:\n        message += \":STARTUP_FIRST\"\n    self._publisher.send(message)", "loc": 11}
{"file": "sanic\\sanic\\worker\\inspector.py", "class_name": "Inspector", "function_name": "scale", "parameters": ["self", "replicas"], "param_types": {"replicas": "Union[str, int]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "logger.info", "self._publisher.send"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Scale the number of workers", "source_code": "def scale(self, replicas: Union[str, int]) -> str:\n    \"\"\"Scale the number of workers\n\n    Args:\n        replicas (Union[str, int]): The number of workers to scale to.\n\n    Returns:\n        str: A log message.\n    \"\"\"\n    num_workers = 1\n    if replicas:\n        num_workers = int(replicas)\n    log_msg = f\"Scaling to {num_workers}\"\n    logger.info(log_msg)\n    message = f\"__SCALE__:{num_workers}\"\n    self._publisher.send(message)\n    return log_msg", "loc": 17}
{"file": "sanic\\sanic\\worker\\loader.py", "class_name": "CertLoader", "function_name": "load", "parameters": ["self", "app"], "param_types": {"app": "SanicApp"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["creator.generate_cert", "process_to_context", "self._creator_class"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load(self, app: SanicApp):\n    if not self._creator_class:\n        return process_to_context(self._ssl_data)\n\n    creator = self._creator_class(app, self._key, self._cert)\n    return creator.generate_cert(self._localhost)", "loc": 6}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "manage", "parameters": ["self", "name", "func", "kwargs", "transient", "restartable", "tracked", "auto_start", "workers", "ident"], "param_types": {"name": "str", "func": "Callable[..., Any]", "kwargs": "dict[str, Any]", "transient": "bool", "restartable": "Optional[bool]", "tracked": "bool", "auto_start": "bool", "workers": "int", "ident": "str"}, "return_type": "Worker", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "Worker"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Instruct Sanic to manage a custom process.", "source_code": "def manage(\n    self,\n    name: str,\n    func: Callable[..., Any],\n    kwargs: dict[str, Any],\n    transient: bool = False,\n    restartable: Optional[bool] = None,\n    tracked: bool = True,\n    auto_start: bool = True,\n    workers: int = 1,\n    ident: str = \"\",\n) -> Worker:\n    \"\"\"Instruct Sanic to manage a custom process.\n\n    Args:\n        name (str): A name for the worker process\n        func (Callable[..., Any]): The function to call in the background process\n        kwargs (Dict[str, Any]): Arguments to pass to the function\n        transient (bool, optional): Whether to mark the process as transient. If `True`\n            then the Worker Manager will restart the process along\n            with any global restart (ex: auto-reload), defaults to `False`\n        restartable (Optional[bool], optional): Whether to mark the process as restartable. If\n            `True` then the Worker Manager will be able to restart the process\n            if prompted. If `transient=True`, this property will be implied\n            to be `True`, defaults to `None`\n        tracked (bool, optional): Whether to track the process after completion,\n            defaults to `True`\n        auto_start (bool, optional): Whether to start the process immediately, defaults to `True`\n        workers (int, optional): The number of worker processes to run. Defaults to `1`.\n        ident (str, optional): The identifier for the worker. If not provided, the name\n            passed will be used. Defaults to `\"\"`.\n\n    Returns:\n        Worker: The Worker instance\n    \"\"\"  # noqa: E501\n    if name in self.transient or name in self.durable:\n        raise ValueError(f\"Worker {name} already exists\")\n    restartable = restartable if restartable is not None else transient\n    if transient and not restartable:\n        raise ValueError(\n            \"Cannot create a transient worker that is not restartable\"\n        )\n    container = self.transient if transient else self.durable\n    worker = Worker(\n        ident or name,\n        name,\n        func,\n        kwargs,\n        self.context,\n        self.worker_state,\n        workers,\n        restartable,\n        tracked,\n        auto_start,\n    )\n    container[worker.name] = worker\n    return worker", "loc": 57}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "create_server", "parameters": ["self"], "param_types": {}, "return_type": "Worker", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["next", "self.manage"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Create a new server process.", "source_code": "def create_server(self) -> Worker:\n    \"\"\"Create a new server process.\n\n    Returns:\n        Worker: The Worker instance\n    \"\"\"\n    server_number = next(self._server_count)\n    return self.manage(\n        f\"{WorkerProcess.SERVER_LABEL}-{server_number}\",\n        self._serve,\n        self._server_settings,\n        transient=True,\n        restartable=True,\n        ident=f\"{WorkerProcess.SERVER_IDENTIFIER}{server_number:2}\",\n    )", "loc": 15}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "shutdown_server", "parameters": ["self", "name"], "param_types": {"name": "Optional[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["choice", "error_logger.error", "process.terminate", "self.transient.values", "worker.name.startswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Shutdown a server process.", "source_code": "def shutdown_server(self, name: Optional[str] = None) -> None:\n    \"\"\"Shutdown a server process.\n\n    Args:\n        name (Optional[str], optional): The name of the server process to shutdown.\n            If `None` then a random server will be chosen. Defaults to `None`.\n    \"\"\"  # noqa: E501\n    if not name:\n        servers = [\n            worker\n            for worker in self.transient.values()\n            if worker.name.startswith(WorkerProcess.SERVER_LABEL)\n        ]\n        if not servers:\n            error_logger.error(\n                \"Server shutdown failed because a server was not found.\"\n            )\n            return\n        worker = choice(servers)  # nosec B311\n    else:\n        worker = self.transient[name]\n\n    for process in worker.processes:\n        process.terminate()\n\n    del self.transient[worker.name]", "loc": 26}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "run", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.cleanup", "self.join", "self.monitor", "self.start", "self.terminate"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Run the worker manager.", "source_code": "def run(self):\n    \"\"\"Run the worker manager.\"\"\"\n    self.start()\n    self.monitor()\n    self.join()\n    self.terminate()\n    self.cleanup()", "loc": 7}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "start", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["process.set_state", "process.start"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Start the worker processes.", "source_code": "def start(self):\n    \"\"\"Start the worker processes.\"\"\"\n    for worker in self.workers:\n        for process in worker.processes:\n            if not worker.auto_start:\n                process.set_state(ProcessState.NONE, True)\n                continue\n            process.start()", "loc": 8}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "join", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["joined.add", "logger.debug", "process.join", "self.join", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Join the worker processes.", "source_code": "def join(self):\n    \"\"\"Join the worker processes.\"\"\"\n    logger.debug(\"Joining processes\", extra={\"verbosity\": 1})\n    joined = set()\n    for process in self.processes:\n        logger.debug(\n            f\"Found {process.pid} - {process.state.name}\",\n            extra={\"verbosity\": 1},\n        )\n        if process.state < ProcessState.JOINED:\n            logger.debug(f\"Joining {process.pid}\", extra={\"verbosity\": 1})\n            joined.add(process.pid)\n            process.join()\n    if joined:\n        self.join()", "loc": 15}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "terminate", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["process.terminate"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Terminate the worker processes.", "source_code": "def terminate(self):\n    \"\"\"Terminate the worker processes.\"\"\"\n    if not self._shutting_down:\n        for process in self.processes:\n            process.terminate()", "loc": 5}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "restart", "parameters": ["self", "process_names", "restart_order"], "param_types": {"process_names": "Optional[list[str]]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["list", "self.restarter.restart"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Restart the worker processes.", "source_code": "def restart(\n    self,\n    process_names: Optional[list[str]] = None,\n    restart_order=RestartOrder.SHUTDOWN_FIRST,\n    **kwargs,\n):\n    \"\"\"Restart the worker processes.\n\n    Args:\n        process_names (Optional[List[str]], optional): The names of the processes to restart.\n            If `None` then all processes will be restarted. Defaults to `None`.\n        restart_order (RestartOrder, optional): The order in which to restart the processes.\n            Defaults to `RestartOrder.SHUTDOWN_FIRST`.\n    \"\"\"  # noqa: E501\n    self.restarter.restart(\n        transient_processes=list(self.transient_processes),\n        durable_processes=list(self.durable_processes),\n        process_names=process_names,\n        restart_order=restart_order,\n        **kwargs,\n    )", "loc": 21}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "scale", "parameters": ["self", "num_worker"], "param_types": {"num_worker": "int"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "abs", "logger.info", "process.start", "range", "self.create_server", "self.shutdown_server"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def scale(self, num_worker: int):\n    if num_worker <= 0:\n        raise ValueError(\"Cannot scale to 0 workers.\")\n\n    change = num_worker - self.num_server\n    if change == 0:\n        logger.info(\n            f\"No change needed. There are already {num_worker} workers.\"\n        )\n        return\n\n    logger.info(f\"Scaling from {self.num_server} to {num_worker} workers\")\n    if change > 0:\n        for _ in range(change):\n            worker = self.create_server()\n            for process in worker.processes:\n                process.start()\n    else:\n        for _ in range(abs(change)):\n            self.shutdown_server()\n    self.num_server = num_worker", "loc": 21}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "monitor", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._cleanup_non_tracked_workers", "self._poll_monitor", "self._sync_states", "self.wait_for_ack"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Monitor the worker processes. First, wait for all of the workers to acknowledge that they are ready. Then, wait for messages from the workers. If a message is received then it is processed and the state of the worker is updated. Also used to restart, shutdown, and scale the workers.", "source_code": "def monitor(self):\n    \"\"\"Monitor the worker processes.\n\n    First, wait for all of the workers to acknowledge that they are ready.\n    Then, wait for messages from the workers. If a message is received\n    then it is processed and the state of the worker is updated.\n\n    Also used to restart, shutdown, and scale the workers.\n\n    Raises:\n        ServerKilled: Raised when a worker fails to come online.\n    \"\"\"\n    self.wait_for_ack()\n    while True:\n        try:\n            cycle = self._poll_monitor()\n            if cycle is MonitorCycle.BREAK:\n                break\n            elif cycle is MonitorCycle.CONTINUE:\n                continue\n            self._sync_states()\n            self._cleanup_non_tracked_workers()\n        except InterruptedError:\n            if not OS_IS_WINDOWS:\n                raise\n            break", "loc": 26}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "wait_for_ack", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["error_logger.error", "self._all_workers_ack", "self.kill", "self.monitor_publisher.send", "self.monitor_subscriber.poll", "self.monitor_subscriber.recv"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Wait for all of the workers to acknowledge that they are ready.", "source_code": "def wait_for_ack(self):  # no cov\n    \"\"\"Wait for all of the workers to acknowledge that they are ready.\"\"\"\n    misses = 0\n    message = (\n        \"It seems that one or more of your workers failed to come \"\n        \"online in the allowed time. Sanic is shutting down to avoid a \"\n        f\"deadlock. The current threshold is {self.THRESHOLD / 10}s. \"\n        \"If this problem persists, please check out the documentation \"\n        \"https://sanic.dev/en/guide/deployment/manager.html#worker-ack.\"\n    )\n    while not self._all_workers_ack():\n        if self.monitor_subscriber.poll(0.1):\n            monitor_msg = self.monitor_subscriber.recv()\n            if monitor_msg != \"__TERMINATE_EARLY__\":\n                self.monitor_publisher.send(monitor_msg)\n                continue\n            misses = self.THRESHOLD\n            message = (\n                \"One of your worker processes terminated before startup \"\n                \"was completed. Please solve any errors experienced \"\n                \"during startup. If you do not see an exception traceback \"\n                \"in your error logs, try running Sanic in a single \"\n                \"process using --single-process or single_process=True. \"\n                \"Once you are confident that the server is able to start \"\n                \"without errors you can switch back to multiprocess mode.\"\n            )\n        misses += 1\n        if misses > self.THRESHOLD:\n            error_logger.error(\n                \"Not all workers acknowledged a successful startup. \"\n                \"Shutting down.\\n\\n\" + message\n            )\n            self.kill()", "loc": 33}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "processes", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Get all of the processes.", "source_code": "def processes(self):\n    \"\"\"Get all of the processes.\"\"\"\n    for worker in self.workers:\n        for process in worker.processes:\n            if not process.pid:\n                continue\n            yield process", "loc": 7}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "kill", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.info", "os.getpgid", "os.kill", "os.killpg", "suppress"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "Kill all of the processes.", "source_code": "def kill(self):\n    \"\"\"Kill all of the processes.\"\"\"\n    for process in self.processes:\n        logger.info(\"Killing %s [%s]\", process.name, process.pid)\n        with suppress(ProcessLookupError):\n            try:\n                os.killpg(os.getpgid(process.pid), SIGKILL)\n            except OSError:\n                os.kill(process.pid, SIGKILL)\n    raise ServerKilled", "loc": 10}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "shutdown_signal", "parameters": ["self", "signal", "frame"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Signals", "logger.info", "self.kill", "self.monitor_publisher.send", "self.shutdown", "suppress"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Handle the shutdown signal.", "source_code": "def shutdown_signal(self, signal, frame):\n    \"\"\"Handle the shutdown signal.\"\"\"\n    if self._shutting_down:\n        logger.info(\"Shutdown interrupted. Killing.\")\n        with suppress(ServerKilled):\n            self.kill()\n        return\n\n    logger.info(\"Received signal %s. Shutting down.\", Signals(signal).name)\n    self.monitor_publisher.send(None)\n    self.shutdown()", "loc": 11}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "shutdown", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["process.is_alive", "process.terminate"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Shutdown the worker manager.", "source_code": "def shutdown(self):\n    \"\"\"Shutdown the worker manager.\"\"\"\n    for process in self.processes:\n        if process.is_alive():\n            process.terminate()\n    self._shutting_down = True", "loc": 6}
{"file": "sanic\\sanic\\worker\\manager.py", "class_name": "WorkerManager", "function_name": "remove_worker", "parameters": ["self", "worker"], "param_types": {"worker": "Worker"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["error_logger.error", "logger.info", "self.durable.pop", "self.transient.pop", "self.worker_state.pop", "worker.has_alive_processes"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_worker(self, worker: Worker) -> None:\n    if worker.tracked:\n        error_logger.error(\n            f\"Worker {worker.name} is tracked and cannot be removed.\"\n        )\n        return\n    if worker.has_alive_processes():\n        error_logger.error(\n            f\"Worker {worker.name} has alive processes and cannot be \"\n            \"removed.\"\n        )\n        return\n    self.transient.pop(worker.name, None)\n    self.durable.pop(worker.name, None)\n    for process in worker.processes:\n        self.worker_state.pop(process.name, None)\n    logger.info(\"Removed worker %s\", worker.name)\n    del worker", "loc": 18}
{"file": "sanic\\sanic\\worker\\multiplexer.py", "class_name": "WorkerMultiplexer", "function_name": "exit", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.debug"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Run cleanup at worker exit.", "source_code": "def exit(self):\n    \"\"\"Run cleanup at worker exit.\"\"\"\n    try:\n        del self._state._state[self.name]\n    except ConnectionRefusedError:\n        logger.debug(\"Monitor process has already exited.\")", "loc": 6}
{"file": "sanic\\sanic\\worker\\multiplexer.py", "class_name": "WorkerMultiplexer", "function_name": "restart", "parameters": ["self", "name", "all_workers", "zero_downtime"], "param_types": {"name": "str", "all_workers": "bool", "zero_downtime": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "name.endswith", "self._monitor_publisher.send"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Restart the worker.", "source_code": "def restart(\n    self,\n    name: str = \"\",\n    all_workers: bool = False,\n    zero_downtime: bool = False,\n):\n    \"\"\"Restart the worker.\n\n    Args:\n        name (str): The name of the process to restart.\n        all_workers (bool): Whether to restart all workers.\n        zero_downtime (bool): Whether to restart with zero downtime.\n    \"\"\"\n    if name and all_workers:\n        raise ValueError(\n            \"Ambiguous restart with both a named process and\"\n            \" all_workers=True\"\n        )\n    if not name:\n        name = \"__ALL_PROCESSES__:\" if all_workers else self.name\n    if not name.endswith(\":\"):\n        name += \":\"\n    if zero_downtime:\n        name += \":STARTUP_FIRST\"\n    self._monitor_publisher.send(name)", "loc": 25}
{"file": "sanic\\sanic\\worker\\process.py", "class_name": "WorkerProcess", "function_name": "set_state", "parameters": ["self", "state", "force"], "param_types": {"state": "ProcessState"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Exception"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_state(self, state: ProcessState, force=False):\n    if not force and state < self.state:\n        raise Exception(\"...\")\n    self.state = state\n    self.worker_state[self.name] = {\n        **self.worker_state[self.name],\n        \"state\": self.state.name,\n    }", "loc": 8}
{"file": "sanic\\sanic\\worker\\process.py", "class_name": "WorkerProcess", "function_name": "start", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_now", "logger.debug", "self._current_process.start", "self.set_state", "self.worker_state[self.name].get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start(self):\n    os.environ[\"SANIC_WORKER_NAME\"] = self.name\n    os.environ[\"SANIC_WORKER_IDENTIFIER\"] = self.ident\n    logger.debug(\n        f\"{Colors.BLUE}Starting a process: {Colors.BOLD}\"\n        f\"{Colors.SANIC}%s{Colors.END}\",\n        self.name,\n    )\n    self.set_state(ProcessState.STARTING)\n    self._current_process.start()\n    self.set_state(ProcessState.STARTED)\n    if not self.worker_state[self.name].get(\"starts\"):\n        self.worker_state[self.name] = {\n            **self.worker_state[self.name],\n            \"pid\": self.pid,\n            \"start_at\": get_now(),\n            \"starts\": 1,\n        }\n    del os.environ[\"SANIC_WORKER_NAME\"]\n    del os.environ[\"SANIC_WORKER_IDENTIFIER\"]", "loc": 20}
{"file": "sanic\\sanic\\worker\\process.py", "class_name": "WorkerProcess", "function_name": "exit", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.debug", "self.is_alive", "sleep"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def exit(self):\n    limit = 100\n    while self.is_alive() and limit > 0:\n        sleep(0.1)\n        limit -= 1\n\n    if not self.is_alive():\n        try:\n            del self.worker_state[self.name]\n        except ConnectionRefusedError:\n            logger.debug(\"Monitor process has already exited.\")\n        except KeyError:\n            logger.debug(\"Could not find worker state to delete.\")", "loc": 13}
{"file": "sanic\\sanic\\worker\\process.py", "class_name": "WorkerProcess", "function_name": "terminate", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.debug", "os.kill", "self.set_state"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def terminate(self):\n    if self.state is not ProcessState.TERMINATED:\n        logger.debug(\n            f\"{Colors.BLUE}Terminating a process: \"\n            f\"{Colors.BOLD}{Colors.SANIC}\"\n            f\"%s {Colors.BLUE}[%s]{Colors.END}\",\n            self.name,\n            self.pid,\n        )\n        self.set_state(ProcessState.TERMINATED, force=True)\n        try:\n            os.kill(self.pid, SIGINT)\n        except (KeyError, AttributeError, ProcessLookupError):\n            ...", "loc": 14}
{"file": "sanic\\sanic\\worker\\process.py", "class_name": "WorkerProcess", "function_name": "restart", "parameters": ["self", "restart_order"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "get_now", "k.upper", "kwargs.items", "logger.debug", "self._add_config", "self._terminate_now", "self._terminate_soon", "self.kwargs.update", "self.set_state", "self.spawn", "self.start"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def restart(self, restart_order=RestartOrder.SHUTDOWN_FIRST, **kwargs):\n    logger.debug(\n        f\"{Colors.BLUE}Restarting a process: {Colors.BOLD}{Colors.SANIC}\"\n        f\"%s {Colors.BLUE}[%s]{Colors.END}\",\n        self.name,\n        self.pid,\n    )\n    self.set_state(ProcessState.RESTARTING, force=True)\n    if restart_order is RestartOrder.SHUTDOWN_FIRST:\n        self._terminate_now()\n    else:\n        self._old_process = self._current_process\n    if self._add_config():\n        self.kwargs.update(\n            {\"config\": {k.upper(): v for k, v in kwargs.items()}}\n        )\n    try:\n        self.spawn()\n        self.start()\n    except AttributeError:\n        raise RuntimeError(\"Restart failed\")\n\n    if restart_order is RestartOrder.STARTUP_FIRST:\n        self._terminate_soon()\n\n    self.worker_state[self.name] = {\n        **self.worker_state[self.name],\n        \"pid\": self.pid,\n        \"starts\": self.worker_state[self.name][\"starts\"] + 1,\n        \"restart_at\": get_now(),\n    }", "loc": 31}
{"file": "sanic\\sanic\\worker\\process.py", "class_name": "WorkerProcess", "function_name": "is_alive", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._current_process.is_alive"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_alive(self):\n    try:\n        return self._current_process.is_alive()\n    except AssertionError:\n        return False", "loc": 5}
{"file": "sanic\\sanic\\worker\\process.py", "class_name": "WorkerProcess", "function_name": "spawn", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Exception", "self.factory"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def spawn(self):\n    if self.state not in (ProcessState.IDLE, ProcessState.RESTARTING):\n        raise Exception(\"Cannot spawn a worker process until it is idle.\")\n    self._current_process = self.factory(\n        name=self.name,\n        target=self.target,\n        kwargs=self.kwargs,\n        daemon=True,\n    )", "loc": 9}
{"file": "sanic\\sanic\\worker\\process.py", "class_name": "Worker", "function_name": "create_process", "parameters": ["self"], "param_types": {}, "return_type": "WorkerProcess", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'-'.join", "WorkerProcess", "len", "self.processes.add", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_process(self) -> WorkerProcess:\n    process = WorkerProcess(\n        # Need to ignore this typing error - The problem is the\n        # BaseContext itself has no Process. But, all of its\n        # implementations do. We can safely ignore as it is a typing\n        # issue in the standard lib.\n        factory=self.context.Process,  # type: ignore\n        name=\"-\".join(\n            [self.WORKER_PREFIX, self.name, str(len(self.processes))]\n        ),\n        ident=self.ident,\n        target=self.serve,\n        kwargs={**self.server_settings},\n        worker_state=self.worker_state,\n        restartable=self.restartable,\n    )\n    self.processes.add(process)\n    return process", "loc": 18}
{"file": "sanic\\sanic\\worker\\reloader.py", "class_name": "Reloader", "function_name": "files", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["chain", "d.glob", "self.python_files"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def files(self):\n    return chain(\n        self.python_files(),\n        *(d.glob(\"**/*\") for d in self.reload_dirs),\n    )", "loc": 5}
{"file": "sanic\\sanic\\worker\\reloader.py", "class_name": "Reloader", "function_name": "check_file", "parameters": ["filename", "mtimes"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["mtimes.get", "os.stat"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_file(filename, mtimes) -> bool:\n    need_reload = False\n\n    mtime = os.stat(filename).st_mtime\n    old_time = mtimes.get(filename)\n    if old_time is None:\n        mtimes[filename] = mtime\n    elif mtime > old_time:\n        mtimes[filename] = mtime\n        need_reload = True\n\n    return need_reload", "loc": 12}
{"file": "sanic\\sanic\\worker\\restarter.py", "class_name": "Restarter", "function_name": "restart", "parameters": ["self", "transient_processes", "durable_processes", "process_names", "restart_order"], "param_types": {"transient_processes": "list[WorkerProcess]", "durable_processes": "list[WorkerProcess]", "process_names": "Optional[list[str]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["', '.join", "error_logger.error", "self._restart_durable", "self._restart_transient"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Restart the worker processes.", "source_code": "def restart(\n    self,\n    transient_processes: list[WorkerProcess],\n    durable_processes: list[WorkerProcess],\n    process_names: Optional[list[str]] = None,\n    restart_order=RestartOrder.SHUTDOWN_FIRST,\n    **kwargs,\n) -> None:\n    \"\"\"Restart the worker processes.\n\n    Args:\n        process_names (Optional[List[str]], optional): The names of the processes to restart.\n            If `None`, then all processes will be restarted. Defaults to `None`.\n        restart_order (RestartOrder, optional): The order in which to restart the processes.\n            Defaults to `RestartOrder.SHUTDOWN_FIRST`.\n    \"\"\"  # noqa: E501\n    restarted = self._restart_transient(\n        transient_processes,\n        process_names or [],\n        restart_order,\n        **kwargs,\n    )\n    restarted |= self._restart_durable(\n        durable_processes,\n        process_names or [],\n        restart_order,\n        **kwargs,\n    )\n\n    if process_names and not restarted:\n        error_logger.error(\n            f\"Failed to restart processes: {', '.join(process_names)}\"\n        )", "loc": 33}
{"file": "sanic\\sanic\\worker\\state.py", "class_name": "WorkerState", "function_name": "update", "parameters": ["self", "mapping"], "param_types": {"mapping": "MappingType[str, Any]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "mapping.keys", "self._write_error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update(self, mapping: MappingType[str, Any]) -> None:\n    if any(k in self.RESTRICTED for k in mapping.keys()):\n        self._write_error(\n            [k for k in mapping.keys() if k in self.RESTRICTED]\n        )\n    self._state[self._name] = {\n        **self._state[self._name],\n        **mapping,\n    }", "loc": 9}
{"file": "sanic\\scripts\\release.py", "class_name": null, "function_name": "release", "parameters": ["args"], "param_types": {"args": "Namespace"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["\"Tag mismatch between what's in git and what was provided by --current-version. Existing: {}, Give: {}\".format", "_fetch_current_version", "_get_current_tag", "_get_new_version", "_tag_release", "_update_release_version_for_sanic", "print", "sys.exit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def release(args: Namespace):\n    current_tag = _get_current_tag()\n    current_version = _fetch_current_version(args.config)\n    if current_tag and current_version not in current_tag:\n        print(\n            \"Tag mismatch between what's in git and what was provided by \"\n            \"--current-version. Existing: {}, Give: {}\".format(\n                current_tag, current_version\n            )\n        )\n        sys.exit(1)\n    new_version = args.release_version or _get_new_version(\n        args.config, current_version, args.micro_release\n    )\n    _update_release_version_for_sanic(\n        current_version=current_version,\n        new_version=new_version,\n        config_file=args.config,\n        generate_changelog=args.generate_changelog,\n    )\n    if args.tag_release:\n        _tag_release(\n            current_version=current_version,\n            new_version=new_version,\n            milestone=args.milestone,\n            release_name=args.release_name,\n            token=args.token,\n        )", "loc": 28}
{"file": "sty\\sty\\lib.py", "class_name": null, "function_name": "mute", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {"objects": "Pass multiple register-objects to the function."}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "isinstance", "obj.mute"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Use this function to mute multiple register-objects at once.", "source_code": "def mute(*objects: Register) -> None:\n    \"\"\"\n    Use this function to mute multiple register-objects at once.\n\n    :param objects: Pass multiple register-objects to the function.\n    \"\"\"\n    err = ValueError(\n        \"The mute() method can only be used with objects that inherit \"\n        \"from the 'Register class'.\"\n    )\n    for obj in objects:\n        if not isinstance(obj, Register):\n            raise err\n        obj.mute()", "loc": 14}
{"file": "sty\\sty\\lib.py", "class_name": null, "function_name": "unmute", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {"objects": "Pass multiple register-objects to the function."}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "isinstance", "obj.unmute"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Use this function to unmute multiple register-objects at once.", "source_code": "def unmute(*objects: Register) -> None:\n    \"\"\"\n    Use this function to unmute multiple register-objects at once.\n\n    :param objects: Pass multiple register-objects to the function.\n    \"\"\"\n    err = ValueError(\n        \"The unmute() method can only be used with objects that inherit \"\n        \"from the 'Register class'.\"\n    )\n    for obj in objects:\n        if not isinstance(obj, Register):\n            raise err\n        obj.unmute()", "loc": 14}
{"file": "sty\\sty\\primitive.py", "class_name": "Register", "function_name": "set_renderfunc", "parameters": ["self", "rendertype", "func"], "param_types": {"rendertype": "Type[RenderType]", "func": "Callable"}, "return_type": "None", "param_doc": {"rendertype": "The render type for which the new renderfunc is used.", "func": "The new render function."}, "return_doc": "", "raises_doc": [], "called_functions": ["dir", "getattr", "isinstance", "self.renderfuncs.update", "setattr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "With this method you can add or replace render-functions for a given register-object:", "source_code": "def set_renderfunc(self, rendertype: Type[RenderType], func: Callable) -> None:\n    \"\"\"\n    With this method you can add or replace render-functions for a given register-object:\n\n    :param rendertype: The render type for which the new renderfunc is used.\n    :param func: The new render function.\n    \"\"\"\n    # Save new render-func in register\n    self.renderfuncs.update({rendertype: func})\n\n    # Update style atributes and styles with the new renderfunc.\n    for attr_name in dir(self):\n        val = getattr(self, attr_name)\n        if isinstance(val, Style):\n            setattr(self, attr_name, val)", "loc": 15}
{"file": "sty\\sty\\primitive.py", "class_name": "Register", "function_name": "mute", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dir", "getattr", "isinstance", "setattr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Sometimes it is useful to disable the formatting for a register-object. You can do so by invoking this method.", "source_code": "def mute(self) -> None:\n    \"\"\"\n    Sometimes it is useful to disable the formatting for a register-object. You can\n    do so by invoking this method.\n    \"\"\"\n    self.is_muted = True\n\n    for attr_name in dir(self):\n        val = getattr(self, attr_name)\n        if isinstance(val, Style):\n            setattr(self, attr_name, val)", "loc": 11}
{"file": "sty\\sty\\primitive.py", "class_name": "Register", "function_name": "unmute", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dir", "getattr", "isinstance", "setattr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Use this method to unmute a previously muted register object.", "source_code": "def unmute(self) -> None:\n    \"\"\"\n    Use this method to unmute a previously muted register object.\n    \"\"\"\n    self.is_muted = False\n\n    for attr_name in dir(self):\n        val = getattr(self, attr_name)\n        if isinstance(val, Style):\n            setattr(self, attr_name, val)", "loc": 10}
{"file": "sty\\sty\\primitive.py", "class_name": "Register", "function_name": "as_dict", "parameters": ["self"], "param_types": {}, "return_type": "Dict[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dir", "getattr", "isinstance", "items.update", "name.startswith", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Export color register as dict.", "source_code": "def as_dict(self) -> Dict[str, str]:\n    \"\"\"\n    Export color register as dict.\n    \"\"\"\n    items: Dict[str, str] = {}\n\n    for name in dir(self):\n        if not name.startswith(\"_\") and isinstance(getattr(self, name), str):\n            items.update({name: str(getattr(self, name))})\n\n    return items", "loc": 11}
{"file": "sty\\sty\\primitive.py", "class_name": "Register", "function_name": "as_namedtuple", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["d.keys", "d.values", "namedtuple", "self.as_dict"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Export color register as namedtuple.", "source_code": "def as_namedtuple(self):\n    \"\"\"\n    Export color register as namedtuple.\n    \"\"\"\n    d = self.as_dict()\n    return namedtuple(\"StyleRegister\", d.keys())(*d.values())", "loc": 6}
{"file": "thonny\\data\\update_circuitpython_variants.py", "class_name": "IndexParser", "function_name": "handle_starttag", "parameters": ["self", "tag", "attrs"], "param_types": {"tag": "str", "attrs": "Dict[str, str]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_attr_value", "self.variants.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_starttag(self, tag: str, attrs: Dict[str, str]):\n    if tag == \"div\" and get_attr_value(attrs, \"class\") == \"download\":\n        data_id = get_attr_value(attrs, \"data-id\")\n        self.variants.append(\n            {\n                \"_id\": get_attr_value(attrs, \"data-id\"),\n                \"vendor\": get_attr_value(attrs, \"data-manufacturer\"),\n                \"model\": get_attr_value(attrs, \"data-name\"),\n                \"family\": get_attr_value(attrs, \"data-mcufamily\"),\n                \"info_url\": f\"https://circuitpython.org/board/{data_id}/\",\n            }\n        )", "loc": 12}
{"file": "thonny\\data\\update_micropython_variants.py", "class_name": "IndexParser", "function_name": "handle_starttag", "parameters": ["self", "tag", "attrs"], "param_types": {"tag": "str", "attrs": "Dict[str, str]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_attr_value", "self.variants.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_starttag(self, tag: str, attrs: Dict[str, str]):\n    if tag == \"a\" and get_attr_value(attrs, \"class\") == \"board-card\":\n        self._current_variant = {\"id\": get_attr_value(attrs, \"href\")}\n        self.variants.append(self._current_variant)\n\n    elif (\n        tag == \"div\"\n        and get_attr_value(attrs, \"class\") in [\"board-product\", \"board-vendor\"]\n        and self._current_variant\n    ):\n        self._current_attribute = get_attr_value(attrs, \"class\")", "loc": 11}
{"file": "thonny\\data\\update_micropython_variants.py", "class_name": "IndexParser", "function_name": "handle_endtag", "parameters": ["self", "tag"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_endtag(self, tag):\n    if tag == \"a\":\n        self._current_variant = None\n    elif tag == \"div\":\n        self._current_attribute = None", "loc": 5}
{"file": "thonny\\data\\update_pypi_summaries.py", "class_name": null, "function_name": "update_packages_json", "parameters": ["top_url", "extra_regexes", "target_path", "attributes"], "param_types": {"top_url": "Optional[str]", "extra_regexes": "List[str]", "target_path": "str", "attributes": "List[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fetch_metadata", "filter_atts", "fp.read", "fp.read().splitlines", "fp.write", "json.dump", "len", "line.endswith", "line[:-len(line_suffix)].split", "list", "normalize", "open", "os.path.exists", "packages.values", "print", "re.search", "requests.get", "requests.get(top_url).json", "sorted"], "control_structures": ["For", "If"], "behavior_type": ["file_io", "network_io", "serialization"], "doc_summary": "", "source_code": "def update_packages_json(top_url: Optional[str], extra_regexes: List[str], target_path: str,\n                         attributes: List[str]) -> None:\n    print(\"UPDATING\", target_path)\n    packages = {}\n    if top_url is not None:\n        top = requests.get(top_url).json()\n        for p in top:\n            if p[\"name\"] is None:\n                continue\n            packages[normalize(p[\"name\"])] = filter_atts(p, attributes)\n    else:\n        packages = {}\n\n    if extra_regexes:\n        index_path = \"pypi_simple.html\"\n        if not os.path.exists(index_path):\n            index = requests.get(\"https://pypi.org/simple/\")\n            with open(index_path, \"w\", encoding=\"utf-8\") as fp:\n                fp.write(index.text)\n\n        with open(index_path, encoding=\"utf-8\") as fp:\n            index_lines = fp.read().splitlines()\n\n        for line in index_lines:\n            line_suffix = \"</a>\"\n            if not line.endswith(line_suffix):\n                continue\n            name = normalize(line[:-(len(line_suffix))].split(\">\")[-1])\n            for regex in extra_regexes:\n                if re.search(regex, name):\n                    metadata = fetch_metadata(name, attributes)\n                    if metadata is not None:\n                        packages[name] = metadata\n                    break\n\n    sorted_packages = list(sorted(packages.values(), key=lambda s: s[\"name\"]))\n\n    with open(target_path, \"w\", encoding=\"utf-8\") as fp:\n        json.dump(sorted_packages, fp, indent=4, sort_keys=True)\n\n    print(\"DONE\\n\\n\")", "loc": 41}
{"file": "thonny\\data\\update_pypi_summaries.py", "class_name": null, "function_name": "filter_atts", "parameters": ["d", "attributes"], "param_types": {"d": "Dict[str, Any]", "attributes": "List[str]"}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def filter_atts(d: Dict[str, Any], attributes: List[str]) -> Dict[str, Any]:\n    result = {}\n    for att in attributes:\n        if att in d:\n            result[att] = d[att]\n\n    return result", "loc": 7}
{"file": "thonny\\data\\update_variants_common.py", "class_name": null, "function_name": "load_page_cache", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["json.load", "open", "os.path.exists"], "control_structures": ["If"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def load_page_cache():\n    if os.path.exists(PAGE_CACHE_PATH):\n        with open(PAGE_CACHE_PATH, \"rt\", encoding=\"utf-8\") as fp:\n            return json.load(fp)\n    else:\n        return {}", "loc": 6}
{"file": "thonny\\data\\update_variants_common.py", "class_name": null, "function_name": "find_download_links", "parameters": ["page_url", "stable_pattern", "max_stable_count", "unstable_pattern", "max_unstable_count", "url_prefix"], "param_types": {"page_url": "Union[str, List[str]]", "stable_pattern": "str", "max_stable_count": "int", "unstable_pattern": "str", "max_unstable_count": "int"}, "return_type": "List[Dict[str, str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FileLinksParser", "RuntimeError", "get_url_status_code", "isinstance", "len", "logging.error", "parser.feed", "re.search", "re.search(stable_pattern, link).group", "re.search(unstable_pattern, link).group", "read_page", "stables.append", "unstables.append"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_download_links(\n    page_url: Union[str, List[str]],\n    stable_pattern: str,\n    max_stable_count: int = 3,\n    unstable_pattern: str = \"\",\n    max_unstable_count: int = 0,\n    url_prefix=\"\",\n) -> List[Dict[str, str]]:\n    parser = FileLinksParser()\n    if isinstance(page_url, str):\n        page_urls = [page_url]\n    else:\n        assert isinstance(page_url, list)\n        page_urls = page_url\n\n    content = \"\"\n    for url in page_urls:\n        try:\n            content += read_page(url)\n        except Exception:\n            logging.error(\"Could not read page %s\", url)\n\n    parser.feed(content)\n\n    stables = []\n    unstables = []\n\n    for link in parser.links:\n        link = url_prefix + link\n        if len(stables) < max_stable_count and re.search(stable_pattern, link):\n            stables.append({\"version\": re.search(stable_pattern, link).group(1), \"url\": link})\n        elif len(unstables) < max_unstable_count and re.search(unstable_pattern, link):\n            unstables.append({\"version\": re.search(unstable_pattern, link).group(1), \"url\": link})\n\n    result = stables + unstables\n    for item in result:\n        url = item[\"url\"]\n        status_code = get_url_status_code(url)\n        if status_code not in [200, 302]:\n            #print(f\"Got {response.status_code} when downloading {url}\")\n            raise RuntimeError(f\"Got {status_code} when downloading {url}\")\n\n    return stables + unstables", "loc": 43}
{"file": "thonny\\data\\update_variants_common.py", "class_name": null, "function_name": "add_download_link_if_exists", "parameters": ["links", "link", "version"], "param_types": {"links": "List[Dict[str, str]]", "link": "str", "version": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_url_status_code", "links.append", "print"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_download_link_if_exists(links: List[Dict[str, str]], link: str, version: str) -> None:\n    status_code = get_url_status_code(link)\n    if status_code in [200, 302]:\n        links.append({\"version\": version, \"url\": link})\n    else:\n        print(f\"Could not download {link}, status: {status_code}\")", "loc": 6}
{"file": "thonny\\data\\update_variants_common.py", "class_name": null, "function_name": "get_attr_value", "parameters": ["attrs", "name"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_attr_value(attrs, name):\n    for key, value in attrs:\n        if key == name:\n            return value\n\n    return None", "loc": 6}
{"file": "thonny\\data\\update_variants_common.py", "class_name": null, "function_name": "add_defaults_and_downloads_to_variants", "parameters": ["defaults", "versions", "variants"], "param_types": {"defaults": "Dict[str, str]", "versions": "List[str]", "variants": "List[Dict[str, Any]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["add_download_link_if_exists", "enumerate", "len", "print", "variant.setdefault", "variant['_download_url_pattern'].format"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_defaults_and_downloads_to_variants(\n    defaults: Dict[str, str],\n    versions: List[str],\n    variants: List[Dict[str, Any]],\n) -> None:\n    for i, variant in enumerate(variants):\n        print(\"Updating variant\", i + 1, \"of\", len(variants))\n        for key in defaults:\n            variant.setdefault(key, defaults[key])\n\n        if \"downloads\" not in variant:\n            variant[\"downloads\"] = []\n\n        for version in versions:\n            download_url = variant[\"_download_url_pattern\"].format(\n                id=variant[\"_id\"], version=version\n            )\n\n            add_download_link_if_exists(variant[\"downloads\"], download_url, version)", "loc": 19}
{"file": "thonny\\data\\update_variants_common.py", "class_name": null, "function_name": "save_variants", "parameters": ["all_variants", "extensions", "families", "file_path", "latest_prerelease_regex"], "param_types": {"all_variants": "List", "extensions": "List[str]", "families": "Set[str]", "file_path": "str", "latest_prerelease_regex": "Optional[str]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["b.get", "b.get('title', b['model']).upper", "b['vendor'].upper", "download['url'].endswith", "filter", "final_variants.append", "json.dump", "key.startswith", "len", "list", "open", "print", "processed_variants.append", "relevant_downloads.append", "sorted", "title.lower", "title.lower() + ' '.startswith", "title.replace", "title[len(variant['vendor']):].strip", "variant.copy", "variant.get", "variant.keys", "variant['vendor'].lower"], "control_structures": ["For", "If"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def save_variants(\n    all_variants: List,\n    extensions: List[str],\n    families: Set[str],\n    file_path: str,\n    latest_prerelease_regex: Optional[str] = None,\n):\n    relevant_variants = list(filter(lambda v: v[\"family\"] in families, all_variants))\n    processed_variants = []\n    for variant in relevant_variants:\n        title = variant.get(\"title\", variant[\"model\"])\n        if (title.lower() + \" \").startswith(variant[\"vendor\"].lower()):\n            variant[\"title\"] = title[len(variant[\"vendor\"]) :].strip()\n        title = variant.get(\"title\", variant[\"model\"])\n\n        # special treatment for Pico\n        if variant[\"vendor\"] == \"Raspberry Pi\":\n            if \"Pimoroni\" not in variant.get(\"title\", \"\"):\n                variant[\"popular\"] = True\n            if variant[\"model\"] == \"Pico\":\n                variant[\"title\"] = title.replace(\"Pico\", \"Pico / Pico H\")\n            elif variant[\"model\"] == \"Pico W\":\n                variant[\"title\"] = title.replace(\"Pico W\", \"Pico W / Pico WH\")\n\n        variant_with_ordered_keys = {}\n        for key in VARIANT_KEY_ORDER:\n            if key in variant:\n                variant_with_ordered_keys[key] = variant[key]\n\n        processed_variants.append(variant_with_ordered_keys)\n\n    processed_variants = sorted(\n        processed_variants,\n        key=lambda b: (b[\"vendor\"].upper(), b.get(\"title\", b[\"model\"]).upper()),\n    )\n\n    # get rid of temporary/private attributes\n    final_variants = []\n    for variant in processed_variants:\n        variant = variant.copy()\n        relevant_downloads = []\n        for extension in extensions:\n            for download in variant[\"downloads\"]:\n                if download[\"url\"].endswith(extension):\n                    relevant_downloads.append(download)\n        if not relevant_downloads:\n            print(f\"No downloads relevant for {extension}:\", variant)\n            continue\n\n        variant[\"downloads\"] = relevant_downloads\n\n        for key in list(variant.keys()):\n            if key.startswith(\"_\"):\n                del variant[key]\n\n        final_variants.append(variant)\n\n    if latest_prerelease_regex and final_variants:\n        # This attribute signifies Thonny should look up the version of the latest unstable\n        # from the info page of this variant and use it all variants up to the next variant\n        # which has this attribute set.\n        final_variants[0][\"latest_prerelease_regex\"] = latest_prerelease_regex\n\n    with open(file_path, mode=\"w\", encoding=\"utf-8\", newline=\"\\n\") as fp:\n        json.dump(final_variants, fp, indent=4)", "loc": 65}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": null, "function_name": "add_LanguageServerServiceServicer_to_server", "parameters": ["servicer", "server"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["grpc.method_handlers_generic_handler", "grpc.unary_stream_rpc_method_handler", "grpc.unary_unary_rpc_method_handler", "server.add_generic_rpc_handlers", "server.add_registered_method_handlers"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_LanguageServerServiceServicer_to_server(servicer, server):\n    rpc_method_handlers = {\n            'GetCompletions': grpc.unary_unary_rpc_method_handler(\n                    servicer.GetCompletions,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.GetCompletionsRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.GetCompletionsResponse.SerializeToString,\n            ),\n            'AcceptCompletion': grpc.unary_unary_rpc_method_handler(\n                    servicer.AcceptCompletion,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.AcceptCompletionRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.AcceptCompletionResponse.SerializeToString,\n            ),\n            'Heartbeat': grpc.unary_unary_rpc_method_handler(\n                    servicer.Heartbeat,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.HeartbeatRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.HeartbeatResponse.SerializeToString,\n            ),\n            'GetAuthToken': grpc.unary_unary_rpc_method_handler(\n                    servicer.GetAuthToken,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.GetAuthTokenRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.GetAuthTokenResponse.SerializeToString,\n            ),\n            'RecordEvent': grpc.unary_unary_rpc_method_handler(\n                    servicer.RecordEvent,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.RecordEventRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.RecordEventResponse.SerializeToString,\n            ),\n            'CancelRequest': grpc.unary_unary_rpc_method_handler(\n                    servicer.CancelRequest,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.CancelRequestRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.CancelRequestResponse.SerializeToString,\n            ),\n            'Exit': grpc.unary_unary_rpc_method_handler(\n                    servicer.Exit,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.ExitRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.ExitResponse.SerializeToString,\n            ),\n            'GetProcesses': grpc.unary_unary_rpc_method_handler(\n                    servicer.GetProcesses,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.GetProcessesRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.GetProcessesResponse.SerializeToString,\n            ),\n            'GetChatMessage': grpc.unary_stream_rpc_method_handler(\n                    servicer.GetChatMessage,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.GetChatMessageRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.GetChatMessageResponse.SerializeToString,\n            ),\n            'RecordChatFeedback': grpc.unary_unary_rpc_method_handler(\n                    servicer.RecordChatFeedback,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.RecordChatFeedbackRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.RecordChatFeedbackResponse.SerializeToString,\n            ),\n            'RecordChatPanelSession': grpc.unary_unary_rpc_method_handler(\n                    servicer.RecordChatPanelSession,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.RecordChatPanelSessionRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.RecordChatPanelSessionResponse.SerializeToString,\n            ),\n            'ClusteredSearch': grpc.unary_unary_rpc_method_handler(\n                    servicer.ClusteredSearch,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.ClusteredSearchRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.ClusteredSearchResponse.SerializeToString,\n            ),\n            'ExactSearch': grpc.unary_unary_rpc_method_handler(\n                    servicer.ExactSearch,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.ExactSearchRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.ExactSearchResponse.SerializeToString,\n            ),\n            'AddTrackedWorkspace': grpc.unary_unary_rpc_method_handler(\n                    servicer.AddTrackedWorkspace,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.AddTrackedWorkspaceRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.AddTrackedWorkspaceResponse.SerializeToString,\n            ),\n            'RemoveTrackedWorkspace': grpc.unary_unary_rpc_method_handler(\n                    servicer.RemoveTrackedWorkspace,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.RemoveTrackedWorkspaceRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.RemoveTrackedWorkspaceResponse.SerializeToString,\n            ),\n            'RefreshContextForIdeAction': grpc.unary_unary_rpc_method_handler(\n                    servicer.RefreshContextForIdeAction,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.RefreshContextForIdeActionRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.RefreshContextForIdeActionResponse.SerializeToString,\n            ),\n            'GetFunctions': grpc.unary_unary_rpc_method_handler(\n                    servicer.GetFunctions,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.GetFunctionsRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.GetFunctionsResponse.SerializeToString,\n            ),\n            'GetUserStatus': grpc.unary_unary_rpc_method_handler(\n                    servicer.GetUserStatus,\n                    request_deserializer=exa_dot_language__server__pb_dot_language__server__pb2.GetUserStatusRequest.FromString,\n                    response_serializer=exa_dot_language__server__pb_dot_language__server__pb2.GetUserStatusResponse.SerializeToString,\n            ),\n    }\n    generic_handler = grpc.method_handlers_generic_handler(\n            'exa.language_server_pb.LanguageServerService', rpc_method_handlers)\n    server.add_generic_rpc_handlers((generic_handler,))\n    server.add_registered_method_handlers('exa.language_server_pb.LanguageServerService', rpc_method_handlers)", "loc": 97}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "GetCompletions", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def GetCompletions(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "AcceptCompletion", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def AcceptCompletion(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "Heartbeat", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def Heartbeat(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "GetAuthToken", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def GetAuthToken(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "RecordEvent", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def RecordEvent(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "CancelRequest", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def CancelRequest(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "Exit", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def Exit(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "GetProcesses", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def GetProcesses(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "GetChatMessage", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Chat RPCs.", "source_code": "def GetChatMessage(self, request, context):\n    \"\"\"Chat RPCs.\n    \"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 6}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "RecordChatFeedback", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def RecordChatFeedback(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "RecordChatPanelSession", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def RecordChatPanelSession(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "ClusteredSearch", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Search RPCs.", "source_code": "def ClusteredSearch(self, request, context):\n    \"\"\"Search RPCs.\n    \"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 6}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "ExactSearch", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def ExactSearch(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "AddTrackedWorkspace", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def AddTrackedWorkspace(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "RemoveTrackedWorkspace", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def RemoveTrackedWorkspace(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "RefreshContextForIdeAction", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Refresh context with editor state on IDE events happening.", "source_code": "def RefreshContextForIdeAction(self, request, context):\n    \"\"\"Refresh context with editor state on IDE events happening.\n    \"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 6}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "GetFunctions", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def GetFunctions(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\exa\\language_server_pb\\language_server_pb2_grpc.py", "class_name": "LanguageServerServiceServicer", "function_name": "GetUserStatus", "parameters": ["self", "request", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "context.set_code", "context.set_details"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Missing associated documentation comment in .proto file.", "source_code": "def GetUserStatus(self, request, context):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n    context.set_details('Method not implemented!')\n    raise NotImplementedError('Method not implemented!')", "loc": 5}
{"file": "thonny\\misc\\can.py", "class_name": null, "function_name": "on_click", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["canvas.find_overlapping", "canvas.tag_raise", "print"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_click(event):\n    stack = canvas.find_overlapping(event.x, event.y, event.x, event.y)\n    print(stack)\n    canvas.tag_raise(stack[-1])\n    global active_id\n    active_id = stack[-1]", "loc": 6}
{"file": "thonny\\misc\\docukatse.py", "class_name": null, "function_name": "reet_role", "parameters": ["role", "rawtext", "text", "lineno", "inliner", "options", "content"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["docutils.utils.unescape", "nodes.inline"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def reet_role(role, rawtext, text, lineno, inliner, options={}, content=[]):\n    \"\"\"\"\"\"\n    # Once nested inline markup is implemented, this and other methods should\n    # recursively call inliner.nested_parse().\n    options[\"classes\"] = \"reet\"\n    return [nodes.inline(rawtext, docutils.utils.unescape(text), **options)], []", "loc": 6}
{"file": "thonny\\misc\\filedlg.py", "class_name": null, "function_name": "ask_file", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["filedialog.asksaveasfilename", "print", "repr", "typevar.get"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ask_file():\n    res = filedialog.asksaveasfilename(parent=root, typevariable=typevar,\n                               filetypes=[(\"Python\", \".py .pyi\"),\n                                          (\"all\", \".*\")],\n                                       initialdir=\"/Users/user/python_stuff\")\n    print(repr(res), repr(typevar.get()))", "loc": 6}
{"file": "thonny\\misc\\format-lsp-flow.py", "class_name": null, "function_name": "format_message", "parameters": ["msg_str", "sender", "fp"], "param_types": {"msg_str": "str", "sender": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fp.write", "json.dumps", "json.loads", "print", "repr"], "control_structures": [], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def format_message(msg_str: str, sender: str, fp) -> None:\n    print(\"formatting\", repr(msg_str))\n    fp.write(f\"[[[ FROM {sender} ]]]\\n\")\n    msg = json.loads(msg_str)\n    fp.write(json.dumps(msg, indent=4, sort_keys=True))\n    fp.write(\"\\n\")", "loc": 6}
{"file": "thonny\\misc\\iterf.py", "class_name": null, "function_name": "print_ast", "parameters": ["node", "level"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.iter_fields", "isinstance", "print", "print_ast"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def print_ast(node, level):\n    print(\" \" * level, node)\n    for name, child in ast.iter_fields(node):\n        if isinstance(child, ast.AST):\n            print(\" \" * level, name, \":\")\n            print_ast(child, level + 1)\n        elif isinstance(child, list):\n            print(\" \" * level, name, \":[\")\n            for elem in child:\n                print_ast(elem, level + 1)\n            print(\" \" * level, \"]\")\n        else:\n            pass", "loc": 13}
{"file": "thonny\\misc\\kbd.py", "class_name": null, "function_name": "check", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["print", "repr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check(event):\n    print(\n        \"keycode:\",\n        event.keycode,\n        \"state:\",\n        event.state,\n        \"char:\",\n        repr(event.char),\n        \"keysym\",\n        event.keysym,\n        \"keysym_num\",\n        event.keysym_num,\n    )", "loc": 13}
{"file": "thonny\\misc\\mp_paste_mode.py", "class_name": null, "function_name": "forward_until", "parameters": ["marker"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["b.decode", "print", "s.read", "total.endswith"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def forward_until(marker):\n    total = b\"\"\n    while not total.endswith(marker):\n        b = s.read(1)\n        total += b\n        print(b.decode(\"UTF-8\"), end=\"\")", "loc": 6}
{"file": "thonny\\misc\\mp_repl_experiment.py", "class_name": null, "function_name": "forward_until", "parameters": ["marker", "must_include"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "b.decode", "print", "s.read", "s.read_all", "total.endswith"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def forward_until(marker, must_include=None):\n    total = b\"\"\n    while not total.endswith(marker):\n        b = s.read(1)\n        total += b\n        print(b.decode(\"UTF-8\"), end=\"\")\n\n    if must_include and must_include not in total:\n        raise RuntimeError(\"Did not find expected data in the output (%s)\"\n                           % (total + s.read_all()))", "loc": 10}
{"file": "thonny\\misc\\mp_repl_experiment.py", "class_name": null, "function_name": "prepare", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["print", "s.read_all", "s.read_until", "s.write"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def prepare():\n    print(\"Interrupting...\")\n    s.write(b\"\\x03\")\n    s.write(b\"\\x03\")\n    print(\"Cleaning...\", s.read_all())\n    s.write(b\"\\x02\")\n    s.read_until(b\">>> \")\n    print(\"Got normal prompt\")", "loc": 8}
{"file": "thonny\\misc\\mp_repl_experiment.py", "class_name": null, "function_name": "run_in_raw_mode", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["code.encode", "forward_until", "s.flush", "s.write", "str", "str(LENGTH_OF_STRING_LITERAL) + \" {'*'}\".encode", "time.sleep"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run_in_raw_mode():\n    data = code.encode(\"UTF-8\")\n    while data:\n        s.write(data[:BLOCK_SIZE])\n        s.flush()\n        data = data[BLOCK_SIZE:]\n        if data:\n            time.sleep(0.01)\n\n    s.write(b\"\\x04\")\n    forward_until(b\"OK\")\n    # wait until completion\n    expected_output = (str(LENGTH_OF_STRING_LITERAL) + \" {'*'}\").encode(\"UTF-8\")\n    forward_until(b\">\", must_include=expected_output)", "loc": 14}
{"file": "thonny\\misc\\mp_repl_experiment.py", "class_name": null, "function_name": "run_in_paste_mode", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["code.splitlines", "forward_until", "line.encode", "line.encode('UTF-8').replace", "s.flush", "s.write", "str", "str(LENGTH_OF_STRING_LITERAL) + \" {'*'}\".encode"], "control_structures": ["For", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run_in_paste_mode():\n    # goto paste mode\n    s.write(b\"\\x05\")\n    forward_until(b\"=== \")\n\n    for line in code.splitlines(keepends=True):\n        data = line.encode(\"UTF-8\").replace(b\"\\n\", b\"\\r\\n\")\n        while data:\n            block = data[:BLOCK_SIZE]\n            s.write(block)\n            s.flush()\n\n            forward_until(block)\n            #time.sleep(0.01)\n            data = data[BLOCK_SIZE:]\n\n    s.write(b\"\\x04\")\n    expected_output = (str(LENGTH_OF_STRING_LITERAL) + \" {'*'}\").encode(\"UTF-8\")\n    forward_until(b\">>> \", must_include=expected_output)", "loc": 19}
{"file": "thonny\\misc\\mp_thread_exp.py", "class_name": null, "function_name": "forward_until", "parameters": ["marker", "must_include"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "b.decode", "print", "s.read", "s.read_all", "total.endswith"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def forward_until(marker, must_include=None):\n    total = b\"\"\n    while not total.endswith(marker):\n        b = s.read(1)\n        total += b\n        print(b.decode(\"UTF-8\"), end=\"\")\n\n    if must_include and must_include not in total:\n        raise RuntimeError(\"Did not find expected data in the output (%s)\"\n                           % (total + s.read_all()))", "loc": 10}
{"file": "thonny\\misc\\mp_thread_exp.py", "class_name": null, "function_name": "run_in_paste_mode", "parameters": ["source"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["block.replace", "forward_until", "s.flush", "s.write"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run_in_paste_mode(source):\n    # goto paste mode\n    s.write(PASTE_MODE_CMD)\n    forward_until(b\"=== \")\n\n    while source:\n        block = source[:BLOCK_SIZE]\n        s.write(block)\n        s.flush()\n        forward_until(block.replace(b\"\\r\", b\"\\r=== \"))\n        source = source[BLOCK_SIZE:]\n\n    s.write(EOT)\n    forward_until(b\">>> \")", "loc": 14}
{"file": "thonny\\misc\\punktid.py", "class_name": null, "function_name": "arvuta", "parameters": ["punktid"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fafa", "len", "min", "momo", "punktid.index", "range", "sqrt", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def arvuta(punktid):\n    momo()\n\n    def fafa(n):\n        pass\n\n    fafa(0)\n    kokku = len(punktid)\n    kaugused_ja_vastavad_punktid = {}\n    m = 0\n    n = 0\n    for punkt in punktid:\n        for i in range(len(punktid)):\n            n += 1\n            esim_punkti_nr = str(punktid.index(punkt) + 1)\n            teise_punkti_nr = str(i + 1)\n            # fafa(n)\n            if punktid.index(punkt) == i:\n                continue\n            firstx = punkt[0]\n            firsty = punkt[1]\n            secondx = punktid[i][0]\n            secondy = punktid[i][1]\n            kaugus = sqrt((secondx - firstx) ** 2 + (secondy - firsty) ** 2)\n            kaugused_ja_vastavad_punktid[kaugus] = esim_punkti_nr, \"ja\", teise_punkti_nr\n    vhim = min(kaugused_ja_vastavad_punktid)\n    vhima_paari_nimi = kaugused_ja_vastavad_punktid[vhim]\n    return vhima_paari_nimi", "loc": 28}
{"file": "thonny\\misc\\pyboard.py", "class_name": null, "function_name": "execfile", "parameters": ["filename", "device", "baudrate", "user", "password"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Pyboard", "pyb.close", "pyb.enter_raw_repl", "pyb.execfile", "pyb.exit_raw_repl", "stdout_write_bytes"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def execfile(filename, device=\"/dev/ttyACM0\", baudrate=115200, user=\"micro\", password=\"python\"):\n    pyb = Pyboard(device, baudrate, user, password)\n    pyb.enter_raw_repl()\n    output = pyb.execfile(filename)\n    stdout_write_bytes(output)\n    pyb.exit_raw_repl()\n    pyb.close()", "loc": 7}
{"file": "thonny\\misc\\pyboard.py", "class_name": null, "function_name": "filesystem_command", "parameters": ["pyb", "args"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dest.endswith", "dest.startswith", "fname_cp_dest", "fname_remote", "op", "print", "pyb.close", "pyb.exit_raw_repl", "src.rsplit", "src.startswith", "srcs[0].startswith", "str", "sys.exit"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def filesystem_command(pyb, args):\n    def fname_remote(src):\n        if src.startswith(\":\"):\n            src = src[1:]\n        return src\n\n    def fname_cp_dest(src, dest):\n        src = src.rsplit(\"/\", 1)[-1]\n        if dest is None or dest == \"\":\n            dest = src\n        elif dest == \".\":\n            dest = \"./\" + src\n        elif dest.endswith(\"/\"):\n            dest += src\n        return dest\n\n    cmd = args[0]\n    args = args[1:]\n    try:\n        if cmd == \"cp\":\n            srcs = args[:-1]\n            dest = args[-1]\n            if srcs[0].startswith(\"./\") or dest.startswith(\":\"):\n                op = pyb.fs_put\n                fmt = \"cp %s :%s\"\n                dest = fname_remote(dest)\n            else:\n                op = pyb.fs_get\n                fmt = \"cp :%s %s\"\n            for src in srcs:\n                src = fname_remote(src)\n                dest2 = fname_cp_dest(src, dest)\n                print(fmt % (src, dest2))\n                op(src, dest2)\n        else:\n            op = {\n                \"ls\": pyb.fs_ls,\n                \"cat\": pyb.fs_cat,\n                \"mkdir\": pyb.fs_mkdir,\n                \"rmdir\": pyb.fs_rmdir,\n                \"rm\": pyb.fs_rm,\n            }[cmd]\n            if cmd == \"ls\" and not args:\n                args = [\"\"]\n            for src in args:\n                src = fname_remote(src)\n                print(\"%s :%s\" % (cmd, src))\n                op(src)\n    except PyboardError as er:\n        print(str(er.args[2], \"ascii\"))\n        pyb.exit_raw_repl()\n        pyb.close()\n        sys.exit(1)", "loc": 53}
{"file": "thonny\\misc\\pyboard.py", "class_name": "TelnetToSerial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytes", "len", "self.fifo.extend", "self.fifo.popleft", "self.tn.read_eager", "time.sleep"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read(self, size=1):\n    while len(self.fifo) < size:\n        timeout_count = 0\n        data = self.tn.read_eager()\n        if len(data):\n            self.fifo.extend(data)\n            timeout_count = 0\n        else:\n            time.sleep(0.25)\n            if self.read_timeout is not None and timeout_count > 4 * self.read_timeout:\n                break\n            timeout_count += 1\n\n    data = b\"\"\n    while len(data) < size and len(self.fifo) > 0:\n        data += bytes([self.fifo.popleft()])\n    return data", "loc": 17}
{"file": "thonny\\misc\\pyboard.py", "class_name": "TelnetToSerial", "function_name": "inWaiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.fifo.extend", "self.tn.read_eager"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def inWaiting(self):\n    n_waiting = len(self.fifo)\n    if not n_waiting:\n        data = self.tn.read_eager()\n        self.fifo.extend(data)\n        return len(data)\n    else:\n        return n_waiting", "loc": 8}
{"file": "thonny\\misc\\pyboard.py", "class_name": "ProcessToSerial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.subp.stdout.read"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read(self, size=1):\n    data = b\"\"\n    while len(data) < size:\n        data += self.subp.stdout.read(size - len(data))\n    return data", "loc": 5}
{"file": "thonny\\misc\\pyboard.py", "class_name": "ProcessToSerial", "function_name": "inWaiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.poll.poll"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def inWaiting(self):\n    # res = self.sel.select(0)\n    res = self.poll.poll(0)\n    if res:\n        return 1\n    return 0", "loc": 6}
{"file": "thonny\\misc\\pyboard.py", "class_name": "Pyboard", "function_name": "read_until", "parameters": ["self", "min_num_bytes", "ending", "timeout", "data_consumer"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.endswith", "data_consumer", "len", "self.serial.inWaiting", "self.serial.read", "time.sleep"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_until(self, min_num_bytes, ending, timeout=10, data_consumer=None):\n    # if data_consumer is used then data is not accumulated and the ending must be 1 byte long\n    assert data_consumer is None or len(ending) == 1\n\n    data = self.serial.read(min_num_bytes)\n    if data_consumer:\n        data_consumer(data)\n    timeout_count = 0\n    while True:\n        if data.endswith(ending):\n            break\n        elif self.serial.inWaiting() > 0:\n            new_data = self.serial.read(1)\n            if data_consumer:\n                data_consumer(new_data)\n                data = new_data\n            else:\n                data = data + new_data\n            timeout_count = 0\n        else:\n            timeout_count += 1\n            if timeout is not None and timeout_count >= 100 * timeout:\n                break\n            time.sleep(0.01)\n    return data", "loc": 25}
{"file": "thonny\\misc\\pyboard.py", "class_name": "Pyboard", "function_name": "enter_raw_repl", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PyboardError", "data.endswith", "print", "self.read_until", "self.serial.inWaiting", "self.serial.read", "self.serial.write"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def enter_raw_repl(self):\n    self.serial.write(b\"\\r\\x03\\x03\")  # ctrl-C twice: interrupt any running program\n\n    # flush input (without relying on serial.flushInput())\n    n = self.serial.inWaiting()\n    while n > 0:\n        self.serial.read(n)\n        n = self.serial.inWaiting()\n\n    self.serial.write(b\"\\r\\x01\")  # ctrl-A: enter raw REPL\n    data = self.read_until(1, b\"raw REPL; CTRL-B to exit\\r\\n>\")\n    if not data.endswith(b\"raw REPL; CTRL-B to exit\\r\\n>\"):\n        print(data)\n        raise PyboardError(\"could not enter raw repl\")\n\n    self.serial.write(b\"\\x04\")  # ctrl-D: soft reset\n    data = self.read_until(1, b\"soft reboot\\r\\n\")\n    if not data.endswith(b\"soft reboot\\r\\n\"):\n        print(data)\n        raise PyboardError(\"could not enter raw repl\")\n    # By splitting this into 2 reads, it allows boot.py to print stuff,\n    # which will show up after the soft reboot and before the raw REPL.\n    data = self.read_until(1, b\"raw REPL; CTRL-B to exit\\r\\n\")\n    if not data.endswith(b\"raw REPL; CTRL-B to exit\\r\\n\"):\n        print(data)\n        raise PyboardError(\"could not enter raw repl\")", "loc": 26}
{"file": "thonny\\misc\\pyboard.py", "class_name": "Pyboard", "function_name": "follow", "parameters": ["self", "timeout", "data_consumer"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PyboardError", "data.endswith", "data_err.endswith", "self.read_until"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def follow(self, timeout, data_consumer=None):\n    # wait for normal output\n    data = self.read_until(1, b\"\\x04\", timeout=timeout, data_consumer=data_consumer)\n    if not data.endswith(b\"\\x04\"):\n        raise PyboardError(\"timeout waiting for first EOF reception\")\n    data = data[:-1]\n\n    # wait for error output\n    data_err = self.read_until(1, b\"\\x04\", timeout=timeout)\n    if not data_err.endswith(b\"\\x04\"):\n        raise PyboardError(\"timeout waiting for second EOF reception\")\n    data_err = data_err[:-1]\n\n    # return normal and error output\n    return data, data_err", "loc": 15}
{"file": "thonny\\misc\\pyboard.py", "class_name": "Pyboard", "function_name": "exec_raw_no_follow", "parameters": ["self", "command"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PyboardError", "bytes", "data.endswith", "isinstance", "len", "min", "range", "self.read_until", "self.serial.read", "self.serial.write", "time.sleep"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def exec_raw_no_follow(self, command):\n    if isinstance(command, bytes):\n        command_bytes = command\n    else:\n        command_bytes = bytes(command, encoding=\"utf8\")\n\n    # check we have a prompt\n    data = self.read_until(1, b\">\")\n    if not data.endswith(b\">\"):\n        raise PyboardError(\"could not enter raw repl\")\n\n    # write command\n    for i in range(0, len(command_bytes), 256):\n        self.serial.write(command_bytes[i : min(i + 256, len(command_bytes))])\n        time.sleep(0.01)\n    self.serial.write(b\"\\x04\")\n\n    # check if we could exec command\n    data = self.serial.read(2)\n    if data != b\"OK\":\n        raise PyboardError(\"could not exec command (response: %r)\" % data)", "loc": 21}
{"file": "thonny\\misc\\pyboard.py", "class_name": "Pyboard", "function_name": "exec_", "parameters": ["self", "command", "data_consumer"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PyboardError", "self.exec_raw"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def exec_(self, command, data_consumer=None):\n    ret, ret_err = self.exec_raw(command, data_consumer=data_consumer)\n    if ret_err:\n        raise PyboardError(\"exception\", ret, ret_err)\n    return ret", "loc": 5}
{"file": "thonny\\misc\\pyboard.py", "class_name": null, "function_name": "fname_cp_dest", "parameters": ["src", "dest"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dest.endswith", "src.rsplit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fname_cp_dest(src, dest):\n    src = src.rsplit(\"/\", 1)[-1]\n    if dest is None or dest == \"\":\n        dest = src\n    elif dest == \".\":\n        dest = \"./\" + src\n    elif dest.endswith(\"/\"):\n        dest += src\n    return dest", "loc": 9}
{"file": "thonny\\misc\\pyboard.py", "class_name": null, "function_name": "execbuffer", "parameters": ["buf"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["print", "pyb.close", "pyb.exec_raw", "pyb.exec_raw_no_follow", "pyb.exit_raw_repl", "stdout_write_bytes", "sys.exit"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def execbuffer(buf):\n    try:\n        if args.no_follow:\n            pyb.exec_raw_no_follow(buf)\n            ret_err = None\n        else:\n            ret, ret_err = pyb.exec_raw(\n                buf, timeout=None, data_consumer=stdout_write_bytes\n            )\n    except PyboardError as er:\n        print(er)\n        pyb.close()\n        sys.exit(1)\n    except KeyboardInterrupt:\n        sys.exit(1)\n    if ret_err:\n        pyb.exit_raw_repl()\n        pyb.close()\n        stdout_write_bytes(ret_err)\n        sys.exit(1)", "loc": 20}
{"file": "thonny\\misc\\sockatse.py", "class_name": null, "function_name": "become_server", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["print", "serversocket.accept", "serversocket.bind", "serversocket.listen", "socket.socket"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def become_server():\n    serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    serversocket.bind((\"localhost\", port))\n    serversocket.listen(5)\n    while True:\n        (clientsocket, address) = serversocket.accept()\n        print(\"got connection:\", clientsocket, address)", "loc": 7}
{"file": "thonny\\misc\\thre.py", "class_name": null, "function_name": "inter", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["os.getpid", "os.kill", "print", "sleep"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def inter():\n    print(\"interwait\")\n    sleep(1)\n    print(\"interrupting\")\n    #interrupt_main()\n    os.kill(os.getpid(), signal.SIGINT)\n    #os.raise_signal(signal.SIGINT)\n    print(\"interrupted\")", "loc": 8}
{"file": "thonny\\misc\\trace_katse.py", "class_name": null, "function_name": "f1", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["f2", "print"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def f1():\n    print(end=\"\")\n    print(end=\"\")\n    print(end=\"\")\n    print(end=\"\")\n    f2()\n    print(end=\"\")\n    print(end=\"\")\n    print(end=\"\")\n    print(end=\"\")", "loc": 10}
{"file": "thonny\\misc\\widget_wraps.py", "class_name": null, "function_name": "string_width", "parameters": ["s"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["temp_label.destroy", "temp_label.winfo_reqwidth", "ttk.Label"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def string_width(s):\n    temp_label = ttk.Label(root, text=s)\n    result = temp_label.winfo_reqwidth()\n    temp_label.destroy()\n    return result", "loc": 5}
{"file": "thonny\\misc\\widget_wraps.py", "class_name": null, "function_name": "publish", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["child.destroy", "child.winfo_children", "enumerate", "grchild.destroy", "label.grid", "label.winfo_reqwidth", "line.grid", "path.split", "print", "root.update", "root.winfo_children", "root.winfo_width", "string_width", "tk.Frame", "ttk.Label"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def publish(event):\n    global prev_width\n    global updating\n\n    if updating:\n        return\n\n    updating= True\n\n    try:\n        available = root.winfo_width()\n\n        if available < 10 or prev_width == available:\n            return\n\n\n        for child in root.winfo_children():\n            for grchild in child.winfo_children():\n                grchild.destroy()\n            child.destroy()\n\n        line = tk.Frame(root, background=\"white\")\n        line.grid(row=0, column=0, sticky=\"nsew\")\n        used = 0\n        linecount = 1\n        colcount = 0\n        for i, part in enumerate(path.split(\"\\\\\")):\n            if i > 0:\n                label = ttk.Label(line, text=\"\\\\\")\n                label.grid(row=linecount, column=colcount, sticky=\"w\")\n                used += label.winfo_reqwidth()\n                colcount += 1\n\n\n            if used + string_width(part) > available:\n                print(\"new line\"\n                      #, line.winfo_reqwidth(), label.winfo_reqwidth(), available\n                      )\n                used = 0 \n                colcount = 0\n                line = tk.Frame(root, background=\"red\")\n                line.grid(row=linecount, column=0, sticky=\"nsew\")\n                linecount += 1\n\n            label = ttk.Label(line, text=part)\n\n            print(i, part, linecount, colcount)\n            label.grid(row=linecount, column=colcount, sticky=\"w\")\n            used += label.winfo_reqwidth()\n            colcount += 1\n\n        #root.columnconfigure(1, weight=1)\n        root.update()\n        prev_width = root.winfo_width()\n    finally:\n        updating = False", "loc": 56}
{"file": "thonny\\misc\\log_utils\\log_utils.py", "class_name": null, "function_name": "parse_log_line", "parameters": ["line"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.literal_eval", "ast.parse", "isinstance", "line.rfind", "line[split_pos + 4:].strip", "strptime"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_log_line(line):\n    split_pos = line.rfind(\" at \")\n    assert split_pos > 0\n    left = line[0:split_pos]\n    right = line[split_pos + 4 :].strip()\n\n    tree = ast.parse(left, mode=\"eval\")\n    assert isinstance(tree, ast.Expression)\n    assert isinstance(tree.body, ast.Call)\n\n    attributes = {\n        \"event_kind\": tree.body.func.id,\n        \"event_time\": strptime(right, \"%Y-%m-%dT%H:%M:%S.%f\"),\n    }\n\n    for kw in tree.body.keywords:\n        attributes[kw.arg] = ast.literal_eval(kw.value)\n\n    return attributes", "loc": 19}
{"file": "thonny\\misc\\log_utils\\log_utils.py", "class_name": null, "function_name": "get_log_file_time", "parameters": ["filename"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "list", "print"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Go from  2014-10-30_10-16-08 to       2014-10-30T10:16:08", "source_code": "def get_log_file_time(filename):\n    \"\"\"\n    Go from  2014-10-30_10-16-08\n    to       2014-10-30T10:16:08\n    \"\"\"\n\n    chars = list(filename[:19])\n    try:\n        assert chars[10] == \"_\" and chars[13] == \"-\" and chars[16] == \"-\"\n    except Exception:\n        print(filename)\n    chars[10] = \"T\"\n    chars[13] = \":\"\n    chars[16] = \":\"\n    return \"\".join(chars)", "loc": 15}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": null, "function_name": "execfile", "parameters": ["filename", "device", "baudrate", "user", "password"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Pyboard", "pyb.close", "pyb.enter_raw_repl", "pyb.execfile", "pyb.exit_raw_repl", "stdout_write_bytes"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def execfile(filename, device=\"/dev/ttyACM0\", baudrate=115200, user=\"micro\", password=\"python\"):\n    pyb = Pyboard(device, baudrate, user, password)\n    pyb.enter_raw_repl()\n    output = pyb.execfile(filename)\n    stdout_write_bytes(output)\n    pyb.exit_raw_repl()\n    pyb.close()", "loc": 7}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "PyboardError", "function_name": "convert", "parameters": ["self", "info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["OSError", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def convert(self, info):\n    if len(self.args) >= 3:\n        if b\"OSError\" in self.args[2] and b\"ENOENT\" in self.args[2]:\n            return OSError(errno.ENOENT, info)\n\n    return self", "loc": 6}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "TelnetToSerial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytes", "len", "self.fifo.extend", "self.fifo.popleft", "self.tn.read_eager", "time.sleep"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read(self, size=1):\n    while len(self.fifo) < size:\n        timeout_count = 0\n        data = self.tn.read_eager()\n        if len(data):\n            self.fifo.extend(data)\n            timeout_count = 0\n        else:\n            time.sleep(0.25)\n            if self.read_timeout is not None and timeout_count > 4 * self.read_timeout:\n                break\n            timeout_count += 1\n\n    data = b\"\"\n    while len(data) < size and len(self.fifo) > 0:\n        data += bytes([self.fifo.popleft()])\n    return data", "loc": 17}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "TelnetToSerial", "function_name": "inWaiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.fifo.extend", "self.tn.read_eager"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def inWaiting(self):\n    n_waiting = len(self.fifo)\n    if not n_waiting:\n        data = self.tn.read_eager()\n        self.fifo.extend(data)\n        return len(data)\n    else:\n        return n_waiting", "loc": 8}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "ProcessToSerial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.subp.stdout.read"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read(self, size=1):\n    data = b\"\"\n    while len(data) < size:\n        data += self.subp.stdout.read(size - len(data))\n    return data", "loc": 5}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "ProcessToSerial", "function_name": "inWaiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.poll.poll"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def inWaiting(self):\n    # res = self.sel.select(0)\n    res = self.poll.poll(0)\n    if res:\n        return 1\n    return 0", "loc": 6}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "read_until", "parameters": ["self", "min_num_bytes", "ending", "timeout", "data_consumer"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.endswith", "data_consumer", "len", "self.serial.inWaiting", "self.serial.read", "time.sleep"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_until(self, min_num_bytes, ending, timeout=10, data_consumer=None):\n    # if data_consumer is used then data is not accumulated and the ending must be 1 byte long\n    assert data_consumer is None or len(ending) == 1\n\n    data = self.serial.read(min_num_bytes)\n    if data_consumer:\n        data_consumer(data)\n    timeout_count = 0\n    while True:\n        if data.endswith(ending):\n            break\n        elif self.serial.inWaiting() > 0:\n            new_data = self.serial.read(1)\n            if data_consumer:\n                data_consumer(new_data)\n                data = new_data\n            else:\n                data = data + new_data\n            timeout_count = 0\n        else:\n            timeout_count += 1\n            if timeout is not None and timeout_count >= 100 * timeout:\n                break\n            time.sleep(0.01)\n    return data", "loc": 25}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "enter_raw_repl", "parameters": ["self", "soft_reset"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PyboardError", "data.endswith", "print", "self.read_until", "self.serial.inWaiting", "self.serial.read", "self.serial.write"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def enter_raw_repl(self, soft_reset=True):\n    self.serial.write(b\"\\r\\x03\\x03\")  # ctrl-C twice: interrupt any running program\n\n    # flush input (without relying on serial.flushInput())\n    n = self.serial.inWaiting()\n    while n > 0:\n        self.serial.read(n)\n        n = self.serial.inWaiting()\n\n    self.serial.write(b\"\\r\\x01\")  # ctrl-A: enter raw REPL\n\n    if soft_reset:\n        data = self.read_until(1, b\"raw REPL; CTRL-B to exit\\r\\n>\")\n        if not data.endswith(b\"raw REPL; CTRL-B to exit\\r\\n>\"):\n            print(data)\n            raise PyboardError(\"could not enter raw repl\")\n\n        self.serial.write(b\"\\x04\")  # ctrl-D: soft reset\n\n        # Waiting for \"soft reboot\" independently to \"raw REPL\" (done below)\n        # allows boot.py to print, which will show up after \"soft reboot\"\n        # and before \"raw REPL\".\n        data = self.read_until(1, b\"soft reboot\\r\\n\")\n        if not data.endswith(b\"soft reboot\\r\\n\"):\n            print(data)\n            raise PyboardError(\"could not enter raw repl\")\n\n    data = self.read_until(1, b\"raw REPL; CTRL-B to exit\\r\\n\")\n    if not data.endswith(b\"raw REPL; CTRL-B to exit\\r\\n\"):\n        print(data)\n        raise PyboardError(\"could not enter raw repl\")\n\n    self.in_raw_repl = True", "loc": 33}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "follow", "parameters": ["self", "timeout", "data_consumer"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PyboardError", "data.endswith", "data_err.endswith", "self.read_until"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def follow(self, timeout, data_consumer=None):\n    # wait for normal output\n    data = self.read_until(1, b\"\\x04\", timeout=timeout, data_consumer=data_consumer)\n    if not data.endswith(b\"\\x04\"):\n        raise PyboardError(\"timeout waiting for first EOF reception\")\n    data = data[:-1]\n\n    # wait for error output\n    data_err = self.read_until(1, b\"\\x04\", timeout=timeout)\n    if not data_err.endswith(b\"\\x04\"):\n        raise PyboardError(\"timeout waiting for second EOF reception\")\n    data_err = data_err[:-1]\n\n    # return normal and error output\n    return data, data_err", "loc": 15}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "raw_paste_write", "parameters": ["self", "command_bytes"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'could not complete raw paste: {}'.format", "'unexpected read during raw paste: {}'.format", "PyboardError", "data.endswith", "len", "min", "self.read_until", "self.serial.inWaiting", "self.serial.read", "self.serial.write", "struct.unpack"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def raw_paste_write(self, command_bytes):\n    # Read initial header, with window size.\n    data = self.serial.read(2)\n    window_size = struct.unpack(\"<H\", data)[0]\n    window_remain = window_size\n\n    # Write out the command_bytes data.\n    i = 0\n    while i < len(command_bytes):\n        while window_remain == 0 or self.serial.inWaiting():\n            data = self.serial.read(1)\n            if data == b\"\\x01\":\n                # Device indicated that a new window of data can be sent.\n                window_remain += window_size\n            elif data == b\"\\x04\":\n                # Device indicated abrupt end.  Acknowledge it and finish.\n                self.serial.write(b\"\\x04\")\n                return\n            else:\n                # Unexpected data from device.\n                raise PyboardError(\"unexpected read during raw paste: {}\".format(data))\n        # Send out as much data as possible that fits within the allowed window.\n        b = command_bytes[i : min(i + window_remain, len(command_bytes))]\n        self.serial.write(b)\n        window_remain -= len(b)\n        i += len(b)\n\n    # Indicate end of data.\n    self.serial.write(b\"\\x04\")\n\n    # Wait for device to acknowledge end of data.\n    data = self.read_until(1, b\"\\x04\")\n    if not data.endswith(b\"\\x04\"):\n        raise PyboardError(\"could not complete raw paste: {}\".format(data))", "loc": 34}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "exec_raw_no_follow", "parameters": ["self", "command"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PyboardError", "bytes", "data.endswith", "isinstance", "len", "min", "print", "range", "self.raw_paste_write", "self.read_until", "self.serial.read", "self.serial.write", "time.sleep"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def exec_raw_no_follow(self, command):\n    if isinstance(command, bytes):\n        command_bytes = command\n    else:\n        command_bytes = bytes(command, encoding=\"utf8\")\n\n    # check we have a prompt\n    data = self.read_until(1, b\">\")\n    if not data.endswith(b\">\"):\n        raise PyboardError(\"could not enter raw repl\")\n\n    if self.use_raw_paste:\n        # Try to enter raw-paste mode.\n        self.serial.write(b\"\\x05A\\x01\")\n        data = self.serial.read(2)\n        if data == b\"R\\x00\":\n            # Device understood raw-paste command but doesn't support it.\n            pass\n        elif data == b\"R\\x01\":\n            # Device supports raw-paste mode, write out the command using this mode.\n            return self.raw_paste_write(command_bytes)\n        else:\n            # Device doesn't support raw-paste, fall back to normal raw REPL.\n            data = self.read_until(1, b\"w REPL; CTRL-B to exit\\r\\n>\")\n            if not data.endswith(b\"w REPL; CTRL-B to exit\\r\\n>\"):\n                print(data)\n                raise PyboardError(\"could not enter raw repl\")\n        # Don't try to use raw-paste mode again for this connection.\n        self.use_raw_paste = False\n\n    # Write command using standard raw REPL, 256 bytes every 10ms.\n    for i in range(0, len(command_bytes), 256):\n        self.serial.write(command_bytes[i : min(i + 256, len(command_bytes))])\n        time.sleep(0.01)\n    self.serial.write(b\"\\x04\")\n\n    # check if we could exec command\n    data = self.serial.read(2)\n    if data != b\"OK\":\n        raise PyboardError(\"could not exec command (response: %r)\" % data)", "loc": 40}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "eval", "parameters": ["self", "expression", "parse"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'print(repr({}))'.format", "'print({})'.format", "ast.literal_eval", "ret.decode", "ret.strip", "self.exec_"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def eval(self, expression, parse=False):\n    if parse:\n        ret = self.exec_(\"print(repr({}))\".format(expression))\n        ret = ret.strip()\n        return ast.literal_eval(ret.decode())\n    else:\n        ret = self.exec_(\"print({})\".format(expression))\n        ret = ret.strip()\n        return ret", "loc": 9}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "exec_", "parameters": ["self", "command", "data_consumer"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PyboardError", "self.exec_raw"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def exec_(self, command, data_consumer=None):\n    ret, ret_err = self.exec_raw(command, data_consumer=data_consumer)\n    if ret_err:\n        raise PyboardError(\"exception\", ret, ret_err)\n    return ret", "loc": 5}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "fs_exists", "parameters": ["self", "src"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.exec_"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fs_exists(self, src):\n    try:\n        self.exec_(\"import uos\\nuos.stat(%s)\" % ((\"'%s'\" % src) if src else \"\"))\n        return True\n    except PyboardError:\n        return False", "loc": 6}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "fs_listdir", "parameters": ["self", "src"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.literal_eval", "b.replace", "buf.decode", "buf.extend", "bytearray", "e.convert", "len", "listdir_result", "self.exec_"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fs_listdir(self, src=\"\"):\n    buf = bytearray()\n\n    def repr_consumer(b):\n        buf.extend(b.replace(b\"\\x04\", b\"\"))\n\n    cmd = \"import uos\\nfor f in uos.ilistdir(%s):\\n\" \" print(repr(f), end=',')\" % (\n        (\"'%s'\" % src) if src else \"\"\n    )\n    try:\n        buf.extend(b\"[\")\n        self.exec_(cmd, data_consumer=repr_consumer)\n        buf.extend(b\"]\")\n    except PyboardError as e:\n        raise e.convert(src)\n\n    return [\n        listdir_result(*f) if len(f) == 4 else listdir_result(*(f + (0,)))\n        for f in ast.literal_eval(buf.decode())\n    ]", "loc": 20}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "fs_stat", "parameters": ["self", "src"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["e.convert", "os.stat_result", "self.eval", "self.exec_"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fs_stat(self, src):\n    try:\n        self.exec_(\"import uos\")\n        return os.stat_result(self.eval(\"uos.stat(%s)\" % ((\"'%s'\" % src)), parse=True))\n    except PyboardError as e:\n        raise e.convert(src)", "loc": 6}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "fs_readfile", "parameters": ["self", "src", "chunk_size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.literal_eval", "b.replace", "buf.decode", "buf.extend", "bytearray", "e.convert", "self.exec_"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fs_readfile(self, src, chunk_size=256):\n    buf = bytearray()\n\n    def repr_consumer(b):\n        buf.extend(b.replace(b\"\\x04\", b\"\"))\n\n    cmd = (\n        \"with open('%s', 'rb') as f:\\n while 1:\\n\"\n        \"  b=f.read(%u)\\n  if not b:break\\n  print(b,end='')\" % (src, chunk_size)\n    )\n    try:\n        self.exec_(cmd, data_consumer=repr_consumer)\n    except PyboardError as e:\n        raise e.convert(src)\n    return ast.literal_eval(buf.decode())", "loc": 15}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "fs_writefile", "parameters": ["self", "dest", "data", "chunk_size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "repr", "self.exec_"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fs_writefile(self, dest, data, chunk_size=256):\n    self.exec_(\"f=open('%s','wb')\\nw=f.write\" % dest)\n    while data:\n        chunk = data[:chunk_size]\n        self.exec_(\"w(\" + repr(chunk) + \")\")\n        data = data[len(chunk) :]\n    self.exec_(\"f.close()\")", "loc": 7}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": "Pyboard", "function_name": "fs_cp", "parameters": ["self", "src", "dest", "chunk_size", "progress_callback"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "progress_callback", "self.exec_", "self.fs_stat"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fs_cp(self, src, dest, chunk_size=256, progress_callback=None):\n    if progress_callback:\n        src_size = self.fs_stat(src).st_size\n        written = 0\n    self.exec_(\"fr=open('%s','rb')\\nr=fr.read\\nfw=open('%s','wb')\\nw=fw.write\" % (src, dest))\n    while True:\n        data_len = int(self.exec_(\"d=r(%u)\\nw(d)\\nprint(len(d))\" % chunk_size))\n        if not data_len:\n            break\n        if progress_callback:\n            written += data_len\n            progress_callback(written, src_size)\n    self.exec_(\"fr.close()\\nfw.close()\")", "loc": 13}
{"file": "thonny\\misc\\mp\\pyboard.py", "class_name": null, "function_name": "execbuffer", "parameters": ["buf"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["print", "pyb.close", "pyb.exec_raw", "pyb.exec_raw_no_follow", "pyb.exit_raw_repl", "stdout_write_bytes", "sys.exit"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def execbuffer(buf):\n    try:\n        if args.follow is None or args.follow:\n            ret, ret_err = pyb.exec_raw(\n                buf, timeout=None, data_consumer=stdout_write_bytes\n            )\n        else:\n            pyb.exec_raw_no_follow(buf)\n            ret_err = None\n    except PyboardError as er:\n        print(er)\n        pyb.close()\n        sys.exit(1)\n    except KeyboardInterrupt:\n        sys.exit(1)\n    if ret_err:\n        pyb.exit_raw_repl()\n        pyb.close()\n        stdout_write_bytes(ret_err)\n        sys.exit(1)", "loc": 20}
{"file": "thonny\\packaging\\linux\\install.py", "class_name": null, "function_name": "try_to_refresh_desktop_and_menus", "parameters": ["menu_dir"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["subprocess.call", "which"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "In KDE, the .desktop files are not taken into account immediately", "source_code": "def try_to_refresh_desktop_and_menus(menu_dir):\n    \"\"\"In KDE, the .desktop files are not taken into account immediately\"\"\"\n    for cmd in [\"kbuildsycoca5\", \"kbuildsycoca4\", \"kbuildsycoca\"]:\n        if which(cmd):\n            subprocess.call([cmd])\n            break\n\n    udd = \"update-desktop-database\"\n    if which(udd):\n        subprocess.call([udd, menu_dir])", "loc": 10}
{"file": "thonny\\packaging\\mac\\find_single_arch_binaries.py", "class_name": null, "function_name": "is_universal_binary_or_non_binary", "parameters": ["file_path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["print", "subprocess.check_output"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_universal_binary_or_non_binary(file_path):\n    try:\n        # Use the `file` command to get information about the binary\n        output = subprocess.check_output(['file', file_path], text=True)\n\n        # Check if the binary is a fat binary (universal binary)\n        if 'fat binary' in output:\n            return True\n\n        if \"Mach-O\" not in output:\n            return True\n\n        # Check if the binary contains multiple architectures\n        elif 'Mach-O' in output and 'x86_64' in output and 'arm64' in output:\n            return True\n        return False\n    except Exception as e:\n        print(f\"Error checking file {file_path}: {e}\")\n        return False", "loc": 19}
{"file": "thonny\\packaging\\mac\\find_single_arch_binaries.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["find_non_universal_binaries", "print"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main():\n    directory_to_search = 'build'  # Replace with your directory path\n    non_universal_binaries = find_non_universal_binaries(directory_to_search)\n\n    print(f\"Non-universal binaries found in {directory_to_search}:\")\n    for binary in non_universal_binaries:\n        print(binary)", "loc": 7}
{"file": "thonny\\thonny\\assistance.py", "class_name": null, "function_name": "format_file_url", "parameters": ["filename", "lineno", "col_offset"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["local_path_to_uri", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_file_url(filename, lineno, col_offset):\n    s = local_path_to_uri(filename)\n    if lineno is not None:\n        s += \"#\" + str(lineno)\n        if col_offset is not None:\n            s += \":\" + str(col_offset)\n\n    return s", "loc": 8}
{"file": "thonny\\thonny\\assistance.py", "class_name": "Assistant", "function_name": "format_message", "parameters": ["self", "message"], "param_types": {"message": "ChatMessage"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.format_attachments"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_message(self, message: ChatMessage) -> str:\n    result = self.format_attachments(message.attachments)\n\n    if result:\n        result += \"User message:\\n\"\n\n    result += message.content\n\n    return result", "loc": 9}
{"file": "thonny\\thonny\\assistance.py", "class_name": "Assistant", "function_name": "format_attachments", "parameters": ["self", "attachments"], "param_types": {"attachments": "List[Attachment]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.format_attachment"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_attachments(self, attachments: List[Attachment]) -> str:\n    result = \"\"\n    for attachment in attachments:\n        result += self.format_attachment(attachment)\n    return result", "loc": 5}
{"file": "thonny\\thonny\\assistance.py", "class_name": "Assistant", "function_name": "format_attachment", "parameters": ["self", "attachment"], "param_types": {"attachment": "Attachment"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_attachment(self, attachment: Attachment) -> str:\n    result = f\"{attachment.description}\"\n    if attachment.tag is not None:\n        result += f\" (#{attachment.tag})\"\n\n    result += f\":\\n```\\n{attachment.content}\\n```\\n\\n\"\n\n    return result", "loc": 8}
{"file": "thonny\\thonny\\assistance.py", "class_name": "EchoAssistant", "function_name": "complete_chat", "parameters": ["self", "context"], "param_types": {"context": "ChatContext"}, "return_type": "Iterator[ChatResponseChunk]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChatResponseChunk", "self.format_message"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "    def complete_chat(self, context: ChatContext) -> Iterator[ChatResponseChunk]:\n        yield ChatResponseChunk(\n            \"\"\"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\n\nUt enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n\n\"\"\",\n            is_final=False,\n            is_interal_error=False,\n        )\n\n        yield ChatResponseChunk(\n            self.format_message(context.messages[-1]), is_final=True, is_interal_error=False\n        )", "loc": 14}
{"file": "thonny\\thonny\\ast_utils.py", "class_name": null, "function_name": "extract_text_range", "parameters": ["source", "text_range"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "isinstance", "source.decode", "source.splitlines"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def extract_text_range(source, text_range):\n    if isinstance(source, bytes):\n        # TODO: may be wrong encoding\n        source = source.decode(\"utf-8\")\n\n    lines = source.splitlines(True)\n    # get relevant lines\n    lines = lines[text_range.lineno - 1 : text_range.end_lineno]\n\n    # trim last and first lines\n    lines[-1] = lines[-1][: text_range.end_col_offset]\n    lines[0] = lines[0][text_range.col_offset :]\n    return \"\".join(lines)", "loc": 13}
{"file": "thonny\\thonny\\ast_utils.py", "class_name": null, "function_name": "find_expression", "parameters": ["start_node", "text_range"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.walk", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_expression(start_node, text_range):\n    for node in ast.walk(start_node):\n        if (\n            isinstance(node, ast.expr)\n            and node.lineno == text_range.lineno\n            and node.col_offset == text_range.col_offset\n            and node.end_lineno == text_range.end_lineno\n            and node.end_col_offset == text_range.end_col_offset\n        ):\n            return node\n\n    return None", "loc": 12}
{"file": "thonny\\thonny\\ast_utils.py", "class_name": null, "function_name": "parse_source", "parameters": ["source", "filename", "mode", "fallback_to_one_char"], "param_types": {"source": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.parse", "isinstance", "mark_text_ranges"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_source(source: str, filename=\"<unknown>\", mode=\"exec\", fallback_to_one_char=False):\n    assert isinstance(source, str)\n    root = ast.parse(source, filename, mode)\n    mark_text_ranges(root, source, fallback_to_one_char)\n    return root", "loc": 5}
{"file": "thonny\\thonny\\ast_utils.py", "class_name": null, "function_name": "mark_text_ranges", "parameters": ["node", "source", "fallback_to_one_char"], "param_types": {"source": "Union[str, bytes]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ASTTokens", "ast.walk", "hasattr", "isinstance"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Node is an AST, source is corresponding source as string. Function adds recursively attributes end_lineno and end_col_offset to each node which has attributes lineno and col_offset.", "source_code": "def mark_text_ranges(node, source: Union[str, bytes], fallback_to_one_char=False):\n    \"\"\"\n    Node is an AST, source is corresponding source as string.\n    Function adds recursively attributes end_lineno and end_col_offset to each node\n    which has attributes lineno and col_offset.\n    \"\"\"\n    assert isinstance(source, (str, bytes))\n    from asttokens.asttokens import ASTTokens\n\n    ASTTokens(source, tree=node)\n    for child in ast.walk(node):\n        if hasattr(child, \"last_token\"):\n            child.end_lineno, child.end_col_offset = child.last_token.end\n\n            if hasattr(child, \"lineno\"):\n                # Fixes problems with some nodes like binop\n                child.lineno, child.col_offset = child.first_token.start\n\n        # some nodes stay without end info\n        if (\n            hasattr(child, \"lineno\")\n            and (not hasattr(child, \"end_lineno\") or not hasattr(child, \"end_col_offset\"))\n            and fallback_to_one_char\n        ):\n            child.end_lineno = child.lineno\n            child.end_col_offset = child.col_offset + 2", "loc": 26}
{"file": "thonny\\thonny\\ast_utils.py", "class_name": null, "function_name": "ok_node", "parameters": ["node"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ok_node(node):\n    if node is None:\n        return None\n\n    assert isinstance(node, (ast.expr, ast.stmt))\n\n    if skip_incorrect and getattr(node, \"incorrect_range\", False):\n        return None\n\n    return node", "loc": 10}
{"file": "thonny\\thonny\\ast_utils.py", "class_name": null, "function_name": "last_ok", "parameters": ["nodes"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "len", "ok_node", "range"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def last_ok(nodes):\n    for i in range(len(nodes) - 1, -1, -1):\n        if ok_node(nodes[i]):\n            node = nodes[i]\n            if isinstance(node, ast.Starred):\n                if ok_node(node.value):\n                    return node.value\n                else:\n                    return None\n            else:\n                return nodes[i]\n\n    return None", "loc": 13}
{"file": "thonny\\thonny\\backend.py", "class_name": null, "function_name": "ensure_posix_directory", "parameters": ["path", "stat_mode_fun", "mkdir_fun"], "param_types": {"path": "str", "stat_mode_fun": "Callable[[str], Optional[int]]", "mkdir_fun": "Callable[[str], None]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AssertionError", "list", "map", "mkdir_fun", "path.startswith", "pathlib.PurePosixPath", "reversed", "stat.S_ISDIR", "stat_mode_fun"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ensure_posix_directory(\n    path: str, stat_mode_fun: Callable[[str], Optional[int]], mkdir_fun: Callable[[str], None]\n) -> None:\n    assert path.startswith(\"/\")\n    if path == \"/\":\n        return\n\n    for step in list(reversed(list(map(str, pathlib.PurePosixPath(path).parents)))) + [path]:\n        if step != \"/\":\n            mode = stat_mode_fun(step)\n            if mode is None:\n                mkdir_fun(step)\n            elif not stat.S_ISDIR(mode):\n                raise AssertionError(\"'%s' is file, not a directory\" % step)", "loc": 14}
{"file": "thonny\\thonny\\backend.py", "class_name": null, "function_name": "interrupt_local_process", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["c_raise", "ctypes.CDLL", "hasattr", "os.getpid", "os.kill", "signal.raise_signal"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Meant to be executed from a background thread", "source_code": "def interrupt_local_process() -> None:\n    \"\"\"Meant to be executed from a background thread\"\"\"\n    import signal\n\n    if hasattr(signal, \"raise_signal\"):\n        # Python 3.8 and later\n        signal.raise_signal(signal.SIGINT)\n    elif sys.platform == \"win32\":\n        # https://stackoverflow.com/a/51122690/261181\n        import ctypes\n\n        ucrtbase = ctypes.CDLL(\"ucrtbase\")\n        c_raise = ucrtbase[\"raise\"]\n        c_raise(signal.SIGINT)\n    else:\n        # Does not give KeyboardInterrupt in Windows\n        os.kill(os.getpid(), signal.SIGINT)", "loc": 17}
{"file": "thonny\\thonny\\backend.py", "class_name": null, "function_name": "convert_newlines_if_has_shebang", "parameters": ["fp"], "param_types": {"fp": "BinaryIO"}, "return_type": "Tuple[BinaryIO, bool]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fp.close", "fp.read", "fp.read().replace", "fp.seek", "io.BytesIO", "new_fp.seek", "new_fp.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def convert_newlines_if_has_shebang(fp: BinaryIO) -> Tuple[BinaryIO, bool]:\n    if fp.read(3) == b\"#!/\":\n        fp.seek(0)\n        new_fp = io.BytesIO()\n        new_fp.write(fp.read().replace(b\"\\r\\n\", b\"\\n\"))\n        fp.close()\n        new_fp.seek(0)\n        return new_fp, True\n    else:\n        fp.seek(0)\n        return fp, False", "loc": 11}
{"file": "thonny\\thonny\\backend.py", "class_name": "BaseBackend", "function_name": "mainloop", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ToplevelResponse", "isinstance", "logger.exception", "logger.info", "report_time", "self._check_for_connection_error", "self._fetch_next_incoming_message", "self._handle_eof_command", "self._handle_normal_command", "self._handle_user_input", "self._perform_idle_tasks", "self._report_internal_exception", "self._send_output", "self.handle_connection_error", "self.send_message", "sys.exit"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def mainloop(self):\n    report_time(\"Beginning of mainloop\")\n\n    try:\n        while True:\n            self._check_for_connection_error()\n            try:\n                msg = self._fetch_next_incoming_message(timeout=0.01)\n            except KeyboardInterrupt:\n                self._send_output(\n                    \"\\nKeyboardInterrupt\", \"stderr\"\n                )  # CPython idle REPL does this\n                self.send_message(ToplevelResponse())\n            except queue.Empty:\n                self._perform_idle_tasks()\n            else:\n                if isinstance(msg, InputSubmission):\n                    self._handle_user_input(msg)\n                elif isinstance(msg, EOFCommand):\n                    self._handle_eof_command(msg)\n                else:\n                    self._current_command = msg\n                    self._handle_normal_command(msg)\n    except KeyboardInterrupt:\n        self._send_output(\"\\nKeyboardInterrupt\", \"stderr\")\n        sys.exit(0)\n    except ConnectionError as e:\n        self.handle_connection_error(e)\n    except Exception:\n        # Error in Thonny's code\n        logger.exception(\"mainloop error\")\n        self._report_internal_exception(\"mainloop error\")\n\n    logger.info(\"After mainloop\")\n    sys.exit(17)", "loc": 35}
{"file": "thonny\\thonny\\backend.py", "class_name": "BaseBackend", "function_name": "handle_connection_error", "parameters": ["self", "error"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.info", "self._send_output", "str", "sys.exit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_connection_error(self, error=None):\n    logger.info(\"Handling connection error\")\n    message = \"Connection lost\"\n    if error:\n        message += \" -- \" + str(error)\n    self._send_output(\n        \"\\n\", \"stderr\"\n    )  # in case we were at prompt or another line without newline\n    self._send_output(\"\\n\" + message + \"\\n\", \"stderr\")\n    self._send_output(\n        \"\\n\" + \"Click  at the bottom of the window or use Stop/Restart to reconnect.\" + \"\\n\",\n        \"stderr\",\n    )\n    sys.exit(ALL_EXPLAINED_STATUS_CODE)", "loc": 14}
{"file": "thonny\\thonny\\backend.py", "class_name": "RemoteProcess", "function_name": "poll", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._channel.exit_status_ready", "self._channel.recv_exit_status"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def poll(self):\n    if self._channel.exit_status_ready():\n        self.returncode = self._channel.recv_exit_status()\n        return self.returncode\n    else:\n        return None", "loc": 6}
{"file": "thonny\\thonny\\backend.py", "class_name": null, "function_name": "ensure_dir", "parameters": ["path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ensure_dir_fun", "ensured_dirs.add"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ensure_dir(path):\n    if path in ensured_dirs:\n        return\n    ensure_dir_fun(path)\n    ensured_dirs.add(path)", "loc": 5}
{"file": "thonny\\thonny\\backend.py", "class_name": null, "function_name": "copy_bytes_notifier", "parameters": ["completed_bytes", "total_bytes"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["round", "self._report_progress", "str"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def copy_bytes_notifier(completed_bytes, total_bytes):\n    completed = completed_cost + completed_bytes\n    desc = str(round(completed / total_cost * 100)) + \"%\"\n\n    self._report_progress(cmd, desc, completed, total_cost)", "loc": 5}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": null, "function_name": "ask_backend_path", "parameters": ["master", "dialog_kind", "filetypes"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BackendFileDialog", "ems_to_pixels", "get_runner", "get_runner().get_backend_proxy", "get_workbench", "get_workbench().get_option", "proxy.get_cwd", "proxy.supports_remote_files", "show_dialog"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ask_backend_path(master, dialog_kind, filetypes):\n    proxy = get_runner().get_backend_proxy()\n    if not proxy:\n        return None\n\n    assert proxy.supports_remote_files()\n\n    dlg = BackendFileDialog(master, dialog_kind, proxy.get_cwd(), filetypes=filetypes)\n    show_dialog(\n        dlg,\n        master,\n        width=ems_to_pixels(get_workbench().get_option(FILE_DIALOG_WIDTH_EMS_OPTION)),\n        height=ems_to_pixels(get_workbench().get_option(FILE_DIALOG_HEIGHT_EMS_OPTION)),\n    )\n    return dlg.result", "loc": 15}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": null, "function_name": "choose_node_for_file_operations", "parameters": ["master", "prompt"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NodeChoiceDialog", "get_runner", "get_runner().ready_for_remote_file_operations", "get_runner().supports_remote_files", "show_dialog"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def choose_node_for_file_operations(master, prompt):\n    if get_runner().supports_remote_files():\n        dlg = NodeChoiceDialog(master, prompt)\n        show_dialog(dlg, master)\n        if dlg.result == \"remote\" and not get_runner().ready_for_remote_file_operations(\n            show_message=True\n        ):\n            return None\n        return dlg.result\n    else:\n        return \"local\"", "loc": 11}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": null, "function_name": "get_local_files_root_text", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_local_files_root_text():\n    global _LOCAL_FILES_ROOT_TEXT\n\n    if not _LOCAL_FILES_ROOT_TEXT:\n        # translation can't be done in module load time\n        _LOCAL_FILES_ROOT_TEXT = tr(\"This computer\")\n\n    return _LOCAL_FILES_ROOT_TEXT", "loc": 8}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "init_header", "parameters": ["self", "row", "column"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CustomToolbutton", "ems_to_pixels", "float", "get_dir_range", "get_hyperlink_cursor", "get_menu_char", "header_frame.columnconfigure", "header_frame.grid", "int", "path.endswith", "self.get_label_foreground", "self.get_path_bar_background", "self.get_url_foreground", "self.menu_button.place", "self.path_bar.bind", "self.path_bar.config", "self.path_bar.get", "self.path_bar.grid", "self.path_bar.index", "self.path_bar.set_read_only", "self.path_bar.tag_add", "self.path_bar.tag_bind", "self.path_bar.tag_configure", "self.path_bar.tag_prevrange", "self.path_bar.tag_remove", "self.request_focus_into", "tktextext.TweakableText", "ttk.Frame"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def init_header(self, row, column):\n    header_frame = ttk.Frame(self, style=\"ViewToolbar.TFrame\")\n    header_frame.grid(row=row, column=column, sticky=\"nsew\")\n    header_frame.columnconfigure(0, weight=1)\n\n    self.path_bar = tktextext.TweakableText(\n        header_frame,\n        borderwidth=0,\n        relief=\"flat\",\n        height=1,\n        font=\"TkDefaultFont\",\n        wrap=\"word\",\n        padx=ems_to_pixels(0.6),\n        pady=ems_to_pixels(0.5),\n        insertwidth=0,\n        highlightthickness=0,\n        background=self.get_path_bar_background(),\n        foreground=self.get_label_foreground(),\n    )\n\n    self.path_bar.grid(row=0, column=0, sticky=\"nsew\")\n    self.path_bar.set_read_only(True)\n    self.path_bar.bind(\"<Configure>\", self.resize_path_bar, True)\n    self.path_bar.tag_configure(\"dir\", foreground=self.get_url_foreground())\n    self.path_bar.tag_configure(\"project\", font=\"BoldTkDefaultFont\")\n    self.path_bar.tag_configure(\"venv\", font=\"ItalicTkDefaultFont\")\n    self.path_bar.tag_configure(\"underline\", underline=True)\n\n    def get_dir_range(event):\n        mouse_index = self.path_bar.index(\"@%d,%d\" % (event.x, event.y))\n        return self.path_bar.tag_prevrange(\"dir\", mouse_index + \"+1c\")\n\n    def dir_tag_motion(event):\n        self.path_bar.tag_remove(\"underline\", \"1.0\", \"end\")\n        dir_range = get_dir_range(event)\n        if dir_range:\n            range_start, range_end = dir_range\n            self.path_bar.tag_add(\"underline\", range_start, range_end)\n\n    def dir_tag_enter(event):\n        self.path_bar.config(cursor=get_hyperlink_cursor())\n\n    def dir_tag_leave(event):\n        self.path_bar.config(cursor=\"\")\n        self.path_bar.tag_remove(\"underline\", \"1.0\", \"end\")\n\n    def dir_tag_click(event):\n        mouse_index = self.path_bar.index(\"@%d,%d\" % (event.x, event.y))\n        lineno = int(float(mouse_index))\n        if lineno == 1:\n            self.request_focus_into(\"\")\n        else:\n            assert lineno == 2\n            dir_range = get_dir_range(event)\n            if dir_range:\n                _, end_index = dir_range\n                path = self.path_bar.get(\"2.0\", end_index)\n                if path.endswith(\":\"):\n                    path += \"\\\\\"\n                self.request_focus_into(path)\n\n    self.path_bar.tag_bind(\"dir\", \"<1>\", dir_tag_click)\n    self.path_bar.tag_bind(\"dir\", \"<Enter>\", dir_tag_enter)\n    self.path_bar.tag_bind(\"dir\", \"<Leave>\", dir_tag_leave)\n    self.path_bar.tag_bind(\"dir\", \"<Motion>\", dir_tag_motion)\n\n    # self.menu_button = ttk.Button(header_frame, text=\" \", style=\"ViewToolbar.Toolbutton\")\n    self.menu_button = CustomToolbutton(\n        header_frame,\n        style=\"ViewToolbar.Toolbutton\",\n        text=f\" {get_menu_char()} \",\n        command=self.post_button_menu,\n    )\n    # self.menu_button.grid(row=0, column=1, sticky=\"ne\")\n    self.menu_button.place(anchor=\"ne\", rely=0, relx=1)", "loc": 75}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "clear", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.clear_error", "self.invalidate_cache", "self.path_bar.direct_delete", "self.tree.set_children"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def clear(self):\n    self.clear_error()\n    self.invalidate_cache()\n    self.path_bar.direct_delete(\"1.0\", \"end\")\n    self.tree.set_children(\"\")\n    self.current_focus = None", "loc": 6}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "focus_into", "parameters": ["self", "path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["create_spacer", "enumerate", "logger.info", "self.clear_error", "self.get_dir_separator", "self.get_root_text", "self.invalidate_cache", "self.is_project_dir", "self.is_venv_dir", "self.path_bar.direct_delete", "self.path_bar.direct_insert", "self.path_bar.get", "self.path_bar.get('2.0', 'end').strip", "self.path_bar.window_create", "self.render_children_from_cache", "self.resize_path_bar", "self.scroll_to_top", "self.split_path", "self.tree.set", "self.tree.set_children", "ttk.Frame"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def focus_into(self, path):\n    logger.info(\"focus_into %r\", path)\n    self.clear_error()\n    self.invalidate_cache()\n\n    # clear\n    self.tree.set_children(ROOT_NODE_ID)\n\n    self.tree.set(ROOT_NODE_ID, \"path\", path)\n\n    self.building_breadcrumbs = True\n    self.path_bar.direct_delete(\"1.0\", \"end\")\n\n    self.path_bar.direct_insert(\"1.0\", self.get_root_text(), (\"dir\",))\n\n    if path and path != \"/\":\n        self.path_bar.direct_insert(\"end\", \"\\n\")\n\n        def create_spacer():\n            return ttk.Frame(self.path_bar, height=1, width=4, style=\"ViewToolbar.TFrame\")\n\n        parts = self.split_path(path)\n        for i, part in enumerate(parts):\n            if i > 0:\n                if parts[i - 1] != \"\":\n                    self.path_bar.window_create(\"end\", window=create_spacer())\n                self.path_bar.direct_insert(\"end\", self.get_dir_separator())\n                self.path_bar.window_create(\"end\", window=create_spacer())\n\n            tags = (\"dir\",)\n            partial_path = self.path_bar.get(\"2.0\", \"end\").strip() + part\n            if self.is_project_dir(partial_path):\n                tags += (\"project\",)\n            elif self.is_venv_dir(partial_path):\n                tags += (\"venv\",)\n            self.path_bar.direct_insert(\"end\", part, tags=tags)\n\n    self.building_breadcrumbs = False\n    self.resize_path_bar()\n    self.render_children_from_cache()\n    self.scroll_to_top()\n    self.current_focus = path", "loc": 42}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "on_open_node", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.get_selected_kind", "self.get_selected_node", "self.render_children_from_cache", "self.tree.set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_open_node(self, event):\n    node_id = self.get_selected_node()\n    if self.get_selected_kind() == \"file\":\n        # can happen in Windows when pressing ENTER on file\n        return \"break\"\n\n    path = self.tree.set(node_id, \"path\")\n    if path:  # and path not in self._cached_child_data:\n        self.render_children_from_cache(node_id)", "loc": 9}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "resize_path_bar", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.path_bar.configure", "self.tk.call"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def resize_path_bar(self, event=None):\n    if self.building_breadcrumbs:\n        return\n    height = self.tk.call((self.path_bar, \"count\", \"-update\", \"-displaylines\", \"1.0\", \"end\"))\n    self.path_bar.configure(height=height)", "loc": 5}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "get_selected_node", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self._cleaned_selection", "self.tree.focus"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_selected_node(self):\n    \"\"\"Returns single node (or nothing)\"\"\"\n    nodes = self._cleaned_selection()\n    if len(nodes) == 1:\n        return nodes[0]\n    elif len(nodes) > 1:\n        return self.tree.focus() or None\n    else:\n        return None", "loc": 9}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "get_selected_nodes", "parameters": ["self", "notify_if_empty"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._cleaned_selection", "self.notify_missing_selection"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Can return several nodes", "source_code": "def get_selected_nodes(self, notify_if_empty=False):\n    \"\"\"Can return several nodes\"\"\"\n    result = self._cleaned_selection()\n    if not result and notify_if_empty:\n        self.notify_missing_selection()\n    return result", "loc": 6}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "get_selection_info", "parameters": ["self", "notify_if_empty"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.get_selected_nodes", "self.tree.set", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_selection_info(self, notify_if_empty=False):\n    nodes = self.get_selected_nodes(notify_if_empty)\n    if not nodes:\n        return None\n    elif len(nodes) == 1:\n        description = \"'\" + self.tree.set(nodes[0], \"name\") + \"'\"\n    else:\n        description = tr(\"%d items\") % len(nodes)\n\n    paths = [self.tree.set(node, \"path\") for node in nodes]\n    kinds = [self.tree.set(node, \"kind\") for node in nodes]\n\n    return {\"description\": description, \"nodes\": nodes, \"paths\": paths, \"kinds\": kinds}", "loc": 13}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "get_extension_from_name", "parameters": ["self", "name"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["name.lower", "name.split", "name.split('.')[-1].lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_extension_from_name(self, name):\n    if name is None:\n        return None\n    if \".\" in name:\n        return \".\" + name.split(\".\")[-1].lower()\n    else:\n        return name.lower()", "loc": 7}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "get_selected_value", "parameters": ["self", "key"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.get_selected_node", "self.tree.set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_selected_value(self, key):\n    node_id = self.get_selected_node()\n\n    if node_id:\n        return self.tree.set(node_id, key)\n    else:\n        return None", "loc": 7}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "show_fs_info", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.get_selected_path", "self.request_fs_info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_fs_info(self):\n    path = self.get_selected_path()\n    if path is None:\n        path = self.current_focus\n    self.request_fs_info(path)", "loc": 5}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "present_fs_info", "parameters": ["self", "info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["info.get", "messagebox.showinfo", "sizeof_fmt", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def present_fs_info(self, info):\n    total_str = \"?\" if info[\"total\"] is None else sizeof_fmt(info[\"total\"])\n    used_str = \"?\" if info[\"used\"] is None else sizeof_fmt(info[\"used\"])\n    free_str = \"?\" if info[\"free\"] is None else sizeof_fmt(info[\"free\"])\n    text = tr(\"Storage space on this drive or filesystem\") + \":\\n\\n\" \"    %s: %s\\n\" % (\n        tr(\"total space\"),\n        total_str,\n    ) + \"    %s: %s\\n\" % (tr(\"used space\"), used_str) + \"    %s: %s\\n\" % (\n        tr(\"free space\"),\n        free_str,\n    )\n\n    if info.get(\"comment\"):\n        text += \"\\n\" + info[\"comment\"]\n\n    messagebox.showinfo(tr(\"Storage info\"), text, master=self)", "loc": 16}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "cache_dirs_child_data", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["child_data.get", "deepcopy", "isinstance", "self._cached_child_data.update"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cache_dirs_child_data(self, data):\n    from copy import deepcopy\n\n    data = deepcopy(data)\n\n    for parent_path in data:\n        children_data = data[parent_path]\n        if isinstance(children_data, dict):\n            for child_name in children_data:\n                child_data = children_data[child_name]\n                assert isinstance(child_data, dict)\n                if \"label\" not in child_data:\n                    child_data[\"label\"] = child_name\n\n                if \"isdir\" not in child_data:\n                    child_data[\"isdir\"] = child_data.get(\"size_bytes\", 0) is None\n        else:\n            assert children_data is None\n\n    self._cached_child_data.update(data)", "loc": 20}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "file_exists_in_cache", "parameters": ["self", "path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def file_exists_in_cache(self, path):\n    for parent_path in self._cached_child_data:\n        # hard to split because it may not be in this system format\n        name = path[len(parent_path) :]\n        if name[0:1] in [\"/\", \"\\\\\"]:\n            name = name[1:]\n\n        if name in self._cached_child_data[parent_path]:\n            return True\n\n    return False", "loc": 11}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "invalidate_cache", "parameters": ["self", "paths"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._cached_child_data.clear"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def invalidate_cache(self, paths=None):\n    if paths is None:\n        self._cached_child_data.clear()\n    else:\n        for path in paths:\n            if path in self._cached_child_data:\n                del self._cached_child_data[path]", "loc": 7}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "show_error", "parameters": ["self", "msg", "node_id"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.tree.insert", "self.tree.item", "self.tree.set_children"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_error(self, msg, node_id=\"\"):\n    if not node_id:\n        # clear tree\n        self.tree.set_children(\"\")\n\n    err_id = self.tree.insert(node_id, \"end\")\n    self.tree.item(err_id, text=msg)\n    self.tree.set_children(node_id, err_id)", "loc": 8}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "join", "parameters": ["self", "parent", "child"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parent.endswith", "self.get_dir_separator"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def join(self, parent, child):\n    if parent == \"\":\n        if self.get_dir_separator() == \"/\":\n            return \"/\" + child\n        else:\n            return child\n\n    if parent.endswith(self.get_dir_separator()):\n        return parent + child\n    else:\n        return parent + self.get_dir_separator() + child", "loc": 11}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "on_secondary_click", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.menu.tk_popup", "self.path_bar.focus_set", "self.refresh_menu", "self.tree.focus", "self.tree.identify_row", "self.tree.selection", "self.tree.selection_set", "self.tree.update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_secondary_click(self, event):\n    node_id = self.tree.identify_row(event.y)\n\n    if node_id:\n        if node_id not in self.tree.selection():\n            # replace current selection\n            self.tree.selection_set(node_id)\n        self.tree.focus(node_id)\n    else:\n        self.tree.selection_set()\n        self.path_bar.focus_set()\n\n    self.tree.update()\n\n    self.refresh_menu(context=\"item\")\n    self.menu.tk_popup(event.x_root, event.y_root)", "loc": 16}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "post_button_menu", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.menu.tk_popup", "self.menu_button.winfo_height", "self.menu_button.winfo_rootx", "self.menu_button.winfo_rooty", "self.refresh_menu"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def post_button_menu(self):\n    self.refresh_menu(context=\"button\")\n    self.menu.tk_popup(\n        self.menu_button.winfo_rootx(),\n        self.menu_button.winfo_rooty() + self.menu_button.winfo_height(),\n    )", "loc": 6}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "refresh_menu", "parameters": ["self", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.add_first_menu_items", "self.add_last_menu_items", "self.add_middle_menu_items", "self.menu.add_separator", "self.menu.delete"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def refresh_menu(self, context):\n    self.menu.delete(0, \"end\")\n    self.add_first_menu_items(context)\n    self.menu.add_separator()\n    self.add_middle_menu_items(context)\n    self.menu.add_separator()\n    self.add_last_menu_items(context)", "loc": 7}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "toggle_hidden_files", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "get_workbench().set_option", "self.refresh_tree"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def toggle_hidden_files(self):\n    get_workbench().set_option(\n        HIDDEN_FILES_OPTION, not get_workbench().get_option(HIDDEN_FILES_OPTION)\n    )\n    self.refresh_tree()", "loc": 5}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "open_extension_dialog", "parameters": ["self", "extension"], "param_types": {"extension": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ask_one_from_choices", "get_file_handler_conf_key", "get_workbench", "get_workbench().get_option", "get_workbench().set_option", "self.refresh_tree", "self.winfo_toplevel", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def open_extension_dialog(self, extension: str) -> None:\n    system_choice = tr(\"Open in system default app\")\n    thonny_choice = tr(\"Open in Thonny's text editor\")\n\n    current_index = (\n        1 if get_workbench().get_option(get_file_handler_conf_key(extension)) == \"thonny\" else 0\n    )\n\n    choice = ask_one_from_choices(\n        title=tr(\"Configure %s files\") % extension,\n        question=tr(\n            \"What to do with a %s file when you double-click it in Thonny's file browser?\"\n        )\n        % extension,\n        choices=[system_choice, thonny_choice],\n        initial_choice_index=current_index,\n        master=self.winfo_toplevel(),\n    )\n\n    if not choice:\n        return\n\n    get_workbench().set_option(\n        get_file_handler_conf_key(extension),\n        \"system\" if choice == system_choice else \"thonny\",\n    )\n    # update icons\n    self.refresh_tree()", "loc": 28}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "add_middle_menu_items", "parameters": ["self", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.copypaste.conflicts", "self.copypaste.has_selection", "self.get_selected_file", "self.menu.add_command", "self.menu.entryconfig", "self.supports_copypaste", "self.supports_directories", "self.supports_new_file", "self.supports_rename", "self.supports_trash", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_middle_menu_items(self, context):\n    if self.supports_new_file():\n        self.menu.add_command(label=tr(\"New file\") + \"...\", command=self.create_new_file)\n\n    if self.supports_directories():\n        self.menu.add_command(label=tr(\"New directory\") + \"...\", command=self.mkdir)\n\n    if self.supports_copypaste():\n        self.menu.add_command(label=tr(\"Cut\"), command=self.cut_files)\n        self.menu.add_command(label=tr(\"Copy\"), command=self.copy_files)\n        target = self.get_selected_file()\n        self.menu.add_command(label=tr(\"Paste\"), command=self.paste_files)\n        if (\n            target is None\n            or not self.copypaste.has_selection()\n            or self.copypaste.conflicts(target)\n        ):\n            self.menu.entryconfig(tr(\"Paste\"), state=\"disabled\")\n\n    if self.supports_rename():\n        self.menu.add_command(label=tr(\"Rename\"), command=self.rename_file)\n\n    if self.supports_trash():\n        trash_label = tr(\"Move to Trash\")\n        self.menu.add_command(label=trash_label, command=self.move_to_trash)\n    else:\n        self.menu.add_command(label=tr(\"Delete\"), command=self.delete)", "loc": 27}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "show_properties", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["messagebox.showinfo", "self.get_selected_node", "self.notify_missing_selection", "self.tree.set", "size_fmt_str.endswith", "str", "text.strip", "tr", "values['modified_fmt'].strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_properties(self):\n    node_id = self.get_selected_node()\n    if node_id is None:\n        self.notify_missing_selection()\n        return\n\n    values = self.tree.set(node_id)\n\n    text = tr(\"Path\") + \":\\n    \" + values[\"path\"] + \"\\n\\n\"\n    if values[\"kind\"] == \"dir\":\n        title = tr(\"Directory properties\")\n    else:\n        title = tr(\"File properties\")\n        size_fmt_str = values[\"size_fmt\"]\n        bytes_str = str(values[\"size_bytes\"]) + \" \" + tr(\"bytes\")\n\n        text += (\n            tr(\"Size\")\n            + \":\\n    \"\n            + (\n                bytes_str\n                if size_fmt_str.endswith(\" B\")\n                else size_fmt_str + \"  (\" + bytes_str + \")\"\n            )\n            + \"\\n\\n\"\n        )\n\n    if values[\"modified_fmt\"].strip():\n        text += tr(\"Modified\") + \":\\n    \" + values[\"modified_fmt\"] + \"\\n\\n\"\n\n    messagebox.showinfo(title, text.strip(), master=self)", "loc": 31}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "refresh_tree", "parameters": ["self", "paths_to_invalidate"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.invalidate_cache", "self.render_children_from_cache", "self.select_path_if_visible", "self.winfo_ismapped"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def refresh_tree(self, paths_to_invalidate=None):\n    self.invalidate_cache(paths_to_invalidate)\n    if self.winfo_ismapped():\n        self.render_children_from_cache(\"\")\n\n    if self.path_to_highlight:\n        self.select_path_if_visible(self.path_to_highlight)\n        self.path_to_highlight = None", "loc": 8}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "create_new_file", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ask_string", "messagebox.showerror", "self.create_new_file", "self.create_new_file_editor", "self.get_selected_node", "self.join", "self.path_exists", "self.tree.parent", "self.tree.set", "self.winfo_toplevel"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_new_file(self):\n    selected_node_id = self.get_selected_node()\n\n    if selected_node_id:\n        selected_path = self.tree.set(selected_node_id, \"path\")\n        selected_kind = self.tree.set(selected_node_id, \"kind\")\n\n        if selected_kind == \"dir\":\n            parent_path = selected_path\n        else:\n            parent_id = self.tree.parent(selected_node_id)\n            parent_path = self.tree.set(parent_id, \"path\")\n    else:\n        parent_path = self.current_focus\n\n    name = ask_string(\n        \"File name\", \"Provide filename\", initial_value=\"\", master=self.winfo_toplevel()\n    )\n\n    if not name:\n        return None\n\n    path = self.join(parent_path, name)\n\n    if self.path_exists(path):\n        messagebox.showerror(\"Error\", \"The file '\" + path + \"' already exists\", master=self)\n        return self.create_new_file()\n    else:\n        self.create_new_file_editor(path)\n\n    return path", "loc": 31}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "delete", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["messagebox.askyesno", "self.get_selection_info", "self.perform_delete", "self.refresh_tree", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def delete(self):\n    selection = self.get_selection_info(True)\n    if not selection:\n        return\n\n    confirmation = \"Are you sure want to delete %s?\" % selection[\"description\"]\n    confirmation += \"\\n\\nNB! Trash bin won't be used (no way to undelete)!\"\n    if \"dir\" in selection[\"kinds\"]:\n        confirmation += \"\\n\" + \"Directories will be deleted with content.\"\n\n    if not messagebox.askyesno(\"Are you sure?\", confirmation, master=self):\n        return\n\n    self.perform_delete(selection[\"paths\"], tr(\"Deleting %s\") % selection[\"description\"])\n    self.refresh_tree()", "loc": 15}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "move_to_trash", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["messagebox.askokcancel", "self.get_selection_info", "self.perform_move_to_trash", "self.refresh_tree", "self.supports_trash", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def move_to_trash(self):\n    assert self.supports_trash()\n\n    selection = self.get_selection_info(True)\n    if not selection:\n        return\n\n    if not messagebox.askokcancel(\n        tr(\"Moving to Trash\"),\n        tr(\"Move %s to Trash?\") % selection[\"description\"],\n        icon=\"info\",\n        master=self,\n    ):\n        return\n\n    self.perform_move_to_trash(\n        selection[\"paths\"], tr(\"Moving %s to Trash\") % (selection[\"description\"])\n    )\n    self.refresh_tree()", "loc": 19}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "get_selected_file", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.get_selection_info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_selected_file(self):\n    selection = self.get_selection_info(False)\n    if not selection or len(selection[\"paths\"]) > 1:\n        return\n    return selection[\"paths\"][0]", "loc": 5}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "on_heading_click", "parameters": ["self", "column_name"], "param_types": {"column_name": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.info", "self._update_heading_labels", "self.refresh_tree"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_heading_click(self, column_name: str):\n    logger.info(\"Click on column %r\", column_name)\n    if column_name == self.order_by:\n        self.reverse_order = not self.reverse_order\n    else:\n        self.order_by = column_name\n        self.reverse_order = False\n\n    self.refresh_tree()\n    self._update_heading_labels()", "loc": 10}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseFileBrowser", "function_name": "item_matches_filter", "parameters": ["self", "name", "atts"], "param_types": {"name": "str", "atts": "Dict[str, Any]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["atts.get", "name.lower", "name.lower().endswith", "suffix.lower"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def item_matches_filter(self, name: str, atts: Dict[str, Any]) -> bool:\n    if self.filter is None:\n        return True\n\n    if atts.get(\"isdir\", False):\n        return True\n\n    for suffix in self.filter:\n        if name.lower().endswith(suffix.lower()):\n            return True\n\n    return False", "loc": 12}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "CopyPaste", "function_name": "get_selection_paths", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.fb.get_selection_info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_selection_paths(self):\n    selection = self.fb.get_selection_info(True)\n    if selection:\n        return selection[\"paths\"]\n    return []", "loc": 5}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseLocalFileBrowser", "function_name": "perform_move_to_trash", "parameters": ["self", "paths", "description"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["send2trash.send2trash"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_move_to_trash(self, paths, description):\n    # TODO: do it with subprocess dialog\n    import send2trash\n\n    for path in paths:\n        send2trash.send2trash(path)", "loc": 6}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseLocalFileBrowser", "function_name": "supports_trash", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def supports_trash(self):\n    try:\n        import send2trash  # @UnusedImport\n\n        return True\n    except ImportError:\n        return False", "loc": 7}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "destroy", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().unbind", "super", "super().destroy"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def destroy(self):\n    super().destroy()\n    get_workbench().unbind(\"get_dirs_children_info_response\", self.update_dir_data)\n    get_workbench().unbind(\"get_fs_info_response\", self.present_fs_info)\n    get_workbench().unbind(\"RemoteFileOperation\", self.on_remote_file_operation)", "loc": 5}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "get_root_text", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "runner.get_node_label"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_root_text(self):\n    runner = get_runner()\n    if runner:\n        return runner.get_node_label()\n\n    return \"Back-end\"", "loc": 6}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "request_dirs_child_data", "parameters": ["self", "node_id", "paths"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InlineCommand", "get_runner", "get_runner().send_command", "show_hidden_files"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_dirs_child_data(self, node_id, paths):\n    if get_runner():\n        get_runner().send_command(\n            InlineCommand(\n                \"get_dirs_children_info\",\n                node_id=node_id,\n                paths=paths,\n                include_hidden=show_hidden_files(),\n            )\n        )", "loc": 10}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "update_dir_data", "parameters": ["self", "msg"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["msg.get", "self.cache_dirs_child_data", "self.render_children_from_cache", "self.select_path_if_visible", "self.show_error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_dir_data(self, msg):\n    if msg.get(\"error\"):\n        self.show_error(msg[\"error\"])\n    else:\n        self.dir_separator = msg[\"dir_separator\"]\n        self.cache_dirs_child_data(msg[\"data\"])\n        self.render_children_from_cache(msg[\"node_id\"])\n\n    if self.path_to_highlight:\n        self.select_path_if_visible(self.path_to_highlight)\n        self.path_to_highlight = None", "loc": 11}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "open_path_with_system_app", "parameters": ["self", "path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["messagebox.showinfo", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def open_path_with_system_app(self, path):\n    messagebox.showinfo(\n        tr(\"Not supported\"),\n        tr(\"Opening remote files in external app is not supported.\")\n        + \"\\n\\n\"\n        + tr(\n            \"If it is a text file, then you can configure it to open in Thonny \"\n            \"by right-clicking it and selecting 'Configure ... files'.\"\n        )\n        + \"\\n\\n\"\n        + tr(\n            \"If the file needs to be opened in external app, then download it to a local \"\n            \"directory and open it from there!\"\n        ),\n        master=self,\n    )", "loc": 16}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "supports_directories", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "proxy.supports_remote_directories", "runner.get_backend_proxy"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def supports_directories(self):\n    runner = get_runner()\n    if not runner:\n        return False\n    proxy = runner.get_backend_proxy()\n    if not proxy:\n        return False\n    return proxy.supports_remote_directories()", "loc": 8}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "on_remote_file_operation", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["path.rfind", "self.file_exists_in_cache", "self.refresh_tree"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_remote_file_operation(self, event):\n    path = event[\"path\"]\n    exists_in_cache = self.file_exists_in_cache(path)\n    if (\n        event[\"operation\"] == \"save\"\n        and exists_in_cache\n        or event[\"operation\"] == \"delete\"\n        and not exists_in_cache\n    ):\n        # No need to refresh\n        return\n\n    if \"/\" in path:\n        parent = path[: path.rfind(\"/\")]\n        if not parent:\n            parent = \"/\"\n    else:\n        parent = \"\"\n\n    self.refresh_tree([parent])\n    self.path_to_highlight = path", "loc": 21}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "perform_delete", "parameters": ["self", "paths", "description"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InlineCommand", "get_runner", "get_runner().send_command_and_wait", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_delete(self, paths, description):\n    get_runner().send_command_and_wait(\n        InlineCommand(\"delete\", paths=paths, description=description),\n        dialog_title=tr(\"Deleting\"),\n    )", "loc": 5}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "perform_mkdir", "parameters": ["self", "parent_dir", "name"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InlineCommand", "get_runner", "get_runner().send_command_and_wait", "parent_dir + self.get_dir_separator() + name.replace", "self.get_dir_separator", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_mkdir(self, parent_dir, name):\n    path = (parent_dir + self.get_dir_separator() + name).replace(\"//\", \"/\")\n    get_runner().send_command_and_wait(\n        InlineCommand(\"mkdir\", path=path),\n        dialog_title=tr(\"Creating directory\"),\n    )", "loc": 6}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "request_focus_into", "parameters": ["self", "path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().ready_for_remote_file_operations", "get_runner().supports_remote_directories", "logger.info", "self.focus_into", "self.request_new_focus"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_focus_into(self, path):\n    logger.info(\"request_focus_into %r\", path)\n    if not get_runner().ready_for_remote_file_operations(show_message=True):\n        logger.info(\"Remote not ready for file operations\")\n        return False\n\n    # super().request_focus_into(path)\n\n    if not get_runner().supports_remote_directories():\n        assert path == \"\"\n        self.focus_into(path)\n    elif self.current_focus == path:\n        # refreshes\n        self.focus_into(path)\n    else:\n        self.request_new_focus(path)\n\n    return True", "loc": 18}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "BaseRemoteFileBrowser", "function_name": "cmd_refresh_tree", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().ready_for_remote_file_operations", "super", "super().cmd_refresh_tree"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cmd_refresh_tree(self):\n    if not get_runner().ready_for_remote_file_operations(show_message=True):\n        return\n\n    super().cmd_refresh_tree()", "loc": 5}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "FileDialog", "function_name": "get_title", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_title(self):\n    if self.kind == \"open\":\n        return tr(\"Open\")\n    elif self.kind == \"save\":\n        return tr(\"Save\")\n    elif self.kind == \"dir\":\n        return tr(\"Select folder\")\n    else:\n        raise ValueError(\"Unexpected kind \" + self.kind)", "loc": 9}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "FileDialog", "function_name": "on_ok", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["messagebox.askyesno", "messagebox.showerror", "name.endswith", "name.startswith", "parent_path.endswith", "self._typevariable.set", "self.destroy", "self.filter_combo.get_selected_value", "self.name_var.get", "self.name_var.get().strip", "self.save_settings", "tr", "tree.get_children", "tree.set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_ok(self, event=None):\n    self.save_settings()\n    tree = self.browser.tree\n    name = self.name_var.get().strip()\n\n    if not name:\n        messagebox.showerror(tr(\"Error\"), tr(\"You need to select a file!\"), master=self)\n        return\n\n    if self.kind == \"save\":\n        # Mimicking a Windows trick\n        # https://www.winhelponline.com/blog/double-extensions-files-save-as-dialog-programs-avoid/\n        if name.endswith('\"') and name.startswith('\"'):\n            name = name[1:-1]\n        else:\n            proposed_extensions = self._extensions_by_desc[\n                self.filter_combo.get_selected_value()\n            ]\n            for ext in proposed_extensions:\n                if name.endswith(ext) or ext in [\".*\", \"*\"]:\n                    break\n            else:\n                name += proposed_extensions[0]\n\n    # In the back-end case I can't ask local OS whether the file exists\n    # Need to consult the tree instead\n    for node_id in tree.get_children(\"\"):  # NB! only works without expanders\n        if name and name == tree.set(node_id, \"name\"):\n            break\n    else:\n        node_id = None\n\n    if node_id is not None:\n        node_kind = tree.set(node_id, \"kind\")\n        if self.kind in [\"open\", \"save\"] and node_kind != \"file\":\n            messagebox.showerror(tr(\"Error\"), tr(\"You need to select a file!\"), master=self)\n            return\n        if self.kind == \"save\":\n            if not messagebox.askyesno(\n                tr(\"Overwrite?\"), tr(\"Do you want to overwrite '%s' ?\") % name, master=self\n            ):\n                return\n\n    parent_path = tree.set(\"\", \"path\")\n    if parent_path == \"\" or parent_path.endswith(self.browser.dir_separator):\n        self.result = parent_path + name\n    else:\n        self.result = parent_path + self.browser.dir_separator + name\n\n    if self._typevariable is not None:\n        self._typevariable.set(self.filter_combo.get_selected_value())\n\n    self.destroy()", "loc": 53}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "FileDialog", "function_name": "on_tree_select", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.browser.get_selected_kind", "self.browser.get_selected_name", "self.name_var.set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_tree_select(self, event=None):\n    if self.updating_selection:\n        return\n\n    if self.browser.get_selected_kind() == \"file\":\n        name = self.browser.get_selected_name()\n        if name:\n            self.name_var.set(name)", "loc": 8}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "FileDialog", "function_name": "on_name_edit", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.name_var.get", "tree.bind", "tree.get_children", "tree.selection_add", "tree.selection_remove", "tree.set", "tree.unbind"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_name_edit(self, event=None):\n    self.updating_selection = True\n    tree = self.browser.tree\n    if self.tree_select_handler_id:\n        tree.unbind(\"<<TreeviewSelect>>\", self.tree_select_handler_id)\n        self.tree_select_handler_id = None\n\n    name = self.name_var.get()\n    for node_id in tree.get_children(\"\"):\n        if name == tree.set(node_id, \"name\"):\n            tree.selection_add(node_id)\n        else:\n            tree.selection_remove(node_id)\n\n    self.updating_selection = False\n    self.tree_select_handler_id = tree.bind(\"<<TreeviewSelect>>\", self.on_tree_select, True)", "loc": 16}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "FileDialog", "function_name": "filter_changed", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.browser.refresh_tree", "self.filter_combo.get_selected_value"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def filter_changed(self, event=None):\n    filter_desc = self.filter_combo.get_selected_value()\n    filter = self._extensions_by_desc[filter_desc]\n    if filter == [\".*\"]:\n        filter = None\n\n    self.browser.filter = filter\n    self.browser.refresh_tree()", "loc": 8}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "FileDialog", "function_name": "save_settings", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().set_option", "pixels_to_ems", "round", "self.winfo_height", "self.winfo_width"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def save_settings(self):\n    get_workbench().set_option(FILE_DIALOG_ORDER_BY_OPTION, self.browser.order_by)\n    get_workbench().set_option(FILE_DIALOG_REVERSE_ORDER_OPTION, self.browser.reverse_order)\n    get_workbench().set_option(\n        FILE_DIALOG_WIDTH_EMS_OPTION, round(pixels_to_ems(self.winfo_width()))\n    )\n    get_workbench().set_option(\n        FILE_DIALOG_HEIGHT_EMS_OPTION, round(pixels_to_ems(self.winfo_height()))\n    )", "loc": 9}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": "NodeChoiceDialog", "function_name": "on_return", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.focus_get", "self.on_local", "self.on_remote"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_return(self, event=None):\n    if self.focus_get() == self.local_button:\n        self.on_local(event)\n    elif self.focus_get() == self.remote_button:\n        self.on_remote(event)", "loc": 5}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": null, "function_name": "dir_tag_motion", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_dir_range", "self.path_bar.tag_add", "self.path_bar.tag_remove"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dir_tag_motion(event):\n    self.path_bar.tag_remove(\"underline\", \"1.0\", \"end\")\n    dir_range = get_dir_range(event)\n    if dir_range:\n        range_start, range_end = dir_range\n        self.path_bar.tag_add(\"underline\", range_start, range_end)", "loc": 6}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": null, "function_name": "dir_tag_click", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["float", "get_dir_range", "int", "path.endswith", "self.path_bar.get", "self.path_bar.index", "self.request_focus_into"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dir_tag_click(event):\n    mouse_index = self.path_bar.index(\"@%d,%d\" % (event.x, event.y))\n    lineno = int(float(mouse_index))\n    if lineno == 1:\n        self.request_focus_into(\"\")\n    else:\n        assert lineno == 2\n        dir_range = get_dir_range(event)\n        if dir_range:\n            _, end_index = dir_range\n            path = self.path_bar.get(\"2.0\", end_index)\n            if path.endswith(\":\"):\n                path += \"\\\\\"\n            self.request_focus_into(path)", "loc": 14}
{"file": "thonny\\thonny\\base_file_browser.py", "class_name": null, "function_name": "file_order", "parameters": ["name"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["name.upper"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def file_order(name):\n    # items in a folder should be ordered so that\n    # folders come first and names are ordered case insensitively\n    if self.order_by == \"size\":\n        return (\n            not children_data[name][\"isdir\"],  # prefer directories\n            not \":\" in name,  # prefer drives\n            children_data[name][\"size_bytes\"],\n            name.upper(),\n            name,\n        )\n    elif self.order_by == \"modified\":\n        return (\n            -children_data[name][\"modified_epoch\"],  # prefer newer files\n            name.upper(),\n            name,\n        )\n    else:\n        return (\n            not children_data[name][\"isdir\"],  # prefer directories\n            not \":\" in name,  # prefer drives\n            name.upper(),\n            name,\n        )", "loc": 24}
{"file": "thonny\\thonny\\codeview.py", "class_name": null, "function_name": "get_syntax_options_for_tag", "parameters": ["tag"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["base_options.update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_syntax_options_for_tag(tag, **base_options):\n    global _syntax_options\n    if tag in _syntax_options:\n        base_options.update(_syntax_options[tag])\n    return base_options", "loc": 5}
{"file": "thonny\\thonny\\codeview.py", "class_name": null, "function_name": "tweak_newlines", "parameters": ["content"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["OLD_MAC_LINEBREAK.findall", "OLD_MAC_LINEBREAK.sub", "UNIX_LINEBREAK.findall", "WINDOWS_LINEBREAK.findall", "WINDOWS_LINEBREAK.sub", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def tweak_newlines(content):\n    cr_count = len(OLD_MAC_LINEBREAK.findall(content))\n    lf_count = len(UNIX_LINEBREAK.findall(content))\n    crlf_count = len(WINDOWS_LINEBREAK.findall(content))\n\n    if cr_count > 0 and lf_count == 0 and crlf_count == 0:\n        original_newlines = \"\\r\"\n    elif crlf_count > 0 and lf_count == 0 and cr_count == 0:\n        original_newlines = \"\\r\\n\"\n    elif lf_count > 0 and crlf_count == 0 and cr_count == 0:\n        original_newlines = \"\\n\"\n    else:\n        original_newlines = os.linesep\n\n    content = OLD_MAC_LINEBREAK.sub(\"\\n\", content)\n    content = WINDOWS_LINEBREAK.sub(\"\\n\", content)\n\n    return content, original_newlines", "loc": 18}
{"file": "thonny\\thonny\\codeview.py", "class_name": null, "function_name": "perform_simple_return", "parameters": ["text", "event"], "param_types": {"text": "EnhancedText"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "len", "text._log_keypress_for_undo", "text.delete", "text.event_generate", "text.get", "text.get_selection_indices", "text.insert", "text.mark_set", "text.see"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_simple_return(text: EnhancedText, event):\n    assert text is event.widget\n    assert isinstance(text, EnhancedText)\n\n    text._log_keypress_for_undo(event)\n\n    try:\n        # delete selection\n        first, last = text.get_selection_indices()\n        if first and last:\n            text.delete(first, last)\n            text.mark_set(\"insert\", first)\n\n        # Strip whitespace after insert point\n        # (ie. don't carry whitespace from the right of the cursor over to the new line)\n        while text.get(\"insert\") in [\" \", \"\\t\"]:\n            text.delete(\"insert\")\n\n        left_part = text.get(\"insert linestart\", \"insert\")\n        # locate first non-white character\n        i = 0\n        n = len(left_part)\n        while i < n and left_part[i] in \" \\t\":\n            i = i + 1\n\n        # start the new line with the same whitespace\n        text.insert(\"insert\", \"\\n\" + left_part[:i])\n        return \"break\"\n\n    finally:\n        text.see(\"insert\")\n        text.event_generate(\"<<NewLine>>\")", "loc": 32}
{"file": "thonny\\thonny\\codeview.py", "class_name": null, "function_name": "get_proposed_encodings", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["item.lower", "result.insert", "result.remove", "sys.getdefaultencoding", "sys_enc.lower"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_proposed_encodings():\n    # https://w3techs.com/technologies/overview/character_encoding\n    result = [\n        \"UTF-8\",\n        \"ISO-8859-1\",\n        \"Windows-1251\",\n        \"Windows-1252\",\n        \"GB2312\",\n        \"Shift JIS\",\n        \"GBK\",\n        \"EUC-KR\",\n        \"ISO-8859-9\",\n        \"Windows-1254\",\n        \"EUC-JP\",\n        \"Big5\",\n        \"ISO-8859-2  \",\n        \"Windows-1250\",\n        \"Windows-874\",\n        \"Windows-1256\",\n        \"ISO-8859-15\",\n        \"US-ASCII\",\n        \"Windows-1255\",\n        \"TIS-620\",\n        \"ISO-8859-7\",\n        \"Windows-1253\",\n        \"UTF-16\",\n        \"KOI8-R\",\n        \"GB18030\",\n        \"Windows-1257\",\n        \"KS C 5601\",\n        \"UTF-7\",\n        \"ISO-8859-8\",\n        \"Windows-31J\",\n        \"ISO-8859-5\",\n        \"ISO-8859-6\",\n        \"ISO-8859-4\",\n        \"ANSI_X3.110-1983\",\n        \"ISO-8859-3\",\n        \"KOI8-U\",\n        \"Big5 HKSCS\",\n        \"ISO-2022-JP\",\n        \"Windows-1258\",\n        \"ISO-8859-13\",\n        \"ISO-8859-14\",\n        \"Windows-949\",\n        \"ISO-8859-10\",\n        \"ISO-8859-11\",\n        \"ISO-8859-16\",\n    ]\n\n    sys_enc = sys.getdefaultencoding()\n    for item in result[:]:\n        if item.lower() == sys_enc.lower():\n            result.remove(item)\n            sys_enc = item\n\n    result.insert(0, sys_enc)\n    return result", "loc": 58}
{"file": "thonny\\thonny\\codeview.py", "class_name": "SyntaxText", "function_name": "set_syntax_options", "parameters": ["self", "syntax_options"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.configure", "self.tag_configure", "self.tag_lower", "self.tag_raise", "self.tag_reset", "syntax_options.get", "syntax_options.get('TEXT', {}).get"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_syntax_options(self, syntax_options):\n    # clear old options\n    for tag_name in self._syntax_options:\n        self.tag_reset(tag_name)\n\n    background = syntax_options.get(\"TEXT\", {}).get(\"background\")\n\n    # apply new options\n    for tag_name in syntax_options:\n        opts = syntax_options[tag_name]\n\n        if tag_name == \"string3\":\n            # Needs explicit background to override uniline tags\n            opts[\"background\"] = background\n\n        if tag_name == \"TEXT\":\n            self.configure(**opts)\n        else:\n            self.tag_configure(tag_name, **opts)\n\n    self._syntax_options = syntax_options\n\n    if \"current_line\" in syntax_options:\n        self.tag_lower(\"current_line\")\n\n    self.tag_raise(\"sel\")\n    self.tag_lower(\"stdout\")", "loc": 27}
{"file": "thonny\\thonny\\codeview.py", "class_name": "SyntaxText", "function_name": "perform_return", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["perform_python_return", "perform_simple_return"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_return(self, event):\n    if self.file_type == \"python\":\n        return perform_python_return(self, event)\n    else:\n        return perform_simple_return(self, event)", "loc": 5}
{"file": "thonny\\thonny\\codeview.py", "class_name": "SyntaxText", "function_name": "perform_smart_backspace", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EnhancedText.perform_smart_backspace", "self._log_keypress_for_undo"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_smart_backspace(self, event):\n    if self.file_type == \"python\":\n        return EnhancedText.perform_smart_backspace(self, event)\n    else:\n        self._log_keypress_for_undo(event)\n        # let the default action work\n        return", "loc": 7}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeViewText", "function_name": "on_secondary_click", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["debugger.get_editor_context_menu", "get_current_debugger", "get_workbench", "get_workbench().get_menu", "menu.tk_popup", "self.mark_set", "super", "super().on_secondary_click"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_secondary_click(self, event=None):\n    super().on_secondary_click(event)\n    self.mark_set(\"insert\", \"@%d,%d\" % (event.x, event.y))\n\n    menu = get_workbench().get_menu(\"edit\")\n    try:\n        from thonny.plugins.debugger import get_current_debugger\n\n        debugger = get_current_debugger()\n        if debugger is not None:\n            menu = debugger.get_editor_context_menu()\n    except ImportError:\n        pass\n\n    menu.tk_popup(event.x_root, event.y_root)", "loc": 15}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "get_content", "parameters": ["self", "up_to_end"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.text.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_content(self, up_to_end=False):\n    if not up_to_end:\n        return self.text.get(\"1.0\", \"end-1c\")  # -1c because Text always adds a newline itself\n    else:\n        return self.text.get(\"1.0\", \"end\")", "loc": 5}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "detect_encoding", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["codecs.lookup", "messagebox.showerror", "self.detect_encoding_without_check"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def detect_encoding(self, data):\n    enc = self.detect_encoding_without_check(data)\n    try:\n        codecs.lookup(enc)\n        return enc\n    except LookupError:\n        messagebox.showerror(\n            \"Error\", \"Unknown encoding '%s'. Using utf-8 instead\" % enc, master=self\n        )\n        return \"utf-8\"", "loc": 10}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "detect_encoding_without_check", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ENCODING_MARKER.search", "data[:1024].splitlines", "io.BytesIO", "len", "match.group", "match.group(2).decode", "re.compile", "self.text.is_python_text", "tokenize.detect_encoding"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def detect_encoding_without_check(self, data):\n    if self.text.is_python_text():\n        import tokenize\n\n        encoding, _ = tokenize.detect_encoding(io.BytesIO(data).readline)\n        return encoding\n    else:\n        ENCODING_MARKER = re.compile(\n            rb\"(charset|coding)[\\t ]*[=: ][\\t ]*[\\\"\\']?([a-z][0-9a-z-_ ]*[0-9a-z])[\\\"\\'\\n\\r\\t ]?\",\n            re.IGNORECASE,\n        )\n\n        for line in data[:1024].splitlines():\n            match = ENCODING_MARKER.search(line)\n            if match and len(match.group(2)) > 2:\n                return match.group(2).decode(\"ascii\", errors=\"replace\")\n\n        return \"UTF-8\"", "loc": 18}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "get_content_as_bytes", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["OLD_MAC_LINEBREAK.sub", "UNIX_LINEBREAK.sub", "WINDOWS_LINEBREAK.sub", "callback", "content.encode", "get_workbench", "get_workbench().iter_save_hooks", "self.detect_encoding", "self.get_content"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_content_as_bytes(self):\n    content = self.get_content()\n\n    for callback in get_workbench().iter_save_hooks():\n        content = callback(self, content=content)\n\n    # convert all linebreaks to original format\n    content = OLD_MAC_LINEBREAK.sub(self._original_newlines, content)\n    content = WINDOWS_LINEBREAK.sub(self._original_newlines, content)\n    content = UNIX_LINEBREAK.sub(self._original_newlines, content)\n\n    return content.encode(self.detect_encoding(content.encode(\"ascii\", errors=\"replace\")))", "loc": 12}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "set_content_as_bytes", "parameters": ["self", "data", "keep_undo"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ask_string", "data.decode", "get_proposed_encodings", "logger.debug", "self.detect_encoding", "self.looks_like_text", "self.set_content", "self.winfo_toplevel", "tr"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_content_as_bytes(self, data, keep_undo=False):\n    encoding = self.detect_encoding(data)\n    logger.debug(\"Detected encoding %s\", encoding)\n    while True:\n        try:\n            chars = data.decode(encoding)\n            if self.looks_like_text(chars):\n                self.set_content(chars, keep_undo)\n                return True\n        except UnicodeDecodeError:\n            pass\n\n        encoding = ask_string(\n            tr(\"Bad encoding\"),\n            tr(\"Could not read as %s text.\\nYou could try another encoding\") % encoding,\n            initial_value=encoding,\n            options=get_proposed_encodings(),\n            master=self.winfo_toplevel(),\n        )\n        if not encoding:\n            return False", "loc": 21}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "looks_like_text", "parameters": ["self", "chars"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def looks_like_text(self, chars):\n    if not chars:\n        return True\n\n    non_text_char_count = 0\n    for ch in chars:\n        if ch in NON_TEXT_CHARS:\n            non_text_char_count += 1\n\n    return non_text_char_count / len(chars) < 0.01", "loc": 10}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "set_content", "parameters": ["self", "content", "keep_undo"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["callback", "get_workbench", "get_workbench().iter_load_hooks", "self.text.direct_delete", "self.text.direct_insert", "self.text.edit_reset", "tweak_newlines"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_content(self, content, keep_undo=False):\n    content, self._original_newlines = tweak_newlines(content)\n\n    for callback in get_workbench().iter_load_hooks():\n        content = callback(self, content=content)\n\n    self.text.direct_delete(\"1.0\", tk.END)\n    self.text.direct_insert(\"1.0\", content)\n\n    if not keep_undo:\n        self.text.edit_reset()", "loc": 11}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "compute_gutter_line", "parameters": ["self", "lineno", "plain"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.text.tag_nextrange", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def compute_gutter_line(self, lineno, plain=False):\n    if plain:\n        yield str(lineno) + \" \", ()\n    else:\n        visual_line_number = self._first_line_number + lineno - 1\n        linestart = str(visual_line_number) + \".0\"\n\n        yield str(lineno), ()\n\n        if self.text.tag_nextrange(\"breakpoint_line\", linestart, linestart + \" lineend\"):\n            yield BREAKPOINT_SYMBOL, (\"breakpoint\",)\n        else:\n            yield \" \", ()", "loc": 13}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "select_range", "parameters": ["self", "text_range"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self.text.mark_set", "self.text.see", "self.text.tag_add", "self.text.tag_remove", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_range(self, text_range):\n    self.text.tag_remove(\"sel\", \"1.0\", tk.END)\n\n    if text_range:\n        if isinstance(text_range, int):\n            # it's line number\n            start = str(text_range - self._first_line_number + 1) + \".0\"\n            end = str(text_range - self._first_line_number + 1) + \".end\"\n        elif isinstance(text_range, TextRange):\n            start = \"%s.%s\" % (\n                text_range.lineno - self._first_line_number + 1,\n                text_range.col_offset,\n            )\n            end = \"%s.%s\" % (\n                text_range.end_lineno - self._first_line_number + 1,\n                text_range.end_col_offset,\n            )\n        else:\n            assert isinstance(text_range, tuple)\n            start, end = text_range\n\n        self.text.tag_add(\"sel\", start, end)\n        if isinstance(text_range, int):\n            self.text.mark_set(\"insert\", end)\n        self.text.see(\"%s -1 lines\" % start)", "loc": 25}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "get_breakpoint_line_numbers", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "num_line.replace", "result.add", "self._gutter.get", "self._gutter.get('1.0', 'end').splitlines", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_breakpoint_line_numbers(self):\n    result = set()\n    for num_line in self._gutter.get(\"1.0\", \"end\").splitlines():\n        if BREAKPOINT_SYMBOL in num_line:\n            result.add(int(num_line.replace(BREAKPOINT_SYMBOL, \"\")))\n    return result", "loc": 6}
{"file": "thonny\\thonny\\codeview.py", "class_name": "CodeView", "function_name": "get_selected_range", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TextRange", "map", "self.text.has_selection", "self.text.index", "self.text.index(tk.INSERT).split", "self.text.index(tk.SEL_FIRST).split", "self.text.index(tk.SEL_LAST).split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_selected_range(self):\n    if self.text.has_selection():\n        lineno, col_offset = map(int, self.text.index(tk.SEL_FIRST).split(\".\"))\n        end_lineno, end_col_offset = map(int, self.text.index(tk.SEL_LAST).split(\".\"))\n    else:\n        lineno, col_offset = map(int, self.text.index(tk.INSERT).split(\".\"))\n        end_lineno, end_col_offset = lineno, col_offset\n\n    return TextRange(lineno, col_offset, end_lineno, end_col_offset)", "loc": 9}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "serialize_message", "parameters": ["msg", "max_line_length"], "param_types": {"msg": "Record"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "ascii", "len", "lines.append", "range", "str"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize_message(msg: Record, max_line_length=65536) -> str:\n    # I want to transfer only ASCII chars because encodings are not reliable\n    # (eg. can't find a way to specify PYTHONIOENCODING for cx_freeze'd program)\n    # The possibility for splitting message into several lines is required because of\n    # default (safe) window size in Paramiko (https://github.com/thonny/thonny/issues/1680)\n    msg_str = ascii(msg)\n\n    lines = []\n    for i in range(0, len(msg_str), max_line_length):\n        lines.append(msg_str[i : i + max_line_length])\n\n    return MESSAGE_MARKER + str(len(lines)) + \" \" + \"\\n\".join(lines)", "loc": 12}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "parse_message", "parameters": ["msg_string"], "param_types": {"msg_string": "str"}, "return_type": "Record", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["eval", "float", "int", "msg_string.index", "msg_string.strip", "msg_string.strip().count", "msg_string.strip().endswith", "msg_string[msg_start:].replace"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_message(msg_string: str) -> Record:\n    # DataFrames may have nan\n    # pylint: disable=unused-variable\n    nan = float(\"nan\")  # @UnusedVariable\n    assert msg_string[0] == MESSAGE_MARKER\n    assert msg_string.strip().endswith(\")\")\n    msg_start = msg_string.index(\" \")\n    line_count = int(msg_string[1:msg_start])\n    assert line_count == msg_string.strip().count(\"\\n\") + 1\n    return eval(msg_string[msg_start:].replace(\"\\n\", \"\"))", "loc": 10}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "get_site_dir", "parameters": ["symbolic_name", "executable"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "subprocess.check_output", "subprocess.check_output([executable, '-m', 'site', '--' + symbolic_name.lower().replace('_', '-')], universal_newlines=True).decode", "subprocess.check_output([executable, '-m', 'site', '--' + symbolic_name.lower().replace('_', '-')], universal_newlines=True).decode().strip", "symbolic_name.lower", "symbolic_name.lower().replace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_site_dir(symbolic_name, executable=None):\n    if not executable or executable == sys.executable:\n        result = getattr(site, symbolic_name, \"\")\n    else:\n        import subprocess\n\n        result = (\n            subprocess.check_output(\n                [executable, \"-m\", \"site\", \"--\" + symbolic_name.lower().replace(\"_\", \"-\")],\n                universal_newlines=True,\n            )\n            .decode()\n            .strip()\n        )\n\n    return result if result else None", "loc": 16}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "update_system_path", "parameters": ["env", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["key.upper"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_system_path(env, value):\n    # in Windows, env keys are not case sensitive\n    # this is important if env is a dict (not os.environ)\n    if sys.platform == \"win32\":\n        found = False\n        for key in env:\n            if key.upper() == \"PATH\":\n                found = True\n                env[key] = value\n\n        if not found:\n            env[\"PATH\"] = value\n    else:\n        env[\"PATH\"] = value", "loc": 14}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "get_windows_volumes_info", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_windows_volume_name", "logger.warning", "max", "os.stat", "windll.kernel32.GetDriveTypeW", "windll.kernel32.GetLogicalDrives"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_windows_volumes_info():\n    # http://stackoverflow.com/a/2288225/261181\n    # http://msdn.microsoft.com/en-us/library/windows/desktop/aa364939%28v=vs.85%29.aspx\n    import string\n    from ctypes import windll\n\n    all_drive_types = [\n        \"DRIVE_UNKNOWN\",\n        \"DRIVE_NO_ROOT_DIR\",\n        \"DRIVE_REMOVABLE\",\n        \"DRIVE_FIXED\",\n        \"DRIVE_REMOTE\",\n        \"DRIVE_CDROM\",\n        \"DRIVE_RAMDISK\",\n    ]\n\n    required_drive_types = [\"DRIVE_REMOVABLE\", \"DRIVE_FIXED\", \"DRIVE_REMOTE\", \"DRIVE_RAMDISK\"]\n\n    result = {}\n\n    bitmask = windll.kernel32.GetLogicalDrives()  # @UndefinedVariable\n    for letter in string.ascii_uppercase:\n        if not bitmask & 1:\n            pass\n        else:\n            drive_type = all_drive_types[\n                windll.kernel32.GetDriveTypeW(\"%s:\\\\\" % letter)\n            ]  # @UndefinedVariable\n\n            # NB! Drive A can be present in bitmask but actually missing.\n            # In this case querying information about it would freeze the UI\n            # for several seconds.\n            # One solution is to uninstall the device in device manager,\n            # but OS may restore the drive later.\n            # Therefore it is safest to skip A drive (user can access it via Open dialog)\n\n            if drive_type in required_drive_types and (\n                letter != \"A\" or drive_type != \"DRIVE_REMOVABLE\"\n            ):\n                drive = letter + \":\"\n                path = drive + \"\\\\\"\n\n                try:\n                    st = os.stat(path)\n                    volume_name = get_windows_volume_name(path)\n                    if not volume_name:\n                        volume_name = \"Disk\"\n\n                    label = volume_name + \" (\" + drive + \")\"\n                    result[path] = {\n                        \"label\": label,\n                        \"size_bytes\": None,\n                        \"modified_epoch\": max(st.st_mtime, st.st_ctime),\n                    }\n                except OSError as e:\n                    logger.warning(\"Could not get information for %s\", path, exc_info=e)\n\n        bitmask >>= 1\n\n    return result", "loc": 60}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "get_windows_volume_name", "parameters": ["path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ctypes.c_wchar_p", "ctypes.create_unicode_buffer", "ctypes.sizeof", "kernel32.GetVolumeInformationW"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_windows_volume_name(path):\n    # https://stackoverflow.com/a/12056414/261181\n    import ctypes\n\n    kernel32 = ctypes.windll.kernel32\n    volume_name_buffer = ctypes.create_unicode_buffer(1024)\n    file_system_name_buffer = ctypes.create_unicode_buffer(1024)\n    serial_number = None\n    max_component_length = None\n    file_system_flags = None\n\n    result = kernel32.GetVolumeInformationW(\n        ctypes.c_wchar_p(path),\n        volume_name_buffer,\n        ctypes.sizeof(volume_name_buffer),\n        serial_number,\n        max_component_length,\n        file_system_flags,\n        file_system_name_buffer,\n        ctypes.sizeof(file_system_name_buffer),\n    )\n\n    if result:\n        return volume_name_buffer.value\n    else:\n        return None", "loc": 26}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "universal_dirname", "parameters": ["path"], "param_types": {"path": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["path.rindex", "path.rstrip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def universal_dirname(path: str) -> str:\n    if \"/\" in path:\n        sep = \"/\"\n    elif \"\\\\\" in path:\n        sep = \"\\\\\"\n    else:\n        # micro:bit\n        return \"\"\n\n    path = path.rstrip(sep)\n    result = path[: path.rindex(sep)]\n    if not result:\n        return sep\n    else:\n        return result", "loc": 15}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "get_python_version_string", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["sys.version.split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_python_version_string():\n    result = sys.version.split()[0]\n\n    if sys.maxsize <= 2**32:\n        result += \", 32-bit\"\n\n    return result", "loc": 7}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "execute_with_frontend_sys_path", "parameters": ["function"], "param_types": {"function": "Callable"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.literal_eval", "function", "isinstance", "logger.debug", "logger.info", "sys.path.remove"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def execute_with_frontend_sys_path(function: Callable) -> Any:\n    import ast\n\n    try:\n        frontend_sys_path = ast.literal_eval(os.environ[\"THONNY_FRONTEND_SYS_PATH\"])\n        assert isinstance(frontend_sys_path, list)\n        logger.info(\"Using THONNY_FRONTEND_SYS_PATH %s\", frontend_sys_path)\n    except Exception as e:\n        logger.debug(\"Could not get THONNY_FRONTEND_SYS_PATH\", exc_info=e)\n        frontend_sys_path = []\n\n    extra_items = [item for item in frontend_sys_path if item not in sys.path]\n    sys.path = sys.path + extra_items\n    try:\n        return function()\n    finally:\n        for item in extra_items:\n            if item in sys.path:\n                sys.path.remove(item)", "loc": 19}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "try_load_modules_with_frontend_sys_path", "parameters": ["module_names"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["execute_with_frontend_sys_path", "import_module"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def try_load_modules_with_frontend_sys_path(module_names):\n    def load():\n        from importlib import import_module\n\n        for name in module_names:\n            try:\n                import_module(name)\n            except ImportError:\n                pass\n\n    execute_with_frontend_sys_path(load)", "loc": 11}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "read_one_incoming_message_str", "parameters": ["line_reader"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "line_reader", "msg_str.startswith", "msg_str[1:].split"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_one_incoming_message_str(line_reader):\n    msg_str = line_reader()\n\n    if msg_str == \"\":\n        return \"\"\n\n    if not msg_str.startswith(MESSAGE_MARKER):\n        return msg_str\n\n    line_count = int(msg_str[1:].split(maxsplit=1)[0])\n    read_lines = 1\n    while read_lines < line_count:\n        msg_str += line_reader()\n        read_lines += 1\n\n    return msg_str", "loc": 16}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "export_distributions_info_from_dir", "parameters": ["dir_path"], "param_types": {"dir_path": "str"}, "return_type": "List[DistInfo]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DistributionFinder.Context", "MetadataPathFinder.find_distributions", "export_distributions_info"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def export_distributions_info_from_dir(dir_path: str) -> List[DistInfo]:\n    from importlib.metadata import DistributionFinder, MetadataPathFinder\n\n    dists = MetadataPathFinder.find_distributions(\n        context=DistributionFinder.Context(path=[dir_path])\n    )\n    return export_distributions_info(dists, assume_pypi=False)", "loc": 7}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "export_distributions_info", "parameters": ["dists", "assume_pypi"], "param_types": {"dists": "Iterable", "assume_pypi": "bool"}, "return_type": "List[DistInfo]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DistInfo", "dist.locate_file", "dist.metadata.items", "get_dist_name", "get_project_urls", "hasattr", "infer_package_url", "label.strip", "name.lower", "name.replace", "str", "url.strip", "value.split"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def export_distributions_info(dists: Iterable, assume_pypi: bool) -> List[DistInfo]:\n    def get_project_urls(dist):\n        result = {}\n        for key, value in dist.metadata.items():\n            if key == \"Project-URL\":\n                label, url = value.split(\",\", maxsplit=1)\n                label = label.strip()\n                url = url.strip()\n                result[label] = url\n        return result\n\n    def get_dist_name(dist):\n        if hasattr(dist, \"name\"):\n            return dist.name\n        else:\n            # I met this case with Python 3.9\n            return dist.metadata[\"Name\"]\n\n    def infer_package_url(dist):\n        name = get_dist_name(dist)\n\n        if (\n            not assume_pypi\n            and \"micropython\" not in name.lower()\n            and \"circuitpython\" not in name.lower()\n        ):\n            # probably a micropython-lib package\n            return None\n\n        pypi_url_name = name.replace(\"_\", \"-\")\n        # NB! no guarantee that this package exists at PyPI or is related to installed package\n        return f\"https://pypi.org/project/{pypi_url_name}/\"\n\n    return [\n        DistInfo(\n            name=get_dist_name(dist),\n            version=dist.version,\n            requires=dist.requires or [],\n            summary=dist.metadata[\"Summary\"] or None,\n            author=dist.metadata[\"Author\"] or None,\n            license=dist.metadata[\"License\"] or None,\n            home_page=dist.metadata[\"Home-page\"] or None,\n            project_urls=get_project_urls(dist),\n            package_url=infer_package_url(dist),\n            classifiers=[value for (key, value) in dist.metadata.items() if key == \"Classifier\"],\n            installed_location=str(dist.locate_file(\"\")),\n        )\n        for dist in dists\n    ]", "loc": 49}
{"file": "thonny\\thonny\\common.py", "class_name": "Record", "function_name": "setdefault", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "setattr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "updates those fields that are not yet present (similar to dict.setdefault)", "source_code": "def setdefault(self, **kw):\n    \"updates those fields that are not yet present (similar to dict.setdefault)\"\n    for key in kw:\n        if not hasattr(self, key):\n            setattr(self, key, kw[key])", "loc": 5}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "load", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["import_module"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load():\n    from importlib import import_module\n\n    for name in module_names:\n        try:\n            import_module(name)\n        except ImportError:\n            pass", "loc": 8}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "get_project_urls", "parameters": ["dist"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dist.metadata.items", "label.strip", "url.strip", "value.split"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_project_urls(dist):\n    result = {}\n    for key, value in dist.metadata.items():\n        if key == \"Project-URL\":\n            label, url = value.split(\",\", maxsplit=1)\n            label = label.strip()\n            url = url.strip()\n            result[label] = url\n    return result", "loc": 9}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "get_dist_name", "parameters": ["dist"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_dist_name(dist):\n    if hasattr(dist, \"name\"):\n        return dist.name\n    else:\n        # I met this case with Python 3.9\n        return dist.metadata[\"Name\"]", "loc": 6}
{"file": "thonny\\thonny\\common.py", "class_name": null, "function_name": "infer_package_url", "parameters": ["dist"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_dist_name", "name.lower", "name.replace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def infer_package_url(dist):\n    name = get_dist_name(dist)\n\n    if (\n        not assume_pypi\n        and \"micropython\" not in name.lower()\n        and \"circuitpython\" not in name.lower()\n    ):\n        # probably a micropython-lib package\n        return None\n\n    pypi_url_name = name.replace(\"_\", \"-\")\n    # NB! no guarantee that this package exists at PyPI or is related to installed package\n    return f\"https://pypi.org/project/{pypi_url_name}/\"", "loc": 14}
{"file": "thonny\\thonny\\config.py", "class_name": null, "function_name": "try_load_configuration", "parameters": ["filename"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ConfigurationManager", "os.replace"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def try_load_configuration(filename):\n    if filename in _manager_cache:\n        return _manager_cache[filename]\n\n    try:\n        # use cache so Workbench doesn't create duplicate manager\n        # when FirstRunWindow already created one\n        mgr = ConfigurationManager(filename)\n    except configparser.Error as e:\n        new_path = filename + \".corrupt\"\n        os.replace(filename, new_path)\n        mgr = ConfigurationManager(filename, error_reading_existing_file=e)\n\n    _manager_cache[filename] = mgr\n    return mgr", "loc": 15}
{"file": "thonny\\thonny\\config.py", "class_name": "ConfigurationManager", "function_name": "get_option", "parameters": ["self", "name", "secondary_default"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self._defaults.get", "self._ini.get", "self._parse_name", "self._parse_value", "self._variables[name].get"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_option(self, name, secondary_default=None):\n    section, option = self._parse_name(name)\n    name = section + \".\" + option\n\n    # variable may have more recent value\n    if name in self._variables:\n        return self._variables[name].get()\n\n    try:\n        val = self._ini.get(section, option)\n\n        # if option's data type is str (inferred from the default value)\n        # then don't try to parse anything (unless it's None)\n        if val == \"None\":\n            return None\n        elif isinstance(self._defaults.get(name), str):\n            return val\n        else:\n            return self._parse_value(val)\n    except Exception:\n        if name in self._defaults:\n            return self._defaults[name]\n        else:\n            return secondary_default", "loc": 24}
{"file": "thonny\\thonny\\config.py", "class_name": "ConfigurationManager", "function_name": "set_option", "parameters": ["self", "name", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "repr", "self._ini.add_section", "self._ini.has_section", "self._ini.set", "self._parse_name", "self._variables[name].set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_option(self, name, value):\n    section, option = self._parse_name(name)\n    name = section + \".\" + option\n    if not self._ini.has_section(section):\n        self._ini.add_section(section)\n\n    if isinstance(value, str):\n        self._ini.set(section, option, value)\n    else:\n        self._ini.set(section, option, repr(value))\n\n    # update variable\n    if name in self._variables:\n        self._variables[name].set(value)", "loc": 14}
{"file": "thonny\\thonny\\config.py", "class_name": "ConfigurationManager", "function_name": "set_default", "parameters": ["self", "name", "primary_default_value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self._parse_name", "self._parse_value"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_default(self, name, primary_default_value):\n    # normalize name\n    section, option = self._parse_name(name)\n    name = section + \".\" + option\n    self._defaults[name] = primary_default_value\n\n    if name in self._defaults_overrides_str:\n        if isinstance(primary_default_value, str):\n            value = self._defaults_overrides_str[name]\n        else:\n            value = self._parse_value(self._defaults_overrides_str[name])\n    else:\n        value = primary_default_value\n\n    self._defaults[name] = value", "loc": 15}
{"file": "thonny\\thonny\\config.py", "class_name": "ConfigurationManager", "function_name": "get_variable", "parameters": ["self", "name"], "param_types": {"name": "str"}, "return_type": "tk.Variable", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["KeyError", "isinstance", "self._parse_name", "self.get_option", "str", "tk.BooleanVar", "tk.DoubleVar", "tk.IntVar", "tk.StringVar", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_variable(self, name: str) -> tk.Variable:\n    section, option = self._parse_name(name)\n    name = section + \".\" + option\n\n    if name in self._variables:\n        return self._variables[name]\n    else:\n        value = self.get_option(name)\n        if isinstance(value, bool):\n            var = tk.BooleanVar(value=value)  # type: tk.Variable\n        elif isinstance(value, int):\n            var = tk.IntVar(value=value)\n        elif isinstance(value, str):\n            var = tk.StringVar(value=value)\n        elif isinstance(value, float):\n            var = tk.DoubleVar(value=value)\n        else:\n            raise KeyError(\n                \"Can't create Tk Variable for \" + name + \". Type is \" + str(type(value))\n            )\n        self._variables[name] = var\n        return var", "loc": 22}
{"file": "thonny\\thonny\\config_ui.py", "class_name": null, "function_name": "add_option_checkbox", "parameters": ["master", "option_name", "description", "row", "column", "columnspan", "pady", "padx", "tooltip"], "param_types": {"master": "tk.Widget", "option_name": "str", "description": "str", "row": "Optional[int]", "column": "int", "columnspan": "int", "pady": "Union[Tuple, int, str, None]", "padx": "Union[Tuple, int, str]", "tooltip": "Optional[str]"}, "return_type": "ttk.Checkbutton", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_check_bundle_with_tooltip_icon", "_ensure_pady", "get_workbench", "get_workbench().get_variable", "master.grid_size", "ttk.Checkbutton", "widget.grid"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_option_checkbox(\n    master: tk.Widget,\n    option_name: str,\n    description: str,\n    row: Optional[int] = None,\n    column: int = 0,\n    columnspan: int = 3,\n    pady: Union[Tuple, int, str, None] = None,\n    padx: Union[Tuple, int, str] = 0,\n    tooltip: Optional[str] = None,\n) -> ttk.Checkbutton:\n    if row is None:\n        row = master.grid_size()[1]\n\n    pady = _ensure_pady(pady)\n\n    variable = get_workbench().get_variable(option_name)\n\n    checkbox = ttk.Checkbutton(master, text=description, variable=variable)\n    widget = _check_bundle_with_tooltip_icon(checkbox, tooltip)\n    widget.grid(row=row, column=column, columnspan=columnspan, sticky=tk.W, padx=padx, pady=pady)\n\n    return checkbox", "loc": 23}
{"file": "thonny\\thonny\\config_ui.py", "class_name": null, "function_name": "add_option_combobox", "parameters": ["master", "option_name_or_variable", "description", "choices", "height", "width", "row", "column", "label_columnspan", "label_pady", "label_padx", "combobox_columnspan", "combobox_pady", "combobox_padx", "tooltip"], "param_types": {"master": "tk.Widget", "option_name_or_variable": "Union[tk.Variable, str, None]", "description": "str", "choices": "Union[List[Any], Dict[str, Any]]", "height": "int", "width": "Optional[int]", "row": "Optional[int]", "column": "int", "label_columnspan": "int", "label_pady": "Union[Tuple, int, str, None]", "label_padx": "Union[Tuple, int, str, None]", "combobox_columnspan": "int", "combobox_pady": "Union[Tuple, int, str, None]", "combobox_padx": "Union[Tuple, int, str]", "tooltip": "Optional[str]"}, "return_type": "MappingCombobox", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["MappingCombobox", "_check_bundle_with_tooltip_icon", "_ensure_pady", "ems_to_pixels", "get_workbench", "get_workbench().get_variable", "isinstance", "label.grid", "master.grid_size", "str", "ttk.Label", "widget.grid"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_option_combobox(\n    master: tk.Widget,\n    option_name_or_variable: Union[tk.Variable, str, None],\n    description: str,\n    choices: Union[List[Any], Dict[str, Any]],\n    height: int = 15,\n    width: Optional[int] = None,\n    row: Optional[int] = None,\n    column: int = 0,\n    label_columnspan: int = 1,\n    label_pady: Union[Tuple, int, str, None] = None,\n    label_padx: Union[Tuple, int, str, None] = None,\n    combobox_columnspan: int = 1,\n    combobox_pady: Union[Tuple, int, str, None] = None,\n    combobox_padx: Union[Tuple, int, str] = 0,\n    tooltip: Optional[str] = None,\n) -> MappingCombobox:\n    if row is None:\n        row = master.grid_size()[1]\n\n    label_pady = _ensure_pady(label_pady)\n    combobox_pady = _ensure_pady(combobox_pady)\n\n    if label_padx is None:\n        label_padx = (0, ems_to_pixels(LABEL_PADDING_EMS))\n\n    label = ttk.Label(master, text=description)\n    label.grid(\n        row=row,\n        column=column,\n        columnspan=label_columnspan,\n        sticky=\"w\",\n        pady=label_pady,\n        padx=label_padx,\n    )\n\n    if isinstance(choices, list):\n        mapping = {str(x): x for x in choices}\n    else:\n        assert isinstance(choices, dict)\n        mapping = choices\n\n    if isinstance(option_name_or_variable, str):\n        variable = get_workbench().get_variable(option_name_or_variable)\n    elif isinstance(option_name_or_variable, tk.Variable):\n        variable = option_name_or_variable\n    else:\n        assert option_name_or_variable is None\n        variable = option_name_or_variable\n\n    combobox = MappingCombobox(\n        master,\n        mapping=mapping,\n        exportselection=False,\n        value_variable=variable,\n        height=height,\n        width=width,\n    )\n    widget = _check_bundle_with_tooltip_icon(combobox, tooltip)\n    widget.grid(\n        row=row,\n        column=column + 1,\n        columnspan=combobox_columnspan,\n        sticky=\"w\",\n        pady=combobox_pady,\n        padx=combobox_padx,\n    )\n\n    return combobox", "loc": 69}
{"file": "thonny\\thonny\\config_ui.py", "class_name": null, "function_name": "add_option_entry", "parameters": ["master", "option_name", "description", "width", "row", "column", "label_columnspan", "label_pady", "label_padx", "entry_columnspan", "entry_pady", "entry_padx", "regex", "tooltip"], "param_types": {"master": "tk.Widget", "option_name": "str", "description": "str", "width": "Optional[int]", "row": "Optional[int]", "column": "int", "label_columnspan": "int", "label_pady": "Union[Tuple, int, str, None]", "label_padx": "Union[Tuple, int, str, None]", "entry_columnspan": "int", "entry_pady": "Union[Tuple, int, str, None]", "entry_padx": "Union[Tuple, int, str]", "regex": "Optional[str]", "tooltip": "Optional[str]"}, "return_type": "ttk.Entry", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_check_bundle_with_tooltip_icon", "_ensure_pady", "ems_to_pixels", "get_regex_validator", "get_workbench", "get_workbench().get_variable", "label.grid", "master.grid_size", "ttk.Entry", "ttk.Label", "widget.grid"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_option_entry(\n    master: tk.Widget,\n    option_name: str,\n    description: str,\n    width: Optional[int] = None,\n    row: Optional[int] = None,\n    column: int = 0,\n    label_columnspan: int = 1,\n    label_pady: Union[Tuple, int, str, None] = None,\n    label_padx: Union[Tuple, int, str, None] = None,\n    entry_columnspan: int = 1,\n    entry_pady: Union[Tuple, int, str, None] = None,\n    entry_padx: Union[Tuple, int, str] = 0,\n    regex: Optional[str] = None,\n    tooltip: Optional[str] = None,\n) -> ttk.Entry:\n    if row is None:\n        row = master.grid_size()[1]\n\n    label_pady = _ensure_pady(label_pady)\n    entry_pady = _ensure_pady(entry_pady)\n\n    if label_padx is None:\n        label_padx = (0, ems_to_pixels(LABEL_PADDING_EMS))\n\n    label = ttk.Label(master, text=description)\n    label.grid(\n        row=row, column=0, columnspan=label_columnspan, sticky=\"w\", pady=label_pady, padx=label_padx\n    )\n\n    variable = get_workbench().get_variable(option_name)\n\n    validation_args = (\n        {}\n        if regex is None\n        else {\"validate\": \"all\", \"validatecommand\": (get_regex_validator(regex), \"%P\")}\n    )\n    entry = ttk.Entry(master, textvariable=variable, width=width, **validation_args)\n    widget = _check_bundle_with_tooltip_icon(entry, tooltip)\n    widget.grid(\n        row=row,\n        column=column + 1,\n        columnspan=entry_columnspan,\n        sticky=\"w\",\n        pady=entry_pady,\n        padx=entry_padx,\n    )\n\n    return entry", "loc": 49}
{"file": "thonny\\thonny\\config_ui.py", "class_name": null, "function_name": "add_label_and_url", "parameters": ["master", "description", "url", "row", "column", "label_columnspan", "label_pady", "label_padx", "url_columnspan", "url_pady", "url_padx", "tooltip"], "param_types": {"master": "tk.Widget", "description": "str", "url": "str", "row": "Optional[int]", "column": "int", "label_columnspan": "int", "label_pady": "Union[Tuple, int, str, None]", "label_padx": "Union[Tuple, int, str, None]", "url_columnspan": "int", "url_pady": "Union[Tuple, int, str, None]", "url_padx": "Union[Tuple, int, str]", "tooltip": "Optional[str]"}, "return_type": "ttk.Label", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_check_bundle_with_tooltip_icon", "_ensure_pady", "create_url_label", "ems_to_pixels", "label.grid", "master.grid_size", "ttk.Label", "widget.grid"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_label_and_url(\n    master: tk.Widget,\n    description: str,\n    url: str,\n    row: Optional[int] = None,\n    column: int = 0,\n    label_columnspan: int = 1,\n    label_pady: Union[Tuple, int, str, None] = None,\n    label_padx: Union[Tuple, int, str, None] = None,\n    url_columnspan: int = 1,\n    url_pady: Union[Tuple, int, str, None] = None,\n    url_padx: Union[Tuple, int, str] = 0,\n    tooltip: Optional[str] = None,\n) -> ttk.Label:\n    if row is None:\n        row = master.grid_size()[1]\n\n    label_pady = _ensure_pady(label_pady)\n    url_pady = _ensure_pady(url_pady)\n\n    if label_padx is None:\n        label_padx = (0, ems_to_pixels(LABEL_PADDING_EMS))\n\n    label = ttk.Label(master, text=description)\n    label.grid(\n        row=row, column=0, columnspan=label_columnspan, sticky=\"w\", pady=label_pady, padx=label_padx\n    )\n\n    url_label = create_url_label(master, url=url)\n    widget = _check_bundle_with_tooltip_icon(url_label, tooltip)\n    widget.grid(\n        row=row,\n        column=column + 1,\n        columnspan=url_columnspan,\n        sticky=\"w\",\n        pady=url_pady,\n        padx=url_padx,\n    )\n\n    return url_label", "loc": 40}
{"file": "thonny\\thonny\\config_ui.py", "class_name": null, "function_name": "add_label_and_text", "parameters": ["master", "description", "text", "row", "column", "label_columnspan", "label_pady", "label_padx", "text_columnspan", "text_pady", "text_padx", "tooltip"], "param_types": {"master": "tk.Widget", "description": "str", "text": "str", "row": "Optional[int]", "column": "int", "label_columnspan": "int", "label_pady": "Union[Tuple, int, str, None]", "label_padx": "Union[Tuple, int, str, None]", "text_columnspan": "int", "text_pady": "Union[Tuple, int, str, None]", "text_padx": "Union[Tuple, int, str]", "tooltip": "Optional[str]"}, "return_type": "ttk.Label", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_check_bundle_with_tooltip_icon", "_ensure_pady", "ems_to_pixels", "label.grid", "master.grid_size", "ttk.Label", "widget.grid"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_label_and_text(\n    master: tk.Widget,\n    description: str,\n    text: str,\n    row: Optional[int] = None,\n    column: int = 0,\n    label_columnspan: int = 1,\n    label_pady: Union[Tuple, int, str, None] = None,\n    label_padx: Union[Tuple, int, str, None] = None,\n    text_columnspan: int = 1,\n    text_pady: Union[Tuple, int, str, None] = None,\n    text_padx: Union[Tuple, int, str] = 0,\n    tooltip: Optional[str] = None,\n) -> ttk.Label:\n    if row is None:\n        row = master.grid_size()[1]\n\n    label_pady = _ensure_pady(label_pady)\n    text_pady = _ensure_pady(text_pady)\n    if label_padx is None:\n        label_padx = (0, ems_to_pixels(LABEL_PADDING_EMS))\n\n    label = ttk.Label(master, text=description)\n    label.grid(\n        row=row, column=0, columnspan=label_columnspan, sticky=\"w\", pady=label_pady, padx=label_padx\n    )\n\n    text_label = ttk.Label(master, text=text)\n    widget = _check_bundle_with_tooltip_icon(text_label, tooltip)\n    widget.grid(\n        row=row,\n        column=column + 1,\n        columnspan=text_columnspan,\n        sticky=\"w\",\n        pady=text_pady,\n        padx=text_padx,\n    )\n\n    return text_label", "loc": 39}
{"file": "thonny\\thonny\\config_ui.py", "class_name": null, "function_name": "add_label_and_box_for_list_of_strings", "parameters": ["master", "description", "lines", "height", "width", "row", "column", "label_columnspan", "label_pady", "label_padx", "box_columnspan", "box_pady", "box_padx", "tooltip"], "param_types": {"master": "tk.Widget", "description": "str", "lines": "List[str]", "height": "int", "width": "Optional[int]", "row": "Optional[int]", "column": "int", "label_columnspan": "int", "label_pady": "Union[Tuple, int, str, None]", "label_padx": "Union[Tuple, int, str]", "box_columnspan": "int", "box_pady": "Union[Tuple, int, str, None]", "box_padx": "Union[Tuple, int, str]", "tooltip": "Optional[str]"}, "return_type": "TextFrame", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "TextFrame", "_check_bundle_with_tooltip_icon", "_ensure_pady", "ems_to_pixels", "master.grid_size", "text_frame.grid", "text_frame.text.insert", "ttk.Label", "widget.grid"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_label_and_box_for_list_of_strings(\n    master: tk.Widget,\n    description: str,\n    lines: List[str],\n    height: int = 4,\n    width: Optional[int] = None,\n    row: Optional[int] = None,\n    column: int = 0,\n    label_columnspan: int = 3,\n    label_pady: Union[Tuple, int, str, None] = None,\n    label_padx: Union[Tuple, int, str] = 0,\n    box_columnspan: int = 3,\n    box_pady: Union[Tuple, int, str, None] = None,\n    box_padx: Union[Tuple, int, str] = 0,\n    tooltip: Optional[str] = None,\n) -> TextFrame:\n    if row is None:\n        row = master.grid_size()[1]\n\n    label_pady = _ensure_pady(label_pady)\n    box_pady = _ensure_pady(box_pady)\n\n    label = ttk.Label(master, text=description)\n    widget = _check_bundle_with_tooltip_icon(label, tooltip)\n    widget.grid(\n        row=row, column=0, columnspan=label_columnspan, sticky=\"w\", pady=label_pady, padx=label_padx\n    )\n\n    text_frame = TextFrame(\n        master,\n        horizontal_scrollbar_class=ui_utils.AutoScrollbar,\n        wrap=\"none\",\n        font=\"TkDefaultFont\",\n        # cursor=\"arrow\",\n        padx=ems_to_pixels(0.3),\n        pady=ems_to_pixels(0.3),\n        height=height,\n        width=width,\n        borderwidth=1,\n        undo=True,\n        relief=\"groove\",\n    )\n    text_frame.grid(\n        row=row + 1,\n        column=column,\n        columnspan=box_columnspan,\n        sticky=\"nsew\",\n        pady=box_pady,\n        padx=box_padx,\n    )\n\n    text_frame.text.insert(\"1.0\", \"\\n\".join(lines) + \"\\n\")\n\n    return text_frame", "loc": 54}
{"file": "thonny\\thonny\\config_ui.py", "class_name": null, "function_name": "add_text_row", "parameters": ["master", "description", "font", "row", "column", "columnspan", "pady", "padx"], "param_types": {"master": "tk.Widget", "description": "str", "font": "Union[str, tk.font.Font]", "row": "Optional[int]", "column": "int", "columnspan": "int", "pady": "Union[Tuple, int, str, None]", "padx": "Union[Tuple, int, str]"}, "return_type": "ttk.Label", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_ensure_pady", "label.grid", "master.grid_size", "ttk.Label"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_text_row(\n    master: tk.Widget,\n    description: str,\n    font: Union[str, tk.font.Font] = \"TkDefaultFont\",\n    row: Optional[int] = None,\n    column: int = 0,\n    columnspan: int = 3,\n    pady: Union[Tuple, int, str, None] = None,\n    padx: Union[Tuple, int, str] = 0,\n) -> ttk.Label:\n    if row is None:\n        row = master.grid_size()[1]\n\n    pady = _ensure_pady(pady)\n\n    label = ttk.Label(master, text=description, font=font)\n    label.grid(row=row, column=column, columnspan=columnspan, sticky=\"w\", pady=pady, padx=padx)\n\n    return label", "loc": 19}
{"file": "thonny\\thonny\\config_ui.py", "class_name": null, "function_name": "add_vertical_separator", "parameters": ["master", "row", "column", "height"], "param_types": {"master": "tk.Widget", "row": "Optional[int]", "column": "int", "height": "Union[str, int, None]"}, "return_type": "ttk.Frame", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ems_to_pixels", "frame.grid", "master.grid_size", "ttk.Frame"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_vertical_separator(\n    master: tk.Widget,\n    row: Optional[int] = None,\n    column: int = 0,\n    height: Union[str, int, None] = None,\n) -> ttk.Frame:\n    if row is None:\n        row = master.grid_size()[1]\n\n    if height is None:\n        height = ems_to_pixels(1)\n\n    frame = ttk.Frame(master, height=height, width=\"1c\")\n    frame.grid(row=row, column=column)\n\n    return frame", "loc": 16}
{"file": "thonny\\thonny\\config_ui.py", "class_name": null, "function_name": "get_regex_validator", "parameters": ["regex"], "param_types": {"regex": "str"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bool", "get_workbench", "get_workbench().register", "re.fullmatch"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_regex_validator(regex: str) -> Any:\n    if regex not in _regex_validators:\n\n        def validate(s: str) -> bool:\n            return bool(re.fullmatch(regex, s))\n\n        _regex_validators[regex] = get_workbench().register(validate)\n\n    return _regex_validators[regex]", "loc": 9}
{"file": "thonny\\thonny\\config_ui.py", "class_name": "ConfigurationDialog", "function_name": "get_changed_options", "parameters": ["self"], "param_types": {}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_changed_options(self) -> List[str]:\n    return [\n        name\n        for name in self._initial_option_values\n        if self._initial_option_values[name] != get_workbench().get_option(name)\n    ]", "loc": 6}
{"file": "thonny\\thonny\\config_ui.py", "class_name": "ConfigurationPage", "function_name": "add_checkbox", "parameters": ["self", "flag_name", "description", "row", "column", "padx", "pady", "columnspan", "tooltip"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["checkbox.grid", "get_workbench", "get_workbench().get_variable", "ttk.Checkbutton", "ui_utils.create_tooltip", "warnings.warn"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_checkbox(\n    self, flag_name, description, row=None, column=0, padx=0, pady=0, columnspan=1, tooltip=None\n):\n    warnings.warn(\n        \"Consider using thonny.config_ui.add_option_checkbox instead\", DeprecationWarning\n    )\n    variable = get_workbench().get_variable(flag_name)\n    checkbox = ttk.Checkbutton(self, text=description, variable=variable)\n    checkbox.grid(\n        row=row, column=column, sticky=tk.W, padx=padx, pady=pady, columnspan=columnspan\n    )\n\n    if tooltip is not None:\n        ui_utils.create_tooltip(checkbox, tooltip)", "loc": 14}
{"file": "thonny\\thonny\\config_ui.py", "class_name": "ConfigurationPage", "function_name": "add_combobox", "parameters": ["self", "variable", "values", "row", "column", "padx", "pady", "columnspan", "width"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["combobox.grid", "get_workbench", "get_workbench().get_variable", "isinstance", "ttk.Combobox", "warnings.warn"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_combobox(\n    self, variable, values, row=None, column=0, padx=0, pady=0, columnspan=1, width=None\n):\n    warnings.warn(\n        \"Consider using thonny.config_ui.add_option_combobox instead\", DeprecationWarning\n    )\n    if isinstance(variable, str):\n        variable = get_workbench().get_variable(variable)\n    combobox = ttk.Combobox(\n        self,\n        exportselection=False,\n        textvariable=variable,\n        state=\"readonly\",\n        height=15,\n        width=width,\n        values=values,\n    )\n    combobox.grid(\n        row=row, column=column, sticky=tk.W, pady=pady, padx=padx, columnspan=columnspan\n    )\n    return variable", "loc": 21}
{"file": "thonny\\thonny\\config_ui.py", "class_name": "ConfigurationPage", "function_name": "add_entry", "parameters": ["self", "option_name", "row", "column", "pady", "padx", "columnspan"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["entry.grid", "get_workbench", "get_workbench().get_variable", "ttk.Entry", "warnings.warn"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_entry(self, option_name, row=None, column=0, pady=0, padx=0, columnspan=1, **kw):\n    warnings.warn(\n        \"Consider using thonny.config_ui.add_option_entry instead\", DeprecationWarning\n    )\n    variable = get_workbench().get_variable(option_name)\n    entry = ttk.Entry(self, textvariable=variable, **kw)\n    entry.grid(row=row, column=column, sticky=tk.W, pady=pady, columnspan=columnspan, padx=padx)", "loc": 7}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebookTabRow", "function_name": "dnd_motion", "parameters": ["self", "source", "event"], "param_types": {"source": "CustomNotebookTab", "event": "tk.Event"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._compute_insertion_position", "self._insertion_mark.place_forget", "self._show_insertion_mark", "self.winfo_rootx", "self.winfo_rooty", "source.notebook.index_of_tab"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dnd_motion(self, source: CustomNotebookTab, event: tk.Event):\n    x = event.x_root - self.winfo_rootx()\n    y = event.y_root - self.winfo_rooty()\n    insertion_index, insertion_widget = self._compute_insertion_position(x, y)\n    source_index = source.notebook.index_of_tab(source)\n    if source.notebook is self.notebook and insertion_index in [source_index, source_index + 1]:\n        # no point in moving a tab right before or after itself\n        self._insertion_mark.place_forget()\n    else:\n        self._show_insertion_mark(insertion_index, insertion_widget)", "loc": 10}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebookTabRow", "function_name": "dnd_commit", "parameters": ["self", "source", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.info", "self.dnd_leave", "self.notebook.insert_from_another_notebook_or_position", "source.notebook.get_page_by_tab"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dnd_commit(self, source, event):\n    logger.info(\"dnd_commit with insertion_index %r\", self._insertion_index)\n    if self._insertion_index is not None:\n        self.notebook.insert_from_another_notebook_or_position(\n            self._insertion_index, source.notebook.get_page_by_tab(source)\n        )\n    self.dnd_leave(source, event)", "loc": 7}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "insert_from_another_notebook_or_position", "parameters": ["self", "pos", "page"], "param_types": {"pos": "Union[int, Literal['end']]", "page": "CustomNotebookPage"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["original_notebook._forget", "page.tab.get_title", "self._insert", "self.index_of_tab"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def insert_from_another_notebook_or_position(\n    self, pos: Union[int, Literal[\"end\"]], page: CustomNotebookPage\n) -> None:\n    original_notebook = page.tab.notebook\n    if original_notebook == self and pos >= self.index_of_tab(page.tab):\n        # tab will be removed first, so the new target index will be one less\n        pos -= 1\n\n    original_notebook._forget(page.content, new_notebook=self)\n    self._insert(pos, page.content, text=page.tab.get_title(), old_notebook=original_notebook)", "loc": 10}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "on_theme_changed", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_lookup_style_option", "bool", "page.tab.update_style", "self.configure", "self.get_bordercolor", "self.tab_row.on_theme_changed"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_theme_changed(self, event):\n    self.dynamic_border = bool(\n        _lookup_style_option(\"CustomNotebook.Tab\", \"dynamic_border\", False)\n    )\n    self.configure(background=self.get_bordercolor())\n    self.tab_row.on_theme_changed()\n    for page in self.pages:\n        page.tab.update_style()", "loc": 8}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "select", "parameters": ["self", "tab_id"], "param_types": {"tab_id": "Union[str, tk.Widget, None]"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.current_page.content.winfo_name", "self.index", "self.select_by_index"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select(self, tab_id: Union[str, tk.Widget, None] = None) -> Optional[str]:\n    if tab_id is None:\n        if self.current_page:\n            return self.current_page.content.winfo_name()\n        return None\n\n    return self.select_by_index(self.index(tab_id))", "loc": 7}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "select_by_index", "parameters": ["self", "index"], "param_types": {"index": "int"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["new_page.content.grid", "new_page.content.grid_propagate", "new_page.tab.update_state", "self.current_page.content.focus_set", "self.current_page.content.grid_remove", "self.current_page.tab.update_state", "self.event_generate"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_by_index(self, index: int) -> None:\n    new_page = self.pages[index]\n    if new_page == self.current_page:\n        return\n\n    new_page.content.grid_propagate(False)\n    new_page.content.grid(row=1, column=0, sticky=\"nsew\", padx=(1, 1), pady=(0, 1), in_=self)\n    if self.current_page:\n        self.current_page.content.grid_remove()\n        # new_page.content.tkraise(self.current_page.content)\n    new_page.tab.update_state(True)\n    if self.current_page:\n        self.current_page.tab.update_state(False)\n\n    self.current_page = new_page\n    self.current_page.content.focus_set()\n    self.event_generate(\"<<NotebookTabChanged>>\")", "loc": 17}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "select_tab", "parameters": ["self", "tab"], "param_types": {"tab": "CustomNotebookTab"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "enumerate", "self.select_by_index"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_tab(self, tab: CustomNotebookTab) -> None:\n    for i, page in enumerate(self.pages):\n        if page.tab == tab:\n            self.select_by_index(i)\n            return\n\n    raise ValueError(f\"Unknown tab {tab}\")", "loc": 7}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "select_another_tab", "parameters": ["self", "event"], "param_types": {"event": "tk.Event"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.bell", "self.index", "self.select_by_index", "shift_is_pressed"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_another_tab(self, event: tk.Event) -> Optional[str]:\n    if len(self.pages) < 2:\n        self.bell()\n        return None\n\n    from thonny.ui_utils import shift_is_pressed\n\n    if shift_is_pressed(event):\n        offset = -1\n    else:\n        offset = 1\n\n    index = self.index(self.current_page.content)\n    new_index = (index + offset) % len(self.pages)\n    self.select_by_index(new_index)\n    return \"break\"", "loc": 16}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "index", "parameters": ["self", "tab_id"], "param_types": {"tab_id": "Union[str, tk.Widget]"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "enumerate", "len", "page.content.winfo_name"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def index(self, tab_id: Union[str, tk.Widget]) -> int:\n    if tab_id == \"end\":\n        return len(self.pages)\n\n    for i, page in enumerate(self.pages):\n        if page.content == tab_id or page.content.winfo_name() == tab_id:\n            return i\n    else:\n        raise RuntimeError(f\"Can't find {tab_id!r}\")", "loc": 9}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "index_of_tab", "parameters": ["self", "tab"], "param_types": {"tab": "CustomNotebookTab"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "enumerate"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def index_of_tab(self, tab: CustomNotebookTab) -> int:\n    for i, page in enumerate(self.pages):\n        if page.tab is tab:\n            return i\n    else:\n        raise RuntimeError(f\"Can't find {tab!r}\")", "loc": 6}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "has_content", "parameters": ["self", "child"], "param_types": {"child": "tk.Widget"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def has_content(self, child: tk.Widget) -> bool:\n    for page in self.pages:\n        if page.content is child:\n            return True\n\n    return False", "loc": 6}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "focus_set", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.current_page.content.focus_set", "super", "super().focus_set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def focus_set(self):\n    if self.current_page:\n        self.current_page.content.focus_set()\n    else:\n        super().focus_set()", "loc": 5}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "get_page_by_tab", "parameters": ["self", "tab"], "param_types": {"tab": "CustomNotebookTab"}, "return_type": "CustomNotebookPage", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_page_by_tab(self, tab: CustomNotebookTab) -> CustomNotebookPage:\n    for page in self.pages:\n        if page.tab == tab:\n            return page\n\n    raise ValueError(f\"Could not find tab {tab}\")", "loc": 6}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "close_tab", "parameters": ["self", "index_or_tab"], "param_types": {"index_or_tab": "Union[int, CustomNotebookTab]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self._forget", "self.get_page_by_tab"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close_tab(self, index_or_tab: Union[int, CustomNotebookTab]) -> None:\n    if isinstance(index_or_tab, int):\n        page = self.pages[index_or_tab]\n    else:\n        page = self.get_page_by_tab(index_or_tab)\n\n    self._forget(page.content, None)", "loc": 7}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebook", "function_name": "close_tabs", "parameters": ["self", "except_tab"], "param_types": {"except_tab": "Optional[CustomNotebookTab]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["reversed", "self.close_tab"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close_tabs(self, except_tab: Optional[CustomNotebookTab] = None):\n    for page in reversed(self.pages):\n        if page.tab == except_tab:\n            continue\n        else:\n            self.close_tab(page.tab)", "loc": 6}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebookTab", "function_name": "update_style", "parameters": ["self", "only_background"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_ems_to_pixels", "_get_style_configuration", "self._get_tab_style_option", "self.button.configure", "self.configure", "self.grid", "self.indicator.configure", "self.label.configure", "self.menu.configure", "self.notebook.get_bordercolor", "self.notebook.get_label_foreground"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_style(self, only_background=False):\n    self.label.configure(foreground=self.notebook.get_label_foreground())\n\n    if self._active:\n        main_background = self._get_tab_style_option(\"activebackground\")\n    elif self._hover:\n        main_background = self._get_tab_style_option(\"hoverbackground\")\n    else:\n        main_background = self._get_tab_style_option(\"background\")\n\n    self.configure(background=main_background)\n    self.label.configure(background=main_background)\n    if self.button:\n        self.button.configure(background=main_background)\n\n    if only_background:\n        return\n\n    if self._active:\n        indicator_background = self._get_tab_style_option(\"indicatorbackground\")\n        indicator_height = self._get_tab_style_option(\"indicatorheight\", _ems_to_pixels(0.2))\n        if self.notebook.dynamic_border:\n            self.grid(padx=1, pady=(1, 0))\n    else:\n        indicator_background = self.notebook.get_bordercolor()\n        indicator_height = 1\n        if self.notebook.dynamic_border:\n            self.grid(padx=0, pady=0)\n\n    self.indicator.configure(background=indicator_background, height=indicator_height)\n\n    self.menu.configure(**_get_style_configuration(\"Menu\"))", "loc": 32}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebookTab", "function_name": "on_click", "parameters": ["self", "event"], "param_types": {"event": "tk.Event"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dnd.dnd_start", "self.notebook.select_tab"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_click(self, event: tk.Event):\n    self.notebook.select_tab(self)\n    self.drag_start_x_root = event.x_root\n    self.drag_start_y_root = event.y_root\n    dnd.dnd_start(self, event)", "loc": 5}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebookTab", "function_name": "dnd_motion_anywhere", "parameters": ["self", "source", "event"], "param_types": {"source": "CustomNotebookTab", "event": "tk.Event"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_ems_to_pixels", "abs", "hasattr", "self.notebook.allows_dragging_to_another_notebook", "self.winfo_toplevel", "toplevel.show_notebook_drop_targets"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dnd_motion_anywhere(self, source: CustomNotebookTab, event: tk.Event):\n    toplevel = self.winfo_toplevel()\n    delta_x = abs(source.drag_start_x_root - event.x_root)\n    delta_y = abs(source.drag_start_y_root - event.y_root)\n    moved_enough = _ems_to_pixels(2)\n    if (\n        (delta_x > moved_enough or delta_y > moved_enough)\n        and hasattr(toplevel, \"show_notebook_drop_targets\")\n        and self.notebook.allows_dragging_to_another_notebook()\n    ):\n        toplevel.show_notebook_drop_targets()", "loc": 11}
{"file": "thonny\\thonny\\custom_notebook.py", "class_name": "CustomNotebookTab", "function_name": "dnd_end", "parameters": ["self", "target", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "logger.info", "self.notebook.allows_dragging_to_another_notebook", "self.winfo_toplevel", "toplevel.hide_notebook_drop_targets"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dnd_end(self, target, event):\n    logger.info(\"Ending DND operation with target %r\", target)\n    toplevel = self.winfo_toplevel()\n    if (\n        hasattr(toplevel, \"hide_notebook_drop_targets\")\n        and self.notebook.allows_dragging_to_another_notebook()\n    ):\n        toplevel.hide_notebook_drop_targets()", "loc": 8}
{"file": "thonny\\thonny\\dnd.py", "class_name": null, "function_name": "dnd_start", "parameters": ["source", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DndHandler"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dnd_start(source, event):\n    h = DndHandler(source, event)\n    if h.root is not None:\n        return h\n    else:\n        return None", "loc": 6}
{"file": "thonny\\thonny\\dnd.py", "class_name": "DndHandler", "function_name": "on_motion", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["attr", "getattr", "motion_anywhere", "new_target.dnd_enter", "old_target.dnd_leave", "old_target.dnd_motion", "self.initial_widget.winfo_containing"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_motion(self, event):\n    x, y = event.x_root, event.y_root\n    target_widget = self.initial_widget.winfo_containing(x, y)\n    source = self.source\n    motion_anywhere = getattr(source, \"dnd_motion_anywhere\", None)\n    if motion_anywhere:\n        motion_anywhere(source, event)\n    new_target = None\n    while target_widget is not None:\n        try:\n            attr = target_widget.dnd_accept\n        except AttributeError:\n            pass\n        else:\n            new_target = attr(source, event)\n            if new_target is not None:\n                break\n        target_widget = target_widget.master\n    old_target = self.target\n    if old_target is new_target:\n        if old_target is not None:\n            old_target.dnd_motion(source, event)\n    else:\n        if old_target is not None:\n            self.target = None\n            old_target.dnd_leave(source, event)\n        if new_target is not None:\n            new_target.dnd_enter(source, event)\n            self.target = new_target", "loc": 29}
{"file": "thonny\\thonny\\dnd.py", "class_name": "DndHandler", "function_name": "finish", "parameters": ["self", "event", "commit"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.initial_widget.unbind", "source.dnd_end", "target.dnd_commit", "target.dnd_leave"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def finish(self, event, commit=0):\n    target = self.target\n    source = self.source\n    widget = self.initial_widget\n    root = self.root\n    try:\n        del root.__dnd\n        self.initial_widget.unbind(self.release_pattern)\n        self.initial_widget.unbind(\"<Motion>\")\n        widget[\"cursor\"] = self.save_cursor\n        self.target = self.source = self.initial_widget = self.root = None\n        if target is not None:\n            if commit:\n                target.dnd_commit(source, event)\n            else:\n                target.dnd_leave(source, event)\n    finally:\n        source.dnd_end(target, event)", "loc": 18}
{"file": "thonny\\thonny\\editors.py", "class_name": null, "function_name": "get_current_breakpoints", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.get_code_view", "editor.get_code_view().get_breakpoint_line_numbers", "editor.get_target_path", "editor.is_local", "get_workbench", "get_workbench().get_editor_notebook", "get_workbench().get_editor_notebook().get_all_editors"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_current_breakpoints():\n    result = {}\n\n    for editor in get_workbench().get_editor_notebook().get_all_editors():\n        if editor.is_local():\n            linenos = editor.get_code_view().get_breakpoint_line_numbers()\n            if linenos:\n                result[editor.get_target_path()] = linenos\n\n    return result", "loc": 10}
{"file": "thonny\\thonny\\editors.py", "class_name": null, "function_name": "get_saved_current_script_path", "parameters": ["force"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.get_target_path", "editor.is_modified", "editor.is_untitled", "editor.save_file", "get_workbench", "get_workbench().get_editor_notebook", "get_workbench().get_editor_notebook().get_current_editor"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_saved_current_script_path(force=True):\n    editor = get_workbench().get_editor_notebook().get_current_editor()\n    if not editor:\n        return None\n\n    if editor.is_untitled() and force:\n        editor.save_file()\n\n    path = editor.get_target_path()\n    if not path:\n        return None\n\n    if editor.is_modified():\n        path = editor.save_file()\n\n    return path", "loc": 16}
{"file": "thonny\\thonny\\editors.py", "class_name": "BaseEditor", "function_name": "get_target_path", "parameters": ["self"], "param_types": {}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.get_uri", "self.is_untitled", "uri_to_target_path"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_target_path(self) -> Optional[str]:\n    if self.is_untitled():\n        return None\n\n    return uri_to_target_path(self.get_uri())", "loc": 5}
{"file": "thonny\\thonny\\editors.py", "class_name": "BaseEditor", "function_name": "update_appearance", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "get_workbench().in_simple_mode", "self._code_view.grid_main_widgets", "self._code_view.set_gutter_visibility", "self._code_view.set_line_length_margin", "self._code_view.text.event_generate", "self._code_view.text.update_tab_stops"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_appearance(self):\n    self._code_view.set_gutter_visibility(\n        get_workbench().get_option(\"view.show_line_numbers\") or get_workbench().in_simple_mode()\n    )\n    self._code_view.set_line_length_margin(\n        get_workbench().get_option(\"view.recommended_line_length\")\n    )\n    self._code_view.text.update_tab_stops()\n    self._code_view.text.indent_width = get_workbench().get_option(\"edit.indent_width\")\n    self._code_view.text.tab_width = get_workbench().get_option(\"edit.tab_width\")\n    self._code_view.text.event_generate(\"<<UpdateAppearance>>\")\n    self._code_view.grid_main_widgets()", "loc": 12}
{"file": "thonny\\thonny\\editors.py", "class_name": "BaseEditor", "function_name": "update_file_type", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._code_view.set_file_type", "self.get_target_path", "self.get_target_path().split", "self.get_target_path().split('.')[-1].lower", "self.is_untitled"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_file_type(self):\n    if self.is_untitled():\n        self._code_view.set_file_type(\"python\")\n    else:\n        ext = self.get_target_path().split(\".\")[-1].lower()\n        if ext in PYTHON_EXTENSIONS:\n            file_type = \"python\"\n        elif ext in PYTHONLIKE_EXTENSIONS:\n            file_type = \"pythonlike\"\n        else:\n            file_type = None\n\n        self._code_view.set_file_type(file_type)", "loc": 13}
{"file": "thonny\\thonny\\editors.py", "class_name": "BaseEditor", "function_name": "get_title", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["format_untitled_uri", "self.get_target_path", "self.get_target_path().split", "self.get_uri", "self.is_local", "self.is_modified", "self.is_remote", "self.is_untitled", "self.shorten_filename_for_title"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_title(self):\n    if self.is_untitled():\n        result = format_untitled_uri(self.get_uri())\n    elif self.is_remote():\n        name = self.get_target_path().split(\"/\")[-1]\n        result = \"[ \" + name + \" ]\"\n    else:\n        assert self.is_local()\n        result = self.shorten_filename_for_title(self.get_target_path())\n\n    if self.is_modified():\n        result += \" *\"\n\n    return result", "loc": 14}
{"file": "thonny\\thonny\\editors.py", "class_name": "Editor", "function_name": "get_filename", "parameters": ["self", "try_hard"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["make_legacy_remote_path", "self.get_target_path", "self.is_remote", "self.is_untitled", "self.save_file", "warnings.warn"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_filename(self, try_hard=False):\n    warnings.warn(\n        \"Editor.get_filename is deprecated. Use get_target_path instead\", DeprecationWarning\n    )\n\n    if self.is_untitled() and try_hard:\n        self.save_file()\n\n    path = self.get_target_path()\n    if path is None:\n        return None\n\n    if self.is_remote():\n        return make_legacy_remote_path(path)\n    else:\n        return path", "loc": 16}
{"file": "thonny\\thonny\\editors.py", "class_name": "Editor", "function_name": "set_uri", "parameters": ["self", "uri"], "param_types": {"uri": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._disconnect_from_language_servers", "self._update_language_servers", "self.update_title", "super", "super().set_uri"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_uri(self, uri: str) -> None:\n    old_uri = self._uri\n    if old_uri != uri:\n        self._disconnect_from_language_servers()\n\n    super().set_uri(uri)\n    self.update_title()\n    if old_uri != uri:\n        self._update_language_servers()", "loc": 9}
{"file": "thonny\\thonny\\editors.py", "class_name": "Editor", "function_name": "get_long_description", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'  @  {} : {}'.format", "exception", "index.split", "int", "self._code_view.text.index", "uri_to_long_title"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_long_description(self):\n    result = uri_to_long_title(self._uri)\n\n    try:\n        index = self._code_view.text.index(\"insert\")\n        if index and \".\" in index:\n            line, col = index.split(\".\")\n            result += \"  @  {} : {}\".format(line, int(col) + 1)\n    except Exception:\n        exception(\"Finding cursor location\")\n\n    return result", "loc": 12}
{"file": "thonny\\thonny\\editors.py", "class_name": "Editor", "function_name": "save_file", "parameters": ["self", "ask_target", "save_copy", "node"], "param_types": {}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().event_generate", "is_remote_uri", "messagebox.showerror", "self._code_view.get_content_as_bytes", "self._update_file_source", "self.ask_new_uri", "self.containing_notebook.get_editor", "self.is_untitled", "self.set_uri", "self.update_title", "self.write_local_file", "self.write_remote_file", "tr", "uri_to_legacy_filename", "uri_to_target_path"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def save_file(self, ask_target=False, save_copy=False, node=None) -> Optional[str]:\n    if not self.is_untitled() and not ask_target:\n        save_uri = self._uri\n        get_workbench().event_generate(\n            \"Save\",\n            editor=self,\n            uri=save_uri,\n            filename=uri_to_legacy_filename(save_uri),\n        )\n    else:\n        save_uri = self.ask_new_uri(node)\n\n        if not save_uri:\n            return None\n\n        if self.containing_notebook.get_editor(save_uri) is not None:\n            messagebox.showerror(\n                tr(\"File is open\"),\n                tr(\n                    \"This file is already open in Thonny.\\n\\n\"\n                    \"If you want to save with this name,\\n\"\n                    \"close the existing editor first!\"\n                ),\n                master=get_workbench(),\n            )\n            return None\n\n        get_workbench().event_generate(\n            \"SaveAs\",\n            editor=self,\n            uri=save_uri,\n            filename=uri_to_legacy_filename(save_uri),\n            save_copy=save_copy,\n        )\n\n    content_bytes = self._code_view.get_content_as_bytes()\n\n    if is_remote_uri(save_uri):\n        result = self.write_remote_file(uri_to_target_path(save_uri), content_bytes, save_copy)\n    else:\n        result = self.write_local_file(uri_to_target_path(save_uri), content_bytes, save_copy)\n\n    if not result:\n        return None\n\n    if not save_copy:\n        self.set_uri(save_uri)\n\n    if not save_copy or self._uri == save_uri:\n        self.update_title()\n        get_workbench().event_generate(\n            \"Saved\", editor=self, uri=save_uri, filename=uri_to_legacy_filename(save_uri)\n        )\n\n    self._update_file_source()\n    return save_uri", "loc": 56}
{"file": "thonny\\thonny\\editors.py", "class_name": "Editor", "function_name": "write_remote_file", "parameters": ["self", "target_path", "content_bytes", "save_copy"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InlineCommand", "get_runner", "get_runner().ready_for_remote_file_operations", "get_runner().send_command_and_wait", "get_workbench", "get_workbench().event_generate", "get_workbench().get_option", "id", "messagebox.showerror", "self._code_view.text.edit_modified", "self.update_title", "str", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write_remote_file(self, target_path, content_bytes, save_copy):\n    if get_runner().ready_for_remote_file_operations(show_message=True):\n\n        result = get_runner().send_command_and_wait(\n            InlineCommand(\n                \"write_file\",\n                path=target_path,\n                content_bytes=content_bytes,\n                editor_id=id(self),\n                blocking=True,\n                description=tr(\"Saving to %s\") % target_path,\n                make_shebang_scripts_executable=get_workbench().get_option(\n                    \"file.make_saved_shebang_scripts_executable\"\n                ),\n            ),\n            dialog_title=tr(\"Saving\"),\n        )\n\n        if result is None:\n            result = {\"error\": \"Unknown error\"}\n\n        if \"error\" in result:\n            messagebox.showerror(tr(\"Could not save\"), str(result[\"error\"]))\n            return False\n\n        if not save_copy:\n            self._code_view.text.edit_modified(False)\n\n        self.update_title()\n\n        # NB! edit_modified is not falsed yet!\n        get_workbench().event_generate(\n            \"RemoteFileOperation\", path=target_path, operation=\"save\"\n        )\n        get_workbench().event_generate(\"RemoteFilesChanged\")\n        return True\n    else:\n        messagebox.showerror(tr(\"Could not save\"), tr(\"Back-end is not ready\"))\n        return False", "loc": 39}
{"file": "thonny\\thonny\\editors.py", "class_name": "Editor", "function_name": "ask_new_uri", "parameters": ["self", "node"], "param_types": {}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["choose_node_for_file_operations", "local_path_to_uri", "remote_path_to_uri", "self.ask_new_local_path", "self.ask_new_remote_path", "self.winfo_toplevel", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ask_new_uri(self, node=None) -> Optional[str]:\n    if node is None:\n        node = choose_node_for_file_operations(self.winfo_toplevel(), tr(\"Where to save to?\"))\n    if not node:\n        return None\n\n    if node == \"local\":\n        path = self.ask_new_local_path()\n        if path is not None:\n            return local_path_to_uri(path)\n    else:\n        assert node == \"remote\"\n        path = self.ask_new_remote_path()\n        if path is not None:\n            return remote_path_to_uri(path)\n\n    return None", "loc": 17}
{"file": "thonny\\thonny\\editors.py", "class_name": "Editor", "function_name": "ask_new_remote_path", "parameters": ["self"], "param_types": {}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ask_backend_path", "make_legacy_remote_path", "self._check_add_py_extension", "self.winfo_toplevel"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ask_new_remote_path(self) -> Optional[str]:\n    target_path = ask_backend_path(self.winfo_toplevel(), \"save\", filetypes=_dialog_filetypes)\n    if target_path:\n        target_path = self._check_add_py_extension(target_path)\n        return make_legacy_remote_path(target_path)\n    else:\n        return None", "loc": 7}
{"file": "thonny\\thonny\\editors.py", "class_name": "Editor", "function_name": "select_line", "parameters": ["self", "lineno", "col_offset"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TextRange", "self._code_view.select_range", "self.get_text_widget", "self.get_text_widget().mark_set", "self.see_line"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_line(self, lineno, col_offset=None):\n    self._code_view.select_range(TextRange(lineno, 0, lineno + 1, 0))\n    self.see_line(lineno)\n\n    if col_offset is None:\n        col_offset = 0\n\n    self.get_text_widget().mark_set(\"insert\", \"%d.%d\" % (lineno, col_offset))", "loc": 8}
{"file": "thonny\\thonny\\editors.py", "class_name": "Editor", "function_name": "destroy", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().event_generate", "get_workbench().unbind", "self.get_text_widget", "ttk.Frame.destroy"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def destroy(self):\n    get_workbench().unbind(\"DebuggerResponse\", self._listen_debugger_progress)\n    get_workbench().unbind(\"ToplevelResponse\", self._listen_for_toplevel_response)\n    ttk.Frame.destroy(self)\n    get_workbench().event_generate(\n        \"EditorTextDestroyed\", editor=self, text_widget=self.get_text_widget()\n    )", "loc": 7}
{"file": "thonny\\thonny\\editors.py", "class_name": "Editor", "function_name": "send_changes_to_primed_servers", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DidChangeTextDocumentParams", "Position", "Range", "RangedTextDocumentContentChangeEvent", "VersionedTextDocumentIdentifier", "len", "logger.debug", "logger.info", "ls_changes.append", "ls_proxy.notify_did_change_text_document", "parse_text_index", "self._get_version_to_be_published", "self.get_uri"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def send_changes_to_primed_servers(self) -> None:\n    if not self._unpublished_incremental_changes:\n        logger.debug(\"No unpublished changes\")\n        return\n\n    if not self._primed_ls_proxies:\n        logger.debug(\"No primed proxies, not sending changes\")\n        return\n\n    logger.debug(\"Publishing %s events\", len(self._unpublished_incremental_changes))\n\n    ls_changes = []\n    for change in self._unpublished_incremental_changes:\n        logger.info(\"processing change %r\", change)\n        if change[\"sequence\"] == \"TextInsert\":\n            line, col = parse_text_index(change[\"index\"])\n            pos = Position(line=line - 1, character=col)  # TODO: Utf-16\n            ls_change = RangedTextDocumentContentChangeEvent(\n                range=Range(start=pos, end=pos), text=change[\"text\"]\n            )\n        else:\n            assert change[\"sequence\"] == \"TextDelete\"\n            start_line, start_col = parse_text_index(change[\"index1\"])\n            end_line, end_col = parse_text_index(change[\"index2\"])\n            ls_change = RangedTextDocumentContentChangeEvent(\n                range=Range(\n                    start=Position(line=start_line - 1, character=start_col),\n                    end=Position(line=end_line - 1, character=end_col),\n                ),\n                text=\"\",\n            )\n\n        ls_changes.append(ls_change)\n\n    version = self._get_version_to_be_published()\n    for ls_proxy in self._primed_ls_proxies:\n        ls_proxy.notify_did_change_text_document(\n            DidChangeTextDocumentParams(\n                textDocument=VersionedTextDocumentIdentifier(\n                    version=version, uri=self.get_uri()\n                ),\n                contentChanges=ls_changes,\n            )\n        )\n\n    self._unpublished_incremental_changes = []", "loc": 46}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "save_all_named_editors", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.is_modified", "editor.is_untitled", "editor.save_file", "self.get_all_editors"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def save_all_named_editors(self):\n    all_saved = True\n    for editor in self.get_all_editors():\n        if not editor.is_untitled() and editor.is_modified():\n            success = editor.save_file()\n            all_saved = all_saved and success\n\n    return all_saved", "loc": 8}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "remember_open_files", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "cast(Editor, editor).get_target_path", "editor.is_local", "get_workbench", "get_workbench().set_option", "self.get_all_editors", "self.get_current_editor", "self.get_current_editor().get_target_path", "self.get_current_editor().is_local"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remember_open_files(self):\n    if self.get_current_editor() is not None and self.get_current_editor().is_local():\n        current_file = self.get_current_editor().get_target_path()\n    else:\n        current_file = None\n\n    get_workbench().set_option(\"file.current_file\", current_file)\n\n    open_files = [\n        cast(Editor, editor).get_target_path()\n        for editor in self.get_all_editors()\n        if editor.is_local()\n    ]\n    get_workbench().set_option(\"file.open_files\", open_files)", "loc": 14}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "open_new_file", "parameters": ["self", "target_path", "remote"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Editor", "get_workbench", "get_workbench().event_generate", "local_path_to_uri", "new_editor.focus_set", "new_editor.get_title", "remote_path_to_uri", "self.add", "self.create_next_untitled_uri", "self.select"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def open_new_file(self, target_path=None, remote=False):\n    if target_path is None:\n        uri = self.create_next_untitled_uri()\n    elif remote:\n        uri = remote_path_to_uri(target_path)\n    else:\n        uri = local_path_to_uri(target_path)\n\n    new_editor = Editor(self, uri=uri)\n    get_workbench().event_generate(\"NewFile\", editor=new_editor)\n    self.add(new_editor, text=new_editor.get_title())\n    self.select(new_editor)\n    new_editor.focus_set()", "loc": 13}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "close_tab", "parameters": ["self", "index_or_tab"], "param_types": {"index_or_tab": "Union[int, CustomNotebookTab]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self.close_editor", "self.get_page_by_tab"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close_tab(self, index_or_tab: Union[int, CustomNotebookTab]):\n    if isinstance(index_or_tab, int):\n        page = self.pages[index_or_tab]\n    else:\n        page = self.get_page_by_tab(index_or_tab)\n\n    assert isinstance(page.content, Editor)\n    self.close_editor(page.content)", "loc": 8}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "close_editor", "parameters": ["self", "editor", "force"], "param_types": {"editor": "Editor"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.close", "self.check_allow_closing", "self.forget"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close_editor(self, editor: Editor, force=False):\n    if not force and not self.check_allow_closing(editor):\n        return\n    self.forget(editor)\n    editor.close()", "loc": 5}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "get_current_editor_content", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.get_content", "self.get_current_editor"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_current_editor_content(self):\n    editor = self.get_current_editor()\n    if editor is None:\n        return None\n    else:\n        return editor.get_content()", "loc": 6}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "local_file_is_opened", "parameters": ["self", "path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.get_target_path", "editor.is_local", "is_same_path", "self.get_all_editors"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def local_file_is_opened(self, path):\n    for editor in self.get_all_editors():\n        if editor.is_local() and is_same_path(path, editor.get_target_path()):\n            return True\n\n    return False", "loc": 6}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "show_file", "parameters": ["self", "path_or_uri", "text_range", "set_focus", "propose_dialog"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.focus_set", "editor.select_range", "logger.exception", "messagebox.showerror", "running_on_mac_os", "self.get_editor", "self.select", "tr"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_file(self, path_or_uri, text_range=None, set_focus=True, propose_dialog=True):\n    # self.close_single_untitled_unmodified_editor()\n    try:\n        editor = self.get_editor(path_or_uri, True)\n    except PermissionError:\n        logger.exception(\"Loading \" + path_or_uri)\n        msg = tr(\"Got permission error when trying to load\\n%s\") % (path_or_uri,)\n        if running_on_mac_os() and propose_dialog:\n            msg += \"\\n\\n\" + tr(\"Try opening it with File => Open.\")\n\n        messagebox.showerror(tr(\"Permission error\"), msg, master=self)\n        return None\n\n    if editor is None:\n        return\n\n    self.select(editor)\n    if set_focus:\n        editor.focus_set()\n\n    if text_range is not None:\n        editor.select_range(text_range)\n\n    return editor", "loc": 24}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "show_remote_file", "parameters": ["self", "target_filename"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().ready_for_remote_file_operations", "make_legacy_remote_path", "self.show_file"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_remote_file(self, target_filename):\n    if not get_runner().ready_for_remote_file_operations(show_message=True):\n        return None\n    else:\n        return self.show_file(make_legacy_remote_path(target_filename))", "loc": 5}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "update_editor_title", "parameters": ["self", "editor", "title"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.get_title", "logger.exception", "self.indicate_modification", "self.tab"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_editor_title(self, editor, title=None):\n    if title is None:\n        title = editor.get_title()\n    try:\n        self.tab(editor, text=title)\n    except TclError:\n        pass\n\n    try:\n        self.indicate_modification()\n    except Exception:\n        logger.exception(\"Could not update modification indication\")", "loc": 12}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "indicate_modification", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["atts.index", "editor.is_modified", "running_on_mac_os", "self.get_all_editors", "self.winfo_toplevel", "self.winfo_toplevel().wm_attributes"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def indicate_modification(self):\n    if not running_on_mac_os():\n        return\n\n    atts = self.winfo_toplevel().wm_attributes()\n    if \"-modified\" in atts:\n        i = atts.index(\"-modified\")\n        mod = atts[i : i + 2]\n        rest = atts[:i] + atts[i + 2 :]\n    else:\n        mod = ()\n        rest = atts\n\n    for editor in self.get_all_editors():\n        if editor.is_modified():\n            if mod != (\"-modified\", 1):\n                self.winfo_toplevel().wm_attributes(*(rest + (\"-modified\", 1)))\n            break\n    else:\n        if mod == (\"-modified\", 1):\n            self.winfo_toplevel().wm_attributes(*(rest + (\"-modified\", 0)))", "loc": 21}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "check_allow_closing", "parameters": ["self", "editor"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["e.is_modified", "editor.is_modified", "editor_.save_file", "isinstance", "len", "messagebox.askyesnocancel", "self.get_all_editors", "tr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_allow_closing(self, editor=None):\n    if not editor:\n        modified_editors = [e for e in self.get_all_editors() if e.is_modified()]\n    else:\n        if not editor.is_modified():\n            return True\n        else:\n            modified_editors = [editor]\n    if len(modified_editors) == 0:\n        return True\n\n    message = tr(\"Do you want to save files before closing?\")\n    if editor:\n        message = tr(\"Do you want to save file before closing?\")\n\n    confirm = messagebox.askyesnocancel(\n        title=tr(\"Save On Close\"), message=message, default=messagebox.YES, master=self\n    )\n\n    if confirm:\n        for editor_ in modified_editors:\n            assert isinstance(editor_, Editor)\n            if not editor_.save_file():\n                return False\n            else:\n                return False\n        return True\n\n    elif confirm is None:\n        return False\n    else:\n        return True", "loc": 32}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "check_for_external_changes", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.check_for_external_changes", "self.get_all_editors"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_for_external_changes(self, event=None):\n    if self._checking_external_changes:\n        # otherwise the method will be re-entered when focus\n        # changes because of a confirmation message box\n        return\n\n    self._checking_external_changes = True\n    try:\n        for editor in self.get_all_editors():\n            editor.check_for_external_changes()\n    finally:\n        self._checking_external_changes = False", "loc": 12}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "after_insert", "parameters": ["self", "pos", "page", "old_notebook"], "param_types": {"pos": "Union[int, Literal['end']]", "page": "CustomNotebookPage", "old_notebook": "Optional[CustomNotebook]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.get_text_widget", "get_workbench", "get_workbench().event_generate", "isinstance", "super", "super().after_insert"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def after_insert(\n    self,\n    pos: Union[int, Literal[\"end\"]],\n    page: CustomNotebookPage,\n    old_notebook: Optional[CustomNotebook],\n) -> None:\n    super().after_insert(pos, page, old_notebook)\n    editor = page.content\n    assert isinstance(editor, Editor)\n    get_workbench().event_generate(\n        \"InsertEditorToNotebook\", pos=pos, editor=editor, text_widget=editor.get_text_widget()\n    )", "loc": 12}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "after_forget", "parameters": ["self", "pos", "page", "new_notebook"], "param_types": {"pos": "int", "page": "CustomNotebookPage", "new_notebook": "Optional[CustomNotebook]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.get_text_widget", "get_workbench", "get_workbench().event_generate", "isinstance", "super", "super().after_forget"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def after_forget(\n    self, pos: int, page: CustomNotebookPage, new_notebook: Optional[CustomNotebook]\n) -> None:\n    super().after_forget(pos, page, new_notebook)\n    editor = page.content\n    assert isinstance(editor, Editor)\n    get_workbench().event_generate(\n        \"RemoveEditorFromNotebook\", pos=pos, editor=editor, text_widget=editor.get_text_widget()\n    )", "loc": 9}
{"file": "thonny\\thonny\\editors.py", "class_name": "EditorNotebook", "function_name": "try_close_remote_files_from_another_machine", "parameters": ["self", "dialog_parent", "new_machine_id"], "param_types": {"new_machine_id": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n  '.join", "all_remote_editors_to_be_closed.append", "editor.get_file_source", "editor.get_target_path", "editor.is_modified", "editor.is_remote", "get_runner", "get_runner().get_node_label", "len", "messagebox.askyesno", "modified_remote_editors_to_be_closed.append", "modified_remote_files_to_be_closed.append", "self.close_editor", "self.get_all_editors", "tr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def try_close_remote_files_from_another_machine(\n    self, dialog_parent, new_machine_id: str\n) -> bool:\n    all_remote_editors_to_be_closed = []\n    modified_remote_editors_to_be_closed = []\n    modified_remote_files_to_be_closed = []\n    for editor in self.get_all_editors():\n        if editor.get_file_source() == new_machine_id:\n            continue\n\n        if editor.is_remote():\n            all_remote_editors_to_be_closed.append(editor)\n            if editor.is_modified():\n                modified_remote_editors_to_be_closed.append(editor)\n                modified_remote_files_to_be_closed.append(editor.get_target_path())\n\n    if len(modified_remote_files_to_be_closed) > 0:\n        message = (\n            tr(\"All files from %s will be closed before switching the interpreter.\")\n            % get_runner().get_node_label()\n        ) + \"\\n\\n\"\n        message += tr(\"Unsaved changes to the following files will be lost:\") + \"\\n\"\n        message += \"\\n  \" + \"\\n  \".join(modified_remote_files_to_be_closed)\n        message += \"\\n\\n\" + tr(\"Do you still want to continue?\")\n\n        confirm = messagebox.askyesno(\n            title=tr(\"Discard unsaved changes?\"),\n            message=message,\n            default=messagebox.NO,\n            master=dialog_parent,\n        )\n        if not confirm:\n            return False\n\n    for editor in all_remote_editors_to_be_closed:\n        self.close_editor(editor, force=True)\n\n    return True", "loc": 38}
{"file": "thonny\\thonny\\editor_helpers.py", "class_name": null, "function_name": "get_active_text_widget", "parameters": [], "param_types": {}, "return_type": "Optional[SyntaxText]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().focus_get", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_active_text_widget() -> Optional[SyntaxText]:\n    widget = get_workbench().focus_get()\n    if isinstance(widget, (CodeViewText, ShellText)):\n        return widget\n\n    return None", "loc": 6}
{"file": "thonny\\thonny\\editor_helpers.py", "class_name": null, "function_name": "get_cursor_ls_position", "parameters": ["text", "cursor_line_offset", "cursor_column_offset"], "param_types": {"text": "SyntaxText", "cursor_line_offset": "int", "cursor_column_offset": "int"}, "return_type": "lsp_types.Position", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_cursor_position", "logger.warning", "lsp_types.Position"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_cursor_ls_position(\n    text: SyntaxText, cursor_line_offset: int = 0, cursor_column_offset: int = 0\n) -> lsp_types.Position:\n    row, col = get_cursor_position(text)\n    row += cursor_line_offset\n    col += cursor_column_offset\n\n    # TODO: convert char position to UFT-16 items\n    logger.warning(\"NB! convert to UTF-16 points\")\n    return lsp_types.Position(line=row - 1, character=col)", "loc": 10}
{"file": "thonny\\thonny\\editor_helpers.py", "class_name": null, "function_name": "get_relevant_source_and_cursor_position", "parameters": ["text"], "param_types": {"text": "SyntaxText"}, "return_type": "Tuple[str, int, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_cursor_position", "isinstance", "len", "source.splitlines", "text.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_relevant_source_and_cursor_position(text: SyntaxText) -> Tuple[str, int, int]:\n    if isinstance(text, ShellText):\n        source = text.get(\"input_start\", \"insert\")\n        lines = source.splitlines()\n        if not lines:\n            return source, 1, 0\n        else:\n            return source, len(lines), len(lines[-1])\n    else:\n        row, col = get_cursor_position(text)\n        return text.get(\"1.0\", \"end-1c\"), row, col", "loc": 11}
{"file": "thonny\\thonny\\editor_helpers.py", "class_name": "EditorInfoBox", "function_name": "hide", "parameters": ["self", "event"], "param_types": {"event": "Optional[tk.Event]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["related_box.hide", "related_box.is_visible", "self._get_related_box", "self.winfo_ismapped", "self.withdraw"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def hide(self, event: Optional[tk.Event] = None) -> None:\n    if self.winfo_ismapped():\n        self.withdraw()\n\n    related_box = self._get_related_box()\n    if related_box and related_box.is_visible():\n        related_box.hide(event)", "loc": 7}
{"file": "thonny\\thonny\\editor_helpers.py", "class_name": "DocuBox", "function_name": "set_content", "parameters": ["self", "completion"], "param_types": {"completion": "CompletionItem"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "logger.warning", "self._append_chars", "self.text.direct_delete"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_content(self, completion: CompletionItem):\n    self.text.direct_delete(\"1.0\", \"end\")\n    if completion.documentation is not None:\n        if isinstance(completion.documentation, MarkupContent):\n            if completion.documentation.kind == MarkupKind.Markdown:\n                logger.warning(\"TODO: support Markdown\")\n            text = completion.documentation.value\n        else:\n            assert isinstance(completion.documentation, str)\n            text = completion.documentation\n\n        self._append_chars(text, [\"prose\"])", "loc": 12}
{"file": "thonny\\thonny\\first_run.py", "class_name": "FirstRunWindow", "function_name": "add_combo", "parameters": ["self", "row", "label_text", "variable", "values"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["combobox.grid", "isinstance", "label.grid", "ttk.Combobox", "ttk.Label", "ui_utils.ems_to_pixels", "ui_utils.running_on_mac_os"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_combo(self, row, label_text, variable, values):\n    pady = ui_utils.ems_to_pixels(0.7)\n    label = ttk.Label(self.main_frame, text=label_text)\n    label.grid(row=row, column=2, sticky=\"sw\", pady=(pady, 0))\n    assert isinstance(variable, tk.Variable)\n    combobox = ttk.Combobox(\n        self.main_frame,\n        exportselection=False,\n        textvariable=variable,\n        state=\"readonly\",\n        height=15,\n        # Actual length of longest value creates too wide combobox\n        width=40 if ui_utils.running_on_mac_os() else 45,\n        values=values,\n    )\n    combobox.grid(\n        row=row,\n        column=3,\n        padx=(ui_utils.ems_to_pixels(1), self.padx),\n        sticky=\"sw\",\n        pady=(pady, 0),\n    )", "loc": 22}
{"file": "thonny\\thonny\\first_run.py", "class_name": "FirstRunWindow", "function_name": "on_ok", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["languages.get_language_code_by_name", "self.conf.save", "self.conf.set_option", "self.destroy", "self.language_variable.get", "self.mode_variable.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_ok(self):\n    if self.mode_variable.get() in [SIMPLE_MODE_TEXT, RPI_MODE_TEXT]:\n        self.conf.set_option(\"general.ui_mode\", \"simple\")\n        if self.mode_variable.get() == RPI_MODE_TEXT:\n            self.conf.set_option(\"debugger.preferred_debugger\", \"faster\")\n            self.conf.set_option(\"view.ui_theme\", \"Raspberry Pi\")\n\n    self.conf.set_option(\n        \"general.language\", languages.get_language_code_by_name(self.language_variable.get())\n    )\n\n    self.conf.save()\n\n    self.ok = True\n    self.destroy()", "loc": 15}
{"file": "thonny\\thonny\\gridtable.py", "class_name": "GridTable", "function_name": "set_data", "parameters": ["self", "data_rows"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.update_screen_data"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_data(self, data_rows):\n    # self.data_rows.update(data_rows) # dict version\n    self.data_rows = data_rows\n    self.data_row_count = len(data_rows)\n    self.update_screen_data()", "loc": 5}
{"file": "thonny\\thonny\\gridtable.py", "class_name": "GridTable", "function_name": "update_header_rows", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["range", "self.get_header_value", "self.get_header_widget", "w.configure", "w.grid"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_header_rows(self):\n    for row_no in range(self.header_row_count):\n        for col_no in range(self.column_count):\n            w = self.get_header_widget(self.screen_row_count, col_no)\n            w.grid(row=row_no, column=col_no, sticky=\"nsew\", pady=(0, 1), padx=(0, 1))\n            w.configure(text=self.get_header_value(row_no, col_no))\n\n    self.screen_row_count = self.header_row_count", "loc": 8}
{"file": "thonny\\thonny\\gridtable.py", "class_name": "GridTable", "function_name": "get_data_widget", "parameters": ["self", "screen_row_no", "col_no"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.create_data_widget"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_data_widget(self, screen_row_no, col_no):\n    if (screen_row_no, col_no) not in self.data_widgets:\n        self.data_widgets[(screen_row_no, col_no)] = self.create_data_widget(col_no)\n\n    return self.data_widgets[(screen_row_no, col_no)]", "loc": 5}
{"file": "thonny\\thonny\\gridtable.py", "class_name": "GridTable", "function_name": "get_header_widget", "parameters": ["self", "row_no", "col_no"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.create_header_widget"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_header_widget(self, row_no, col_no):\n    if (row_no, col_no) not in self.header_widgets:\n        self.header_widgets[(row_no, col_no)] = self.create_header_widget(col_no)\n\n    return self.header_widgets[(row_no, col_no)]", "loc": 5}
{"file": "thonny\\thonny\\gridtable.py", "class_name": "GridTable", "function_name": "create_data_widget", "parameters": ["self", "col_no"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["tk.Label"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_data_widget(self, col_no):\n    if col_no < self.frozen_column_count:\n        background = None\n    else:\n        background = \"white\"\n\n    return tk.Label(self, background=background, anchor=\"e\", padx=7, text=\"\")", "loc": 7}
{"file": "thonny\\thonny\\gridtable.py", "class_name": "GridTable", "function_name": "update_screen_widgets", "parameters": ["self", "available_screen_height"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["max", "min", "range", "self._clear_screen_row", "self.get_data_widget", "w.grid"], "control_structures": ["For", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_screen_widgets(self, available_screen_height):\n    max_screen_rows = available_screen_height // self.screen_row_height\n    target_screen_row_count = max(\n        min(\n            max_screen_rows,\n            self.header_row_count\n            + self.data_row_count\n            + self.footer_row_count\n            - self.first_visible_data_row_no,\n        ),\n        self.header_row_count + 1 + self.footer_row_count,\n    )\n    # target_screen_row_count = 30\n\n    # remove cells not required anymore ...\n    while self.screen_row_count > target_screen_row_count:\n        # print(\"removing\")\n        self._clear_screen_row(self.screen_row_count - 1)\n        self.screen_row_count -= 1\n\n    # ... or add cells that can be shown\n    while self.screen_row_count < target_screen_row_count:\n        # print(\"adding\")\n        for col in range(self.column_count):\n            w = self.get_data_widget(self.screen_row_count, col)\n            w.grid(\n                row=self.screen_row_count, column=col, sticky=\"nsew\", pady=(0, 1), padx=(0, 1)\n            )\n\n        self.screen_row_count += 1\n\n    self.visible_data_row_count = (\n        self.screen_row_count - self.header_row_count - self.footer_row_count\n    )", "loc": 34}
{"file": "thonny\\thonny\\gridtable.py", "class_name": "GridTable", "function_name": "update_screen_data", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["range", "self.get_data_value", "self.get_data_widget", "self.update_screen_widgets", "self.winfo_height", "str", "w.configure"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_screen_data(self):\n    self.update_screen_widgets(self.winfo_height())\n    for screen_row_no in range(self.header_row_count, self.screen_row_count):\n        data_row_no = self.first_visible_data_row_no + screen_row_no - self.header_row_count\n        if data_row_no == self.data_row_count:\n            break\n\n        for col_no in range(self.column_count):\n            w = self.get_data_widget(screen_row_no, col_no)\n            value = self.get_data_value(data_row_no, col_no)\n            if value is None:\n                w.configure(text=\"\")\n            else:\n                w.configure(text=str(value))", "loc": 14}
{"file": "thonny\\thonny\\gridtable.py", "class_name": "GridTable", "function_name": "on_configure", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.grid_bbox", "self.update_screen_data", "self.update_screen_widgets"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_configure(self, event):\n    # query row height\n    _, _, _, height = self.grid_bbox(row=1)\n    if height > 10 and height < 100:\n        \"self.screen_row_height = height + 2\"\n\n    # screen_available_height = self.winfo_height()\n\n    # print(\"HE\", self.winfo_height(), event.height, self.screen_row_height)\n    self.update_screen_widgets(event.height)\n\n    self.update_screen_data()", "loc": 12}
{"file": "thonny\\thonny\\languages.py", "class_name": null, "function_name": "get_button_padding", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_button_padding():\n    from thonny import get_workbench\n\n    code = get_workbench().get_option(\"general.language\")\n    if code in BUTTON_PADDING_SIZES:\n        return BUTTON_PADDING_SIZES[code] * \" \"\n    else:\n        return \"\"", "loc": 8}
{"file": "thonny\\thonny\\languages.py", "class_name": null, "function_name": "get_language_code_by_name", "parameters": ["name"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_language_code_by_name(name):\n    for code in LANGUAGES_DICT:\n        if LANGUAGES_DICT[code] == name:\n            return code\n\n    raise RuntimeError(\"Unknown language name '%s'\" % name)", "loc": 6}
{"file": "thonny\\thonny\\lsp_proxy.py", "class_name": "LanguageServerProxy", "function_name": "shut_down", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.exception", "logger.info", "logger.warning", "self._invalidate", "self._proc.kill", "self._proc.terminate", "self._server_process_alive", "time.sleep", "time.time"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def shut_down(self):\n    self._invalidate()\n    if not self._server_process_alive():\n        logger.warning(\"Language server already closed\")\n        return\n    \"\"\"\n    basedpyright does not exit after successful shutdown\n    timeout_for_shutdown = 2\n    self.request_shutdown(self._on_shut_down_response)\n    start_time = time.time()\n    while time.time() - start_time < timeout_for_shutdown:\n        time.sleep(0.1)\n\n        if not self._server_process_alive():\n            logger.info(\"Shutdown completed normally\")\n            return\n\n        if self._shutdown_accepted:\n            # basedpyright server does not close after shutdown\n            time.sleep(0.1)\n            if self._server_process_alive():\n                logger.warning(\"Shutdown accepted but not completed. Will terminate\")\n                break\n    else:\n        logger.warning(f\"Shutdown not accepted in {timeout_for_shutdown} seconds. Will terminate.\")\n    \"\"\"\n\n    try:\n        self._proc.terminate()\n    except Exception:\n        logger.exception(\"Problem when terminating language server process\")\n        return\n\n    termination_timeout = 1\n    start_time = time.time()\n    while time.time() - start_time < termination_timeout:\n        time.sleep(0.1)\n        if not self._server_process_alive():\n            logger.info(\"Termination completed normally\")\n            return\n\n    logger.warning(f\"Termination not completed in {termination_timeout} seconds. Using kill.\")\n    try:\n        self._proc.kill()\n    except Exception:\n        logger.exception(\"Problem when killing language server process\")", "loc": 46}
{"file": "thonny\\thonny\\lsp_types.py", "class_name": "LspResponse", "function_name": "get_result_or_raise", "parameters": ["self"], "param_types": {}, "return_type": "T", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_result_or_raise(self) -> T:\n    if self._error is not None:\n        raise self._error\n\n    return self._result", "loc": 5}
{"file": "thonny\\thonny\\main.py", "class_name": null, "function_name": "run", "parameters": [], "param_types": {}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_check_welcome", "_delegate_to_existing_instance", "_get_frontend_log_file", "_parse_arguments_to_dict", "_set_dpi_aware", "_should_delegate", "bench.mainloop", "choose_logging_level", "configure_logging", "get_runner", "get_thonny_user_dir", "len", "logger.exception", "messagebox.showerror", "prepare_thonny_user_dir", "print", "runner.destroy_backend", "runpy.run_module", "str", "sys.executable.endswith", "traceback.print_exc", "type", "workbench.Workbench"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run() -> int:\n    # First make sure the command line is good\n    parsed_args = _parse_arguments_to_dict(sys.argv[1:])\n\n    # Temporary compatibility measure for the breaking change introduced in version 5.0\n    thonny.THONNY_USER_DIR = get_thonny_user_dir()\n\n    import runpy\n\n    if sys.executable.endswith(\"thonny.exe\"):\n        # otherwise some library may try to run its subprocess with thonny.exe\n        # NB! Must be pythonw.exe not python.exe, otherwise Runner thinks console\n        # is already allocated.\n        sys.executable = sys.executable[: -len(\"thonny.exe\")] + \"pythonw.exe\"\n\n    _set_dpi_aware()\n\n    try:\n        runpy.run_module(\"thonny.customize\", run_name=\"__main__\")\n    except ImportError:\n        pass\n\n    prepare_thonny_user_dir()\n    configure_logging(_get_frontend_log_file(), choose_logging_level())\n\n    if not _check_welcome():\n        return 0\n\n    if _should_delegate():\n        try:\n            _delegate_to_existing_instance(parsed_args)\n            print(\"Delegated to an existing Thonny instance. Exiting now.\")\n            return 0\n        except Exception:\n            import traceback\n\n            traceback.print_exc()\n\n    # Did not or could not delegate\n\n    try:\n        from thonny import workbench\n\n        bench = workbench.Workbench(parsed_args)\n        bench.mainloop()\n        return 0\n\n    except Exception as e:\n        title = \"Internal launch or mainloop error\"\n        logger.exception(title)\n\n        import tkinter as tk\n\n        if tk._default_root is not None:\n            from tkinter import messagebox\n\n            # Messagebox may or may not be shown, but here it's no use of being defencive anymore\n            messagebox.showerror(\n                title,\n                f\"Thonny encountered an internal error:\\n{str(e) or type(e)}\"\n                f\"\\n\\nSee frontend.log for more details\",\n                parent=tk._default_root,\n            )\n\n        return -1\n    finally:\n        runner = get_runner()\n        if runner is not None:\n            runner.destroy_backend()", "loc": 69}
{"file": "thonny\\thonny\\memory.py", "class_name": null, "function_name": "format_object_id", "parameters": ["object_id"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hex"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_object_id(object_id):\n    # this format aligns with how Python shows memory addresses\n    if object_id is None:\n        return None\n    else:\n        return \"0x\" + hex(object_id)[2:]  # .rjust(8,'0')", "loc": 6}
{"file": "thonny\\thonny\\memory.py", "class_name": "MemoryFrame", "function_name": "get_object_id", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_object_id", "self.tree.focus", "self.tree.item"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_object_id(self):\n    iid = self.tree.focus()\n    if iid != \"\":\n        # NB! Assuming id is second column!\n        id_str = self.tree.item(iid)[\"values\"][1]\n        if id_str in [\"\", None, \"None\"]:\n            return None\n\n        return parse_object_id(id_str)\n\n    return None", "loc": 11}
{"file": "thonny\\thonny\\memory.py", "class_name": "VariablesFrame", "function_name": "update_variables", "parameters": ["self", "all_variables"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["format_object_id", "isinstance", "self._clear_tree", "self.tree.insert", "self.tree.set", "sorted", "variables.keys", "x.startswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_variables(self, all_variables):\n    self._clear_tree()\n\n    if not all_variables:\n        return\n\n    if isinstance(all_variables, list):\n        groups = all_variables\n    else:\n        groups = [(\"\", all_variables)]\n\n    for group_title, variables in groups:\n        if group_title:\n            node_id = self.tree.insert(\"\", \"end\", tags=(\"group_title\",))\n            self.tree.set(node_id, \"name\", group_title)\n\n        for name in sorted(variables.keys(), key=lambda x: (x.startswith(\"_\"), x)):\n            node_id = self.tree.insert(\"\", \"end\", tags=\"item\")\n            self.tree.set(node_id, \"name\", name)\n            if isinstance(variables[name], ValueInfo):\n                description = variables[name].repr\n                id_str = variables[name].id\n            else:\n                description = variables[name]\n                id_str = None\n\n            self.tree.set(node_id, \"id\", format_object_id(id_str))\n            self.tree.set(node_id, \"value\", description)", "loc": 28}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "get_known_folder", "parameters": ["ID"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ctypes.create_unicode_buffer", "ctypes.windll.shell32.SHGetFolderPathW"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_known_folder(ID):\n    # http://stackoverflow.com/a/3859336/261181\n    # https://tarma.com/support/im9/using/symbols/functions/csidls.htm\n    import ctypes.wintypes\n\n    SHGFP_TYPE_CURRENT = 0\n    buf = ctypes.create_unicode_buffer(ctypes.wintypes.MAX_PATH)\n    ctypes.windll.shell32.SHGetFolderPathW(0, ID, 0, SHGFP_TYPE_CURRENT, buf)\n    assert buf.value\n    return buf.value", "loc": 10}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "running_on_rpi", "parameters": [], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["machine_lower.startswith", "os.environ.get", "platform.uname", "platform.uname().machine.lower", "running_on_linux"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def running_on_rpi() -> bool:\n    machine_lower = platform.uname().machine.lower()\n    return running_on_linux() and (\n        # not great heuristics, I know\n        machine_lower.startswith(\"arm\")\n        or machine_lower.startswith(\"aarch64\")\n        or os.environ.get(\"DESKTOP_SESSION\") == \"LXDE-pi\"\n        or os.environ.get(\"DESKTOP_SESSION\") == \"LXDE-pi-wayfire\"\n    )", "loc": 9}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "get_user_site_packages_dir_for_base", "parameters": ["userbase"], "param_types": {"userbase": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["sys.winver.replace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_user_site_packages_dir_for_base(userbase: str) -> str:\n    # copied from site._get_path of 3.8 and 3.10\n    version = sys.version_info\n\n    if os.name == \"nt\":\n        if sys.version_info < (3, 10):\n            return f\"{userbase}\\\\Python{version[0]}{version[1]}\\\\site-packages\"\n        else:\n            ver_nodot = sys.winver.replace(\".\", \"\")\n            return f\"{userbase}\\\\Python{ver_nodot}\\\\site-packages\"\n\n    if sys.platform == \"darwin\" and sys._framework:\n        return f\"{userbase}/lib/python/site-packages\"\n\n    return f\"{userbase}/lib/python{version[0]}.{version[1]}/site-packages\"", "loc": 15}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "get_win_volume_name", "parameters": ["path"], "param_types": {"path": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "ctypes.c_wchar_p", "ctypes.create_unicode_buffer", "ctypes.sizeof", "ctypes.windll.kernel32.GetVolumeInformationW", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Each disk or external device connected to windows has an attribute called \"volume name\". This function returns the volume name for the given disk/device.", "source_code": "def get_win_volume_name(path: str) -> str:\n    \"\"\"\n    Each disk or external device connected to windows has an attribute\n    called \"volume name\". This function returns the volume name for\n    the given disk/device.\n    Code from http://stackoverflow.com/a/12056414\n    \"\"\"\n    if sys.platform == \"win32\":\n        import ctypes\n\n        vol_name_buf = ctypes.create_unicode_buffer(1024)\n        ctypes.windll.kernel32.GetVolumeInformationW(  # @UndefinedVariable\n            ctypes.c_wchar_p(path),\n            vol_name_buf,\n            ctypes.sizeof(vol_name_buf),\n            None,\n            None,\n            None,\n            None,\n            0,\n        )\n        assert isinstance(vol_name_buf.value, str)\n        return vol_name_buf.value\n    else:\n        raise RuntimeError(\"Only meant for Windows\")", "loc": 25}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "find_volumes_by_name", "parameters": ["volume_name", "skip_letters"], "param_types": {"volume_name": "str"}, "return_type": "Sequence[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_win_volume_name", "get_win_volume_name(volume).upper", "list_volumes", "volume.endswith", "volume_name.upper"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_volumes_by_name(volume_name: str, skip_letters={\"A\"}) -> Sequence[str]:\n    volumes = list_volumes(skip_letters=skip_letters)\n    if os.name == \"nt\":\n        return [\n            volume\n            for volume in volumes\n            if get_win_volume_name(volume).upper() == volume_name.upper()\n        ]\n    else:\n        return [volume for volume in volumes if volume.endswith(volume_name)]", "loc": 10}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "find_volume_by_name", "parameters": ["volume_name", "not_found_msg", "found_several_msg", "parent"], "param_types": {"volume_name": "str", "not_found_msg": "Optional[str]", "found_several_msg": "Optional[str]"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["askdirectory", "askyesno", "find_volumes_by_name", "len", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_volume_by_name(\n    volume_name: str,\n    not_found_msg: Optional[str] = None,\n    found_several_msg: Optional[str] = None,\n    parent=None,\n) -> Optional[str]:\n    from thonny.languages import tr\n\n    # Can't translate in the header as _ may not be available at import time\n    if not_found_msg is None:\n        not_found_msg = tr(\"Could not find disk '%s'. Do you want to locate it yourself?\")\n\n    if found_several_msg is None:\n        found_several_msg = tr(\"Found several '%s' disks. Do you want to choose one yourself?\")\n\n    volumes = find_volumes_by_name(volume_name)\n    if len(volumes) == 1:\n        return volumes[0]\n    else:\n        if len(volumes) == 0:\n            msg = not_found_msg % volume_name\n        else:\n            msg = found_several_msg % volume_name\n\n        import tkinter as tk\n        from tkinter.messagebox import askyesno\n\n        from thonny.ui_utils import askdirectory\n\n        if askyesno(tr(\"Can't find suitable disk\"), msg, master=parent):\n            path = askdirectory(parent=parent)\n            if path:\n                return path\n\n    return None", "loc": 35}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "shorten_repr", "parameters": ["original_repr", "max_len"], "param_types": {"original_repr": "str", "max_len": "int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def shorten_repr(original_repr: str, max_len: int = 1000) -> str:\n    if len(original_repr) > max_len:\n        return original_repr[: max_len - 1] + \"\"\n    else:\n        return original_repr", "loc": 5}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "construct_cmd_line", "parameters": ["parts", "safe_tokens"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "map", "shlex.quote"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def construct_cmd_line(parts, safe_tokens=[]) -> str:\n    def quote(s):\n        if s in safe_tokens:\n            return s\n        else:\n            return shlex.quote(s)\n\n    return \" \".join(map(quote, parts))", "loc": 8}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "user_friendly_python_command_line", "parameters": ["cmd"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "cmd.index", "len", "lines.append", "lines[-1] + ' ' + item.strip", "subprocess.list2cmdline"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def user_friendly_python_command_line(cmd):\n    if \"-m\" in cmd:\n        cmd = cmd[cmd.index(\"-m\") + 1 :]\n\n    lines = [\"\"]\n    for item in cmd:\n        if lines[-1] and len(lines[-1] + \" \" + item) > 60:\n            lines.append(\"\")\n        lines[-1] = (lines[-1] + \" \" + item).strip()\n\n    return \"\\n\".join(lines)\n\n    return subprocess.list2cmdline(cmd)", "loc": 13}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "jaro_similarity", "parameters": ["s", "t"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "max", "min", "range"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "Jaro distance between two strings.", "source_code": "def jaro_similarity(s, t):\n    \"\"\"Jaro distance between two strings.\"\"\"\n    # Source: https://rosettacode.org/wiki/Jaro_similarity\n    s_len = len(s)\n    t_len = len(t)\n\n    if s_len == 0 and t_len == 0:\n        return 1\n\n    match_distance = (max(s_len, t_len) // 2) - 1\n\n    s_matches = [False] * s_len\n    t_matches = [False] * t_len\n\n    matches = 0\n    transpositions = 0\n\n    for i in range(s_len):\n        start = max(0, i - match_distance)\n        end = min(i + match_distance + 1, t_len)\n\n        for j in range(start, end):\n            if t_matches[j]:\n                continue\n            if s[i] != t[j]:\n                continue\n            s_matches[i] = True\n            t_matches[j] = True\n            matches += 1\n            break\n\n    if matches == 0:\n        return 0\n\n    k = 0\n    for i in range(s_len):\n        if not s_matches[i]:\n            continue\n        while not t_matches[k]:\n            k += 1\n        if s[i] != t[k]:\n            transpositions += 1\n        k += 1\n\n    return ((matches / s_len) + (matches / t_len) + ((matches - transpositions / 2) / matches)) / 3", "loc": 45}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "lap_time", "parameters": ["text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["print", "round", "time.time"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def lap_time(text=\"\"):\n    global _timer_time\n    new_time = time.time()\n    print(\"LAP\", text, round(new_time - _timer_time, 4))\n    _timer_time = time.time()", "loc": 5}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "sizeof_fmt", "parameters": ["num", "suffix"], "param_types": {}, "return_type": null, "param_doc": {"num": "Bytes value", "suffix": "Unit suffix (optional) default = B"}, "return_doc": "", "raises_doc": [], "called_functions": ["abs"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Readable file size", "source_code": "def sizeof_fmt(num, suffix=\"B\"):\n    \"\"\"Readable file size\n    :param num: Bytes value\n    :type num: int\n    :param suffix: Unit suffix (optional) default = B\n    :type suffix: str\n    :rtype: str\n    \"\"\"\n    # https://gist.github.com/cbwar/d2dfbc19b140bd599daccbe0fe925597\n    for unit in [\"\", \"k\", \"M\", \"G\", \"T\", \"P\", \"E\", \"Z\"]:\n        if abs(num) < 1024.0:\n            if unit == \"\":\n                return \"%d %s%s\" % (num, unit, suffix)\n            return \"%.1f %s%s\" % (num, unit, suffix)\n        num /= 1024.0\n    return \"%.1f%s%s\" % (num, \"Yi\", suffix)", "loc": 16}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "show_command_not_available_in_flatpak_message", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "messagebox.showinfo", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_command_not_available_in_flatpak_message():\n    from tkinter import messagebox\n\n    from thonny import get_workbench\n    from thonny.languages import tr\n\n    messagebox.showinfo(\n        tr(\"Command not available\"),\n        tr(\"This command is not available if Thonny is run via Flatpak\"),\n        parent=get_workbench(),\n    )", "loc": 11}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "get_menu_char", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["running_on_windows"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_menu_char():\n    if running_on_windows():\n        return \"\"  # Identical to\n    else:\n        return \"\"  # Trigram for heaven, too heavy on Windows", "loc": 5}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "post_and_return_stream", "parameters": ["url", "data", "headers", "timeout"], "param_types": {"url": "str", "data": "Any", "headers": "Dict[str, Any]", "timeout": "int"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Request", "data.encode", "headers.items", "isinstance", "json.dumps", "json.dumps(data).encode", "str", "urlopen"], "control_structures": ["If"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def post_and_return_stream(\n    url: str, data: Any, headers: Dict[str, Any] = {}, timeout: int = 10\n) -> Any:\n    import json\n    from urllib.request import Request, urlopen\n\n    if not isinstance(data, bytes):\n        if isinstance(data, str):\n            data = data.encode(encoding=\"utf-8\")\n        else:\n            data = json.dumps(data).encode(encoding=\"utf-8\")\n\n    req = Request(url, headers={key: str(value) for key, value in headers.items()})\n\n    return urlopen(req, data=data, timeout=timeout)", "loc": 15}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "post_and_parse_json", "parameters": ["url", "data", "headers", "timeout"], "param_types": {"url": "str", "data": "Any", "headers": "Dict[str, Any]", "timeout": "int"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["headers.items", "json.load", "post_and_return_stream", "str"], "control_structures": [], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def post_and_parse_json(\n    url: str, data: Any, headers: Dict[str, Any] = {}, timeout: int = 10\n) -> Any:\n    import json\n\n    resp = post_and_return_stream(\n        url, data=data, headers={key: str(value) for key, value in headers.items()}, timeout=timeout\n    )\n    return json.load(resp)", "loc": 9}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "get_and_parse_json", "parameters": ["url", "headers", "timeout"], "param_types": {"url": "str", "headers": "Dict[str, Any]", "timeout": "int"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Request", "json.load", "urlopen"], "control_structures": [], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def get_and_parse_json(url: str, headers: Dict[str, Any] = {}, timeout: int = 10) -> Any:\n    import json\n    from urllib.request import Request, urlopen\n\n    req = Request(url, headers=headers)\n\n    resp = urlopen(req, timeout=timeout)\n    return json.load(resp)", "loc": 8}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "format_date_and_time_compact", "parameters": ["timestamp", "without_seconds", "optimize_year"], "param_types": {"timestamp": "time.struct_time", "without_seconds": "bool", "optimize_year": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["format_date_compact", "format_time_compact"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_date_and_time_compact(\n    timestamp: time.struct_time, without_seconds: bool, optimize_year: bool = False\n):\n    return (\n        format_date_compact(timestamp, optimize_year=optimize_year)\n        + \"  \"\n        + format_time_compact(timestamp, without_seconds=without_seconds)\n    )", "loc": 8}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "format_time_compact", "parameters": ["timestamp", "without_seconds"], "param_types": {"timestamp": "time.struct_time", "without_seconds": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "s.rfind", "time.strftime"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_time_compact(timestamp: time.struct_time, without_seconds: bool):\n\n    # Useful with locale specific formats, which would be a hassle to construct from parts\n    s = time.strftime(\"%X\", timestamp)\n    if without_seconds:\n        seconds_part = \":%02d\" % (timestamp.tm_sec,)\n        seconds_index = s.rfind(seconds_part)\n        if seconds_index == -1:\n            return s\n\n        return s[:seconds_index] + s[seconds_index + len(seconds_part) :]\n    else:\n        return s", "loc": 13}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "format_date_compact", "parameters": ["timestamp", "optimize_year"], "param_types": {"timestamp": "time.struct_time", "optimize_year": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_date_format_with_month_abbrev", "str", "time.localtime", "time.mktime", "time.strftime", "time.time", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_date_compact(timestamp: time.struct_time, optimize_year: bool = False):\n    # Useful with locale specific formats, which would be a hassle to construct from parts\n    now = time.localtime()\n    if (\n        timestamp.tm_year == now.tm_year\n        and timestamp.tm_mon == now.tm_mon\n        and timestamp.tm_mday == now.tm_mday\n    ):\n        return tr(\"Today\")\n\n    result = time.strftime(get_date_format_with_month_abbrev(), timestamp)\n    age_in_days = (time.time() - time.mktime(timestamp)) / 60 / 60 / 24\n    if (\n        age_in_days < 0\n        or (now.tm_year != timestamp.tm_year and age_in_days > 10)\n        or age_in_days > 10\n    ):\n        result += \" \" + str(timestamp.tm_year)\n\n    return result", "loc": 20}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "get_date_format_with_month_abbrev", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_compute_date_format_with_month_abbrev"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_date_format_with_month_abbrev() -> str:\n    global _date_format_with_month_abbrev\n    if _date_format_with_month_abbrev is None:\n        _date_format_with_month_abbrev = _compute_date_format_with_month_abbrev()\n    return _date_format_with_month_abbrev", "loc": 5}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "is_local_path", "parameters": ["s"], "param_types": {"s": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_legacy_remote_filename", "s.startswith"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_local_path(s: str) -> bool:\n    return (\n        not is_legacy_remote_filename(s)\n        and not s.startswith(\"<\")\n        and (s.startswith(\"/\") or s[1:3] == \":\\\\\")\n    )", "loc": 6}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "uri_to_legacy_filename", "parameters": ["uri"], "param_types": {"uri": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_remote_uri", "make_legacy_remote_path", "uri_to_target_path"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def uri_to_legacy_filename(uri: str) -> str:\n    \"\"\"Returns 'blah :: /path/file' for remote files, as was common in Thonny 4\"\"\"\n    if is_remote_uri(uri):\n        return make_legacy_remote_path(uri_to_target_path(uri))\n    else:\n        return uri_to_target_path(uri)", "loc": 6}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "ensure_uri", "parameters": ["filename_or_uri"], "param_types": {"filename_or_uri": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "is_legacy_remote_filename", "is_local_path", "legacy_filename_to_uri", "local_path_to_uri"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ensure_uri(filename_or_uri: str) -> str:\n    if is_legacy_remote_filename(filename_or_uri):\n        return legacy_filename_to_uri(filename_or_uri)\n    elif is_local_path(filename_or_uri):\n        return local_path_to_uri(filename_or_uri)\n    elif \":\" in filename_or_uri:\n        return filename_or_uri\n    else:\n        raise ValueError(f\"Can't understand filename or uri: {filename_or_uri!r}\")", "loc": 9}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "legacy_filename_to_uri", "parameters": ["filename"], "param_types": {"filename": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["is_legacy_remote_filename", "legacy_remote_filename_to_target_path", "local_path_to_uri", "remote_path_to_uri"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def legacy_filename_to_uri(filename: str) -> str:\n    if is_legacy_remote_filename(filename):\n        return remote_path_to_uri(legacy_remote_filename_to_target_path(filename))\n    else:\n        return local_path_to_uri(filename)", "loc": 5}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "uri_to_long_title", "parameters": ["uri"], "param_types": {"uri": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "format_untitled_uri", "is_local_uri", "is_remote_uri", "is_untitled_uri", "make_legacy_remote_path", "uri_to_target_path"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def uri_to_long_title(uri: str) -> str:\n    if is_untitled_uri(uri):\n        return format_untitled_uri(uri)\n    elif is_remote_uri(uri):\n        return make_legacy_remote_path(uri_to_target_path(uri))\n    elif is_local_uri(uri):\n        return uri_to_target_path(uri)\n    else:\n        raise ValueError(f\"Unexpected uri: {uri}\")", "loc": 9}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "get_memory_info", "parameters": ["process"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["GetProcessMemoryInfo", "PROCESS_MEMORY_COUNTERS_EX", "ctypes.WinError", "ctypes.byref", "ctypes.sizeof", "dict", "get_current_process", "getattr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return Win32 process memory counters structure as a dict.", "source_code": "def get_memory_info(process=None):\n    \"\"\"Return Win32 process memory counters structure as a dict.\"\"\"\n    if process is None:\n        process = get_current_process()\n    counters = PROCESS_MEMORY_COUNTERS_EX()\n    ret = GetProcessMemoryInfo(process, ctypes.byref(counters), ctypes.sizeof(counters))\n    if not ret:\n        raise ctypes.WinError()\n    info = dict((name, getattr(counters, name)) for name, _ in counters._fields_)\n    return info", "loc": 10}
{"file": "thonny\\thonny\\misc_utils.py", "class_name": null, "function_name": "quote", "parameters": ["s"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["shlex.quote"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def quote(s):\n    if s in safe_tokens:\n        return s\n    else:\n        return shlex.quote(s)", "loc": 5}
{"file": "thonny\\thonny\\program_analysis.py", "class_name": "SubprocessProgramAnalyzer", "function_name": "analyze", "parameters": ["self", "main_file"], "param_types": {"main_file": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ProgramAnalyzerResponseItem", "cast", "dict", "get_workbench", "get_workbench().queue_event", "results.append", "self._proc.stderr.read", "self._proc.stderr.read().strip", "self.cancel", "self.parse_output_line", "self.start_subprocess", "type"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def analyze(self, main_file: str) -> None:\n    self.cancel()\n\n    results = []\n\n    self.start_subprocess(main_file)\n    for line in self._proc.stdout:\n        item = self.parse_output_line(line)\n        if item is not None:\n            results.append(item)\n\n    err = cast(str, self._proc.stderr.read().strip())\n    if err:\n        results.append(\n            ProgramAnalyzerResponseItem(\n                \"INTERNAL ERROR: \" + err,\n                ProgramAnalyzerResponseItemType.ERROR,\n                file=None,\n                line=None,\n                column=None,\n            )\n        )\n\n    self._results = results\n    get_workbench().queue_event(\n        \"ProgramAnalysisCompleted\", event=dict(analyzer_class=type(self).__name__)\n    )", "loc": 27}
{"file": "thonny\\thonny\\program_analysis.py", "class_name": "SubprocessProgramAnalyzer", "function_name": "cancel", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.warning", "self._proc.kill", "self._proc.poll", "type"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cancel(self) -> None:\n    if self._proc is not None and self._proc.poll() is None:\n        try:\n            self._proc.kill()\n        except Exception:\n            logger.warning(\"Could not kill subprocess in %r\", type(self))\n        finally:\n            self._proc = None\n            self._results = None", "loc": 9}
{"file": "thonny\\thonny\\roughparse.py", "class_name": "RoughParser", "function_name": "find_good_parse_start", "parameters": ["self", "is_char_in_string", "_synchre"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_synchre", "is_char_in_string", "len", "m.span", "m.start", "range", "str.rfind"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_good_parse_start(self, is_char_in_string=None, _synchre=_synchre):\n    # pylint: disable=redefined-builtin\n\n    str, pos = self.str, None  # @ReservedAssignment\n\n    if not is_char_in_string:\n        # no clue -- make the caller pass everything\n        return None\n\n    # Peek back from the end for a good place to start,\n    # but don't try too often; pos will be left None, or\n    # bumped to a legitimate synch point.\n    limit = len(str)\n    for _ in range(5):\n        i = str.rfind(\":\\n\", 0, limit)\n        if i < 0:\n            break\n        i = str.rfind(\"\\n\", 0, i) + 1  # start of colon line\n        m = _synchre(str, i, limit)\n        if m and not is_char_in_string(m.start()):\n            pos = m.start()\n            break\n        limit = i\n    if pos is None:\n        # Nothing looks like a block-opener, or stuff does\n        # but is_char_in_string keeps returning true; most likely\n        # we're in or near a giant string, the colorizer hasn't\n        # caught up enough to be helpful, or there simply *aren't*\n        # any interesting stmts.  In any of these cases we're\n        # going to have to parse the whole thing to be sure, so\n        # give it one last try from the start, but stop wasting\n        # time here regardless of the outcome.\n        m = _synchre(str)\n        if m and not is_char_in_string(m.start()):\n            pos = m.start()\n        return pos\n\n    # Peeking back worked; look forward until _synchre no longer\n    # matches.\n    i = pos + 1\n    while 1:\n        m = _synchre(str, i)\n        if m:\n            s, i = m.span()\n            if not is_char_in_string(s):\n                pos = s\n        else:\n            break\n    return pos", "loc": 49}
{"file": "thonny\\thonny\\roughparse.py", "class_name": "RoughParser", "function_name": "compute_bracket_indent", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_itemre", "len", "m.end", "self._study2", "str.find", "str.rfind", "str[i:j].expandtabs"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def compute_bracket_indent(self):\n    # pylint: disable=redefined-builtin\n    self._study2()\n    assert self.continuation == C_BRACKET\n    j = self.lastopenbracketpos\n    str = self.str  # @ReservedAssignment\n    n = len(str)\n    origi = i = str.rfind(\"\\n\", 0, j) + 1\n    j = j + 1  # one beyond open bracket\n    # find first list item; set i to start of its line\n    while j < n:\n        m = _itemre(str, j)\n        if m:\n            j = m.end() - 1  # index of first interesting char\n            extra = 0\n            break\n        else:\n            # this line is junk; advance to next line\n            i = j = str.find(\"\\n\", j) + 1\n    else:\n        # nothing interesting follows the bracket;\n        # reproduce the bracket line's indentation + a level\n        j = i = origi\n        while str[j] in \" \\t\":\n            j = j + 1\n        extra = self.indent_width\n    return len(str[i:j].expandtabs(self.tab_width)) + extra", "loc": 27}
{"file": "thonny\\thonny\\roughparse.py", "class_name": "RoughParser", "function_name": "compute_backslash_indent", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_match_stringre", "_match_stringre(str, i, endpos).end", "len", "re.match", "self._study2", "str.find", "str[self.stmt_start:i].expandtabs"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def compute_backslash_indent(self):\n    # pylint: disable=redefined-builtin\n    self._study2()\n    assert self.continuation == C_BACKSLASH\n    str = self.str  # @ReservedAssignment\n    i = self.stmt_start\n    while str[i] in \" \\t\":\n        i = i + 1\n    startpos = i\n\n    # See whether the initial line starts an assignment stmt; i.e.,\n    # look for an = operator\n    endpos = str.find(\"\\n\", startpos) + 1\n    found = level = 0\n    while i < endpos:\n        ch = str[i]\n        if ch in \"([{\":\n            level = level + 1\n            i = i + 1\n        elif ch in \")]}\":\n            if level:\n                level = level - 1\n            i = i + 1\n        elif ch == '\"' or ch == \"'\":\n            i = _match_stringre(str, i, endpos).end()\n        elif ch == \"#\":\n            break\n        elif (\n            level == 0\n            and ch == \"=\"\n            and (i == 0 or str[i - 1] not in \"=<>!\")\n            and str[i + 1] != \"=\"\n        ):\n            found = 1\n            break\n        else:\n            i = i + 1\n\n    if found:\n        # found a legit =, but it may be the last interesting\n        # thing on the line\n        i = i + 1  # move beyond the =\n        found = re.match(r\"\\s*\\\\\", str[i:endpos]) is None\n\n    if not found:\n        # oh well ... settle for moving beyond the first chunk\n        # of non-whitespace chars\n        i = startpos\n        while str[i] not in \" \\t\\n\":\n            i = i + 1\n\n    return len(str[self.stmt_start : i].expandtabs(self.tab_width)) + 1", "loc": 52}
{"file": "thonny\\thonny\\roughparse.py", "class_name": "RoughParser", "function_name": "get_base_indent_string", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._study2"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_base_indent_string(self):\n    self._study2()\n    i, n = self.stmt_start, self.stmt_end\n    j = i\n    str_ = self.str\n    while j < n and str_[j] in \" \\t\":\n        j = j + 1\n    return str_[i:j]", "loc": 8}
{"file": "thonny\\thonny\\roughparse.py", "class_name": "HyperParser", "function_name": "set_index", "parameters": ["self", "index"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "len", "self.text.get"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Set the index to which the functions relate. The index must be in the same statement.", "source_code": "def set_index(self, index):\n    \"\"\"Set the index to which the functions relate.\n\n    The index must be in the same statement.\n    \"\"\"\n    indexinrawtext = len(self.rawtext) - len(self.text.get(index, self.stopatindex))\n    if indexinrawtext < 0:\n        raise ValueError(\"Index %s precedes the analyzed statement\" % index)\n    self.indexinrawtext = indexinrawtext\n    # find the rightmost bracket to which index belongs\n    self.indexbracket = 0\n    while (\n        self.indexbracket < len(self.bracketing) - 1\n        and self.bracketing[self.indexbracket + 1][0] < self.indexinrawtext\n    ):\n        self.indexbracket += 1\n    if (\n        self.indexbracket < len(self.bracketing) - 1\n        and self.bracketing[self.indexbracket + 1][0] == self.indexinrawtext\n        and not self.isopener[self.indexbracket + 1]\n    ):\n        self.indexbracket += 1", "loc": 22}
{"file": "thonny\\thonny\\roughparse.py", "class_name": "HyperParser", "function_name": "get_surrounding_brackets", "parameters": ["self", "openers", "mustclose"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "min", "self.text.index"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Return bracket indexes or None. If the index given to the HyperParser is surrounded by a bracket defined in openers (or at least has one before it),", "source_code": "def get_surrounding_brackets(self, openers=\"([{\", mustclose=False):\n    \"\"\"Return bracket indexes or None.\n\n    If the index given to the HyperParser is surrounded by a\n    bracket defined in openers (or at least has one before it),\n    return the indices of the opening bracket and the closing\n    bracket (or the end of line, whichever comes first).\n\n    If it is not surrounded by brackets, or the end of line comes\n    before the closing bracket and mustclose is True, returns None.\n    \"\"\"\n\n    bracketinglevel = self.bracketing[self.indexbracket][1]\n    before = self.indexbracket\n    while (\n        not self.isopener[before]\n        or self.rawtext[self.bracketing[before][0]] not in openers\n        or self.bracketing[before][1] > bracketinglevel\n    ):\n        before -= 1\n        if before < 0:\n            return None\n        bracketinglevel = min(bracketinglevel, self.bracketing[before][1])\n    after = self.indexbracket + 1\n    while after < len(self.bracketing) and self.bracketing[after][1] >= bracketinglevel:\n        after += 1\n\n    beforeindex = self.text.index(\n        \"%s-%dc\" % (self.stopatindex, len(self.rawtext) - self.bracketing[before][0])\n    )\n    if after >= len(self.bracketing) or self.bracketing[after][0] > len(self.rawtext):\n        if mustclose:\n            return None\n        afterindex = self.stopatindex\n    else:\n        # We are after a real char, so it is a ')' and we give the\n        # index before it.\n        afterindex = self.text.index(\n            \"%s-%dc\" % (self.stopatindex, len(self.rawtext) - (self.bracketing[after][0] - 1))\n        )\n\n    return beforeindex, afterindex", "loc": 42}
{"file": "thonny\\thonny\\roughparse.py", "class_name": "HyperParser", "function_name": "get_expression", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "self._eat_identifier", "self.is_in_code"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Return a string with the Python expression which ends at the given index, which is empty if there is no real one.", "source_code": "def get_expression(self):\n    \"\"\"Return a string with the Python expression which ends at the\n    given index, which is empty if there is no real one.\n    \"\"\"\n    if not self.is_in_code():\n        raise ValueError(\"get_expression should only be called\" \"if index is inside a code.\")\n\n    rawtext = self.rawtext\n    bracketing = self.bracketing\n\n    brck_index = self.indexbracket\n    brck_limit = bracketing[brck_index][0]\n    pos = self.indexinrawtext\n\n    last_identifier_pos = pos\n    postdot_phase = True\n\n    while 1:\n        # Eat whitespaces, comments, and if postdot_phase is False - a dot\n        while 1:\n            if pos > brck_limit and rawtext[pos - 1] in self._whitespace_chars:\n                # Eat a whitespace\n                pos -= 1\n            elif not postdot_phase and pos > brck_limit and rawtext[pos - 1] == \".\":\n                # Eat a dot\n                pos -= 1\n                postdot_phase = True\n            # The next line will fail if we are *inside* a comment,\n            # but we shouldn't be.\n            elif (\n                pos == brck_limit\n                and brck_index > 0\n                and rawtext[bracketing[brck_index - 1][0]] == \"#\"\n            ):\n                # Eat a comment\n                brck_index -= 2\n                brck_limit = bracketing[brck_index][0]\n                pos = bracketing[brck_index + 1][0]\n            else:\n                # If we didn't eat anything, quit.\n                break\n\n        if not postdot_phase:\n            # We didn't find a dot, so the expression end at the\n            # last identifier pos.\n            break\n\n        ret = self._eat_identifier(rawtext, brck_limit, pos)\n        if ret:\n            # There is an identifier to eat\n            pos = pos - ret\n            last_identifier_pos = pos\n            # Now, to continue the search, we must find a dot.\n            postdot_phase = False\n            # (the loop continues now)\n\n        elif pos == brck_limit:\n            # We are at a bracketing limit. If it is a closing\n            # bracket, eat the bracket, otherwise, stop the search.\n            level = bracketing[brck_index][1]\n            while brck_index > 0 and bracketing[brck_index - 1][1] > level:\n                brck_index -= 1\n            if bracketing[brck_index][0] == brck_limit:\n                # We were not at the end of a closing bracket\n                break\n            pos = bracketing[brck_index][0]\n            brck_index -= 1\n            brck_limit = bracketing[brck_index][0]\n            last_identifier_pos = pos\n            if rawtext[pos] in \"([\":\n                # [] and () may be used after an identifier, so we\n                # continue. postdot_phase is True, so we don't allow a dot.\n                pass\n            else:\n                # We can't continue after other types of brackets\n                if rawtext[pos] in \"'\\\"\":\n                    # Scan a string prefix\n                    while pos > 0 and rawtext[pos - 1] in \"rRbBuU\":\n                        pos -= 1\n                    last_identifier_pos = pos\n                break\n\n        else:\n            # We've found an operator or something.\n            break\n\n    return rawtext[last_identifier_pos : self.indexinrawtext]", "loc": 87}
{"file": "thonny\\thonny\\rst_utils.py", "class_name": null, "function_name": "escape", "parameters": ["s"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["s.replace", "s.replace('\\\\', '\\\\\\\\').replace", "s.replace('\\\\', '\\\\\\\\').replace('*', '\\\\*').replace", "s.replace('\\\\', '\\\\\\\\').replace('*', '\\\\*').replace('`', '\\\\`').replace", "s.replace('\\\\', '\\\\\\\\').replace('*', '\\\\*').replace('`', '\\\\`').replace('_', '\\\\_').replace"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def escape(s):\n    return (\n        s.replace(\"\\\\\", \"\\\\\\\\\")\n        .replace(\"*\", \"\\\\*\")\n        .replace(\"`\", \"\\\\`\")\n        .replace(\"_\", \"\\\\_\")\n        .replace(\"..\", \"\\\\..\")\n    )", "loc": 8}
{"file": "thonny\\thonny\\rst_utils.py", "class_name": "RstText", "function_name": "configure_tags", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bold_font.cget", "bold_font.configure", "bold_font.copy", "get_syntax_options_for_tag", "h1_font.configure", "h2_font.configure", "h3_font.configure", "italic_font.configure", "italic_font.copy", "main_font.cget", "main_font.copy", "range", "round", "self.tag_bind", "self.tag_configure", "self.tag_raise", "small_font.configure", "small_italic_font.configure", "tk.font.nametofont", "tk.font.nametofont('TkFixedFont').cget", "toti_code_font.configure", "ui_utils.get_tk_version_info", "underline_font.configure"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def configure_tags(self):\n    main_font = tk.font.nametofont(\"TkDefaultFont\")\n\n    bold_font = main_font.copy()\n    bold_font.configure(weight=\"bold\", size=main_font.cget(\"size\"))\n\n    italic_font = main_font.copy()\n    italic_font.configure(slant=\"italic\", size=main_font.cget(\"size\"))\n\n    h1_font = main_font.copy()\n    h1_font.configure(size=main_font.cget(\"size\") * 2, weight=\"bold\")\n\n    h2_font = main_font.copy()\n    h2_font.configure(size=round(main_font.cget(\"size\") * 1.5), weight=\"bold\")\n\n    h3_font = main_font.copy()\n    h3_font.configure(size=main_font.cget(\"size\"), weight=\"bold\")\n\n    small_font = main_font.copy()\n    small_font.configure(size=round(main_font.cget(\"size\") * 0.8))\n    small_italic_font = italic_font.copy()\n    small_italic_font.configure(size=round(main_font.cget(\"size\") * 0.8))\n\n    # Underline on font looks better than underline on tag\n    underline_font = main_font.copy()\n    underline_font.configure(underline=True)\n\n    self.tag_configure(\"h1\", font=h1_font, spacing3=5)\n    self.tag_configure(\"h2\", font=h2_font, spacing3=5)\n    self.tag_configure(\"h3\", font=h3_font, spacing3=5)\n    self.tag_configure(\"p\", spacing1=0, spacing3=10, spacing2=0)\n    self.tag_configure(\"line_block\", spacing1=0, spacing3=10, spacing2=0)\n    self.tag_configure(\"em\", font=italic_font)\n    self.tag_configure(\"strong\", font=bold_font)\n\n    # TODO: hyperlink syntax options may require different background as well\n    hyperlink_opts = get_syntax_options_for_tag(\"hyperlink\")\n    hyperlink_opts[\"underline\"] = False\n    hyperlink_opts[\"font\"] = underline_font\n    self.tag_configure(\"a\", **hyperlink_opts)\n\n    self.tag_configure(\"small\", font=small_font)\n    self.tag_configure(\"light\", foreground=\"gray\")\n    self.tag_configure(\"remark\", font=small_italic_font)\n    self.tag_bind(\"a\", \"<Enter>\", self._hyperlink_enter)\n    self.tag_bind(\"a\", \"<Leave>\", self._hyperlink_leave)\n\n    self.tag_configure(\"topic_title\", lmargin2=16, font=bold_font)\n    self.tag_configure(\"topic_body\", lmargin1=16, lmargin2=16)\n    self.tag_configure(\n        \"code\",\n        font=\"TkFixedFont\",\n        # wrap=\"none\", # TODO: needs automatic hor-scrollbar and better padding mgmt\n        # background=\"#eeeeee\"\n    )\n    # if ui_utils.get_tk_version_info() >= (8,6,6):\n    #    self.tag_configure(\"code\", lmargincolor=self[\"background\"])\n\n    for i in range(1, 6):\n        self.tag_configure(\"list%d\" % i, lmargin1=i * 10, lmargin2=i * 10 + 10)\n\n    toti_code_font = bold_font.copy()\n    toti_code_font.configure(\n        family=tk.font.nametofont(\"TkFixedFont\").cget(\"family\"), size=bold_font.cget(\"size\")\n    )\n    self.tag_configure(\"topic_title_code\", font=toti_code_font)\n    self.tag_raise(\"topic_title_code\", \"code\")\n    self.tag_raise(\"topic_title_code\", \"topic_title\")\n    self.tag_raise(\"a\", \"topic_title\")\n\n    # TODO: topic_title + em\n    self.tag_raise(\"em\", \"topic_title\")\n    self.tag_raise(\"a\", \"em\")\n    self.tag_raise(\"a\", \"topic_body\")\n    self.tag_raise(\"a\", \"topic_title\")\n\n    if ui_utils.get_tk_version_info() >= (8, 6, 6):\n        self.tag_configure(\"sel\", lmargincolor=self[\"background\"])\n    self.tag_raise(\"sel\")", "loc": 79}
{"file": "thonny\\thonny\\rst_utils.py", "class_name": "RstText", "function_name": "append_rst", "parameters": ["self", "rst_source", "global_tags"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["doc.walkabout", "docutils.core.publish_doctree", "self.create_visitor", "self.direct_insert", "traceback.format_exc"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def append_rst(self, rst_source, global_tags=()):\n    try:\n        import docutils.core\n\n        doc = docutils.core.publish_doctree(rst_source)\n        doc.walkabout(self.create_visitor(doc, global_tags))\n    except Exception:\n        self.direct_insert(\"end\", \"RST SOURCE:\\n\" + rst_source + \"\\n\\n\")\n        self.direct_insert(\"end\", traceback.format_exc())", "loc": 9}
{"file": "thonny\\thonny\\rst_utils.py", "class_name": "RstText", "function_name": "on_theme_changed", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "lookup_style_option", "self.configure_tags", "self.nametowidget", "self.window_names", "w.configure"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_theme_changed(self):\n    self.configure_tags()\n    text_bg = lookup_style_option(\"Text\", \"background\")\n    for name in self.window_names():\n        w = self.nametowidget(name)\n        if isinstance(w, tk.Label):\n            w.configure(background=text_bg)", "loc": 7}
{"file": "thonny\\thonny\\rst_utils.py", "class_name": "TkTextRenderingVisitor", "function_name": "depart_paragraph", "parameters": ["self", "node"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._append_text", "self._pop_tag"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def depart_paragraph(self, node):\n    self.in_paragraph = False\n    self._append_text(\"\\n\")\n    if not self.active_lists:\n        self._pop_tag(\"p\")", "loc": 5}
{"file": "thonny\\thonny\\rst_utils.py", "class_name": "TkTextRenderingVisitor", "function_name": "visit_topic", "parameters": ["self", "node"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._visit_empty_topic", "self._visit_toggle_topic", "self.default_visit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_topic(self, node):\n    self.in_topic = True\n\n    if \"toggle\" in node.attributes[\"classes\"]:\n        return self._visit_toggle_topic(node)\n    elif \"empty\" in node.attributes[\"classes\"]:\n        return self._visit_empty_topic(node)\n    else:\n        return self.default_visit(node)", "loc": 9}
{"file": "thonny\\thonny\\rst_utils.py", "class_name": "TkTextRenderingVisitor", "function_name": "visit_list_item", "parameters": ["self", "node"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "self._append_text"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def visit_list_item(self, node):\n    if self.active_lists[-1] == \"*\":\n        self._append_text(\" \")\n    elif self.active_lists[-1] == \"arabic\":\n        for i, sib in enumerate(node.parent.children):\n            if sib is node:\n                self._append_text(\"%d. \" % (i + 1))\n                break", "loc": 8}
{"file": "thonny\\thonny\\rst_utils.py", "class_name": null, "function_name": "get_toggler_image_name", "parameters": ["kind"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().uses_dark_ui_theme"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_toggler_image_name(kind):\n    if get_workbench().uses_dark_ui_theme():\n        return kind + \"_light\"\n    else:\n        return kind", "loc": 5}
{"file": "thonny\\thonny\\rst_utils.py", "class_name": null, "function_name": "toggle_body", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bool", "get_toggler_image_name", "get_workbench", "get_workbench().get_image", "label.configure", "self.text.has_selection", "self.text.tag_cget", "self.text.tag_configure", "self.text.tag_remove"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def toggle_body(event=None):\n    elide = self.text.tag_cget(body_id_tag, \"elide\")\n    if elide == \"1\":\n        elide = True\n    elif elide == \"0\":\n        elide = False\n    else:\n        elide = bool(elide)\n\n    elide = not elide\n\n    self.text.tag_configure(body_id_tag, elide=elide)\n    if self.text.has_selection():\n        self.text.tag_remove(\"sel\", \"1.0\", \"end\")\n\n    if elide:\n        label.configure(\n            image=get_workbench().get_image(get_toggler_image_name(\"boxplus\"))\n        )\n    else:\n        label.configure(\n            image=get_workbench().get_image(get_toggler_image_name(\"boxminus\"))\n        )", "loc": 23}
{"file": "thonny\\thonny\\running.py", "class_name": null, "function_name": "create_frontend_python_process", "parameters": ["args", "stdin", "stdout", "stderr", "environment_extras", "universal_newlines"], "param_types": {"environment_extras": "Optional[Dict[str, str]]", "universal_newlines": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_create_python_process", "env.update", "get_environment_for_python_subprocess", "get_front_interpreter_for_subprocess", "get_front_interpreter_for_subprocess().replace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Used for running helper commands (eg. for installing plug-ins on by the plug-ins)", "source_code": "def create_frontend_python_process(\n    args,\n    stdin=None,\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    environment_extras: Optional[Dict[str, str]] = None,\n    universal_newlines: bool = True,\n):\n    \"\"\"Used for running helper commands (eg. for installing plug-ins on by the plug-ins)\"\"\"\n    if _console_allocated:\n        python_exe = get_front_interpreter_for_subprocess().replace(\"pythonw.exe\", \"python.exe\")\n    else:\n        python_exe = get_front_interpreter_for_subprocess().replace(\"python.exe\", \"pythonw.exe\")\n    env = get_environment_for_python_subprocess(python_exe)\n    env[\"PYTHONIOENCODING\"] = \"utf-8\"\n    env[\"PYTHONUNBUFFERED\"] = \"1\"\n    if environment_extras is not None:\n        env.update(environment_extras)\n    return _create_python_process(\n        python_exe, args, stdin, stdout, stderr, env=env, universal_newlines=universal_newlines\n    )", "loc": 21}
{"file": "thonny\\thonny\\running.py", "class_name": null, "function_name": "get_environment_with_overrides", "parameters": ["overrides"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "key.upper", "os.environ.copy", "update_system_path"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_environment_with_overrides(overrides):\n    env = os.environ.copy()\n    for key in overrides:\n        if overrides[key] is None and key in env:\n            del env[key]\n        else:\n            assert isinstance(overrides[key], str)\n            if key.upper() == \"PATH\":\n                update_system_path(env, overrides[key])\n            else:\n                env[key] = overrides[key]\n    return env", "loc": 12}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "start", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_shell", "get_shell().print_error", "logger.exception", "self._check_alloc_console", "self.restart_backend"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start(self) -> None:\n    global _console_allocated\n    try:\n        self._check_alloc_console()\n        _console_allocated = True\n    except Exception:\n        logger.exception(\"Problem allocating console\")\n        _console_allocated = False\n\n    try:\n        self.restart_backend(False, True)\n    except Exception as e:\n        logger.exception(\"Could not start backend when starting Runner\")\n        get_shell().print_error(f\"\\nStarting the back-end failed with following error: {e}\\n\")", "loc": 14}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "send_command_and_wait_in_thread", "parameters": ["self", "cmd", "timeout"], "param_types": {"cmd": "InlineCommand", "timeout": "int"}, "return_type": "MessageFromBackend", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "TimeoutError", "cmd.get", "generate_command_id", "logger.info", "self._thread_commands.put", "time.sleep", "time.time"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def send_command_and_wait_in_thread(\n    self, cmd: InlineCommand, timeout: int\n) -> MessageFromBackend:\n    logger.info(\"Runner.send_command_and_wait_in_thread %r\", cmd)\n    # should not send directly, as we're in thread\n    cmd_id = cmd.get(\"id\")\n    if cmd_id is None:\n        cmd_id = generate_command_id()\n        cmd[\"id\"] = cmd_id\n\n    start_time = time.time()\n    proxy_at_start = self._proxy\n\n    self._thread_commands.put(cmd)\n\n    while time.time() - start_time < timeout:\n        if self._proxy is not proxy_at_start:\n            raise RuntimeError(\"Backend restarted\")\n        elif cmd_id in self._thread_command_results:\n            result = self._thread_command_results[cmd_id]\n            del self._thread_command_results[cmd_id]\n            return result\n        else:\n            time.sleep(0.1)\n    else:\n        raise TimeoutError(f\"Could not receive response to {cmd} in {timeout} seconds\")", "loc": 26}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "execute_via_shell", "parameters": ["self", "cmd_line", "working_directory"], "param_types": {"cmd_line": "Union[str, List[str]]", "working_directory": "Optional[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["construct_cd_command", "construct_cmd_line", "get_shell", "get_shell().submit_magic_command", "isinstance", "self._proxy.get_cwd"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def execute_via_shell(\n    self,\n    cmd_line: Union[str, List[str]],\n    working_directory: Optional[str] = None,\n) -> None:\n    if working_directory and self._proxy.get_cwd() != working_directory:\n        # create compound command\n        # start with %cd\n        cd_cmd_line = construct_cd_command(working_directory) + \"\\n\"\n    else:\n        # create simple command\n        cd_cmd_line = \"\"\n\n    if not isinstance(cmd_line, str):\n        cmd_line = construct_cmd_line(cmd_line)\n\n    # submit to shell (shell will execute it)\n    get_shell().submit_magic_command(cd_cmd_line + cmd_line)", "loc": 18}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "execute_script", "parameters": ["self", "script_path", "args", "working_directory", "command_name"], "param_types": {"script_path": "str", "args": "List[str]", "working_directory": "Optional[str]", "command_name": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["construct_cmd_line", "self.execute_via_shell", "universal_relpath"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def execute_script(\n    self,\n    script_path: str,\n    args: List[str],\n    working_directory: Optional[str],\n    command_name: str = \"Run\",\n) -> None:\n    rel_filename = universal_relpath(script_path, working_directory)\n    cmd_parts = [\"%\" + command_name, rel_filename] + args\n    cmd_line = construct_cmd_line(cmd_parts, [EDITOR_CONTENT_TOKEN])\n\n    self.execute_via_shell(cmd_line, working_directory)", "loc": 12}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "execute_editor_content", "parameters": ["self", "command_name", "args"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["command_name.lower", "construct_cmd_line", "get_shell", "get_shell().submit_magic_command", "get_workbench", "messagebox.showinfo", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def execute_editor_content(self, command_name, args):\n    if command_name.lower() in [\"debug\", \"fastdebug\"]:\n        messagebox.showinfo(\n            tr(\"Information\"),\n            tr(\"For debugging the program must be saved first.\"),\n            master=get_workbench(),\n        )\n        return\n\n    get_shell().submit_magic_command(\n        construct_cmd_line(\n            [\"%\" + command_name, \"-c\", EDITOR_CONTENT_TOKEN] + args, [EDITOR_CONTENT_TOKEN]\n        )\n    )", "loc": 14}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "execute_current", "parameters": ["self", "command_name"], "param_types": {"command_name": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["command_name[0].isupper", "editor.get_uri", "editor.is_modified", "editor.is_untitled", "editor.save_file", "get_shell", "get_shell().print_error", "get_target_dir_from_uri", "get_workbench", "get_workbench().get_editor_notebook", "get_workbench().get_editor_notebook().get_current_editor", "get_workbench().get_option", "is_local_uri", "is_remote_uri", "logger.debug", "logger.info", "self._get_active_arguments", "self._proxy.can_run_local_files", "self._proxy.can_run_remote_files", "self._proxy.get_cwd", "self._proxy.interrupt", "self._proxy.should_restart_interpreter_before_run", "self._proxy.stop_restart_kills_user_program", "self._wait_for_prompt", "self.cmd_stop_restart", "self.execute_editor_content", "self.execute_script", "self.get_state", "self.is_waiting_toplevel_command", "uri_to_target_path"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "This method's job is to create a command for running/debugging current file/script and submit it to shell", "source_code": "def execute_current(self, command_name: str) -> None:\n    \"\"\"\n    This method's job is to create a command for running/debugging\n    current file/script and submit it to shell\n    \"\"\"\n\n    if not self._proxy:\n        return\n\n    assert (\n        command_name[0].isupper()\n        or command_name == \"run\"\n        and not self._proxy.should_restart_interpreter_before_run()\n    )\n\n    if not self.is_waiting_toplevel_command():\n        logger.info(\"Trying to execute current but runner is %r\", self.get_state())\n        self._proxy.interrupt()\n\n        try:\n            self._wait_for_prompt(1)\n        except TimeoutError:\n            # turtle.mainloop, for example, is not easy to interrupt.\n            get_shell().print_error(\"Could not interrupt current process. \")\n            wait_instructions = \"Please wait, try again or select Stop/Restart!\"\n\n            if self._proxy.stop_restart_kills_user_program():\n                get_shell().print_error(\"Forcing the program to stop.\\n\")\n                self.cmd_stop_restart()\n                try:\n                    self._wait_for_prompt(1)\n                except TimeoutError:\n                    get_shell().print_error(\n                        \"Could not force-stop the program. \" + wait_instructions + \"\\n\"\n                    )\n            else:\n                # For some back-ends (e.g. BareMetalMicroPython) killing is not an option.\n                # Besides, they may be configured to avoid refreshing the environment\n                # before run (for performance reasons).\n                get_shell().print_error(wait_instructions + \"\\n\")\n                return\n\n    editor = get_workbench().get_editor_notebook().get_current_editor()\n    if not editor:\n        return\n\n    UNTITLED = f\"{UNTITLED_URI_SCHEME}:0\"\n    if not editor.is_untitled() or not get_workbench().get_option(\n        \"run.allow_running_unnamed_programs\"\n    ):\n        if not editor.is_untitled() and not editor.is_modified():\n            # Don't attempt to save as the file may be read-only\n            logger.debug(\"Not saving read only file %s\", editor.get_uri())\n            uri = editor.get_uri()\n        else:\n            uri = editor.save_file()\n            if not uri:\n                # user has cancelled file saving\n                return\n    else:\n        uri = UNTITLED\n\n    if not self._proxy:\n        # Saving the file may have killed the proxy\n        return\n\n    if (\n        is_remote_uri(uri)\n        and not self._proxy.can_run_remote_files()\n        or is_local_uri(uri)\n        and not self._proxy.can_run_local_files()\n        or uri == UNTITLED\n    ):\n        self.execute_editor_content(command_name, self._get_active_arguments())\n    else:\n        if get_workbench().get_option(\"run.auto_cd\") and command_name[0].isupper():\n            working_directory = get_target_dir_from_uri(uri)\n        else:\n            working_directory = self._proxy.get_cwd()\n\n        target_path = uri_to_target_path(uri)\n        self.execute_script(\n            target_path, self._get_active_arguments(), working_directory, command_name\n        )", "loc": 84}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "cmd_run_current_script", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().hide_view", "get_workbench().in_simple_mode", "report_time", "self._proxy.should_restart_interpreter_before_run", "self.execute_current"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cmd_run_current_script(self) -> None:\n    if get_workbench().in_simple_mode():\n        get_workbench().hide_view(\"VariablesView\")\n    report_time(\"Before Run\")\n    if self._proxy and self._proxy.should_restart_interpreter_before_run():\n        self.execute_current(\"Run\")\n    else:\n        self.execute_current(\"run\")\n    report_time(\"After Run\")", "loc": 9}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "cmd_stop_restart", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().hide_view", "get_workbench().in_simple_mode", "self.restart_backend"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cmd_stop_restart(self) -> None:\n    if get_workbench().in_simple_mode():\n        get_workbench().hide_view(\"VariablesView\")\n\n    self.restart_backend(clean=True)", "loc": 5}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "ctrld", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EOFCommand", "get_shell", "get_shell().has_pending_input", "get_workbench", "messagebox.showerror", "proxy.send_command", "self._set_state", "self.get_backend_proxy"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ctrld(self):\n    proxy = self.get_backend_proxy()\n    if not proxy:\n        return\n\n    if get_shell().has_pending_input():\n        messagebox.showerror(\n            \"Can't perform this action\",\n            \"Ctrl+D only has effect on an empty line / prompt.\\n\"\n            + \"Submit current input (press ENTER) and try again\",\n            master=get_workbench(),\n        )\n        return\n\n    proxy.send_command(EOFCommand())\n    self._set_state(\"running\")", "loc": 16}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "restart_backend", "parameters": ["self", "clean", "first", "automatic"], "param_types": {"clean": "bool", "first": "bool", "automatic": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["UserError", "backend_class", "get_shell", "get_shell().restart", "get_shell().update_idletasks", "get_workbench", "get_workbench().after_idle", "get_workbench().event_generate", "get_workbench().get_backends", "get_workbench().get_option", "logger.info", "self._set_state", "self.destroy_backend", "self.is_running"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Recreate (or replace) backend proxy / backend process.", "source_code": "def restart_backend(self, clean: bool, first: bool = False, automatic: bool = False) -> None:\n    \"\"\"Recreate (or replace) backend proxy / backend process.\"\"\"\n    logger.info(\n        \"Restarting back-end, clean: %r, first: %r, automatic: %r\", clean, first, automatic\n    )\n    was_running = self.is_running()\n    self.destroy_backend()\n    self._last_accepted_backend_command = None\n    backend_name = get_workbench().get_option(\"run.backend_name\")\n    if backend_name not in get_workbench().get_backends():\n        raise UserError(\n            f\"Unknown interpreter kind '{backend_name}'. Please select another interpreter from options\"\n        )\n\n    backend_class = get_workbench().get_backends()[backend_name].proxy_class\n    self._set_state(\"running\")\n    self._proxy = None\n    logger.info(\"Starting backend %r\", backend_class)\n    self._proxy = backend_class(clean)\n\n    if not first:\n        get_shell().restart(automatic=automatic, was_running=was_running)\n        get_shell().update_idletasks()\n\n    get_workbench().event_generate(\"BackendRestart\", full=True)\n\n    get_workbench().after_idle(self._poll_backend_messages)", "loc": 27}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "destroy_backend", "parameters": ["self", "for_restart"], "param_types": {"for_restart": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().after_cancel", "get_workbench().event_generate", "logger.info", "self._proxy.destroy"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def destroy_backend(self, for_restart: bool = False) -> None:\n    logger.info(\"Destroying backend\")\n\n    if self._polling_after_id is not None:\n        get_workbench().after_cancel(self._polling_after_id)\n        self._polling_after_id = None\n\n    self._postponed_commands = []\n    if self._proxy:\n        self._proxy.destroy(for_restart=for_restart)\n        self._proxy = None\n        get_workbench().event_generate(\"BackendTerminated\")", "loc": 12}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "ready_for_remote_file_operations", "parameters": ["self", "show_message"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "messagebox.showerror", "self._proxy.is_connected", "self._proxy.ready_for_remote_file_operations", "self.supports_remote_files", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ready_for_remote_file_operations(self, show_message=False):\n    if not self._proxy or not self.supports_remote_files():\n        return False\n\n    ready = self._proxy.ready_for_remote_file_operations()\n\n    if not ready and show_message:\n        if not self._proxy.is_connected():\n            msg = \"Device is not connected\"\n        else:\n            msg = (\n                \"Device is busy -- can't perform this action now.\"\n                + \"\\nPlease wait or cancel current work and try again!\"\n            )\n        messagebox.showerror(tr(\"Can't complete\"), msg, master=get_workbench())\n\n    return ready", "loc": 17}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "supports_remote_files", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._proxy.supports_remote_files"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def supports_remote_files(self):\n    if self._proxy is None:\n        return False\n    else:\n        return self._proxy.supports_remote_files()", "loc": 5}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "supports_remote_directories", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._proxy.supports_remote_directories"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def supports_remote_directories(self):\n    if self._proxy is None:\n        return False\n    else:\n        return self._proxy.supports_remote_directories()", "loc": 5}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "get_node_label", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._proxy.get_node_label"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_node_label(self):\n    if self._proxy is None:\n        return \"Back-end\"\n    else:\n        return self._proxy.get_node_label()", "loc": 5}
{"file": "thonny\\thonny\\running.py", "class_name": "Runner", "function_name": "is_connected", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._proxy.is_connected"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_connected(self):\n    if self._proxy is None:\n        return False\n    else:\n        return self._proxy.is_connected()", "loc": 5}
{"file": "thonny\\thonny\\running.py", "class_name": "BackendProxy", "function_name": "get_package_installation_confirmations", "parameters": ["self", "dist_info"], "param_types": {"dist_info": "DistInfo"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dist_info.name.lower", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_package_installation_confirmations(self, dist_info: DistInfo) -> List[str]:\n    if \"thonny\" in dist_info.name.lower():\n        return [\n            tr(\n                \"Looks like you are installing a Thonny-related package.\\n\"\n                + \"If you meant to install a Thonny plugin, then you should\\n\"\n                + \"choose 'Tools  Manage plugins...' instead\\n\"\n                + \"\\n\"\n                + \"Are you sure you want to install %s for the back-end?\"\n            )\n            % dist_info.name\n        ]\n\n    return []", "loc": 14}
{"file": "thonny\\thonny\\running.py", "class_name": "BackendProxy", "function_name": "search_packages", "parameters": ["cls", "query"], "param_types": {"query": "str"}, "return_type": "List[DistInfo]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_data_url", "perform_pypi_search"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def search_packages(cls, query: str) -> List[DistInfo]:\n    from thonny.plugins.pip_gui import perform_pypi_search\n\n    return perform_pypi_search(\n        query, get_workbench().get_data_url(\"pypi_summaries_cpython.json\"), []\n    )", "loc": 6}
{"file": "thonny\\thonny\\running.py", "class_name": "SubprocessProxy", "function_name": "send_command", "parameters": ["self", "cmd"], "param_types": {"cmd": "CommandToBackend"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cmd.name[0].isupper", "getattr", "hasattr", "isinstance", "logger.info", "self._prepare_clean_launch", "self._send_msg"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Send the command to backend. Return None, 'discard' or 'postpone'", "source_code": "def send_command(self, cmd: CommandToBackend) -> Optional[str]:\n    \"\"\"Send the command to backend. Return None, 'discard' or 'postpone'\"\"\"\n    if isinstance(cmd, ToplevelCommand) and cmd.name[0].isupper():\n        self._prepare_clean_launch()\n        logger.info(\"Prepared clean state for executing %r\", cmd)\n\n    if isinstance(cmd, ToplevelCommand):\n        # required by SshCPythonBackend for creating fresh target process\n        cmd[\"expected_cwd\"] = self._cwd\n\n    method_name = \"_cmd_\" + cmd.name\n\n    if hasattr(self, method_name):\n        getattr(self, method_name)(cmd)\n    else:\n        self._send_msg(cmd)", "loc": 16}
{"file": "thonny\\thonny\\running.py", "class_name": "SubprocessProxy", "function_name": "get_site_packages", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["d.endswith", "path_startswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_site_packages(self):\n    # NB! site.sitepackages may not be present in virtualenv\n    for d in self._sys_path:\n        if d.endswith(\"site-packages\") and path_startswith(d, self._sys_prefix):\n            return d\n\n    return None", "loc": 7}
{"file": "thonny\\thonny\\running.py", "class_name": "SubprocessProxy", "function_name": "has_next_message", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.is_terminated"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def has_next_message(self) -> bool:\n    if self.is_terminated():\n        return False\n\n    return len(self._response_queue) > 0", "loc": 5}
{"file": "thonny\\thonny\\running.py", "class_name": "SubprocessProxy", "function_name": "fetch_next_message", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BackendTerminatedError", "_ends_with_incomplete_ansi_code", "isinstance", "len", "self._check_remember_current_configuration", "self._response_queue.appendleft", "self._response_queue.popleft", "self._store_state_info", "self.is_terminated", "sleep"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fetch_next_message(self):\n    if not self._response_queue or len(self._response_queue) == 0:\n        if self.is_terminated():\n            raise BackendTerminatedError(self._proc.returncode if self._proc else None)\n        else:\n            return None\n\n    msg = self._response_queue.popleft()\n    if isinstance(msg, ToplevelResponse):\n        self._store_state_info(msg)\n        if not self._have_check_remembered_current_configuration:\n            self._check_remember_current_configuration()\n            self._have_check_remembered_current_configuration = True\n\n    if msg.event_type == \"ProgramOutput\":\n        # combine available small output messages to one single message,\n        # in order to put less pressure on UI code\n\n        wait_time = 0.01\n        total_wait_time = 0\n        while True:\n            if len(self._response_queue) == 0:\n                if _ends_with_incomplete_ansi_code(msg[\"data\"]) and total_wait_time < 0.1:\n                    # Allow reader to send the remaining part\n                    sleep(wait_time)\n                    total_wait_time += wait_time\n                    continue\n                else:\n                    return msg\n            else:\n                next_msg = self._response_queue.popleft()\n                if (\n                    next_msg.event_type == \"ProgramOutput\"\n                    and next_msg[\"stream_name\"] == msg[\"stream_name\"]\n                    and (\n                        len(msg[\"data\"]) + len(next_msg[\"data\"]) <= OUTPUT_MERGE_THRESHOLD\n                        and (\"\\n\" not in msg[\"data\"] or not io_animation_required)\n                        or _ends_with_incomplete_ansi_code(msg[\"data\"])\n                    )\n                ):\n                    msg[\"data\"] += next_msg[\"data\"]\n                else:\n                    # not to be sent in the same block, put it back\n                    self._response_queue.appendleft(next_msg)\n                    return msg\n\n    else:\n        return msg", "loc": 48}
{"file": "thonny\\thonny\\running.py", "class_name": "InlineCommandDialog", "function_name": "send_command_to_backend", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "get_runner", "get_runner().send_command", "isinstance", "logger.debug", "logger.error", "self._cmd", "self.append_text", "self.report_done", "self.set_action_text", "traceback.format_exc"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def send_command_to_backend(self):\n    if not isinstance(self._cmd, CommandToBackend):\n        # it was a lazy definition\n        try:\n            self._cmd = self._cmd()\n        except Exception as e:\n            logger.error(\"Could not produce command for backend\", self._cmd)\n            self.set_action_text(\"Error!\")\n            self.append_text(\"Could not produce command for backend\\n\")\n            self.append_text(\"\".join(traceback.format_exc()) + \"\\n\")\n            self.report_done(False)\n            return\n\n    logger.debug(\"Starting command in dialog: %s\", self._cmd)\n    get_runner().send_command(self._cmd)", "loc": 15}
{"file": "thonny\\thonny\\running.py", "class_name": "InlineCommandDialog", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_shell", "get_shell().set_ignore_program_output", "get_workbench", "get_workbench().unbind", "super", "super(InlineCommandDialog, self).close"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self):\n    get_workbench().unbind(\"InlineResponse\", self._on_response)\n    get_workbench().unbind(\"InlineProgress\", self._on_progress)\n    super(InlineCommandDialog, self).close()\n    get_shell().set_ignore_program_output(False)", "loc": 5}
{"file": "thonny\\thonny\\running.py", "class_name": null, "function_name": "publish_as_msg", "parameters": ["data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "message_queue.append", "parse_message", "sleep"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def publish_as_msg(data):\n    msg = parse_message(data)\n    if \"cwd\" in msg:\n        self.cwd = msg[\"cwd\"]\n    message_queue.append(msg)\n\n    if len(message_queue) > 10:\n        # Probably backend runs an infinite/long print loop.\n        # Throttle message throughput in order to keep GUI thread responsive.\n        while len(message_queue) > 0:\n            sleep(0.005)", "loc": 11}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellView", "function_name": "get_tab_text", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["replace_unsupported_chars", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_tab_text(self) -> str:\n    result = tr(\"Shell\")\n    if self._osc_title:\n        result += \"  \" + replace_unsupported_chars(self._osc_title)\n    return result", "loc": 5}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellView", "function_name": "init_plotter", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_command", "get_workbench().get_variable", "get_workbench().set_default", "self.update_plotter_visibility", "self.winfo_ismapped", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def init_plotter(self):\n    self.plotter = None\n    get_workbench().set_default(\"view.show_plotter\", False)\n    get_workbench().set_default(\"view.shell_sash_position\", 400)\n\n    self.plotter_visibility_var = get_workbench().get_variable(\"view.show_plotter\")\n\n    def can_toggle():\n        return self.winfo_ismapped()\n\n    get_workbench().add_command(\n        \"toggle_plotter\",\n        \"view\",\n        tr(\"Plotter\"),\n        self.toggle_plotter,\n        can_toggle,\n        flag_name=\"view.show_plotter\",\n        group=11,\n    )\n\n    self.update_plotter_visibility(True)", "loc": 21}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellView", "function_name": "update_plotter_visibility", "parameters": ["self", "initializing_shell_view"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.hide_plotter", "self.plotter_visibility_var.get", "self.show_plotter"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_plotter_visibility(self, initializing_shell_view=False):\n    if self.plotter_visibility_var.get():\n        self.show_plotter(initializing_shell_view)\n    else:\n        self.hide_plotter()", "loc": 5}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellView", "function_name": "show_plotter", "parameters": ["self", "initializing_shell_view"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PlotterCanvas", "get_workbench", "get_workbench().get_option", "get_workbench().show_view", "self.add", "self.plotter.winfo_ismapped", "self.sash_place", "self.update_plotter"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_plotter(self, initializing_shell_view=False):\n    if not initializing_shell_view:\n        get_workbench().show_view(\"ShellView\", True)\n\n    if self.plotter is None:\n        self.plotter = PlotterCanvas(self, self.text)\n\n    if not self.plotter.winfo_ismapped():\n        self.add(self.plotter, minsize=100)\n\n    self.sash_place(0, get_workbench().get_option(\"view.shell_sash_position\"), 0)\n\n    running.io_animation_required = True\n    self.update_plotter()", "loc": 14}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellView", "function_name": "hide_plotter", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.plotter.winfo_ismapped", "self.remove"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def hide_plotter(self):\n    if self.plotter is None or not self.plotter.winfo_ismapped():\n        return\n    else:\n        self.remove(self.plotter)\n        running.io_animation_required = False", "loc": 6}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellView", "function_name": "set_notice", "parameters": ["self", "text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.notice.grid", "self.notice.grid_forget", "self.notice.winfo_ismapped", "self.text.see"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_notice(self, text):\n    if text is None:\n        self.notice.grid_forget()\n    else:\n        self.notice[\"text\"] = text\n        if not self.notice.winfo_ismapped():\n            self.notice.grid(row=0, column=1, columnspan=2, sticky=\"nsew\", pady=(0, 1))\n            # height of the text was reduced so adjust the scrolling\n            # self.update()\n            self.text.see(\"end\")", "loc": 10}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellView", "function_name": "print_error", "parameters": ["self", "txt"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.text._insert_text_directly", "self.text.is_scrolled_to_end", "self.text.see"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def print_error(self, txt):\n    was_scrolled_to_end = self.text.is_scrolled_to_end()\n    self.text._insert_text_directly(txt, (\"io\", \"stderr\"))\n    if was_scrolled_to_end:\n        self.text.see(\"end\")", "loc": 5}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellView", "function_name": "submit_magic_command", "parameters": ["self", "cmd_line"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cmd_line.endswith", "construct_cmd_line", "isinstance", "self.text.submit_command"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def submit_magic_command(self, cmd_line):\n    if isinstance(cmd_line, list):\n        cmd_line = construct_cmd_line(cmd_line)\n\n    if not cmd_line.endswith(\"\\n\"):\n        cmd_line += \"\\n\"\n\n    self.text.submit_command(cmd_line, (\"magic\",))", "loc": 8}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellView", "function_name": "report_exception", "parameters": ["self", "prelude", "conclusion"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.text.direct_insert", "traceback.format_exc"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def report_exception(self, prelude=None, conclusion=None):\n    if prelude is not None:\n        self.text.direct_insert(\"end\", prelude + \"\\n\", (\"stderr\",))\n\n    self.text.direct_insert(\"end\", traceback.format_exc() + \"\\n\", (\"stderr\",))\n\n    if conclusion is not None:\n        self.text.direct_insert(\"end\", conclusion + \"\\n\", (\"stderr\",))", "loc": 8}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellView", "function_name": "text_inserted", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.update_plotter", "self.vert_scrollbar.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def text_inserted(self, event):\n    if (\n        event.text_widget == self.text\n        and \"\\n\" in event.text\n        # only when scrollbar doesn't move, because otherwise\n        # the update gets triggered by scrollbar anyway\n        and self.vert_scrollbar.get() == (0.0, 1.0)\n    ):\n        self.update_plotter()", "loc": 9}
{"file": "thonny\\thonny\\shell.py", "class_name": "ShellMenu", "function_name": "add_extra_items", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.add_checkbutton", "self.add_command", "self.add_separator", "self.view.plotter_visibility_var.get", "self.view.plotter_visibility_var.set", "self.view.toggle_plotter", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_extra_items(self):\n    self.add_separator()\n    self.add_command(label=tr(\"Clear\"), command=self.text._clear_shell)\n\n    def toggle_from_menu():\n        # I don't like that Tk menu toggles checbutton variable\n        # automatically before calling the handler.\n        # So I revert the toggle before calling the actual handler.\n        # This way the handler doesn't have to worry whether it\n        # needs to toggle the variable or not, and it can choose to\n        # decline the toggle.\n        self.view.plotter_visibility_var.set(not self.view.plotter_visibility_var.get())\n        self.view.toggle_plotter()\n\n    self.add_checkbutton(\n        label=tr(\"Show Plotter\"),\n        command=toggle_from_menu,\n        variable=self.view.plotter_visibility_var,\n    )", "loc": 19}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "submit_command", "parameters": ["self", "cmd_line", "tags"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._try_submit_input", "self.delete", "self.insert", "self.mark_set", "self.see"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def submit_command(self, cmd_line, tags):\n    # assert get_runner().is_waiting_toplevel_command()\n    self.delete(\"input_start\", \"end\")\n    self.insert(\"input_start\", cmd_line, tags)\n    self.see(\"end\")\n    self.mark_set(\"insert\", \"end\")\n    self._try_submit_input()", "loc": 7}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "update_tab_stops", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["compute_tab_stops", "get_workbench", "get_workbench().get_option", "logger.debug", "self.configure", "self.tag_configure", "tk.font.nametofont", "tuple"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_tab_stops(self):\n    # Code tabs\n    code_tab_chars = get_workbench().get_option(\"edit.tab_width\")\n    code_font = tk.font.nametofont(self[\"font\"])\n    code_tab_stops = compute_tab_stops(code_tab_chars, code_font, self.io_indent)\n    logger.debug(\"Using following tab stops for code: %r\", code_tab_stops)\n    self.configure(tabs=tuple(code_tab_stops), tabstyle=\"wordprocessor\")\n\n    # IO tabs\n    io_tab_chars = get_workbench().get_option(\"shell.io_tab_width\")\n    io_font = tk.font.nametofont(\"IOFont\")\n    io_tab_stops = compute_tab_stops(io_tab_chars, io_font, self.io_indent)\n    logger.debug(\"Using following tab stops for IO: %r\", io_tab_stops)\n    self.tag_configure(\"io\", tabs=io_tab_stops, tabstyle=\"wordprocessor\")", "loc": 14}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "restart", "parameters": ["self", "automatic", "was_running"], "param_types": {"automatic": "bool", "was_running": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_shell", "get_shell().set_osc_title", "get_workbench", "get_workbench().get_option", "logger.info", "self._clear_content", "self._insert_text_directly", "self.get", "self.get('1.0', '3.0').strip", "self.see", "self.set_read_only", "self.tag_names"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def restart(self, automatic: bool = False, was_running: bool = False):\n    logger.info(\"BaseShellText.restart(%r)\", automatic)\n    self.set_read_only(False)\n    if (\n        get_workbench().get_option(\"shell.clear_for_new_process\")\n        and not automatic\n        and not was_running\n    ):\n        self._clear_content(\"end\")\n    else:\n        if (\n            \"restart_line\" in self.tag_names(\"output_insert -2 chars\")\n            or not self.get(\"1.0\", \"3.0\").strip()\n        ):\n            return\n\n        self._insert_text_directly(\n            # \"\\n============================== RESTART ==============================\\n\",\n            \"\\n\" + \"\" * 200 + \"\\n\",\n            # \"\\n\" + \"\"*200 + \"\\n\",\n            (\"magic\", \"restart_line\"),\n        )\n\n    self.see(\"end\")\n    get_shell().set_osc_title(\"\")\n\n    self._last_ls_uri = None\n    self._last_ls_version = None\n    self._context_lines_for_language_server = []\n    self._session_num_executed_lines_sent_to_ls = 0", "loc": 30}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "intercept_insert", "parameters": ["self", "index", "chars", "tags"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EnhancedTextWithLogging.intercept_insert", "get_runner", "get_runner().is_waiting_toplevel_command", "get_workbench", "get_workbench().bell", "self._editing_allowed", "self._in_current_input_range", "self._try_submit_input", "self.mark_gravity", "self.see", "self.tag_add"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def intercept_insert(self, index, chars, tags=None, **kw):\n    if tags is None:\n        tags = ()\n\n    # pylint: disable=arguments-differ\n    if self._editing_allowed() and self._in_current_input_range(index):\n        # self._print_marks(\"before insert\")\n        # I want all marks to stay in place\n        self.mark_gravity(\"input_start\", tk.LEFT)\n        self.mark_gravity(\"output_insert\", tk.LEFT)\n\n        if get_runner().is_waiting_toplevel_command():\n            tags = tags + (\"toplevel\", \"command\")\n        else:\n            tags = tags + (\"io\", \"stdin\")\n\n        EnhancedTextWithLogging.intercept_insert(self, index, chars, tags)\n\n        if not get_runner().is_waiting_toplevel_command():\n            if not self._applied_io_events:\n                # tag preceding command line differently\n                self.tag_add(\"before_io\", \"input_start -1 lines linestart\")\n\n            self._try_submit_input()\n\n        self.see(\"insert\")\n    else:\n        get_workbench().bell()", "loc": 28}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "intercept_delete", "parameters": ["self", "index1", "index2"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().bell", "self._editing_allowed", "self._in_current_input_range", "self.direct_delete", "self.has_selection"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def intercept_delete(self, index1, index2=None, **kw):\n    if index1 == \"sel.first\" and index2 == \"sel.last\" and not self.has_selection():\n        return\n\n    if (\n        self._editing_allowed()\n        and self._in_current_input_range(index1)\n        and (index2 is None or self._in_current_input_range(index2))\n    ):\n        self.direct_delete(index1, index2, **kw)\n    else:\n        get_workbench().bell()", "loc": 12}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "selection_is_writable", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._in_current_input_range", "self.has_selection", "self.index"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def selection_is_writable(self):\n    try:\n        if not self.has_selection():\n            return self._in_current_input_range(self.index(\"insert\"))\n        else:\n            return self._in_current_input_range(\n                self.index(\"sel.first\")\n            ) and self._in_current_input_range(self.index(\"sel.last\"))\n    except TclError:\n        return True", "loc": 10}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "perform_return", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EnhancedTextWithLogging.perform_return", "get_runner", "get_runner().is_running", "get_runner().is_waiting_toplevel_command", "perform_python_return", "self._code_is_ready_for_submission", "self._try_submit_input", "self.get", "self.mark_set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_return(self, event):\n    if get_runner().is_running():\n        # if we are fixing the middle of the input string and pressing ENTER\n        # then we expect the whole line to be submitted not linebreak to be inserted\n        # (at least that's how IDLE works)\n        self.mark_set(\"insert\", \"end\")  # move cursor to the end\n\n        # Do the return without auto indent\n        EnhancedTextWithLogging.perform_return(self, event)\n\n        self._try_submit_input()\n\n    elif get_runner().is_waiting_toplevel_command():\n        # Same with editing middle of command, but only if it's a single line command\n        whole_input = self.get(\"input_start\", \"end-1c\")  # asking the whole input\n        if \"\\n\" not in whole_input and self._code_is_ready_for_submission(whole_input):\n            self.mark_set(\"insert\", \"end\")  # move cursor to the end\n            # Do the return without auto indent\n            EnhancedTextWithLogging.perform_return(self, event)\n        else:\n            # Don't want auto indent when code is ready for submission\n            source = self.get(\"input_start\", \"insert\")\n            tail = self.get(\"insert\", \"end\")\n\n            if self._code_is_ready_for_submission(source + \"\\n\", tail):\n                # No auto-indent\n                EnhancedTextWithLogging.perform_return(self, event)\n            else:\n                # Allow auto-indent\n                perform_python_return(self, event)\n\n        self._try_submit_input()\n\n    return \"break\"", "loc": 34}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "compute_smart_home_destination_index", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._in_current_input_range", "super", "super().compute_smart_home_destination_index"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Is used by EnhancedText", "source_code": "def compute_smart_home_destination_index(self):\n    \"\"\"Is used by EnhancedText\"\"\"\n\n    if self._in_current_input_range(\"insert\"):\n        # on input line, go to just after prompt\n        return \"input_start\"\n    else:\n        return super().compute_smart_home_destination_index()", "loc": 8}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "get_lines_above_viewport_bottom", "parameters": ["self", "tag_name", "n"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.get", "self.index", "self.tag_nextrange", "self.winfo_height"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_lines_above_viewport_bottom(self, tag_name, n):\n    end_index = self.index(\"@%d,%d lineend\" % (self.winfo_height(), self.winfo_height()))\n    start_index = self.index(end_index + \" -50 lines\")\n\n    result = \"\"\n    while True:\n        r = self.tag_nextrange(tag_name, start_index, end_index)\n        if not r:\n            break\n        result += self.get(r[0], r[1])\n        start_index = r[1]\n\n    return result", "loc": 13}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "extract_last_execution_info", "parameters": ["self", "command_pattern"], "param_types": {"command_pattern": "str"}, "return_type": "Optional[ExecutionInfo]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ExecutionInfo", "float", "int", "logger.info", "logger.warning", "self.get", "self.search", "self.tag_names", "self.tag_nextrange"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def extract_last_execution_info(self, command_pattern: str) -> Optional[ExecutionInfo]:\n    search_start = \"end\"\n    while True:\n        command_index = self.search(\n            command_pattern, index=search_start, backwards=True, regexp=True\n        )\n        if not command_index:\n            return None\n\n        if \"magic\" in self.tag_names(command_index):\n            # yep, that's the command\n            break\n        else:\n            # false alarm, keep looking\n            search_start = command_index\n\n    command_line = self.get(command_index, f\"{command_index} lineend\")\n    line_number = int(float(command_index))\n\n    # assuming there is next line\n    io_start_index = f\"{line_number + 1}.0\"\n    if not \"io\" in self.tag_names(io_start_index):\n        logger.info(\"No IO on the next line after %r\", command_line)\n        return None\n\n    io_start_index2, io_end_index = self.tag_nextrange(\"io\", io_start_index)\n    if io_start_index2 != io_start_index:\n        logger.warning(\n            \"IO start index %r vs %r. IO end index: %r\",\n            io_start_index,\n            io_start_index2,\n            io_end_index,\n        )\n        return None\n\n    if io_start_index == io_end_index:\n        logger.warning(\"IO start index == IO end index (%r)\", io_end_index)\n        return None\n\n    return ExecutionInfo(command_line, io_start_index, io_end_index)", "loc": 40}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "get_current_line_ls_offset", "parameters": ["self"], "param_types": {}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["float", "int", "len", "self.index"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_current_line_ls_offset(self) -> int:\n    \"\"\"\n    Returns:\n        Difference between current line position in ls_source and shell's current content\n    \"\"\"\n    input_start_line = int(float(self.index(\"input_start\")))\n    num_preceding_lines_in_shell = input_start_line - 1\n    num_preceding_lines_in_ls = len(self._context_lines_for_language_server)\n    return num_preceding_lines_in_ls - num_preceding_lines_in_shell", "loc": 9}
{"file": "thonny\\thonny\\shell.py", "class_name": "BaseShellText", "function_name": "get_current_column_ls_offset", "parameters": ["self"], "param_types": {}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["float", "int", "map", "self.index", "self.index('input_start').split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_current_column_ls_offset(self) -> int:\n    \"\"\"\n    Returns:\n        a negative integer if the line starts with non-input characters (e.g. prompt)\n    \"\"\"\n    input_start_line, input_start_col = map(int, self.index(\"input_start\").split(\".\"))\n    current_line = int(float(self.index(\"insert\")))\n    if current_line == input_start_line:\n        return -input_start_col\n\n    return 0", "loc": 11}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "create_close_button", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_image", "self.close_img.height", "self.close_img.width", "self.create_image", "self.create_rectangle", "self.tag_bind", "self.winfo_width"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_close_button(self):\n    self.close_img = get_workbench().get_image(\"tab-close\")\n    self.close_active_img = get_workbench().get_image(\"tab-close-active\")\n\n    self.close_rect = self.create_rectangle(\n        self.winfo_width() - self.close_img.width() - self.linespace,\n        self.linespace / 2,\n        self.winfo_width(),\n        self.linespace / 2 + self.close_img.height(),\n        fill=self.background,\n        width=0,\n        tags=(\"close\",),\n    )\n\n    self.close_button = self.create_image(\n        self.winfo_width() - self.linespace / 2,\n        self.linespace / 2,\n        anchor=\"ne\",\n        image=self.close_img,\n        activeimage=self.close_active_img,\n        tags=(\"close\",),\n    )\n\n    self.tag_bind(\"close\", \"<1>\", self.on_close)", "loc": 24}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "update_close_button", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.close_img.height", "self.close_img.width", "self.coords", "self.winfo_width"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_close_button(self):\n    self.coords(\n        self.close_rect,\n        self.winfo_width() - self.close_img.width() - self.linespace / 1.5,\n        self.linespace / 2,\n        self.winfo_width() - self.linespace / 2,\n        self.linespace / 2 + self.close_img.height(),\n    )\n    self.coords(self.close_button, self.winfo_width() - self.linespace / 2, self.linespace / 2)", "loc": 9}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "update_plot", "parameters": ["self", "force_clean"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data_lines.append", "float", "int", "list", "range", "segments_by_color.append", "self.create_text_with_background", "self.delete", "self.draw_segments", "self.extract_pattern_and_numbers", "self.extract_series_segments", "self.get_num_steps", "self.tag_raise", "self.text.get", "self.text.index", "self.text.tag_names", "self.text.winfo_height", "self.text.winfo_width", "self.update_legend", "self.update_range", "self.winfo_height", "self.winfo_width", "tr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_plot(self, force_clean=False):\n    data_lines = []\n    bottom_index = self.text.index(\n        \"@%d,%d\" % (self.text.winfo_width(), self.text.winfo_height())\n    )\n    bottom_lineno = int(float(bottom_index))\n\n    for i in range(bottom_lineno - self.get_num_steps(), bottom_lineno + 1):\n        line_start_index = \"%d.0\" % i\n        if i < 1 or \"stdout\" not in self.text.tag_names(line_start_index):\n            data_lines.append(([], []))\n        else:\n            content = self.text.get(line_start_index, line_start_index + \" lineend\")\n            data_lines.append(self.extract_pattern_and_numbers(content))\n\n    # data_lines need to be transposed\n    segments_by_color = []\n    for i in range(100):\n        segments = list(self.extract_series_segments(data_lines, i))\n        if segments:\n            segments_by_color.append(segments)\n        else:\n            break\n\n    self.delete(\"segment\")\n\n    self.update_range(segments_by_color, force_clean)\n    segment_count = self.draw_segments(segments_by_color)\n    self.update_legend(data_lines, force_clean)\n\n    self.delete(\"info\")\n    if segment_count == 0:\n        info_text = (\n            tr(\"Plotter visualizes series of\\n\" + \"numbers printed to the Shell.\")\n            + \"\\n\\n\"\n            + tr(\"See Help for details.\")\n        )\n\n        self.create_text_with_background(\n            self.winfo_width() / 2,\n            self.winfo_height() / 2,\n            text=info_text,\n            anchor=\"center\",\n            justify=\"center\",\n            tags=(\"info\",),\n        )\n        # self.delete(\"guide\", \"tick\", \"legend\")\n        # self.range_start = 0\n        # self.range_end = 0\n        self.tag_raise(\"info\")\n\n    self.fresh_range = False", "loc": 52}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "update_legend", "parameters": ["self", "data_lines", "force_clean"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "len", "marker.join", "self.create_rectangle", "self.create_text", "self.delete", "self.font.measure", "self.tag_raise", "self.winfo_height", "self.winfo_width"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_legend(self, data_lines, force_clean=False):\n    legend = None\n    i = len(data_lines) - 2  # one before last\n    while i >= 0:\n        legend = data_lines[i][0]\n        if legend and legend == data_lines[i + 1][0]:\n            # found last legend, which covers at least 2 consecutive points\n            break\n        i -= 1\n\n    if self.last_legend == legend and not force_clean:\n        # just make sure it remains topmost\n        self.tag_raise(\"legend\")\n        return\n\n    self.delete(\"legend\")\n\n    if legend is None:\n        return\n\n    # add horizontal padding\n    # legend[0] = \" \" + legend[0]\n    # legend[-1] = legend[-1] + \" \"\n\n    marker = \"\"  # \"\" \"\"\n    marker_width = self.font.measure(marker)\n    full_text_width = self.font.measure(marker.join(legend))\n\n    y = self.winfo_height() - self.linespace // 2\n    x = self.winfo_width() - full_text_width - self.linespace\n\n    self.create_rectangle(\n        x - self.linespace // 4,\n        y - self.linespace,\n        x + full_text_width + self.linespace // 4,\n        y,\n        fill=self.background,\n        width=0,\n        tags=(\"legend\",),\n    )\n\n    for i, part in enumerate(legend):\n        if i > 0:\n            self.create_text(\n                x,\n                y,\n                text=marker,\n                anchor=\"sw\",\n                fill=self.colors[(i - 1) % len(self.colors)],\n                tags=(\"legend\",),\n            )\n            x += marker_width\n\n        self.create_text(x, y, text=part, anchor=\"sw\", tags=(\"legend\",), fill=self.foreground)\n        x += self.font.measure(part)\n\n    self.last_legend = legend", "loc": 57}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "draw_segments", "parameters": ["self", "segments_by_color"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "self.draw_segment", "self.tag_raise"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def draw_segments(self, segments_by_color):\n    count = 0\n    for color, segments in enumerate(segments_by_color):\n        for pos, nums in segments:\n            self.draw_segment(color, pos, nums)\n            count += 1\n\n    # raise certain elements above segments\n    self.tag_raise(\"tick\")\n    self.tag_raise(\"close\")\n    return count", "loc": 11}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "draw_segment", "parameters": ["self", "color", "pos", "nums"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["args.extend", "len", "self.create_line"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def draw_segment(self, color, pos, nums):\n    x = self.x_padding_left + pos * self.x_scale\n\n    args = []\n    for num in nums:\n        y = self.y_padding + (self.range_end - num) * self.y_scale\n        args.extend([x, y])\n        x += self.x_scale\n\n    self.create_line(\n        *args,\n        width=2,\n        fill=self.colors[color % len(self.colors)],\n        tags=(\"segment\",),\n        # arrow may be confusing\n        # and doesn't play nice with distinguishing between\n        # scrollback view and fresh_range view\n        # arrow=\"last\",\n        # arrowshape=(3,5,3)\n    )", "loc": 20}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "update_range", "parameters": ["self", "segments_by_color", "clean"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "max", "min", "reversed", "self.get_num_steps", "self.update_guides_and_ticks", "self.winfo_height", "self.winfo_width"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_range(self, segments_by_color, clean):\n    if not segments_by_color:\n        return\n\n    range_start = 2**15\n    range_end = -(2**15)\n\n    # if new block is using 3/4 of the width,\n    # then don't consider old block's values anymore\n    interest_position = 0\n    for start_pos, nums in reversed(segments_by_color[0]):\n        if start_pos < self.get_num_steps() / 10:\n            interest_position = start_pos\n            break\n\n    assert isinstance(interest_position, int)\n    for segments in segments_by_color:\n        for start_pos, nums in segments:\n            if start_pos >= interest_position:\n                range_start = min(range_start, *nums)\n                range_end = max(range_end, *nums)\n\n    if interest_position == 0 and not self.fresh_range:\n        # meaning we still care about old line's values\n        range_start = min(range_start, self.range_start)\n        range_end = max(range_end, self.range_end)\n\n    if range_end == range_start:\n        range_end += 1\n\n    if (\n        not clean\n        and not self.fresh_range\n        and self.x_scale is not None\n        and range_end == self.range_end\n        and range_start == self.range_start\n    ):\n        # don't recompute as nothing was changed\n        return\n\n    value_range = range_end - range_start\n    range_block_size = value_range // 4\n    # prefer round blocks\n    for size in self.range_block_sizes:\n        if size * 4 >= value_range:\n            range_block_size = size\n            break\n\n    # extend to range block boundary\n    if range_end % range_block_size != 0:\n        range_end -= range_end % -range_block_size\n\n    if range_start % range_block_size != 0:\n        range_start -= range_start % range_block_size\n\n    # not sure about these assertions when using floats\n    # assert range_start % range_block_size == 0\n    # assert range_end % range_block_size == 0, \"range_end: %s, bs: %s\" % (range_end, range_block_size)\n\n    # remember\n    self.range_start = range_start\n    self.range_end = range_end\n    self.value_range = range_end - range_start\n    self.range_block_size = range_block_size\n\n    available_height = self.winfo_height() - 2 * self.y_padding\n    available_width = self.winfo_width() - self.x_padding_left - self.x_padding_right\n    num_steps = self.get_num_steps()\n\n    self.x_scale = available_width / (num_steps - 1)\n    self.y_scale = available_height / self.value_range\n\n    self.update_guides_and_ticks()", "loc": 73}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "update_guides_and_ticks", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "self.create_line", "self.create_text_with_background", "self.delete", "self.winfo_width", "str"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_guides_and_ticks(self):\n    self.delete(\"guide\", \"tick\")\n    value = self.range_start\n    while value <= self.range_end:\n        y = self.y_padding + (self.range_end - value) * self.y_scale\n\n        # guide\n        self.create_line(\n            0, y, self.winfo_width(), y, tags=(\"guide\",), dash=(2, 2), fill=\"#aaaaaa\"\n        )\n\n        # tick\n        if value == int(value):\n            value = int(value)\n\n        caption = \" \" + str(value) + \" \"\n        self.create_text_with_background(\n            self.linespace // 2, y, caption, anchor=\"w\", tags=(\"tick\",)\n        )\n        value += self.range_block_size", "loc": 20}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "extract_pattern_and_numbers", "parameters": ["self", "line"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NUMBER_SPLIT_REGEX.split", "float", "len", "numbers.append", "pattern.append", "range"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def extract_pattern_and_numbers(self, line):\n    parts = NUMBER_SPLIT_REGEX.split(line)\n    if len(parts) < 2:\n        return ([], [])\n\n    assert len(parts) % 2 == 1\n\n    pattern = []\n    numbers = []\n    for i in range(0, len(parts), 2):\n        pattern.append(parts[i])\n\n    for i in range(1, len(parts), 2):\n        numbers.append(float(parts[i]))\n\n    return (pattern, numbers)", "loc": 16}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "extract_series_segments", "parameters": ["self", "data_lines", "series_nr"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "len", "segment[1].append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Yields numbers which form connected multilines on graph Each segment is pair of starting position and numbers", "source_code": "def extract_series_segments(self, data_lines, series_nr):\n    \"\"\"Yields numbers which form connected multilines on graph\n    Each segment is pair of starting position and numbers\"\"\"\n    segment = (0, [])\n    prev_pattern = None\n    for i, (pattern, nums) in enumerate(data_lines):\n        if len(nums) <= series_nr or pattern != prev_pattern:\n            # break the segment\n            if len(segment[1]) > 1:\n                yield segment\n            segment = (i, [])\n\n        if len(nums) > series_nr:\n            segment[1].append(nums[series_nr])\n\n        prev_pattern = pattern\n\n    if len(segment[1]) > 1:\n        yield segment", "loc": 19}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "create_text_with_background", "parameters": ["self", "x", "y", "text", "anchor", "justify", "background", "tags"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "max", "self.create_rectangle", "self.create_text", "self.font.measure", "text.splitlines"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_text_with_background(\n    self, x, y, text, anchor=\"w\", justify=\"left\", background=None, tags=()\n):\n    if background is None:\n        background = self.background\n\n    width = 0\n    lines = text.splitlines()\n    for line in lines:\n        width = max(width, self.font.measure(line))\n\n    height = len(lines) * self.linespace\n\n    rect_x = x\n    rect_y = y\n    if anchor == \"center\":\n        rect_x = x - width / 2\n        rect_y = y - height / 2\n    elif anchor == \"w\":\n        rect_y = y - height / 2\n    else:\n        \"TODO:\"\n\n    self.create_rectangle(\n        rect_x, rect_y, rect_x + width, rect_y + height, fill=background, width=0, tags=tags\n    )\n    self.create_text(\n        x, y, anchor=anchor, text=text, tags=tags, fill=self.foreground, justify=justify\n    )", "loc": 29}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "reload_theme_options", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_syntax_options_for_tag", "self.configure", "self.itemconfig", "self.update_plot"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def reload_theme_options(self, event):\n    self.background = get_syntax_options_for_tag(\"TEXT\")[\"background\"]\n    self.foreground = get_syntax_options_for_tag(\"TEXT\")[\"foreground\"]\n    self.configure(background=self.background)\n    self.itemconfig(self.close_rect, fill=self.background)\n    self.update_plot(True)", "loc": 6}
{"file": "thonny\\thonny\\shell.py", "class_name": "PlotterCanvas", "function_name": "on_resize", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().set_option", "isinstance", "self.master.resize_plotter", "self.update_close_button", "self.update_plot", "self.winfo_width"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_resize(self, event):\n    if self.winfo_width() > 10:\n        get_workbench().set_option(\"view.plotter_width\", self.winfo_width())\n    self.update_plot(True)\n    self.update_close_button()\n    assert isinstance(self.master, ShellView)\n    self.master.resize_plotter()", "loc": 7}
{"file": "thonny\\thonny\\shell.py", "class_name": null, "function_name": "toggle_from_menu", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.view.plotter_visibility_var.get", "self.view.plotter_visibility_var.set", "self.view.toggle_plotter"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def toggle_from_menu():\n    # I don't like that Tk menu toggles checbutton variable\n    # automatically before calling the handler.\n    # So I revert the toggle before calling the actual handler.\n    # This way the handler doesn't have to worry whether it\n    # needs to toggle the variable or not, and it can choose to\n    # decline the toggle.\n    self.view.plotter_visibility_var.set(not self.view.plotter_visibility_var.get())\n    self.view.toggle_plotter()", "loc": 9}
{"file": "thonny\\thonny\\tktextext.py", "class_name": null, "function_name": "get_text_font", "parameters": ["text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "tkfont.nametofont"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_text_font(text):\n    font = text[\"font\"]\n    if isinstance(font, str):\n        return tkfont.nametofont(font)\n    else:\n        return font", "loc": 6}
{"file": "thonny\\thonny\\tktextext.py", "class_name": null, "function_name": "classifyws", "parameters": ["s", "tab_width"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def classifyws(s, tab_width):\n    raw = effective = 0\n    for ch in s:\n        if ch == \" \":\n            raw = raw + 1\n            effective = effective + 1\n        elif ch == \"\\t\":\n            raw = raw + 1\n            effective = (effective // tab_width + 1) * tab_width\n        else:\n            break\n    return raw, effective", "loc": 12}
{"file": "thonny\\thonny\\tktextext.py", "class_name": null, "function_name": "rebind_control_a", "parameters": ["root"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "root.bind_class", "widget.tag_add", "widget.tag_remove"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def rebind_control_a(root):\n    # Tk 8.6 has <<SelectAll>> event but 8.5 doesn't\n    # http://stackoverflow.com/questions/22907200/remap-default-keybinding-in-tkinter\n    def control_a(event):\n        widget = event.widget\n        if isinstance(widget, tk.Text):\n            widget.tag_remove(\"sel\", \"1.0\", \"end\")\n            widget.tag_add(\"sel\", \"1.0\", \"end\")\n\n    root.bind_class(\"Text\", \"<Control-a>\", control_a)", "loc": 10}
{"file": "thonny\\thonny\\tktextext.py", "class_name": null, "function_name": "get_keyboard_language", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "ctypes.WinDLL", "user32.GetForegroundWindow", "user32.GetKeyboardLayout", "user32.GetWindowThreadProcessId"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_keyboard_language():\n    # https://stackoverflow.com/a/42047820/261181\n    if sys.platform != \"win32\":\n        raise NotImplementedError(\"Can provide keyboard language only on Windows\")\n\n    import ctypes\n\n    user32 = ctypes.WinDLL(\"user32\", use_last_error=True)\n    curr_window = user32.GetForegroundWindow()\n    thread_id = user32.GetWindowThreadProcessId(curr_window, 0)\n    # Made up of 0xAAABBBB, AAA = HKL (handle object) & BBBB = language ID\n    klid = user32.GetKeyboardLayout(thread_id)\n    # Language ID -> low 10 bits, Sub-language ID -> high 6 bits\n    # Extract language ID from KLID\n    lid = klid & (2**16 - 1)\n\n    return lid", "loc": 17}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "TweakableText", "function_name": "set_insertwidth", "parameters": ["self", "new_width"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.config"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Change cursor width NB! Need to be careful with setting text[\"insertwidth\"]! My first straightforward solution caused unexplainable", "source_code": "def set_insertwidth(self, new_width):\n    \"\"\"Change cursor width\n\n    NB! Need to be careful with setting text[\"insertwidth\"]!\n    My first straightforward solution caused unexplainable\n    infinite loop of insertions and deletions in the text\n    (Repro: insert a line and a word, select that word and then do Ctrl-Z).\n\n    This solution seems safe but be careful!\n    \"\"\"\n    if self._suppress_events:\n        return\n\n    if self[\"insertwidth\"] != new_width:\n        old_suppress = self._suppress_events\n        try:\n            self._suppress_events = True\n            self.config(insertwidth=new_width)\n        finally:\n            self._suppress_events = old_suppress", "loc": 20}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "TweakableText", "function_name": "intercept_insert", "parameters": ["self", "index", "chars", "tags"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self.bell", "self.direct_insert", "self.is_read_only"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def intercept_insert(self, index, chars, tags=None, **kw):\n    assert isinstance(chars, str)\n    if chars >= \"\\uf704\" and chars <= \"\\uf70d\":  # Function keys F1..F10 in Mac cause these\n        pass\n    elif self.is_read_only():\n        self.bell()\n    else:\n        self.direct_insert(index, chars, tags, **kw)", "loc": 8}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "TweakableText", "function_name": "intercept_delete", "parameters": ["self", "index1", "index2"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._is_erroneous_delete", "self.bell", "self.direct_delete", "self.has_selection", "self.is_read_only"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def intercept_delete(self, index1, index2=None, **kw):\n    if index1 == \"sel.first\" and index2 == \"sel.last\" and not self.has_selection():\n        return\n\n    if self.is_read_only():\n        self.bell()\n    elif self._is_erroneous_delete(index1, index2):\n        pass\n    else:\n        self.direct_delete(index1, index2, **kw)", "loc": 10}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "TweakableText", "function_name": "direct_mark", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._original_mark", "self.event_generate", "time.time"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def direct_mark(self, *args):\n    self._original_mark(*args)\n    self._last_operation_time = time.time()\n    if args[:2] == (\"set\", \"insert\") and not self._suppress_events:\n        self.event_generate(\"<<CursorMove>>\")", "loc": 5}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "TweakableText", "function_name": "index_sel_first", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.index", "self.tag_ranges"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def index_sel_first(self):\n    # Tk will give error without this check\n    if self.tag_ranges(\"sel\"):\n        return self.index(\"sel.first\")\n    else:\n        return None", "loc": 6}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "TweakableText", "function_name": "index_sel_last", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.index", "self.tag_ranges"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def index_sel_last(self):\n    if self.tag_ranges(\"sel\"):\n        return self.index(\"sel.last\")\n    else:\n        return None", "loc": 5}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "TweakableText", "function_name": "get_selection_indices", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.has_selection", "self.index"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_selection_indices(self):\n    # If a selection is defined in the text widget, return (start,\n    # end) as Tkinter text indices, otherwise return (None, None)\n    if self.has_selection():\n        return self.index(\"sel.first\"), self.index(\"sel.last\")\n    else:\n        return None, None", "loc": 7}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "TweakableText", "function_name": "direct_insert", "parameters": ["self", "index", "chars", "tags"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._original_insert", "self.event_generate", "time.time"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def direct_insert(self, index, chars, tags=None, **kw):\n    self._original_insert(index, chars, tags, **kw)\n    self._edit_count += 1\n    self._last_operation_time = time.time()\n    if not self._suppress_events:\n        self.event_generate(\"<<TextChange>>\")", "loc": 6}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "TweakableText", "function_name": "direct_delete", "parameters": ["self", "index1", "index2"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._original_delete", "self.event_generate", "time.time"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def direct_delete(self, index1, index2=None, **kw):\n    self._original_delete(index1, index2, **kw)\n    self._edit_count += 1\n    self._last_operation_time = time.time()\n    if not self._suppress_events:\n        self.event_generate(\"<<TextChange>>\")", "loc": 6}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedText", "function_name": "perform_smart_backspace", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["chars.expandtabs", "chars.strip", "len", "self._log_keypress_for_undo", "self.get_selection_indices", "text.bell", "text.compare", "text.delete", "text.get", "text.insert", "text.mark_set"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_smart_backspace(self, event):\n    self._log_keypress_for_undo(event)\n\n    text = self\n    first, last = self.get_selection_indices()\n    if first and last:\n        text.delete(first, last)\n        text.mark_set(\"insert\", first)\n        return \"break\"\n    # Delete whitespace left, until hitting a real char or closest\n    # preceding virtual tab stop.\n    chars = text.get(\"insert linestart\", \"insert\")\n    if chars == \"\":\n        if text.compare(\"insert\", \">\", \"1.0\"):\n            # easy: delete preceding newline\n            text.delete(\"insert-1c\")\n        else:\n            text.bell()  # at start of buffer\n        return \"break\"\n\n    if (\n        chars.strip() != \"\"\n    ):  # there are non-whitespace chars somewhere to the left of the cursor\n        # easy: delete preceding real char\n        text.delete(\"insert-1c\")\n        self._log_keypress_for_undo(event)\n        return \"break\"\n\n    # Ick.  It may require *inserting* spaces if we back up over a\n    # tab character!  This is written to be clear, not fast.\n    have = len(chars.expandtabs(self.tab_width))\n    assert have > 0\n    want = ((have - 1) // self.indent_width) * self.indent_width\n    # Debug prompt is multilined....\n    # if self.context_use_ps1:\n    #    last_line_of_prompt = sys.ps1.split('\\n')[-1]\n    # else:\n    last_line_of_prompt = \"\"\n    ncharsdeleted = 0\n    while 1:\n        if chars == last_line_of_prompt:\n            break\n        chars = chars[:-1]\n        ncharsdeleted = ncharsdeleted + 1\n        have = len(chars.expandtabs(self.tab_width))\n        if have <= want or chars[-1] not in \" \\t\":\n            break\n    text.delete(\"insert-%dc\" % ncharsdeleted, \"insert\")\n    if have < want:\n        text.insert(\"insert\", \" \" * (want - have))\n    return \"break\"", "loc": 51}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedText", "function_name": "perform_smart_tab", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["classifyws", "index2line", "len", "prefix.expandtabs", "self._log_keypress_for_undo", "self._reindent_to", "self.delete", "self.get", "self.get_selection_indices", "self.indent_region", "self.insert", "self.mark_set", "self.see", "self.should_indent_with_tabs"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_smart_tab(self, event=None):\n    self._log_keypress_for_undo(event)\n\n    # if intraline selection:\n    #     delete it\n    # elif multiline selection:\n    #     do indent-region\n    # else:\n    #     indent one level\n\n    first, last = self.get_selection_indices()\n    if first and last:\n        if index2line(first) != index2line(last):\n            return self.indent_region(event)\n        self.delete(first, last)\n        self.mark_set(\"insert\", first)\n    prefix = self.get(\"insert linestart\", \"insert\")\n    raw, effective = classifyws(prefix, self.tab_width)\n    if raw == len(prefix):\n        # only whitespace to the left\n        self._reindent_to(effective + self.indent_width)\n    else:\n        # tab to the next 'stop' within or to right of line's text:\n        if self.should_indent_with_tabs():\n            pad = \"\\t\"\n        else:\n            effective = len(prefix.expandtabs(self.tab_width))\n            n = self.indent_width\n            pad = \" \" * (n - effective % n)\n        self.insert(\"insert\", pad)\n    self.see(\"insert\")\n    return \"break\"", "loc": 32}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedText", "function_name": "perform_page_down", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["last_visible_idx.split", "logger.exception", "map", "self.get_line_count", "self.index", "self.mark_set", "self.winfo_height"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_page_down(self, event):\n    # if last line is visible then go to last line\n    # (by default it doesn't move then)\n    try:\n        last_visible_idx = self.index(\"@0,%d\" % self.winfo_height())\n        row, _ = map(int, last_visible_idx.split(\".\"))\n        line_count = self.get_line_count()\n\n        if row == line_count or row == line_count - 1:  # otherwise tk doesn't show last line\n            self.mark_set(\"insert\", \"end\")\n    except Exception as e:\n        logger.exception(\"Could not perform page down\", exc_info=e)", "loc": 12}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedText", "function_name": "perform_page_up", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["first_visible_idx.split", "logger.exception", "map", "self.index", "self.mark_set"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_page_up(self, event):\n    # if first line is visible then go there\n    # (by default it doesn't move then)\n    try:\n        first_visible_idx = self.index(\"@0,0\")\n        row, _ = map(int, first_visible_idx.split(\".\"))\n        if row == 1:\n            self.mark_set(\"insert\", \"1.0\")\n    except Exception as e:\n        logger.exception(\"Could not perform page up\", exc_info=e)", "loc": 10}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedText", "function_name": "compute_smart_home_destination_index", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "len", "range", "self.get", "self.index", "self.index('insert').split", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Is overridden in shell", "source_code": "def compute_smart_home_destination_index(self):\n    \"\"\"Is overridden in shell\"\"\"\n\n    line = self.get(\"insert linestart\", \"insert lineend\")\n    for insertpt in range(len(line)):\n        if line[insertpt] not in (\" \", \"\\t\"):\n            break\n    else:\n        insertpt = len(line)\n\n    lineat = int(self.index(\"insert\").split(\".\")[1])\n    if insertpt == lineat:\n        insertpt = 0\n    return \"insert linestart+\" + str(insertpt) + \"c\"", "loc": 14}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedText", "function_name": "perform_smart_home", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.compare", "self.compute_smart_home_destination_index", "self.index", "self.index_sel_first", "self.mark_set", "self.see", "self.tag_add", "self.tag_remove"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_smart_home(self, event):\n    if (event.state & 4) != 0 and event.keysym == \"Home\":\n        # state&4==Control. If <Control-Home>, use the Tk binding.\n        return None\n\n    dest = self.compute_smart_home_destination_index()\n\n    if (event.state & 1) == 0:\n        # shift was not pressed\n        self.tag_remove(\"sel\", \"1.0\", \"end\")\n    else:\n        if not self.index_sel_first():\n            # there was no previous selection\n            self.mark_set(\"my_anchor\", \"insert\")\n        else:\n            if self.compare(self.index_sel_first(), \"<\", self.index(\"insert\")):\n                self.mark_set(\"my_anchor\", \"sel.first\")  # extend back\n            else:\n                self.mark_set(\"my_anchor\", \"sel.last\")  # extend forward\n        first = self.index(dest)\n        last = self.index(\"my_anchor\")\n        if self.compare(first, \">\", last):\n            first, last = last, first\n        self.tag_remove(\"sel\", \"1.0\", \"end\")\n        self.tag_add(\"sel\", first, last)\n    self.mark_set(\"insert\", dest)\n    self.see(\"insert\")\n    return \"break\"", "loc": 28}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedText", "function_name": "move_to_edge_if_selection", "parameters": ["self", "edge_index"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.has_selection", "self.mark_set"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Cursor move begins at start or end of selection When a left/right cursor key is pressed create and return to Tkinter a function which causes a cursor move from the associated edge of the", "source_code": "def move_to_edge_if_selection(self, edge_index):\n    \"\"\"Cursor move begins at start or end of selection\n\n    When a left/right cursor key is pressed create and return to Tkinter a\n    function which causes a cursor move from the associated edge of the\n    selection.\n    \"\"\"\n\n    def move_at_edge(event):\n        if (\n            self.has_selection() and (event.state & 5) == 0\n        ):  # no shift(==1) or control(==4) pressed\n            try:\n                self.mark_set(\"insert\", (\"sel.first+1c\", \"sel.last-1c\")[edge_index])\n            except tk.TclError:\n                pass\n\n    return move_at_edge", "loc": 18}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedText", "function_name": "perform_tab", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["left_text.strip", "self._log_keypress_for_undo", "self.dedent_region", "self.get", "self.has_selection", "self.index", "self.perform_midline_tab", "self.perform_smart_tab"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_tab(self, event=None):\n    self._log_keypress_for_undo(event)\n    if event.state & 0x0001:  # shift is pressed (http://stackoverflow.com/q/32426250/261181)\n        return self.dedent_region(event)\n    else:\n        # check whether there are letters before cursor on this line\n        index = self.index(\"insert\")\n        left_text = self.get(index + \" linestart\", index)\n        if left_text.strip() == \"\" or self.has_selection():\n            return self.perform_smart_tab(event)\n        else:\n            return self.perform_midline_tab(event)", "loc": 12}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedText", "function_name": "set_read_only", "parameters": ["self", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TweakableText.set_read_only", "self._reload_theme_options", "self._tag_current_line", "self.is_read_only"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_read_only(self, value):\n    if value == self.is_read_only():\n        return\n\n    TweakableText.set_read_only(self, value)\n    self._reload_theme_options()\n    if self._should_tag_current_line:\n        self._tag_current_line()", "loc": 8}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedText", "function_name": "on_secondary_click", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.focus_set", "self.mark_set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Use this for invoking context menu", "source_code": "def on_secondary_click(self, event=None):\n    \"Use this for invoking context menu\"\n    self.focus_set()\n    if event:\n        self.mark_set(\"insert\", \"@%d,%d\" % (event.x, event.y))", "loc": 5}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "TextFrame", "function_name": "grid_main_widgets", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._hbar.grid", "self._vbar.grid", "self._vbar_stripe.grid", "self._vbar_stripe.tkraise", "self.text.grid"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def grid_main_widgets(self):\n    self.text.grid(row=0, column=1, sticky=tk.NSEW)\n    if self._vbar:\n        self._vbar.grid(\n            row=0, column=2, sticky=tk.NSEW, rowspan=self._vertical_scrollbar_rowspan\n        )\n        if self._vbar_stripe:\n            self._vbar_stripe.grid(row=0, column=2, sticky=\"nse\")\n            self._vbar_stripe.tkraise()\n    if self._hbar:\n        self._hbar.grid(row=1, column=0, sticky=tk.NSEW, columnspan=2)", "loc": 11}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedTextFrame", "function_name": "set_gutter_visibility", "parameters": ["self", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._gutter.grid", "self._gutter.grid_forget", "self.update_gutter"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_gutter_visibility(self, value):\n    if value and not self._gutter_is_gridded:\n        self._gutter.grid(row=0, column=0, sticky=tk.NSEW)\n        self._gutter_is_gridded = True\n    elif not value and self._gutter_is_gridded:\n        self._gutter.grid_forget()\n        self._gutter_is_gridded = False\n    else:\n        return\n\n    \"\"\"\n    # insert first line number (NB! Without trailing linebreak. See update_gutter)\n    self._gutter.config(state=\"normal\")\n    self._gutter.delete(\"1.0\", \"end\")\n    for content, tags in self.compute_gutter_line(self._first_line_number):\n        self._gutter.insert(\"end\", content, (\"content\",) + tags)\n    self._gutter.config(state=\"disabled\")\n    \"\"\"\n    self.update_gutter(True)", "loc": 19}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedTextFrame", "function_name": "update_gutter", "parameters": ["self", "clean"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "int", "line2index", "parts.append", "range", "self._gutter.config", "self._gutter.configure", "self._gutter.delete", "self._gutter.index", "self._gutter.index('end').split", "self._gutter.insert", "self._gutter.yview_moveto", "self._update_gutter_active_line", "self.compute_gutter_line", "self.text.index", "self.text.index('end').split", "self.text.yview"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_gutter(self, clean=False):\n    if clean:\n        self._gutter.config(state=\"normal\")\n        self._gutter.delete(\"1.0\", \"end\")\n        # need to add first item separately, because Text can't report 0 rows\n        for content, tags in self.compute_gutter_line(self._first_line_number):\n            self._gutter.insert(\"end-1c\", content, tags + (\"content\",))\n\n        self._gutter.config(state=\"disabled\")\n\n    text_line_count = int(self.text.index(\"end\").split(\".\")[0])\n    gutter_line_count = int(self._gutter.index(\"end\").split(\".\")[0])\n\n    if text_line_count != gutter_line_count:\n        self._gutter.config(state=\"normal\")\n\n        # NB! Text acts weird with last symbol\n        # (don't really understand whether it automatically keeps a newline there or not)\n        # Following seems to ensure both Text-s have same height\n        if text_line_count > gutter_line_count:\n            delta = text_line_count - gutter_line_count\n            start = gutter_line_count + self._first_line_number - 1\n\n            if not clean and text_line_count > 10 and gutter_line_count < 3:\n                # probably initial load, do bulk insert\n                parts = []\n                for i in range(start, start + delta):\n                    parts.append(\"\\n\")\n                    for content, tags in self.compute_gutter_line(i, plain=True):\n                        parts.append(content)\n\n                self._gutter.insert(\"end-1c\", \"\".join(parts), (\"content\",) + tags)\n            else:\n                for i in range(start, start + delta):\n                    self._gutter.insert(\"end-1c\", \"\\n\", (\"content\",))\n                    for content, tags in self.compute_gutter_line(i):\n                        self._gutter.insert(\"end-1c\", content, (\"content\",) + tags)\n        else:\n            self._gutter.delete(line2index(text_line_count) + \"-1c\", \"end-1c\")\n\n        self._gutter.config(state=\"disabled\")\n\n    # synchronize gutter scroll position with text\n    # https://mail.python.org/pipermail/tkinter-discuss/2010-March/002197.html\n    first, _ = self.text.yview()\n    self._gutter.yview_moveto(first)\n    self._update_gutter_active_line()\n\n    if text_line_count > 9998:\n        self._gutter.configure(width=7)\n    elif text_line_count > 998:\n        self._gutter.configure(width=6)", "loc": 52}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedTextFrame", "function_name": "update_margin_line", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["first_visible_idx.split", "get_text_font", "get_text_font(self.text).measure", "int", "logger.exception", "self._margin_line.place", "self._margin_line.place_forget", "self.text.bbox", "self.text.index", "self.text.update_idletasks"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_margin_line(self):\n    if self._recommended_line_length == 0:\n        self._margin_line.place_forget()\n    else:\n        try:\n            self.text.update_idletasks()\n            # How far left has text been scrolled\n            first_visible_idx = self.text.index(\"@0,0\")\n            first_visible_col = int(first_visible_idx.split(\".\")[1])\n            bbox = self.text.bbox(first_visible_idx)\n            first_visible_col_x = bbox[0]\n\n            margin_line_visible_col = self._recommended_line_length - first_visible_col\n            delta = first_visible_col_x\n        except Exception:\n            # fall back to ignoring scroll position\n            margin_line_visible_col = self._recommended_line_length\n            delta = 0\n\n        if margin_line_visible_col > -1:\n            try:\n                x = (\n                    get_text_font(self.text).measure((margin_line_visible_col - 1) * \"M\")\n                    + delta\n                    + self.text[\"padx\"]\n                )\n            except TclError:\n                logger.exception(\"Could not measure text\")\n                x = -10\n        else:\n            x = -10\n\n        # print(first_visible_col, first_visible_col_x)\n\n        self._margin_line.place(y=-10, x=x)", "loc": 35}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedTextFrame", "function_name": "on_gutter_click", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.exception", "self._gutter.index", "self._gutter.index('@%s,%s' % (event.x, event.y)).split", "self._gutter.mark_set", "self.text.mark_set", "self.text.tag_remove"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_gutter_click(self, event=None):\n    try:\n        linepos = self._gutter.index(\"@%s,%s\" % (event.x, event.y)).split(\".\")[0]\n        self.text.mark_set(\"insert\", \"%s.0\" % linepos)\n        self._gutter.mark_set(\"gutter_selection_start\", \"%s.0\" % linepos)\n        if (\n            event.type == \"4\"\n        ):  # In Python 3.6 you can use tk.EventType.ButtonPress instead of \"4\"\n            self.text.tag_remove(\"sel\", \"1.0\", \"end\")\n    except tk.TclError:\n        logger.exception(\"on_gutter_click\")", "loc": 11}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedTextFrame", "function_name": "on_gutter_double_click", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.exception", "self._gutter.mark_unset", "self._gutter.tag_remove", "self.text.tag_remove"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_gutter_double_click(self, event=None):\n    try:\n        self._gutter.mark_unset(\"gutter_selection_start\")\n        self.text.tag_remove(\"sel\", \"1.0\", \"end\")\n        self._gutter.tag_remove(\"sel\", \"1.0\", \"end\")\n    except tk.TclError:\n        logger.exception(\"on_gutter_click\")", "loc": 7}
{"file": "thonny\\thonny\\tktextext.py", "class_name": "EnhancedTextFrame", "function_name": "on_gutter_motion", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "logger.exception", "max", "min", "self._gutter.index", "self._gutter.index('@%s,%s' % (event.x, event.y)).split", "self._gutter.index('gutter_selection_start').split", "self._gutter.mark_names", "self.text.focus_set", "self.text.mark_set", "self.text.select_lines"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_gutter_motion(self, event=None):\n    try:\n        if \"gutter_selection_start\" not in self._gutter.mark_names():\n            return\n        linepos = int(self._gutter.index(\"@%s,%s\" % (event.x, event.y)).split(\".\")[0])\n        gutter_selection_start = int(self._gutter.index(\"gutter_selection_start\").split(\".\")[0])\n        self.text.select_lines(\n            min(gutter_selection_start, linepos), max(gutter_selection_start - 1, linepos - 1)\n        )\n        self.text.mark_set(\"insert\", \"%s.0\" % linepos)\n        self.text.focus_set()\n    except tk.TclError:\n        logger.exception(\"on_gutter_motion\")", "loc": 13}
{"file": "thonny\\thonny\\tktextext.py", "class_name": null, "function_name": "control_a", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "widget.tag_add", "widget.tag_remove"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def control_a(event):\n    widget = event.widget\n    if isinstance(widget, tk.Text):\n        widget.tag_remove(\"sel\", \"1.0\", \"end\")\n        widget.tag_add(\"sel\", \"1.0\", \"end\")", "loc": 5}
{"file": "thonny\\thonny\\tktextext.py", "class_name": null, "function_name": "if_not_readonly", "parameters": ["fun"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fun", "self.is_read_only"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def if_not_readonly(fun):\n    def dispatch(event):\n        if not self.is_read_only():\n            return fun(event)\n        else:\n            return \"break\"\n\n    return dispatch", "loc": 8}
{"file": "thonny\\thonny\\tktextext.py", "class_name": null, "function_name": "move_at_edge", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.has_selection", "self.mark_set"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def move_at_edge(event):\n    if (\n        self.has_selection() and (event.state & 5) == 0\n    ):  # no shift(==1) or control(==4) pressed\n        try:\n            self.mark_set(\"insert\", (\"sel.first+1c\", \"sel.last-1c\")[edge_index])\n        except tk.TclError:\n            pass", "loc": 8}
{"file": "thonny\\thonny\\tktextext.py", "class_name": null, "function_name": "dispatch", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fun", "self.is_read_only"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dispatch(event):\n    if not self.is_read_only():\n        return fun(event)\n    else:\n        return \"break\"", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "ask_string", "parameters": ["title", "prompt", "initial_value", "options", "entry_width", "master"], "param_types": {"title": "str", "prompt": "str", "initial_value": "str", "options": "List[str]", "entry_width": "Optional[int]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["QueryDialog", "dlg.get_result", "show_dialog"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ask_string(\n    title: str,\n    prompt: str,\n    initial_value: str = \"\",\n    options: List[str] = [],\n    entry_width: Optional[int] = None,\n    master=None,\n):\n    dlg = QueryDialog(\n        master, title, prompt, initial_value=initial_value, options=options, entry_width=entry_width\n    )\n    show_dialog(dlg, master)\n    return dlg.get_result()", "loc": 13}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "sequence_to_accelerator", "parameters": ["sequence"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'+'.join", "accelerator.replace", "accelerator.replace('Minus', '-').replace", "accelerator.replace('Minus', '-').replace('minus', '-').replace", "accelerator.replace('Minus', '-').replace('minus', '-').replace('Plus', '+').replace", "accelerator.replace('Minus', '-').replace('minus', '-').replace('Plus', '+').replace('plus', '+').replace", "accelerator.split", "len", "parts.insert", "parts[-1].isupper", "parts[-1].upper", "sequence.startswith", "sequence.strip", "sequence.strip('<>').replace", "sequence.strip('<>').replace('Key-', '').replace", "sequence.strip('<>').replace('Key-', '').replace('KeyPress-', '').replace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Translates Tk event sequence to customary shortcut string for showing in the menu", "source_code": "def sequence_to_accelerator(sequence):\n    \"\"\"Translates Tk event sequence to customary shortcut string\n    for showing in the menu\"\"\"\n\n    if not sequence:\n        return \"\"\n\n    if not sequence.startswith(\"<\"):\n        return sequence\n\n    accelerator = (\n        sequence.strip(\"<>\").replace(\"Key-\", \"\").replace(\"KeyPress-\", \"\").replace(\"Control\", \"Ctrl\")\n    )\n\n    # Tweaking individual parts\n    parts = accelerator.split(\"-\")\n    # tkinter shows shift with capital letter, but in shortcuts it's customary to include it explicitly\n    if len(parts[-1]) == 1 and parts[-1].isupper() and not \"Shift\" in parts:\n        parts.insert(-1, \"Shift\")\n\n    # even when shift is not required, it's customary to show shortcut with capital letter\n    if len(parts[-1]) == 1:\n        parts[-1] = parts[-1].upper()\n\n    accelerator = \"+\".join(parts)\n\n    # Post processing\n    accelerator = (\n        accelerator.replace(\"Minus\", \"-\")\n        .replace(\"minus\", \"-\")\n        .replace(\"Plus\", \"+\")\n        .replace(\"plus\", \"+\")\n        .replace(\"space\", \"Space\")\n    )\n\n    return accelerator", "loc": 36}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "get_zoomed", "parameters": ["toplevel"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bool", "toplevel.wm_attributes", "toplevel.wm_state"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_zoomed(toplevel):\n    if \"-zoomed\" in toplevel.wm_attributes():  # Linux\n        return bool(toplevel.wm_attributes(\"-zoomed\"))\n    else:  # Win/Mac\n        return toplevel.wm_state() == \"zoomed\"", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "set_zoomed", "parameters": ["toplevel", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "str", "toplevel.wm_attributes", "toplevel.wm_state"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_zoomed(toplevel, value):\n    if \"-zoomed\" in toplevel.wm_attributes():  # Linux\n        toplevel.wm_attributes(\"-zoomed\", str(int(value)))\n    else:  # Win/Mac\n        if value:\n            toplevel.wm_state(\"zoomed\")\n        else:\n            toplevel.wm_state(\"normal\")", "loc": 8}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "update_entry_text", "parameters": ["entry", "text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["entry.cget", "entry.config", "entry.delete", "entry.insert"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_entry_text(entry, text):\n    original_state = entry.cget(\"state\")\n    entry.config(state=\"normal\")\n    entry.delete(0, \"end\")\n    entry.insert(0, text)\n    entry.config(state=original_state)", "loc": 6}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "create_tooltip", "parameters": ["widget", "text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ToolTip", "get_style_configuration", "get_style_configuration('Tooltip').copy", "options.setdefault", "options.update", "toolTip.hidetip", "toolTip.showtip", "widget.bind"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_tooltip(widget, text, **kw):\n    options = get_style_configuration(\"Tooltip\").copy()\n    options.setdefault(\"background\", \"#ffffe0\")\n    options.setdefault(\"foreground\", \"#000000\")\n    options.setdefault(\"relief\", \"solid\")\n    options.setdefault(\"borderwidth\", 1)\n    options.setdefault(\"padx\", 1)\n    options.setdefault(\"pady\", 0)\n    options.update(kw)\n\n    toolTip = ToolTip(widget, options)\n\n    def enter(event):\n        toolTip.showtip(text)\n\n    def leave(event):\n        toolTip.hidetip()\n\n    widget.bind(\"<Enter>\", enter, True)\n    widget.bind(\"<Leave>\", leave, True)", "loc": 20}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "get_widget_offset_from_toplevel", "parameters": ["widget"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["widget.winfo_toplevel", "widget.winfo_x", "widget.winfo_y"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_widget_offset_from_toplevel(widget):\n    x = 0\n    y = 0\n    toplevel = widget.winfo_toplevel()\n    while widget != toplevel:\n        x += widget.winfo_x()\n        y += widget.winfo_y()\n        widget = widget.master\n    return x, y", "loc": 9}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "alt_is_pressed_without_char", "parameters": ["event"], "param_types": {"event": "tk.Event"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["running_on_mac_os", "running_on_windows"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def alt_is_pressed_without_char(event: tk.Event) -> bool:\n    # https://tkdocs.com/shipman/event-handlers.html\n    # http://stackoverflow.com/q/32426250/261181\n    # https://bugs.python.org/msg268429\n    if event.char:\n        return False\n\n    if running_on_windows():\n        return event.state & 0x20000\n    elif running_on_mac_os():\n        # combinations always produce a char or are consumed by the OS\n        return False\n    else:\n        return event.state & 0x0010", "loc": 14}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "command_is_pressed", "parameters": ["event"], "param_types": {"event": "tk.Event"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["running_on_mac_os"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def command_is_pressed(event: tk.Event) -> bool:\n    # https://tkdocs.com/shipman/event-handlers.html\n    # http://stackoverflow.com/q/32426250/261181\n    if not running_on_mac_os():\n        return False\n    return event.state & 0x0008", "loc": 6}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "get_hyperlink_cursor", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["running_on_mac_os"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_hyperlink_cursor() -> str:\n    if running_on_mac_os():\n        return \"pointinghand\"\n    else:\n        return \"hand2\"", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "get_beam_cursor", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["running_on_mac_os", "running_on_windows"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_beam_cursor() -> str:\n    if running_on_mac_os() or running_on_windows():\n        return \"ibeam\"\n    else:\n        return \"xterm\"", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "sequence_to_event_state_and_keycode", "parameters": ["sequence"], "param_types": {"sequence": "str"}, "return_type": "Optional[Tuple[int, int]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["letter.isupper", "letter.upper", "list", "modifiers.add", "ord", "part.lower", "parts.pop", "parts.remove", "parts[-1].lower", "sequence.strip", "sequence.strip('<').strip", "sequence.strip('<').strip('>').split"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def sequence_to_event_state_and_keycode(sequence: str) -> Optional[Tuple[int, int]]:\n    # remember handlers for certain shortcuts which require\n    # different treatment on non-latin keyboards\n    if sequence[0] != \"<\":\n        return None\n\n    parts = sequence.strip(\"<\").strip(\">\").split(\"-\")\n    # support only latin letters for now\n    if parts[-1].lower() not in list(\"abcdefghijklmnopqrstuvwxyz\"):\n        return None\n\n    letter = parts.pop(-1)\n    if \"Key\" in parts:\n        parts.remove(\"Key\")\n    if \"key\" in parts:\n        parts.remove(\"key\")\n\n    modifiers = {part.lower() for part in parts}\n\n    if letter.isupper():\n        modifiers.add(\"shift\")\n\n    if modifiers not in [{\"control\"}, {\"control\", \"shift\"}]:\n        # don't support others for now\n        return None\n\n    event_state = 0\n    # https://tkdocs.com/shipman/event-handlers.html\n    # https://stackoverflow.com/questions/32426250/python-documentation-and-or-lack-thereof-e-g-keyboard-event-state\n    for modifier in modifiers:\n        if modifier == \"shift\":\n            event_state |= 0x0001\n        elif modifier == \"control\":\n            event_state |= 0x0004\n        else:\n            # unsupported modifier\n            return None\n\n    # for latin letters keycode is same as its ascii code\n    return (event_state, ord(letter.upper()))", "loc": 40}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "select_sequence", "parameters": ["win_version", "mac_version", "linux_version"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["running_on_linux", "running_on_mac_os", "running_on_windows"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_sequence(win_version, mac_version, linux_version=None):\n    if running_on_windows():\n        return win_version\n    elif running_on_mac_os():\n        return mac_version\n    elif running_on_linux() and linux_version:\n        return linux_version\n    else:\n        return win_version", "loc": 9}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "try_remove_linenumbers", "parameters": ["text", "master"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["has_line_numbers", "messagebox.askyesno", "remove_line_numbers", "traceback.print_exc"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def try_remove_linenumbers(text, master):\n    try:\n        if has_line_numbers(text) and messagebox.askyesno(\n            title=\"Remove linenumbers\",\n            message=\"Do you want to remove linenumbers from pasted text?\",\n            default=messagebox.YES,\n            master=master,\n        ):\n            return remove_line_numbers(text)\n        else:\n            return text\n    except Exception:\n        traceback.print_exc()\n        return text", "loc": 14}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "split_after_line_number", "parameters": ["s"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "re.split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def split_after_line_number(s):\n    parts = re.split(r\"(^\\s*\\d+\\.?)\", s)\n    if len(parts) == 1:\n        return parts\n    else:\n        assert len(parts) == 3 and parts[0] == \"\"\n        return parts[1:]", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "remove_line_numbers", "parameters": ["s"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "cleaned_lines.append", "len", "s.splitlines", "split_after_line_number", "textwrap.dedent"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_line_numbers(s):\n    cleaned_lines = []\n    for line in s.splitlines():\n        parts = split_after_line_number(line)\n        if len(parts) != 2:\n            return s\n        else:\n            cleaned_lines.append(parts[1])\n\n    return textwrap.dedent((\"\\n\".join(cleaned_lines)) + \"\\n\")", "loc": 10}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "run_with_waiting_dialog", "parameters": ["master", "action", "args", "description"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ThreadPool", "WaitingDialog", "async_result.get", "pool.apply_async", "show_dialog"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run_with_waiting_dialog(master, action, args=(), description=\"Working\"):\n    # http://stackoverflow.com/a/14299004/261181\n    from multiprocessing.pool import ThreadPool\n\n    pool = ThreadPool(processes=1)\n\n    async_result = pool.apply_async(action, args)\n    dlg = WaitingDialog(master, async_result, description=description)\n    show_dialog(dlg, master)\n\n    return async_result.get()", "loc": 11}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "ask_one_from_choices", "parameters": ["master", "title", "question", "choices", "initial_choice_index"], "param_types": {"question": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChoiceDialog", "show_dialog"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ask_one_from_choices(\n    master=None,\n    title=\"Choose one\",\n    question: str = \"Choose one:\",\n    choices=[],\n    initial_choice_index=None,\n):\n    dlg = ChoiceDialog(master, title, question, choices, initial_choice_index)\n    show_dialog(dlg, master)\n    return dlg.result", "loc": 10}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "get_busy_cursor", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["running_on_mac_os", "running_on_windows"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_busy_cursor():\n    if running_on_windows():\n        return \"wait\"\n    elif running_on_mac_os():\n        return \"spinning\"\n    else:\n        return \"watch\"", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "get_tk_version_info", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_tk_version_str", "get_tk_version_str().split", "int", "result.append", "tuple"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_tk_version_info():\n    result = []\n    for part in get_tk_version_str().split(\".\"):\n        try:\n            result.append(int(part))\n        except Exception:\n            result.append(0)\n    return tuple(result)", "loc": 8}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "get_style_configuration", "parameters": ["style_name", "default"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["style.configure", "ttk.Style"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_style_configuration(style_name, default={}):\n    style = ttk.Style()\n    # NB! style.configure seems to reuse the returned dict\n    # Don't change it without copying first\n    result = style.configure(style_name)\n    if result is None:\n        return default\n    else:\n        return result", "loc": 9}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "lookup_style_option", "parameters": ["style_name", "option_name", "default"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["style.lookup", "ttk.Style"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def lookup_style_option(style_name, option_name, default=None):\n    style = ttk.Style()\n    setting = style.lookup(style_name, option_name)\n    if setting in [None, \"\"]:\n        return default\n    elif setting == \"True\":\n        return True\n    elif setting == \"False\":\n        return False\n    else:\n        return setting", "loc": 11}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "try_restore_focus_after_file_dialog", "parameters": ["dialog_parent"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dialog_parent.winfo_toplevel", "dialog_parent.winfo_toplevel().focus_force", "dialog_parent.winfo_toplevel().focus_get", "dialog_parent.winfo_toplevel().grab_release", "dialog_parent.winfo_toplevel().grab_set", "dialog_parent.winfo_toplevel().lift", "logger.info", "logger.warning", "old_focused_widget.focus_force", "running_on_mac_os"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def try_restore_focus_after_file_dialog(dialog_parent):\n    if dialog_parent is None:\n        return\n\n    logger.info(\"Restoring focus to %s\", dialog_parent)\n    old_focused_widget = dialog_parent.winfo_toplevel().focus_get()\n\n    dialog_parent.winfo_toplevel().lift()\n    dialog_parent.winfo_toplevel().focus_force()\n    dialog_parent.winfo_toplevel().grab_set()\n    if running_on_mac_os():\n        dialog_parent.winfo_toplevel().grab_release()\n\n    if old_focused_widget is not None:\n        try:\n            old_focused_widget.focus_force()\n        except TclError:\n            logger.warning(\"Could not restore focus to %r\", old_focused_widget)", "loc": 18}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "askdirectory", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_check_dialog_parent", "_get_dialog_provider", "_get_dialog_provider().askdirectory", "try_restore_focus_after_file_dialog"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def askdirectory(**options):\n    # https://tcl.tk/man/tcl8.6/TkCmd/chooseDirectory.htm\n    parent = _check_dialog_parent(options)\n    try:\n        return _get_dialog_provider().askdirectory(**options)\n    finally:\n        try_restore_focus_after_file_dialog(parent)", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "register_latin_shortcut", "parameters": ["registry", "sequence", "handler", "tester"], "param_types": {"sequence": "str", "handler": "Callable", "tester": "Optional[Callable]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["registry[res].append", "sequence_to_event_state_and_keycode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def register_latin_shortcut(\n    registry, sequence: str, handler: Callable, tester: Optional[Callable]\n) -> None:\n    res = sequence_to_event_state_and_keycode(sequence)\n    if res is not None:\n        if res not in registry:\n            registry[res] = []\n        registry[res].append((handler, tester))", "loc": 8}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "handle_mistreated_latin_shortcuts", "parameters": ["registry", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["handler", "ord", "running_on_mac_os", "shift_is_pressed", "tester"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_mistreated_latin_shortcuts(registry, event):\n    # tries to handle Ctrl+LatinLetter shortcuts\n    # given from non-Latin keyboards\n    # See: https://bitbucket.org/plas/thonny/issues/422/edit-keyboard-shortcuts-ctrl-c-ctrl-v-etc\n\n    # only consider events with Control held\n    if not event.state & 0x04:\n        return\n\n    if running_on_mac_os():\n        return\n\n    # consider only part of the state,\n    # because at least on Windows, Ctrl-shortcuts' state\n    # has something extra\n    simplified_state = 0x04\n    if shift_is_pressed(event):\n        simplified_state |= 0x01\n\n    # print(simplified_state, event.keycode)\n    if (simplified_state, event.keycode) in registry:\n        if event.keycode != ord(event.char) and event.keysym in (None, \"??\"):\n            # keycode and char doesn't match,\n            # this means non-latin keyboard\n            for handler, tester in registry[(simplified_state, event.keycode)]:\n                if tester is None or tester():\n                    handler()", "loc": 27}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "show_dialog", "parameters": ["dlg", "master", "width", "height", "left", "top", "modal", "transient"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_place_window", "dlg.focus_set", "dlg.grab_release", "dlg.grab_set", "dlg.lift", "dlg.set_initial_focus", "dlg.transient", "dlg.update_idletasks", "dlg.wait_visibility", "dlg.wait_window", "ems_to_pixels", "get_size_option_name", "get_workbench", "get_workbench().event_generate", "get_workbench().get_option", "getattr", "hasattr", "logger.warning", "master.focus_get", "master.winfo_toplevel", "master.winfo_toplevel().focus_force", "master.winfo_toplevel().grab_release", "master.winfo_toplevel().grab_set", "master.winfo_toplevel().lift", "master.winfo_toplevel().winfo_viewable", "max", "min", "old_focused_widget.focus_force", "running_on_mac_os", "str"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_dialog(\n    dlg, master=None, width=None, height=None, left=None, top=None, modal=True, transient=True\n):\n    if getattr(dlg, \"closed\", False):\n        return\n\n    if master is None:\n        master = getattr(dlg, \"parent\", None) or getattr(dlg, \"master\", None) or tk._default_root\n\n    master = master.winfo_toplevel()\n\n    get_workbench().event_generate(\"WindowFocusOut\")\n    # following order seems to give most smooth appearance\n    old_focused_widget = master.focus_get()\n    if transient and master.winfo_toplevel().winfo_viewable():\n        dlg.transient(master.winfo_toplevel())\n\n    saved_size = get_workbench().get_option(get_size_option_name(dlg))\n    if saved_size:\n        width = min(max(saved_size[0], ems_to_pixels(10)), ems_to_pixels(500))\n        height = min(max(saved_size[1], ems_to_pixels(8)), ems_to_pixels(300))\n\n    _place_window(dlg, master, width=width, height=height)\n\n    dlg.lift()\n    try:\n        dlg.wait_visibility()\n    except tk.TclError as e:\n        if \"was deleted before its visibility changed\" in str(e):\n            return\n        else:\n            raise\n\n    if modal:\n        try:\n            dlg.grab_set()\n        except TclError as e:\n            logger.warning(\"Can't grab: %s\", e)\n\n    dlg.update_idletasks()\n    dlg.focus_set()\n    if hasattr(dlg, \"set_initial_focus\"):\n        dlg.set_initial_focus()\n\n    if modal:\n        dlg.wait_window(dlg)\n        dlg.grab_release()\n        master.winfo_toplevel().lift()\n        master.winfo_toplevel().focus_force()\n        master.winfo_toplevel().grab_set()\n        if running_on_mac_os():\n            master.winfo_toplevel().grab_release()\n\n        if old_focused_widget is not None:\n            try:\n                old_focused_widget.focus_force()\n            except TclError:\n                pass", "loc": 58}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "create_action_label", "parameters": ["master", "text", "click_handler"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_hyperlink_cursor", "tkinter.font.nametofont", "tkinter.font.nametofont('TkDefaultFont').copy", "ttk.Label", "url_font.configure", "url_label.bind"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_action_label(master, text, click_handler, **kw):\n    url_font = tkinter.font.nametofont(\"TkDefaultFont\").copy()\n    url_font.configure(underline=1)\n    url_label = ttk.Label(\n        master, text=text, style=\"Url.TLabel\", cursor=get_hyperlink_cursor(), font=url_font, **kw\n    )\n    url_label.bind(\"<Button-1>\", click_handler)\n    return url_label", "loc": 8}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "get_default_basic_theme", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["running_on_mac_os", "running_on_windows"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_default_basic_theme():\n    if running_on_windows():\n        return \"vista\"\n    elif running_on_mac_os():\n        return \"aqua\"\n    else:\n        return \"clam\"", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "ems_to_pixels", "parameters": ["x"], "param_types": {"x": "float"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "tkinter.font.nametofont", "tkinter.font.nametofont('TkDefaultFont').measure"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ems_to_pixels(x: float) -> int:\n    global EM_WIDTH\n    if EM_WIDTH is None:\n        EM_WIDTH = tkinter.font.nametofont(\"TkDefaultFont\").measure(\"m\")\n    return int(EM_WIDTH * x)", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "pixels_to_ems", "parameters": ["x"], "param_types": {"x": "int"}, "return_type": "float", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["tkinter.font.nametofont", "tkinter.font.nametofont('TkDefaultFont').measure"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def pixels_to_ems(x: int) -> float:\n    global EM_WIDTH\n    if EM_WIDTH is None:\n        EM_WIDTH = tkinter.font.nametofont(\"TkDefaultFont\").measure(\"m\")\n    return x / EM_WIDTH", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "set_text_if_different", "parameters": ["widget", "text"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_text_if_different(widget, text) -> bool:\n    if widget[\"text\"] != text:\n        widget[\"text\"] = text\n        return True\n    else:\n        return False", "loc": 6}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "tr_btn", "parameters": ["s"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_button_padding", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Translates button caption, adds padding to make sure text fits", "source_code": "def tr_btn(s):\n    \"\"\"Translates button caption, adds padding to make sure text fits\"\"\"\n    global _btn_padding\n    if _btn_padding is None:\n        _btn_padding = get_button_padding()\n\n    return _btn_padding + tr(s) + _btn_padding", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "add_messagebox_parent_checker", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_check_dialog_parent", "getattr", "original", "setattr", "wrap_with_parent_checker"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_messagebox_parent_checker():\n    def wrap_with_parent_checker(original):\n        def wrapper(*args, **options):\n            _check_dialog_parent(options)\n            return original(*args, **options)\n\n        return wrapper\n\n    from tkinter import messagebox\n\n    for name in [\n        \"showinfo\",\n        \"showwarning\",\n        \"showerror\",\n        \"askquestion\",\n        \"askokcancel\",\n        \"askyesno\",\n        \"askyesnocancel\",\n        \"askretrycancel\",\n    ]:\n        fun = getattr(messagebox, name)\n        setattr(messagebox, name, wrap_with_parent_checker(fun))", "loc": 22}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "replace_unsupported_chars", "parameters": ["text"], "param_types": {"text": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "get_tk_version_info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def replace_unsupported_chars(text: str) -> str:\n    if get_tk_version_info() < (8, 6, 12):\n        # can crash with emojis\n        return \"\".join(c if c < \"\\U00010000\" else \"\" for c in text)\n    else:\n        return text", "loc": 6}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "windows_known_extensions_are_hidden", "parameters": [], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["reg_key.Close", "running_on_windows", "winreg.OpenKey", "winreg.QueryValueEx"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def windows_known_extensions_are_hidden() -> bool:\n    assert running_on_windows()\n    import winreg\n\n    reg_key = winreg.OpenKey(\n        winreg.HKEY_CURRENT_USER,\n        r\"SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Advanced\",\n        0,\n        winreg.KEY_READ,\n    )\n    try:\n        return winreg.QueryValueEx(reg_key, \"HideFileExt\")[0] == 1\n    finally:\n        reg_key.Close()", "loc": 14}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "os_is_in_dark_mode", "parameters": [], "param_types": {}, "return_type": "Optional[bool]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bool", "int", "logger.exception", "running_on_mac_os", "tk._default_root.eval"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def os_is_in_dark_mode() -> Optional[bool]:\n    if running_on_mac_os():\n        try:\n            return bool(\n                int(\n                    tk._default_root.eval(\n                        f\"tk::unsupported::MacWindowStyle isdark {tk._default_root}\"\n                    )\n                )\n            )\n        except Exception:\n            logger.exception(\"Could not query for dark mode\")\n            return None\n\n    return None", "loc": 15}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "check_create_aqua_scrollbar_stripe", "parameters": ["master"], "param_types": {}, "return_type": "Optional[tk.Frame]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ScrollbarStripe", "lookup_style_option"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_create_aqua_scrollbar_stripe(master) -> Optional[tk.Frame]:\n    stripe_width = lookup_style_option(\"Vertical.TScrollbar\", \"rightmost_pixels_to_hide\", 0)\n    if stripe_width > 0:\n        return ScrollbarStripe(master, stripe_width)\n    else:\n        return None", "loc": 6}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "check_create_heading_stripe", "parameters": ["master"], "param_types": {}, "return_type": "Optional[tk.Frame]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["HeadingStripe", "get_style_configuration", "int", "isinstance", "len", "opts.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_create_heading_stripe(master) -> Optional[tk.Frame]:\n    opts = get_style_configuration(\"Heading\")\n    px_to_hide = opts.get(\"topmost_pixels_to_hide\", 0)\n    if isinstance(px_to_hide, list):\n        # don't know why it happens sometimes\n        assert len(px_to_hide) == 1\n        px_to_hide = px_to_hide[0]\n    elif isinstance(px_to_hide, str):\n        px_to_hide = int(px_to_hide)\n    background = opts.get(\"background\")\n    if px_to_hide > 0 and background is not None:\n        return HeadingStripe(master, height=px_to_hide, background=background)\n    else:\n        return None", "loc": 14}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "open_with_default_app", "parameters": ["path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["os.startfile", "running_on_mac_os", "running_on_windows", "subprocess.run"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def open_with_default_app(path):\n    if running_on_windows():\n        os.startfile(path)\n    elif running_on_mac_os():\n        subprocess.run([\"open\", path])\n    else:\n        subprocess.run([\"xdg-open\", path])", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "compute_tab_stops", "parameters": ["tab_width_in_chars", "font", "offset_px"], "param_types": {"tab_width_in_chars": "int", "font": "tk.font.Font"}, "return_type": "List[int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["font.measure", "range", "tabs.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def compute_tab_stops(tab_width_in_chars: int, font: tk.font.Font, offset_px=0) -> List[int]:\n    tab_pixels = font.measure(\"n\" * tab_width_in_chars)\n\n    tabs = []\n    if offset_px > 0:\n        tabs.append(offset_px)\n\n    for _ in range(20):\n        offset_px += tab_pixels\n        tabs.append(offset_px)\n\n    return tabs", "loc": 12}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "create_custom_toolbutton_in_frame", "parameters": ["master", "borderwidth", "bordercolor"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CustomToolbutton", "frame.button.grid", "tk.Frame"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_custom_toolbutton_in_frame(master, borderwidth, bordercolor, **kwargs):\n    frame = tk.Frame(master, background=bordercolor)\n    frame.button = CustomToolbutton(frame, **kwargs)\n    frame.button.grid(pady=borderwidth, padx=borderwidth)\n    return frame", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "set_windows_titlebar_darkness", "parameters": ["window", "value"], "param_types": {"window": "tk.Tk", "value": "int"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ctypes.byref", "ctypes.c_int", "ctypes.sizeof", "ctypes.windll.dwmapi.DwmSetWindowAttribute", "ctypes.windll.user32.GetParent", "print", "window.update", "window.winfo_id"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_windows_titlebar_darkness(window: tk.Tk, value: int):\n    import ctypes\n\n    window.update()\n    winfo_id = window.winfo_id()\n    hwnd = ctypes.windll.user32.GetParent(winfo_id)\n    DWMWA_USE_IMMERSIVE_DARK_MODE = 20\n    DWMWA_USE_IMMERSIVE_DARK_MODE_BEFORE_20H1 = 19\n\n    # try with DWMWA_USE_IMMERSIVE_DARK_MODE\n    result = ctypes.windll.dwmapi.DwmSetWindowAttribute(\n        hwnd,\n        DWMWA_USE_IMMERSIVE_DARK_MODE,\n        ctypes.byref(ctypes.c_int(value)),\n        ctypes.sizeof(ctypes.c_int(value)),\n    )\n    if result != 0:\n        result = ctypes.windll.dwmapi.DwmSetWindowAttribute(\n            hwnd,\n            DWMWA_USE_IMMERSIVE_DARK_MODE_BEFORE_20H1,\n            ctypes.byref(ctypes.c_int(value)),\n            ctypes.sizeof(ctypes.c_int(value)),\n        )\n        print(\"got with second\", result)\n    else:\n        print(\"got with first\", result)", "loc": 26}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "update_text_height", "parameters": ["text", "min_lines", "max_lines"], "param_types": {"text": "tk.Text", "min_lines": "int", "max_lines": "int"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.info", "max", "min", "text.configure", "text.tk.call", "text.winfo_width"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_text_height(text: tk.Text, min_lines: int, max_lines: int) -> None:\n    if text.winfo_width() < 10:\n        logger.info(\"Skipping text height update because width is %s\", text.winfo_width())\n        return\n    required_height = text.tk.call((text, \"count\", \"-update\", \"-displaylines\", \"1.0\", \"end\"))\n    text.configure(height=min(max(required_height, min_lines), max_lines))", "loc": 6}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "CustomToolbutton", "function_name": "cget", "parameters": ["self", "key"], "param_types": {"key": "str"}, "return_type": "Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.label.cget", "super", "super().cget"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cget(self, key: str) -> Any:\n    if key in [\"text\", \"image\"]:\n        return self.label.cget(key)\n    else:\n        return super().cget(key)", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "CustomToolbutton", "function_name": "configure", "parameters": ["self", "cnf", "state", "image", "command", "background"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cnf.get", "self.label.configure", "super", "super().configure"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def configure(self, cnf={}, state=None, image=None, command=None, background=None, **kw):\n    if command:\n        self.command = command\n\n    if \"state\" in cnf and not state:\n        state = cnf.get(\"state\")\n    elif not state:\n        state = \"normal\"\n\n    self.state = state\n    if image:\n        self.current_image = image\n    elif self.state == \"disabled\":\n        self.current_image = self.disabled_image\n    else:\n        self.current_image = self.normal_image\n\n    super().configure(background=background)\n    # tkinter.Frame should be always state=normal as it won't display the image if \"disabled\"\n    # at least on mac with Tk 8.6.13\n    self.label.configure(\n        cnf, image=self.current_image, state=\"normal\", background=background, **kw\n    )", "loc": 23}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "CustomToolbutton", "function_name": "prepare_style_options", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_style_configuration"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def prepare_style_options(self):\n    style_conf = get_style_configuration(\"CustomToolbutton\")\n    if self.style:\n        style_conf |= get_style_configuration(self.style)\n    self.normal_background = self.background or style_conf[\"background\"]\n    self.normal_foreground = self.foreground or style_conf[\"foreground\"]\n    self.hover_background = style_conf[\"activebackground\"]", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "CustomToolbutton", "function_name": "destroy", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().is_closing", "self.unbind", "super", "super().destroy"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def destroy(self):\n    if not get_workbench().is_closing():\n        try:\n            self.unbind(\"<<ThemeChanged>>\", self._on_theme_changed_binding)\n        except Exception:\n            pass\n    super().destroy()", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "CommonDialog", "function_name": "set_initial_focus", "parameters": ["self", "node"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "node.focus_set", "node.winfo_children", "self.set_initial_focus"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_initial_focus(self, node=None) -> bool:\n    if node is None:\n        node = self\n\n    if isinstance(\n        node,\n        (\n            ttk.Entry,\n            ttk.Combobox,\n            ttk.Treeview,\n            tk.Text,\n            ttk.Notebook,\n            CustomNotebook,\n            ttk.Button,\n            tk.Listbox,\n        ),\n    ):\n        node.focus_set()\n        return True\n\n    else:\n        for child in node.winfo_children():\n            if self.set_initial_focus(child):\n                return True\n\n    return False", "loc": 26}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "WorkbenchPanedWindow", "function_name": "all_children_hidden", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.panecget", "self.panes"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def all_children_hidden(self):\n    for child in self.panes():\n        if not self.panecget(child, \"hide\"):\n            return False\n\n    return True", "loc": 6}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "WorkbenchPanedWindow", "function_name": "update_visibility", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().set_option", "isinstance", "self.all_children_hidden", "self.cget", "self.master.paneconfig", "self.winfo_height", "self.winfo_ismapped", "self.winfo_width"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_visibility(self):\n    if isinstance(self.master, tk.PanedWindow):\n        should_be_hidden = self.all_children_hidden()\n        if self.winfo_ismapped() and should_be_hidden and self.size_config_key is not None:\n            if self.cget(\"orient\") == \"vertical\":\n                value = self.winfo_width()\n            else:\n                value = self.winfo_height()\n\n            get_workbench().set_option(self.size_config_key, value)\n\n        self.master.paneconfig(self, hide=should_be_hidden)", "loc": 12}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "WorkbenchPanedWindow", "function_name": "has_several_visible_panes", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["child.winfo_ismapped", "self.winfo_children"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def has_several_visible_panes(self):\n    count = 0\n    for child in self.winfo_children():\n        if child.winfo_ismapped():\n            count += 1\n\n    return count > 1", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "ViewNotebook", "function_name": "forget", "parameters": ["self", "child"], "param_types": {"child": "tk.Widget"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().set_option", "isinstance", "self.master.has_several_visible_panes", "self.winfo_height", "super", "super().forget"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def forget(self, child: tk.Widget) -> None:\n    if (\n        isinstance(self.master, WorkbenchPanedWindow)\n        and self.master.has_several_visible_panes()\n    ):\n        close_height = self.winfo_height()\n        get_workbench().set_option(\n            f\"layout.{self.location_in_workbench}_nb_height\", close_height\n        )\n\n    super().forget(child)", "loc": 11}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "ViewNotebook", "function_name": "after_insert", "parameters": ["self", "pos", "page", "old_notebook"], "param_types": {"pos": "Union[int, Literal['end']]", "page": "CustomNotebookPage", "old_notebook": "Optional[CustomNotebook]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().event_generate", "self._update_visibility", "super", "super().after_insert"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def after_insert(\n    self,\n    pos: Union[int, Literal[\"end\"]],\n    page: CustomNotebookPage,\n    old_notebook: Optional[CustomNotebook],\n) -> None:\n    super().after_insert(pos, page, old_notebook)\n    self._update_visibility()\n    if old_notebook is None:\n        get_workbench().event_generate(\"NotebookPageOpened\", page=page)\n    else:\n        get_workbench().event_generate(\n            \"NotebookPageMoved\", page=page, new_notebook=self, old_notebook=old_notebook\n        )", "loc": 14}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "ViewNotebook", "function_name": "after_forget", "parameters": ["self", "pos", "page", "new_notebook"], "param_types": {"pos": "int", "page": "CustomNotebookPage", "new_notebook": "Optional[CustomNotebook]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().event_generate", "self._update_visibility", "super", "super().after_forget"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def after_forget(\n    self, pos: int, page: CustomNotebookPage, new_notebook: Optional[CustomNotebook]\n):\n    # see the comment at after_add_or_insert\n    super().after_forget(pos, page, new_notebook)\n    self._update_visibility()\n    if new_notebook is None:\n        get_workbench().event_generate(\"NotebookPageClosed\", page=page)", "loc": 8}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "TreeFrame", "function_name": "on_copy", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\t'.join", "combined.strip", "map", "os.linesep.join", "self.clipboard_append", "self.clipboard_clear", "self.tree.item", "self.tree.selection", "texts.append"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_copy(self):\n    texts = []\n    for item in self.tree.selection():\n        text = self.tree.item(item, option=\"text\")\n        values = map(str, self.tree.item(item, option=\"values\"))\n        combined = text + \"\\t\" + \"\\t\".join(values)\n        texts.append(combined.strip(\"\\t\"))\n    self.clipboard_clear()\n    self.clipboard_append(os.linesep.join(texts))", "loc": 9}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "EnhancedTextWithLogging", "function_name": "direct_insert", "parameters": ["self", "index", "chars", "tags"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().event_generate", "self._is_trivial_edit", "self.get", "self.index", "tktextext.EnhancedText.direct_insert"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def direct_insert(self, index, chars, tags=None, **kw):\n    # try removing line numbers\n    # TODO: shouldn't it take place only on paste?\n    # TODO: does it occur when opening a file with line numbers in it?\n    # if self._propose_remove_line_numbers and isinstance(chars, str):\n    #    chars = try_remove_linenumbers(chars, self)\n\n    concrete_index = self.index(index)\n    line_before = self.get(concrete_index + \" linestart\", concrete_index + \" lineend\")\n    self._last_event_changed_line_count = \"\\n\" in chars\n    result = tktextext.EnhancedText.direct_insert(self, index, chars, tags=tags, **kw)\n    line_after = self.get(concrete_index + \" linestart\", concrete_index + \" lineend\")\n    trivial_for_coloring, trivial_for_parens = self._is_trivial_edit(\n        chars, line_before, line_after\n    )\n    if not self._suppress_events:\n        get_workbench().event_generate(\n            \"TextInsert\",\n            index=concrete_index,\n            text=chars,\n            tags=tags,\n            text_widget=self,\n            trivial_for_coloring=trivial_for_coloring,\n            trivial_for_parens=trivial_for_parens,\n        )\n    return result", "loc": 26}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "EnhancedTextWithLogging", "function_name": "direct_delete", "parameters": ["self", "index1", "index2"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().event_generate", "self._is_trivial_edit", "self.get", "self.index", "tktextext.EnhancedText.direct_delete"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def direct_delete(self, index1, index2=None, **kw):\n    try:\n        # index1 may be eg \"sel.first\" and it doesn't make sense *after* deletion\n        concrete_index1 = self.index(index1)\n        if index2 is not None:\n            concrete_index2 = self.index(index2)\n        else:\n            concrete_index2 = self.index(index1 + \" +1c\")\n\n        chars = self.get(index1, index2)\n        self._last_event_changed_line_count = \"\\n\" in chars\n        line_before = self.get(\n            concrete_index1 + \" linestart\",\n            (concrete_index1 if concrete_index2 is None else concrete_index2) + \" lineend\",\n        )\n        return tktextext.EnhancedText.direct_delete(self, index1, index2=index2, **kw)\n    finally:\n        line_after = self.get(\n            concrete_index1 + \" linestart\",\n            (concrete_index1 if concrete_index2 is None else concrete_index2) + \" lineend\",\n        )\n        trivial_for_coloring, trivial_for_parens = self._is_trivial_edit(\n            chars, line_before, line_after\n        )\n        if not self._suppress_events:\n            get_workbench().event_generate(\n                \"TextDelete\",\n                index1=concrete_index1,\n                index2=concrete_index2,\n                text_widget=self,\n                trivial_for_coloring=trivial_for_coloring,\n                trivial_for_parens=trivial_for_parens,\n            )", "loc": 33}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "SafeScrollbar", "function_name": "set", "parameters": ["self", "first", "last"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["traceback.print_exc", "ttk.Scrollbar.set"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set(self, first, last):\n    try:\n        ttk.Scrollbar.set(self, first, last)\n    except Exception:\n        traceback.print_exc()", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "AutoScrollbar", "function_name": "set", "parameters": ["self", "first", "last"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["float", "self.grid", "self.grid_remove", "ttk.Scrollbar.set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set(self, first, last):\n    if float(first) <= 0.0 and float(last) >= 1.0:\n        # Need to accept 1 automatic hide, otherwise even narrow files\n        # get horizontal scrollbar\n        if self.gridded and self.hide_count < 2:\n            self.grid_remove()\n    elif float(first) > 0.001 or float(last) < 0.999:\n        # with >0 and <1 it occasionally made scrollbar wobble back and forth\n        if not self.gridded:\n            self.grid()\n    ttk.Scrollbar.set(self, first, last)", "loc": 11}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "VerticallyScrollableFrame", "function_name": "update_scrollbars", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.canvas.config", "self.canvas.itemconfigure", "self.canvas.winfo_width", "self.interior.winfo_reqheight", "self.interior.winfo_reqwidth"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_scrollbars(self):\n    # update the scrollbars to match the size of the inner frame\n    size = (self.canvas.winfo_width(), self.interior.winfo_reqheight())\n    self.canvas.config(scrollregion=\"0 0 %s %s\" % size)\n    if (\n        self.interior.winfo_reqwidth() != self.canvas.winfo_width()\n        and self.canvas.winfo_width() > 10\n    ):\n        # update the interior's width to fit canvas\n        # print(\"CAWI\", self.canvas.winfo_width())\n        self.canvas.itemconfigure(self.interior_id, width=self.canvas.winfo_width())", "loc": 11}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "ToolTip", "function_name": "showtip", "parameters": ["self", "text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ems_to_pixels", "get_tk_version_info", "label.pack", "running_on_mac_os", "self.widget.bbox", "self.widget.winfo_height", "self.widget.winfo_rootx", "self.widget.winfo_rooty", "self.widget.winfo_toplevel", "self.widget.winfo_toplevel().bind", "tk.Label", "tk.Toplevel", "tw.tk.call", "tw.wm_geometry", "tw.wm_overrideredirect", "tw.wm_transient"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Display text in tooltip window", "source_code": "def showtip(self, text):\n    \"Display text in tooltip window\"\n    self.text = text\n    if self.tipwindow or not self.text:\n        return\n\n    # x = self.widget.winfo_pointerx() + ems_to_pixels(0)\n    # y = self.widget.winfo_pointery() + ems_to_pixels(0.8)\n    x, y, _, cy = self.widget.bbox(\"insert\")\n    x = x + self.widget.winfo_rootx()\n    y = y + self.widget.winfo_rooty() + self.widget.winfo_height() + ems_to_pixels(0.2)\n    self.tipwindow = tw = tk.Toplevel(self.widget)\n    if running_on_mac_os():\n        try:\n            # Must be the first thing to do after creating window\n            # https://wiki.tcl-lang.org/page/MacWindowStyle\n            tw.tk.call(\n                \"::tk::unsupported::MacWindowStyle\", \"style\", tw._w, \"help\", \"noActivates\"\n            )\n            if get_tk_version_info() >= (8, 6, 10) and running_on_mac_os():\n                tw.wm_overrideredirect(1)\n        except tk.TclError:\n            pass\n    else:\n        tw.wm_overrideredirect(1)\n\n    tw.wm_geometry(\"+%d+%d\" % (x, y))\n\n    if running_on_mac_os():\n        # TODO: maybe it's because of Tk 8.5, not because of Mac\n        tw.wm_transient(self.widget)\n\n    label = tk.Label(tw, text=self.text, **self.options)\n    label.pack()\n    self.focus_out_bind_ref = self.widget.winfo_toplevel().bind(\n        \"<FocusOut>\", self.hidetip, True\n    )", "loc": 37}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "ToolTip", "function_name": "hidetip", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.widget.unbind", "tw.destroy"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def hidetip(self, event=None):\n    tw = self.tipwindow\n    self.tipwindow = None\n    if self.tipwindow:\n        self.widget.unbind(\"<FocusOut>\", self.focus_out_bind_ref)\n    if tw:\n        tw.destroy()", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "NoteBox", "function_name": "clear", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._click_bindings.clear", "self.text.direct_delete", "self.text.tag_remove", "self.text.tag_unbind"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def clear(self):\n    for tag in self._click_bindings:\n        self.text.tag_unbind(tag, \"<1>\", self._click_bindings[tag])\n        self.text.tag_remove(tag, \"1.0\", \"end\")\n\n    self.text.direct_delete(\"1.0\", \"end\")\n    self._current_chars = \"\"\n    self._click_bindings.clear()", "loc": 8}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "NoteBox", "function_name": "set_content", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["callable", "isinstance", "len", "self.append_text", "self.clear", "self.text.direct_insert", "self.text.see", "tuple"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_content(self, *items):\n    self.clear()\n\n    for item in items:\n        if isinstance(item, str):\n            self.text.direct_insert(\"1.0\", item)\n            self._current_chars = item\n        else:\n            assert isinstance(item, (list, tuple))\n            chars, *props = item\n            if len(props) > 0 and callable(props[-1]):\n                tags = tuple(props[:-1])\n                click_handler = props[-1]\n            else:\n                tags = tuple(props)\n                click_handler = None\n\n            self.append_text(chars, tags, click_handler)\n\n        self.text.see(\"1.0\")", "loc": 20}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "NoteBox", "function_name": "append_text", "parameters": ["self", "chars", "tags", "click_handler"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.text.direct_insert", "self.text.tag_bind", "tuple"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def append_text(self, chars, tags=(), click_handler=None):\n    tags = tuple(tags)\n\n    if click_handler is not None:\n        click_tag = \"click_%d\" % len(self._click_bindings)\n        tags = tags + (click_tag,)\n        binding = self.text.tag_bind(click_tag, \"<1>\", click_handler, True)\n        self._click_bindings[click_tag] = binding\n\n    self.text.direct_insert(\"end\", chars, tags)\n    self._current_chars += chars", "loc": 11}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "NoteBox", "function_name": "place", "parameters": ["self", "target", "focus"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TypeError", "float", "font.measure", "font.metrics", "int", "isinstance", "max", "min", "self._current_chars.splitlines", "self.deiconify", "self.text.index", "self.update_idletasks", "self.wm_geometry", "target.bbox", "target.winfo_height", "target.winfo_rootx", "target.winfo_rooty", "tk.font.nametofont"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def place(self, target, focus=None):\n    # Compute the area that will be described by this Note\n    focus_x = target.winfo_rootx()\n    focus_y = target.winfo_rooty()\n    focus_height = target.winfo_height()\n\n    if isinstance(focus, TextRange):\n        assert isinstance(target, tk.Text)\n        topleft = target.bbox(\"%d.%d\" % (focus.lineno, focus.col_offset))\n        if focus.end_col_offset == 0:\n            botright = target.bbox(\n                \"%d.%d lineend\" % (focus.end_lineno - 1, focus.end_lineno - 1)\n            )\n        else:\n            botright = target.bbox(\"%d.%d\" % (focus.end_lineno, focus.end_col_offset))\n\n        if topleft and botright:\n            focus_x += topleft[0]\n            focus_y += topleft[1]\n            focus_height = botright[1] - topleft[1] + botright[3]\n\n    elif isinstance(focus, (list, tuple)):\n        focus_x += focus[0]\n        focus_y += focus[1]\n        focus_height = focus[3]\n\n    elif focus is None:\n        pass\n\n    else:\n        raise TypeError(\"Unsupported focus\")\n\n    # Compute dimensions of the note\n    font = self.text[\"font\"]\n    if isinstance(font, str):\n        font = tk.font.nametofont(font)\n\n    lines = self._current_chars.splitlines()\n    max_line_width = 0\n    for line in lines:\n        max_line_width = max(max_line_width, font.measure(line))\n\n    width = min(max_line_width, self._max_default_width) + self.padx * 2 + 2\n    self.wm_geometry(\"%dx%d+%d+%d\" % (width, 100, focus_x, focus_y + focus_height))\n\n    self.update_idletasks()\n    line_count = int(float(self.text.index(\"end\")))\n    line_height = font.metrics()[\"linespace\"]\n\n    self.wm_geometry(\n        \"%dx%d+%d+%d\" % (width, line_count * line_height, focus_x, focus_y + focus_height)\n    )\n\n    # TODO: detect the situation when note doesn't fit under\n    # the focus box and should be placed above\n\n    self.deiconify()", "loc": 57}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "HeadingStripe", "function_name": "on_theme_changed", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_style_configuration", "isinstance", "len", "opts.get", "self.configure"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_theme_changed(self, event=None):\n    opts = get_style_configuration(\"Heading\")\n    px_to_hide = opts.get(\"topmost_pixels_to_hide\", 0)\n    if isinstance(px_to_hide, list):\n        # don't know why it happens sometimes\n        assert len(px_to_hide) == 1\n        px_to_hide = px_to_hide[0]\n    background = opts.get(\"background\")\n    self.configure(height=px_to_hide, background=background)", "loc": 9}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "ScrollbarStripe", "function_name": "get_background", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["os_is_in_dark_mode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_background(self):\n    # Not sure if it is good idea to use fixed colors, but no named (light-dark aware) color matches.\n    # Best dynamic alternative is probably systemTextBackgroundColor\n    if os_is_in_dark_mode():\n        return \"#2d2e31\"\n    else:\n        return \"#fafafa\"", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "ScrollbarStripe", "function_name": "on_theme_changed", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["lookup_style_option", "self.configure", "self.get_background", "self.grid", "self.grid_remove"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_theme_changed(self, event=None):\n    px_to_hide = lookup_style_option(\"Vertical.TScrollbar\", \"rightmost_pixels_to_hide\", 0)\n    if px_to_hide == 0:\n        self.grid_remove()\n    else:\n        self.grid()\n        self.configure(background=self.get_background())", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "_ZenityDialogProvider", "function_name": "askopenfilename", "parameters": ["cls"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls._call", "cls._check_zenity_exists", "cls._convert_common_options"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def askopenfilename(cls, **options):\n    if not cls._check_zenity_exists(options[\"parent\"]):\n        return None\n\n    args = cls._convert_common_options(\"Open file\", **options)\n    return cls._call(args)", "loc": 6}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "_ZenityDialogProvider", "function_name": "askopenfilenames", "parameters": ["cls"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls._call", "cls._call(args + ['--multiple']).split", "cls._check_zenity_exists", "cls._convert_common_options"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def askopenfilenames(cls, **options):\n    if not cls._check_zenity_exists(options[\"parent\"]):\n        return None\n\n    args = cls._convert_common_options(\"Open files\", **options)\n    return cls._call(args + [\"--multiple\"]).split(\"|\")", "loc": 6}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "_ZenityDialogProvider", "function_name": "asksaveasfilename", "parameters": ["cls"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["args.append", "cls._call", "cls._check_zenity_exists", "cls._convert_common_options"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def asksaveasfilename(cls, **options):\n    if not cls._check_zenity_exists(options[\"parent\"]):\n        return None\n\n    args = cls._convert_common_options(\"Save as\", **options)\n    args.append(\"--save\")\n\n    filename = cls._call(args)\n    if not filename:\n        return None\n\n    return filename", "loc": 12}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "_ZenityDialogProvider", "function_name": "askdirectory", "parameters": ["cls"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["args.append", "cls._call", "cls._check_zenity_exists", "cls._convert_common_options"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def askdirectory(cls, **options):\n    if not cls._check_zenity_exists(options[\"parent\"]):\n        return None\n\n    args = cls._convert_common_options(\"Select directory\", **options)\n    args.append(\"--directory\")\n    return cls._call(args)", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "read_stream", "parameters": ["stream", "target_list"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["stream.readline", "target_list.append"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_stream(stream, target_list):\n    while True:\n        line = stream.readline()\n        if line:\n            target_list.append(line)\n        else:\n            break", "loc": 7}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "poll", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "on_completion", "proc.poll", "t_err.join", "t_out.join", "tk._default_root.after"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def poll():\n    if proc.poll() is not None:\n        t_out.join(3)\n        t_err.join(3)\n        on_completion(proc, out_lines, err_lines)\n        return\n\n    tk._default_root.after(int(poll_delay * 1000), poll)", "loc": 8}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "MenuEx", "function_name": "update_item_availability", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["range", "self._testers.get", "self.entryconfigure", "self.index", "tester"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_item_availability(self):\n    for i in range(self.index(\"end\") + 1):\n        item_data = self.entryconfigure(i)\n        if \"label\" in item_data:\n            tester = self._testers.get(item_data[\"label\"])\n            if tester and not tester():\n                self.entryconfigure(i, state=tk.DISABLED)\n            else:\n                self.entryconfigure(i, state=tk.NORMAL)", "loc": 9}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "MenuEx", "function_name": "add", "parameters": ["self", "itemType", "cnf"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cnf.get", "itemdata.get", "self.entryconfigure", "self.index", "super", "super().add"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add(self, itemType, cnf={}, **kw):\n    cnf = cnf or kw\n    tester = cnf.get(\"tester\")\n    if \"tester\" in cnf:\n        del cnf[\"tester\"]\n\n    super().add(itemType, cnf)\n\n    itemdata = self.entryconfigure(self.index(\"end\"))\n    labeldata = itemdata.get(\"label\")\n    if labeldata:\n        self._testers[labeldata] = tester", "loc": 12}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "TextMenu", "function_name": "get_selected_text", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.text.get"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_selected_text(self):\n    try:\n        return self.text.get(\"sel.first\", \"sel.last\")\n    except TclError:\n        return \"\"", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "TextMenu", "function_name": "selection_is_read_only", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "self.text.is_read_only"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def selection_is_read_only(self):\n    if hasattr(self.text, \"is_read_only\"):\n        return self.text.is_read_only()\n\n    return False", "loc": 5}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "wrap_with_parent_checker", "parameters": ["original"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_check_dialog_parent", "original"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wrap_with_parent_checker(original):\n    def wrapper(*args, **options):\n        _check_dialog_parent(options)\n        return original(*args, **options)\n\n    return wrapper", "loc": 6}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": "AdvancedLabel", "function_name": "set_url", "parameters": ["self", "url"], "param_types": {"url": "Optional[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_hyperlink_cursor", "self.configure"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_url(self, url: Optional[str]) -> None:\n    if self._url == url:\n        return\n\n    self._url = url\n    if url:\n        self.configure(style=\"Url.TLabel\", cursor=get_hyperlink_cursor(), font=self._url_font)\n    else:\n        self.configure(style=\"TLabel\", cursor=\"\", font=self._default_font)", "loc": 9}
{"file": "thonny\\thonny\\ui_utils.py", "class_name": null, "function_name": "click", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["label_widget.winfo_height", "label_widget.winfo_rootx", "label_widget.winfo_rooty", "menu.tk_popup"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def click(event):\n    try:\n        # print(\"Before\")\n        self._opened_menu = menu\n        menu.tk_popup(\n            label_widget.winfo_rootx(),\n            label_widget.winfo_rooty() + label_widget.winfo_height(),\n        )\n    finally:\n        # print(\"After\")\n        self._opened_menu = None", "loc": 11}
{"file": "thonny\\thonny\\venv_dialog.py", "class_name": "VenvDialog", "function_name": "populate_main_frame", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["MappingCombobox", "base_label.grid", "exes.insert", "exes.remove", "find_local_cpython_executables", "get_runner", "get_runner().get_backend_proxy", "get_workbench", "get_workbench().get_local_cwd", "get_workbench().is_using_aqua_based_theme", "isinstance", "logger.info", "proxy.get_base_executable", "self._base_browse_button.grid", "self._base_combo.grid", "self._base_combo.select_value", "self._base_packages_checkbox.grid", "self._name_entry.grid", "self._name_label.grid", "self._new_exe_entry.grid", "self._new_exe_label.grid", "self._parent_browse_button.grid", "self._parent_combo.grid", "self._parent_combo.set", "self._parent_label.grid", "self.get_large_padding", "self.get_small_padding", "self.main_frame.columnconfigure", "tk.BooleanVar", "tk.StringVar", "tr", "ttk.Button", "ttk.Checkbutton", "ttk.Combobox", "ttk.Entry", "ttk.Label"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def populate_main_frame(self):\n    from thonny.plugins.cpython_frontend import LocalCPythonProxy\n    from thonny.plugins.cpython_frontend.cp_front import find_local_cpython_executables\n\n    epadx = self.get_large_padding()\n    ipadx = self.get_small_padding()\n    epady = epadx\n    ipady = ipadx\n\n    exes = find_local_cpython_executables()\n\n    proxy = get_runner().get_backend_proxy()\n    if isinstance(proxy, LocalCPythonProxy):\n        current_base_cpython = proxy.get_base_executable()\n    else:\n        current_base_cpython = None\n\n    logger.info(\"Current base executable: %r\", current_base_cpython)\n\n    if current_base_cpython is not None:\n        if current_base_cpython in exes:\n            exes.remove(current_base_cpython)\n        exes.insert(0, current_base_cpython)\n\n    browse_button_width = 2 if get_workbench().is_using_aqua_based_theme() else 3\n\n    base_label = ttk.Label(self.main_frame, text=tr(\"Base interpreter\"))\n    base_label.grid(row=1, column=1, columnspan=2, sticky=\"w\", padx=epadx, pady=(epady, 0))\n    self._base_combo = MappingCombobox(\n        self.main_frame, mapping={path: path for path in exes}, exportselection=False, width=30\n    )\n    if current_base_cpython is not None:\n        self._base_combo.select_value(current_base_cpython)\n    self._base_combo.grid(\n        row=2, column=1, columnspan=2, sticky=\"we\", padx=(epadx, ipadx), pady=(0, ipady)\n    )\n    self._base_browse_button = ttk.Button(\n        self.main_frame,\n        text=\"...\",\n        command=self._browse_base_interpreter,\n        width=browse_button_width,\n    )\n    self._base_browse_button.grid(row=2, column=3, padx=(0, epadx), pady=(0, ipady))\n\n    self._parent_label = ttk.Label(\n        self.main_frame, text=tr(\"Parent folder of the new environment\")\n    )\n    self._parent_label.grid(\n        row=3, column=1, columnspan=2, sticky=\"w\", padx=epadx, pady=(ipady, 0)\n    )\n    self._parent_combo = ttk.Combobox(self.main_frame, width=30)\n    self._parent_combo.grid(\n        row=4, column=1, columnspan=2, sticky=\"we\", padx=(epadx, ipadx), pady=(0, ipady)\n    )\n    self._parent_browse_button = ttk.Button(\n        self.main_frame,\n        text=\"...\",\n        command=self._browse_parent_folder,\n        width=browse_button_width,\n    )\n    self._parent_browse_button.grid(row=4, column=3, padx=(0, epadx), pady=(0, ipady))\n    self._parent_combo.set(get_workbench().get_local_cwd())\n\n    self._name_label = ttk.Label(self.main_frame, text=tr(\"Environment name\"))\n    self._name_label.grid(row=5, column=1, sticky=\"w\", padx=(epadx, 0), pady=(ipady, 0))\n    self._name_var = tk.StringVar(self, value=\"venv\")\n    self._name_entry = ttk.Entry(self.main_frame, width=12, textvariable=self._name_var)\n    self._name_entry.grid(row=6, column=1, sticky=\"w\", padx=(epadx, 0), pady=(0, ipady))\n\n    self._new_exe_label = ttk.Label(\n        self.main_frame, text=\" \" + tr(\"Path of the new Python executable\")\n    )\n    self._new_exe_label.grid(\n        row=5, column=2, columnspan=2, sticky=\"w\", padx=(epadx, epadx), pady=(ipady, 0)\n    )\n    self._new_exe_var = tk.StringVar(self)\n    self._new_exe_entry = ttk.Entry(\n        self.main_frame, width=30, state=\"readonly\", textvariable=self._new_exe_var\n    )\n    self._new_exe_entry.grid(\n        row=6, column=2, columnspan=2, sticky=\"we\", padx=(epadx, epadx), pady=(0, ipady)\n    )\n\n    self._base_packages_variable = tk.BooleanVar(value=False)\n    self._base_packages_checkbox = ttk.Checkbutton(\n        self.main_frame,\n        text=tr(\"Include packages installed for the base interpreter\"),\n        variable=self._base_packages_variable,\n    )\n    self._base_packages_checkbox.grid(\n        row=9, column=1, columnspan=2, sticky=\"w\", padx=epadx, pady=(ipady, ipady)\n    )\n\n    self.main_frame.columnconfigure(2, weight=1)", "loc": 94}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "finalize_startup", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.exception", "logger.info", "messagebox.showerror", "self._check_version_alignment", "self._editor_notebook.focus_set", "self._editor_notebook.load_previous_files", "self._editor_notebook.update_appearance", "self._load_stuff_from_command_line", "self.event_generate", "self.poll_events", "self.report_exception"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def finalize_startup(self):\n    logger.info(\"Finalizing startup\")\n    try:\n        self.ready = True\n        self._editor_notebook.update_appearance()\n        if self._configuration_manager.error_reading_existing_file:\n            messagebox.showerror(\n                \"Problem\",\n                f\"Previous configuration could not be read:\\n\\n\"\n                f\"{self._configuration_manager.error_reading_existing_file}).\\n\\n\"\n                \"Using default settings\",\n                master=self,\n            )\n        self._editor_notebook.load_previous_files()\n        self._load_stuff_from_command_line(self._initial_args)\n        self._editor_notebook.focus_set()\n        self.event_generate(\"WorkbenchReady\")\n        self.poll_events()\n        self._check_version_alignment()\n    except Exception:\n        logger.exception(\"Exception while finalizing startup\")\n        self.report_exception()", "loc": 22}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "poll_events", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._event_queue.empty", "self._event_queue.get", "self.after", "self.event_generate"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def poll_events(self) -> None:\n    if self._event_queue is None or self._closing:\n        self._event_polling_id = None\n        return\n\n    while not self._event_queue.empty():\n        sequence, event = self._event_queue.get()\n        self.event_generate(sequence, event)\n\n    self._event_polling_id = self.after(20, self.poll_events)", "loc": 10}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "start_or_restart_language_servers", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ClientCapabilities", "ClientInfo", "CompletionClientCapabilities", "CompletionClientCapabilitiesCompletionItem", "CompletionClientCapabilitiesCompletionList", "DefinitionClientCapabilities", "DocumentHighlightClientCapabilities", "DocumentSymbolClientCapabilities", "GeneralClientCapabilities", "InitializeParams", "PublishDiagnosticsClientCapabilities", "SignatureHelpClientCapabilities", "SignatureHelpClientCapabilitiesParameterInformation", "SignatureHelpClientCapabilitiesSignatureInformation", "SymbolKinds", "TextDocumentClientCapabilities", "TextDocumentSyncClientCapabilities", "WindowClientCapabilities", "WorkspaceClientCapabilities", "WorkspaceFolder", "class_", "logger.info", "os.getpid", "pathlib.Path", "pathlib.Path(self.get_local_cwd()).as_uri", "self._ls_proxies.append", "self.get_local_cwd", "self.get_option", "self.in_debug_mode", "self.shut_down_language_servers", "thonny.get_version"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start_or_restart_language_servers(self) -> None:\n    self.shut_down_language_servers()\n\n    for class_ in self._language_server_proxy_classes:\n        logger.info(\"Constructing language server %s\", class_)\n        ls_proxy = class_(\n            InitializeParams(\n                capabilities=ClientCapabilities(\n                    workspace=WorkspaceClientCapabilities(\n                        applyEdit=None,\n                        codeLens=None,\n                        fileOperations=None,\n                        inlineValue=None,\n                        inlayHint=None,\n                        diagnostics=None,\n                        # workspaceFolders=True, # TODO: This may require workspace/didChangeWorkspaceFolders to activate Pyright?\n                    ),\n                    textDocument=TextDocumentClientCapabilities(\n                        publishDiagnostics=PublishDiagnosticsClientCapabilities(\n                            relatedInformation=False\n                        ),\n                        synchronization=TextDocumentSyncClientCapabilities(),\n                        documentSymbol=DocumentSymbolClientCapabilities(\n                            symbolKind=SymbolKinds(\n                                [\n                                    SymbolKind.Enum,\n                                    SymbolKind.Class,\n                                    SymbolKind.Method,\n                                    SymbolKind.Property,\n                                    SymbolKind.Function,\n                                ]\n                            ),\n                            hierarchicalDocumentSymbolSupport=True,\n                        ),\n                        completion=CompletionClientCapabilities(\n                            completionItem=CompletionClientCapabilitiesCompletionItem(\n                                snippetSupport=False,\n                                commitCharactersSupport=True,\n                                documentationFormat=None,  # TODO\n                                deprecatedSupport=False,  # TODO\n                                preselectSupport=True,\n                                insertReplaceSupport=True,\n                                labelDetailsSupport=False,\n                            ),\n                            completionItemKind=None,  # TODO\n                            insertTextMode=None,\n                            contextSupport=False,\n                            completionList=CompletionClientCapabilitiesCompletionList(\n                                itemDefaults=[\"commitCharacters\"]\n                            ),\n                        ),\n                        signatureHelp=SignatureHelpClientCapabilities(\n                            signatureInformation=SignatureHelpClientCapabilitiesSignatureInformation(\n                                documentationFormat=[MarkupKind.PlainText, MarkupKind.Markdown],\n                                parameterInformation=SignatureHelpClientCapabilitiesParameterInformation(\n                                    labelOffsetSupport=True\n                                ),\n                                activeParameterSupport=True,\n                            )\n                        ),\n                        definition=DefinitionClientCapabilities(linkSupport=True),\n                        documentHighlight=DocumentHighlightClientCapabilities(),\n                    ),\n                    notebookDocument=None,\n                    window=WindowClientCapabilities(\n                        workDoneProgress=None,\n                        showMessage=None,\n                        showDocument=None,\n                    ),\n                    general=GeneralClientCapabilities(\n                        staleRequestSupport=None,\n                        regularExpressions=None,\n                        markdown=None,\n                        positionEncodings=[PositionEncodingKind.UTF16],\n                    ),\n                ),\n                processId=os.getpid(),\n                clientInfo=ClientInfo(name=\"Thonny\", version=thonny.get_version()),\n                locale=self.get_option(\"general.language\"),\n                workspaceFolders=[\n                    WorkspaceFolder(\n                        uri=pathlib.Path(self.get_local_cwd()).as_uri(), name=\"localws\"\n                    ),\n                ],\n                trace=TraceValues.Verbose if self.in_debug_mode() else TraceValues.Messages,\n            )\n        )\n\n        self._ls_proxies.append(ls_proxy)", "loc": 89}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "shut_down_language_servers", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.info", "ls_proxy.shut_down"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def shut_down_language_servers(self):\n    for ls_proxy in self._ls_proxies:\n        logger.info(\"Shutting down language server %s\", ls_proxy)\n        ls_proxy.shut_down()\n\n    self._ls_proxies = []", "loc": 6}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "add_command", "parameters": ["self", "command_id", "menu_name", "command_label", "handler", "tester", "default_sequence", "extra_sequences", "flag_name", "skip_sequence_binding", "accelerator", "group", "position_in_group", "image", "caption", "alternative_caption", "include_in_menu", "include_in_toolbar", "submenu", "bell_when_denied", "show_extra_sequences"], "param_types": {"command_id": "str", "menu_name": "str", "command_label": "str", "handler": "Optional[Callable[[], None]]", "tester": "Optional[Callable[[], bool]]", "default_sequence": "Optional[str]", "extra_sequences": "Sequence[str]", "flag_name": "Optional[str]", "skip_sequence_binding": "bool", "accelerator": "Optional[str]", "group": "int", "image": "Optional[str]", "caption": "Optional[str]", "alternative_caption": "Optional[str]", "include_in_menu": "bool", "include_in_toolbar": "bool", "submenu": "Optional[tk.Menu]", "bell_when_denied": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dict", "self._commands.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Registers an item to be shown in specified menu.", "source_code": "def add_command(\n    self,\n    command_id: str,\n    menu_name: str,\n    command_label: str,\n    handler: Optional[Callable[[], None]] = None,\n    tester: Optional[Callable[[], bool]] = None,\n    default_sequence: Optional[str] = None,\n    extra_sequences: Sequence[str] = [],\n    flag_name: Optional[str] = None,\n    skip_sequence_binding: bool = False,\n    accelerator: Optional[str] = None,\n    group: int = 99,\n    position_in_group=\"end\",\n    image: Optional[str] = None,\n    caption: Optional[str] = None,\n    alternative_caption: Optional[str] = None,\n    include_in_menu: bool = True,\n    include_in_toolbar: bool = False,\n    submenu: Optional[tk.Menu] = None,\n    bell_when_denied: bool = True,\n    show_extra_sequences=False,\n) -> None:\n    \"\"\"Registers an item to be shown in specified menu.\n\n    Args:\n        menu_name: Name of the menu the command should appear in.\n            Standard menu names are \"file\", \"edit\", \"run\", \"view\", \"help\".\n            If a menu with given name doesn't exist, then new menu is created\n            (with label=name).\n        command_label: Label for this command\n        handler: Function to be called when the command is invoked.\n            Should be callable with one argument (the event or None).\n        tester: Function to be called for determining if command is available or not.\n            Should be callable with one argument (the event or None).\n            Should return True or False.\n            If None then command is assumed to be always available.\n        default_sequence: Default shortcut (Tk style)\n        flag_name: Used for toggle commands. Indicates the name of the boolean option.\n        group: Used for grouping related commands together. Value should be int.\n            Groups with smaller numbers appear before.\n\n    Returns:\n        None\n    \"\"\"\n\n    # Temporary solution for plug-ins made for versions before 3.2\n    if menu_name == \"device\":\n        menu_name = \"tools\"\n        group = 150\n\n    # store command to be published later\n    self._commands.append(\n        dict(\n            command_id=command_id,\n            menu_name=menu_name,\n            command_label=command_label,\n            handler=handler,\n            tester=tester,\n            default_sequence=default_sequence,\n            extra_sequences=extra_sequences,\n            flag_name=flag_name,\n            skip_sequence_binding=skip_sequence_binding,\n            accelerator=accelerator,\n            group=group,\n            position_in_group=position_in_group,\n            image=image,\n            caption=caption,\n            alternative_caption=alternative_caption,\n            include_in_menu=include_in_menu,\n            include_in_toolbar=include_in_toolbar,\n            submenu=submenu,\n            bell_when_denied=bell_when_denied,\n            show_extra_sequences=show_extra_sequences,\n        )\n    )", "loc": 76}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "add_view", "parameters": ["self", "cls", "label", "default_location", "visible_by_default", "default_position_key"], "param_types": {"cls": "Type[tk.Widget]", "label": "str", "default_location": "str", "visible_by_default": "bool", "default_position_key": "Optional[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "len", "logger.info", "nb_views.insert", "self.add_command", "self.get_option", "self.get_variable", "self.hide_view", "self.in_simple_mode", "self.set_default", "self.set_option", "self.show_view", "tk.BooleanVar", "visibility_var.get"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "Adds item to \"View\" menu for showing/hiding given view.", "source_code": "def add_view(\n    self,\n    cls: Type[tk.Widget],\n    label: str,\n    default_location: str,\n    visible_by_default: bool = False,\n    default_position_key: Optional[str] = None,\n) -> None:\n    \"\"\"Adds item to \"View\" menu for showing/hiding given view.\n\n    Args:\n        view_class: Class or constructor for view. Should be callable with single\n            argument (the master of the view)\n        label: Label of the view tab\n        location: Location descriptor. Can be \"nw\", \"sw\", \"s\", \"se\", \"ne\"\n\n    Returns: None\n    \"\"\"\n    view_id = cls.__name__\n    if default_position_key is None:\n        default_position_key = view_id\n\n    for nb_name in VIEW_LOCATION_CODES:\n        nb_views = self.get_option(\"layout.notebook_\" + nb_name + \".views\")\n        if view_id in nb_views:\n            # view is already known, positioned and possibly re-positioned and hidden/shown by the user\n            break\n    else:\n        # Position the view into the notebook's list\n        nb_views = self.get_option(\"layout.notebook_\" + default_location + \".views\")\n        logger.info(\"First time adding %r to %r\", view_id, nb_views)\n        i = 0\n        while i + 1 < len(nb_views) and nb_views[i] < default_position_key:\n            i += 1\n        nb_views.insert(i, view_id)\n        self.set_option(\"layout.notebook_\" + default_location + \".views\", nb_views)\n\n    self.set_default(\"view.\" + view_id + \".visible\", visible_by_default)\n\n    if self.in_simple_mode():\n        visibility_var = tk.BooleanVar(value=view_id in SIMPLE_MODE_VIEWS)\n    else:\n        visibility_var = cast(tk.BooleanVar, self.get_variable(\"view.\" + view_id + \".visible\"))\n\n    # Prepare the elements for creating the view and representing its visibility\n    self._view_records[view_id] = {\n        \"class\": cls,\n        \"label\": label,\n        \"visibility_var\": visibility_var,\n    }\n\n    # handler\n    def toggle_view_visibility():\n        if visibility_var.get():\n            self.hide_view(view_id)\n        else:\n            self.show_view(view_id, True)\n\n    self.add_command(\n        \"toggle_\" + view_id,\n        menu_name=\"view\",\n        command_label=label,\n        handler=toggle_view_visibility,\n        flag_name=\"view.\" + view_id + \".visible\",\n        group=10,\n        position_in_group=\"alphabetic\",\n    )", "loc": 67}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "add_backend", "parameters": ["self", "name", "proxy_class", "description", "config_page_constructor", "sort_key"], "param_types": {"name": "str", "proxy_class": "Type[BackendProxy]", "description": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BackendSpec", "self.set_default"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_backend(\n    self,\n    name: str,\n    proxy_class: Type[BackendProxy],\n    description: str,\n    config_page_constructor,\n    sort_key=None,\n) -> None:\n    self._backends[name] = BackendSpec(\n        name,\n        proxy_class,\n        description,\n        config_page_constructor,\n        sort_key if sort_key is not None else description,\n    )\n\n    self.set_default(f\"{name}.last_configurations\", [])\n\n    # assign names to related classes\n    proxy_class.backend_name = name  # type: ignore\n    proxy_class.backend_description = description  # type: ignore\n    config_page_constructor.backend_name = name\n    config_page_constructor.proxy_class = proxy_class", "loc": 23}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "add_ui_theme", "parameters": ["self", "name", "parent", "settings", "dark_mode_overrides", "images"], "param_types": {"name": "str", "parent": "Union[str, None]", "settings": "FlexibleUiThemeSettings", "dark_mode_overrides": "Optional[FlexibleUiThemeSettings]", "images": "Dict[str, str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["tr", "warn"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_ui_theme(\n    self,\n    name: str,\n    parent: Union[str, None],\n    settings: FlexibleUiThemeSettings,\n    dark_mode_overrides: Optional[FlexibleUiThemeSettings] = None,\n    images: Dict[str, str] = {},\n) -> None:\n    if name in self._ui_themes:\n        warn(tr(\"Overwriting theme '%s'\") % name)\n\n    self._ui_themes[name] = (parent, settings, dark_mode_overrides, images)", "loc": 12}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "add_syntax_theme", "parameters": ["self", "name", "parent", "settings"], "param_types": {"name": "str", "parent": "Optional[str]", "settings": "FlexibleSyntaxThemeSettings"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["tr", "warn"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_syntax_theme(\n    self, name: str, parent: Optional[str], settings: FlexibleSyntaxThemeSettings\n) -> None:\n    if name in self._syntax_themes:\n        warn(tr(\"Overwriting theme '%s'\") % name)\n\n    self._syntax_themes[name] = (parent, settings)", "loc": 7}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "scale", "parameters": ["self", "value"], "param_types": {"value": "Union[int, float]"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotImplementedError", "int", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def scale(self, value: Union[int, float]) -> int:\n    if isinstance(value, (int, float)):\n        # using int instead of round so that thin lines will stay\n        # one pixel even with scaling_factor 1.67\n        result = int(self._scaling_factor * value)\n        if result == 0 and value > 0:\n            # don't lose thin lines because of scaling\n            return 1\n        else:\n            return result\n    else:\n        raise NotImplementedError(\"Only numeric dimensions supported at the moment\")", "loc": 12}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "reload_themes", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.warning", "self._apply_syntax_theme", "self._apply_ui_theme", "self.get_default_syntax_theme", "self.get_default_ui_theme", "self.get_option", "self.get_usable_ui_theme_names", "self.set_option"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def reload_themes(self) -> None:\n    ui_theme = self.get_option(\"view.ui_theme\")\n    available_themes = self.get_usable_ui_theme_names()\n    if ui_theme not in available_themes:\n        logger.warning(\"Could not find UI theme %r, switching to default\", ui_theme)\n        ui_theme = self.get_default_ui_theme()\n        self.set_option(\"view.ui_theme\", ui_theme)\n\n    self._apply_ui_theme(ui_theme)\n\n    syntax_theme = self.get_option(\"view.syntax_theme\")\n    if syntax_theme not in self._syntax_themes:\n        logger.warning(\"Could not find syntax theme %r, switching to default\", syntax_theme)\n        syntax_theme = self.get_default_syntax_theme()\n        self.set_option(\"view.syntax_theme\", syntax_theme)\n\n    self._apply_syntax_theme(syntax_theme)", "loc": 17}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "get_default_ui_theme", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["running_on_rpi", "self.get_usable_ui_theme_names"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_default_ui_theme(self) -> str:\n    available_themes = self.get_usable_ui_theme_names()\n    if \"Windows\" in available_themes:\n        return \"Windows\"\n    elif running_on_rpi() and \"Raspberry Pi\" in available_themes:\n        return \"Raspberry Pi\"\n    elif \"macOS\" in available_themes:\n        return \"macOS\"\n    else:\n        return \"Tidy Light A\"", "loc": 10}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "get_default_syntax_theme", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.uses_dark_ui_theme"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_default_syntax_theme(self) -> str:\n    if self.uses_dark_ui_theme():\n        return \"Default Dark\"\n    else:\n        return \"Default Light\"", "loc": 5}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "uses_dark_ui_theme", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["name.lower", "self._style.theme_use"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def uses_dark_ui_theme(self) -> bool:\n    name = self._style.theme_use()\n    while True:\n        if \"dark\" in name.lower():\n            return True\n        try:\n            name, _, _, _ = self._ui_themes[name]\n        except KeyError:\n            return False\n\n        if name is None:\n            # reached start of the chain\n            break\n\n    return False", "loc": 15}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "log_program_arguments_string", "parameters": ["self", "arg_str"], "param_types": {"arg_str": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["arg_str.strip", "past_args.insert", "past_args.remove", "self.get_option", "self.program_arguments_box.configure", "self.set_option"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def log_program_arguments_string(self, arg_str: str) -> None:\n    arg_str = arg_str.strip()\n    self.set_option(\"run.program_arguments\", arg_str)\n\n    if arg_str == \"\":\n        # empty will be handled differently\n        return\n\n    past_args = self.get_option(\"run.past_program_arguments\")\n\n    if arg_str in past_args:\n        past_args.remove(arg_str)\n\n    past_args.insert(0, arg_str)\n    past_args = past_args[:10]\n\n    self.set_option(\"run.past_program_arguments\", past_args)\n    self.program_arguments_box.configure(values=[\"\"] + past_args)", "loc": 18}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "set_local_cwd", "parameters": ["self", "value"], "param_types": {"value": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.event_generate", "self.get_option", "self.set_option"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_local_cwd(self, value: str) -> None:\n    if self.get_option(\"run.working_directory\") != value:\n        self.set_option(\"run.working_directory\", value)\n        if value:\n            self.event_generate(\"LocalWorkingDirectoryChanged\", cwd=value)", "loc": 5}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "get_menu", "parameters": ["self", "name", "label"], "param_types": {"name": "str", "label": "Optional[str]"}, "return_type": "tk.Menu", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_style_configuration", "running_on_mac_os", "self._menubar.add_cascade", "self._update_menu", "tk.Menu", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Gives the menu with given name. Creates if not created yet.", "source_code": "def get_menu(self, name: str, label: Optional[str] = None) -> tk.Menu:\n    \"\"\"Gives the menu with given name. Creates if not created yet.\n\n    Args:\n        name: meant to be used as not translatable menu name\n        label: translated label, used only when menu with given name doesn't exist yet\n    \"\"\"\n\n    # For compatibility with plug-ins\n    if name in [\"device\", \"tempdevice\"] and label is None:\n        label = tr(\"Device\")\n\n    if name not in self._menus:\n        if running_on_mac_os():\n            conf = {}\n        else:\n            conf = get_style_configuration(\"Menu\")\n\n        menu = tk.Menu(self._menubar, name=name, **conf)\n        menu[\"postcommand\"] = lambda: self._update_menu(menu, name)\n        self._menubar.add_cascade(label=label if label else name, menu=menu)\n\n        self._menus[name] = menu\n        if label:\n            self._menus[label] = menu\n\n    return self._menus[name]", "loc": 27}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "get_view", "parameters": ["self", "view_id", "create"], "param_types": {"view_id": "str", "create": "bool"}, "return_type": "tk.Widget", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "class_"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_view(self, view_id: str, create: bool = True) -> tk.Widget:\n    if \"instance\" not in self._view_records[view_id]:\n        if not create:\n            raise RuntimeError(\"View %s not created\" % view_id)\n        class_ = self._view_records[view_id][\"class\"]\n        # View's master must contain all notebooks to allow dragging between notebooks\n        view = class_(self._main_pw)\n        view.containing_notebook = None\n        view.view_id = view_id\n        self._view_records[view_id][\"instance\"] = view\n\n    return self._view_records[view_id][\"instance\"]", "loc": 12}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "show_view", "parameters": ["self", "view_id", "set_focus"], "param_types": {"view_id": "str", "set_focus": "bool"}, "return_type": "Union[bool, tk.Widget]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "hasattr", "len", "logger.info", "nb_view_order.index", "notebook.add", "notebook.insert", "self._convert_view_id", "self._get_view_notebook_name_and_instance", "self.get_option", "self.get_view", "view.before_show", "view.containing_notebook.select", "view.focus_set", "view.get_tab_text", "view.on_show", "visible_nb_views.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "View must be already registered.", "source_code": "def show_view(self, view_id: str, set_focus: bool = True) -> Union[bool, tk.Widget]:\n    \"\"\"View must be already registered.\n\n    Args:\n        view_id: View class name without package name (e.g. 'ShellView')\"\"\"\n\n    view_id = self._convert_view_id(view_id)\n\n    # get or create\n    view = self.get_view(view_id)\n    containing_notebook = getattr(view, \"containing_notebook\", None)\n\n    if hasattr(view, \"before_show\") and view.before_show() == False:  # type: ignore\n        return False\n\n    if containing_notebook is None:\n        nb_name, notebook = self._get_view_notebook_name_and_instance(view_id)\n        label = None\n        if hasattr(view, \"get_tab_text\"):\n            label = view.get_tab_text()\n        if not label:\n            label = self._view_records[view_id][\"label\"]\n        logger.info(\"Adding view %r to notebook %s\", view, notebook)\n\n        # Compute the position among current visible views in this notebook\n        nb_view_order: List[str] = self.get_option(\"layout.notebook_\" + nb_name + \".views\")\n        visible_nb_views = []\n        for page in notebook.pages:\n            other_view_id = getattr(page.content, \"view_id\", None)\n            if other_view_id is not None:\n                visible_nb_views.append(other_view_id)\n\n        assert view_id not in visible_nb_views\n        assert view_id in nb_view_order\n\n        visible_on_the_left = 0\n        for visible_view_id in visible_nb_views:\n            if nb_view_order.index(visible_view_id) < nb_view_order.index(view_id):\n                visible_on_the_left += 1\n            else:\n                break\n\n        if visible_on_the_left == len(notebook.pages):\n            notebook.add(view, text=label)\n        else:\n            notebook.insert(visible_on_the_left, view, text=label)\n\n        if hasattr(view, \"on_show\"):\n            view.on_show()\n\n    # switch to the tab\n    view.containing_notebook.select(view)  # type: ignore\n\n    # add focus\n    if set_focus:\n        view.focus_set()\n\n    return view", "loc": 58}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "hide_view", "parameters": ["self", "view_id"], "param_types": {"view_id": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["view.containing_notebook.forget"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def hide_view(self, view_id: str) -> None:\n    if \"instance\" in self._view_records[view_id]:\n        view = self._view_records[view_id][\"instance\"]\n        if view.containing_notebook is None:\n            # Already hidden\n            return\n\n        view.containing_notebook.forget(view)", "loc": 8}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "event_generate", "parameters": ["self", "sequence", "event"], "param_types": {"sequence": "str", "event": "Any"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "WorkbenchEvent", "event.update", "handler", "isinstance", "self._event_handlers[sequence].copy", "self._update_toolbar", "self.report_exception", "sequence.startswith", "sorted", "tk.Tk.event_generate", "type"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Uses custom event handling when sequence doesn't start with <. In this case arbitrary attributes can be added to the event. Otherwise forwards the call to Tk's event_generate", "source_code": "def event_generate(self, sequence: str, event: Any = None, **kwargs) -> None:\n    \"\"\"Uses custom event handling when sequence doesn't start with <.\n    In this case arbitrary attributes can be added to the event.\n    Otherwise forwards the call to Tk's event_generate\"\"\"\n    # pylint: disable=arguments-differ\n    if sequence.startswith(\"<\"):\n        assert event is None\n        tk.Tk.event_generate(self, sequence, **kwargs)\n    else:\n        if sequence in self._event_handlers:\n            if event is None:\n                event = WorkbenchEvent(sequence, **kwargs)\n            elif kwargs:\n                if isinstance(event, (Record, Dict)):\n                    event.update(kwargs)\n                else:\n                    raise ValueError(f\"Can't update {type(event)} with kwargs\")\n\n            # make a copy of handlers, so that event handler can remove itself\n            # from the registry during iteration\n            # (or new handlers can be added)\n            for handler in sorted(self._event_handlers[sequence].copy(), key=str):\n                try:\n                    handler(event)\n                except Exception:\n                    self.report_exception(\"Problem when handling '\" + sequence + \"'\")\n\n    if not self._closing:\n        self._update_toolbar()", "loc": 29}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "bind", "parameters": ["self", "sequence", "func", "add"], "param_types": {"sequence": "str", "func": "Callable", "add": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Workbench.bind({}, ..., add={}) -- did you really want to replace existing bindings?'.format", "logger.warning", "self._event_handlers[sequence].add", "sequence.startswith", "set", "tk.Tk.bind"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Uses custom event handling when sequence doesn't start with <. Otherwise forwards the call to Tk's bind", "source_code": "def bind(self, sequence: str, func: Callable, add: bool = None) -> None:  # type: ignore\n    \"\"\"Uses custom event handling when sequence doesn't start with <.\n    Otherwise forwards the call to Tk's bind\"\"\"\n    # pylint: disable=signature-differs\n\n    if not add:\n        logger.warning(\n            \"Workbench.bind({}, ..., add={}) -- did you really want to replace existing bindings?\".format(\n                sequence, add\n            )\n        )\n\n    if sequence.startswith(\"<\"):\n        tk.Tk.bind(self, sequence, func, add)\n    else:\n        if sequence not in self._event_handlers or not add:\n            self._event_handlers[sequence] = set()\n\n        self._event_handlers[sequence].add(func)", "loc": 19}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "unbind", "parameters": ["self", "sequence", "func"], "param_types": {"sequence": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.exception", "self._event_handlers[sequence].remove", "sequence.startswith", "tk.Tk.unbind"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unbind(self, sequence: str, func=None) -> None:\n    # pylint: disable=arguments-differ\n    if sequence.startswith(\"<\"):\n        tk.Tk.unbind(self, sequence, funcid=func)\n    else:\n        try:\n            self._event_handlers[sequence].remove(func)\n        except Exception:\n            logger.exception(\"Can't remove binding for '%s' and '%s'\", sequence, func)", "loc": 9}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "in_heap_mode", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._configuration_manager.has_option", "self.get_option"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def in_heap_mode(self) -> bool:\n    # TODO: add a separate command for enabling the heap mode\n    # untie the mode from HeapView\n\n    return self._configuration_manager.has_option(\"view.HeapView.visible\") and self.get_option(\n        \"view.HeapView.visible\"\n    )", "loc": 7}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "in_debug_mode", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["os.environ.get", "self.get_option"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def in_debug_mode(self) -> bool:\n    return os.environ.get(\"THONNY_DEBUG\", False) in [\n        \"1\",\n        1,\n        \"True\",\n        True,\n        \"true\",\n    ] or self.get_option(\"general.debug_mode\", False)", "loc": 8}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "update_fonts", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["max", "round", "self._compute_treeview_rowheight", "self._editor_notebook.update_appearance", "self._guard_font_size", "self.get_option", "self.get_ui_mode", "self.get_view", "shell.update_appearance", "style.configure", "tk_font.nametofont", "tk_font.nametofont('BoldEditorFont').configure", "tk_font.nametofont('BoldItalicEditorFont').configure", "tk_font.nametofont('EditorFont').configure", "tk_font.nametofont('ItalicEditorFont').configure", "tk_font.nametofont('SmallEditorFont').configure", "tk_font.nametofont('SmallLinkFont').configure", "tk_font.nametofont('TkDefaultFont').configure", "tk_font.nametofont('TkHeadingFont').configure", "tk_font.nametofont(io_name).configure", "ttk.Style"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_fonts(self) -> None:\n    editor_font_size = self._guard_font_size(self.get_option(\"view.editor_font_size\"))\n    editor_font_family = self.get_option(\"view.editor_font_family\")\n\n    io_font_size = self._guard_font_size(self.get_option(\"view.io_font_size\"))\n    io_font_family = self.get_option(\"view.io_font_family\")\n    for io_name in [\n        \"IOFont\",\n        \"BoldIOFont\",\n        \"UnderlineIOFont\",\n        \"ItalicIOFont\",\n        \"BoldItalicIOFont\",\n    ]:\n        tk_font.nametofont(io_name).configure(family=io_font_family, size=io_font_size)\n\n    try:\n        shell = self.get_view(\"ShellView\", create=False)\n    except Exception:\n        # shell may be not created yet\n        pass\n    else:\n        shell.update_appearance()\n\n    tk_font.nametofont(\"EditorFont\").configure(family=editor_font_family, size=editor_font_size)\n    tk_font.nametofont(\"SmallEditorFont\").configure(\n        family=editor_font_family, size=editor_font_size - 2\n    )\n    tk_font.nametofont(\"BoldEditorFont\").configure(\n        family=editor_font_family, size=editor_font_size\n    )\n    tk_font.nametofont(\"ItalicEditorFont\").configure(\n        family=editor_font_family, size=editor_font_size\n    )\n    tk_font.nametofont(\"BoldItalicEditorFont\").configure(\n        family=editor_font_family, size=editor_font_size\n    )\n\n    if self.get_ui_mode() == \"simple\":\n        default_size_factor = max(0.7, 1 - (editor_font_size - 10) / 25)\n        small_size_factor = max(0.6, 0.8 - (editor_font_size - 10) / 25)\n\n        tk_font.nametofont(\"TkDefaultFont\").configure(\n            size=round(editor_font_size * default_size_factor)\n        )\n        tk_font.nametofont(\"TkHeadingFont\").configure(\n            size=round(editor_font_size * default_size_factor)\n        )\n        tk_font.nametofont(\"SmallLinkFont\").configure(\n            size=round(editor_font_size * small_size_factor)\n        )\n\n    # Tk doesn't update Treeview row height properly, at least not in Linux Tk\n    style = ttk.Style()\n    style.configure(\"Treeview\", rowheight=self._compute_treeview_rowheight())\n\n    if self._editor_notebook is not None:\n        self._editor_notebook.update_appearance()", "loc": 57}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "show_options", "parameters": ["self", "page_key"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ConfigurationDialog", "dlg.select_page", "get_runner", "get_runner().restart_backend", "ui_utils.show_dialog"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_options(self, page_key=None):\n    dlg = ConfigurationDialog(self, self._configuration_pages)\n    if page_key:\n        dlg.select_page(page_key)\n\n    ui_utils.show_dialog(dlg)\n\n    if dlg.backend_restart_required:\n        get_runner().restart_backend(False)", "loc": 9}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "focus_get", "parameters": ["self"], "param_types": {}, "return_type": "Optional[tk.Widget]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["tk.Tk.focus_get"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def focus_get(self) -> Optional[tk.Widget]:\n    try:\n        return tk.Tk.focus_get(self)\n    except Exception:\n        # This may give error in Ubuntu\n        return None", "loc": 6}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "report_exception", "parameters": ["self", "title"], "param_types": {"title": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["issubclass", "logger.exception", "messagebox.showerror", "self.set_status_message", "str", "sys.exc_info", "type"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def report_exception(self, title: str = \"Internal error\") -> None:\n    logger.exception(title)\n    if tk._default_root and not self._closing:  # type: ignore\n        (typ, value, _) = sys.exc_info()\n        assert typ is not None\n        if issubclass(typ, UserError):\n            msg = str(value)\n            status_prefix = \"\"\n        else:\n            msg = f\"{str(value) or type(value)}\\nSee frontend.log for more details\"\n            status_prefix = \"INTERNAL ERROR: \"\n\n        try:\n            self.set_status_message(status_prefix + msg)\n            messagebox.showerror(\n                title,\n                msg,\n                parent=tk._default_root,\n            )\n        except Exception:\n            logger.exception(\"Could not show internal error\")", "loc": 21}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "become_active_window", "parameters": ["self", "force"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.focus_set", "running_on_linux", "self.after_idle", "self.attributes", "self.deiconify", "self.focus_set", "self.get_editor_notebook", "self.get_editor_notebook().get_current_editor", "self.iconify", "self.lift"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def become_active_window(self, force=True) -> None:\n    # Looks like at least on Windows all following is required\n    # for ensuring the window gets focus\n    # (deiconify, ..., iconify, deiconify)\n    self.deiconify()\n\n    if force:\n        self.attributes(\"-topmost\", True)\n        self.after_idle(self.attributes, \"-topmost\", False)\n        self.lift()\n\n        if not running_on_linux():\n            # http://stackoverflow.com/a/13867710/261181\n            self.iconify()\n            self.deiconify()\n\n    editor = self.get_editor_notebook().get_current_editor()\n    if editor is not None:\n        # This method is meant to be called when new file is opened, so it's safe to\n        # send the focus to the editor\n        editor.focus_set()\n    else:\n        self.focus_set()", "loc": 23}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "show_notebook_drop_targets", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["NotebookTabDropTarget", "dict", "ems_to_pixels", "self._notebook_drop_targets.append", "self._view_notebooks.items", "target.place"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_notebook_drop_targets(self):\n    from thonny.custom_notebook import NotebookTabDropTarget\n\n    if self._notebook_drop_targets:\n        # Already visible. Assuming the location and size of the Workbench hasn't changed during DND,\n        # so nothing to do.\n        return\n\n    positions = {\n        \"nw\": dict(relx=0.0, rely=0.0),\n        \"w\": dict(relx=0.0, rely=0.5),\n        \"sw\": dict(relx=0.0, rely=1.0),\n        \"s\": dict(relx=0.5, rely=1.0),\n        \"se\": dict(relx=1.0, rely=1.0),\n        \"e\": dict(relx=1.0, rely=0.5),\n        \"ne\": dict(relx=1.0, rely=0.0),\n    }\n\n    for key, nb in self._view_notebooks.items():\n        width = ems_to_pixels(3)\n        height = ems_to_pixels(8)\n        if key == \"s\":\n            width, height = height, width\n\n        target = NotebookTabDropTarget(master=self, notebook=nb, width=width, height=height)\n        pos = positions[key]\n        target.place(in_=self._main_pw, anchor=key, **pos)\n        self._notebook_drop_targets.append(target)", "loc": 28}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "hide_notebook_drop_targets", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["item.destroy"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def hide_notebook_drop_targets(self):\n    for item in self._notebook_drop_targets:\n        item.destroy()\n\n    self._notebook_drop_targets = []", "loc": 5}
{"file": "thonny\\thonny\\workbench.py", "class_name": "Workbench", "function_name": "select_another_tab", "parameters": ["self", "event"], "param_types": {"event": "tk.Event"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "nb.select_another_tab", "self.focus_get", "widget.nametowidget", "widget.winfo_parent"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_another_tab(self, event: tk.Event) -> Optional[str]:\n    # handles also Shift-Control-Tab\n    # needs to be bound here because Notebooks don't own their contents\n    widget = self.focus_get()\n    while widget is not None:\n        nb: CustomNotebook = getattr(widget, \"containing_notebook\", None)\n        if nb is not None:\n            return nb.select_another_tab(event)\n        else:\n            widget_name = widget.winfo_parent()\n            if widget_name and widget_name != \".\":\n                widget = widget.nametowidget(widget_name)\n\n    return None", "loc": 14}
{"file": "thonny\\thonny\\workbench.py", "class_name": null, "function_name": "try_choose_backend", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.literal_eval", "backend_conf.items", "get_runner", "get_runner().restart_backend", "isinstance", "self._backend_conf_variable.get", "self._backend_conf_variable.set", "self.get_editor_notebook", "self.get_editor_notebook().try_close_remote_files_from_another_machine", "self.set_option"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def try_choose_backend():\n    backend_conf, machine_id = ast.literal_eval(self._backend_conf_variable.get())\n    could_close = self.get_editor_notebook().try_close_remote_files_from_another_machine(\n        dialog_parent=self, new_machine_id=machine_id\n    )\n    if not could_close:\n        # the variable has been changed. Need to revert it\n        self._backend_conf_variable.set(value=self._last_active_backend_conf_variable_value)\n        return\n\n    assert isinstance(backend_conf, dict), \"backend conf is %r\" % backend_conf\n    for name, value in backend_conf.items():\n        self.set_option(name, value)\n    get_runner().restart_backend(False)", "loc": 14}
{"file": "thonny\\thonny\\workbench.py", "class_name": null, "function_name": "dispatch", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["handler", "logger.debug", "self.bell", "self.event_generate", "tester"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dispatch(event=None):\n    if not tester or tester():\n        denied = False\n        handler()\n    else:\n        denied = True\n        logger.debug(\"Command '\" + command_id + \"' execution denied\")\n        if bell_when_denied:\n            self.bell()\n\n    self.event_generate(\"UICommandDispatched\", command_id=command_id, denied=denied)", "loc": 11}
{"file": "thonny\\thonny\\workbench.py", "class_name": null, "function_name": "toggle_view_visibility", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.hide_view", "self.show_view", "visibility_var.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def toggle_view_visibility():\n    if visibility_var.get():\n        self.hide_view(view_id)\n    else:\n        self.show_view(view_id, True)", "loc": 5}
{"file": "thonny\\thonny\\workbench.py", "class_name": null, "function_name": "get_settings", "parameters": ["name"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["callable", "get_settings", "result[key].update", "self.report_exception", "settings"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_settings(name):\n    try:\n        parent, settings = self._syntax_themes[name]\n    except KeyError:\n        self.report_exception(\"Can't find theme '%s'\" % name)\n        return {}\n\n    if callable(settings):\n        settings = settings()\n\n    if parent is None:\n        return settings\n    else:\n        result = get_settings(parent)\n        for key in settings:\n            if key in result:\n                result[key].update(settings[key])\n            else:\n                result[key] = settings[key]\n        return result", "loc": 20}
{"file": "thonny\\thonny\\workbench.py", "class_name": null, "function_name": "update_visibility", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["frame.grid", "frame.grid_remove", "frame.winfo_ismapped", "visibility_var.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_visibility():\n    if visibility_var.get():\n        if not frame.winfo_ismapped():\n            frame.grid(row=0, column=col, sticky=\"nse\")\n    else:\n        if frame.winfo_ismapped():\n            frame.grid_remove()", "loc": 7}
{"file": "thonny\\thonny\\workbench.py", "class_name": null, "function_name": "on_click", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.set_option", "tk.messagebox.showinfo", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_click(event):\n    self.set_option(\"general.ui_mode\", \"regular\")\n    tk.messagebox.showinfo(\n        tr(\"Regular mode\"),\n        tr(\n            \"Configuration has been updated. \"\n            + \"Restart Thonny to start working in regular mode.\\n\\n\"\n            + \"(See 'Tools  Options  General' if you change your mind later.)\"\n        ),\n        master=self,\n    )", "loc": 11}
{"file": "thonny\\thonny\\workbench.py", "class_name": null, "function_name": "toolbar_handler", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["handler", "self._editor_notebook.focus_set", "self._update_toolbar", "self.focus_get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def toolbar_handler(*args):\n    handler()\n    self._update_toolbar()\n    if self.focus_get() == button:\n        # previously selected widget would be better candidate, but this is\n        # better than button\n        self._editor_notebook.focus_set()", "loc": 7}
{"file": "thonny\\thonny\\workbench.py", "class_name": null, "function_name": "dispatch_from_menu", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dispatch", "self.get_variable", "var.get", "var.set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dispatch_from_menu():\n    # I don't like that Tk menu toggles checkbutton variable\n    # automatically before calling the handler.\n    # So I revert the toggle before calling the actual handler.\n    # This way the handler doesn't have to worry whether it\n    # needs to toggle the variable or not, and it can choose to\n    # decline the toggle.\n    if flag_name is not None:\n        var = self.get_variable(flag_name)\n        var.set(not var.get())\n\n    dispatch(None)", "loc": 12}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "init_instructions_frame", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_style_configuration", "self.get_instructions", "self.get_large_padding", "self.instructions_frame.columnconfigure", "self.instructions_frame.grid", "self.instructions_frame.rowconfigure", "self.instructions_label.grid", "tk.Frame", "tk.Label"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def init_instructions_frame(self):\n    instructions = self.get_instructions()\n    # Aqua doesn't allow changing ttk.Frame background via theming\n    tip_background = get_style_configuration(\"Tip.TFrame\")[\"background\"]\n    tip_foreground = get_style_configuration(\"Tip.TLabel\")[\"foreground\"]\n\n    self.instructions_frame = tk.Frame(self, background=tip_background)\n    self.instructions_frame.grid(row=0, column=0, sticky=\"nsew\")\n    self.instructions_frame.rowconfigure(0, weight=1)\n    self.instructions_frame.columnconfigure(0, weight=1)\n\n    pad = self.get_large_padding()\n    self.instructions_label = tk.Label(\n        self,\n        background=tip_background,\n        text=instructions,\n        justify=\"left\",\n        foreground=tip_foreground,\n    )\n    self.instructions_label.grid(row=0, column=0, sticky=\"w\", padx=pad, pady=pad)", "loc": 20}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "init_action_frame", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["create_action_label", "ems_to_pixels", "get_menu_char", "get_style_configuration", "round", "running_on_mac_os", "self._cancel_button.grid", "self._current_action_label.grid", "self._menu_button.grid", "self._ok_button.grid", "self.action_frame.columnconfigure", "self.action_frame.grid", "self.get_action_text_max_length", "self.get_cancel_text", "self.get_large_padding", "self.get_ok_text", "self.get_small_padding", "self.has_action_menu", "tk.Menu", "ttk.Button", "ttk.Frame", "ttk.Progressbar"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def init_action_frame(self):\n    padding = self.get_large_padding()\n    intpad = self.get_small_padding()\n\n    self.action_frame = ttk.Frame(self)\n    self.action_frame.grid(row=2, column=0, sticky=\"nsew\")\n\n    self._progress_bar = ttk.Progressbar(\n        self.action_frame, length=ems_to_pixels(4), mode=\"indeterminate\"\n    )\n\n    self._current_action_label = create_action_label(\n        self.action_frame,\n        text=\"\",\n        width=round(self.get_action_text_max_length() * 1.1),\n        click_handler=self.toggle_log_frame,\n    )\n    self._current_action_label.grid(\n        row=1, column=2, sticky=\"we\", pady=padding, padx=(0, intpad)\n    )\n\n    self._menu_button = ttk.Button(\n        self.action_frame,\n        text=get_menu_char(),\n        command=self.post_action_menu,\n        # style=\"Toolbutton\"\n        width=3,\n    )\n    if self.has_action_menu():\n        self._menu_button.grid(column=3, row=1, pady=padding, padx=(0, intpad))\n\n    if running_on_mac_os():\n        menu_conf = {}\n    else:\n        menu_conf = get_style_configuration(\"Menu\")\n    self._action_menu = tk.Menu(self, tearoff=False, **menu_conf)\n\n    self._ok_button = ttk.Button(\n        self.action_frame,\n        text=self.get_ok_text(),\n        command=self.on_click_ok_button,\n        state=\"disabled\",\n        default=\"active\",\n    )\n    if not self._autostart:\n        self._ok_button.grid(column=4, row=1, pady=padding, padx=(0, intpad))\n\n    self._cancel_button = ttk.Button(\n        self.action_frame,\n        text=self.get_cancel_text(),\n        command=self.on_cancel,\n    )\n    self._cancel_button.grid(column=5, row=1, padx=(0, padding), pady=padding)\n\n    self.action_frame.columnconfigure(2, weight=1)", "loc": 55}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "post_action_menu", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._action_menu.delete", "self._action_menu.tk_popup", "self._menu_button.winfo_height", "self._menu_button.winfo_rootx", "self._menu_button.winfo_rooty", "self.populate_action_menu"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def post_action_menu(self) -> None:\n    self._action_menu.delete(0, \"end\")\n    post_x = self._menu_button.winfo_rootx()\n    post_y = self._menu_button.winfo_rooty() + self._menu_button.winfo_height()\n    self.populate_action_menu(self._action_menu)\n    self._action_menu.tk_popup(post_x, post_y)", "loc": 6}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "init_log_frame", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fixed_font.cget", "fixed_font.copy", "font.configure", "round", "self.get_initial_log_line_count", "self.get_large_padding", "self.log_frame.columnconfigure", "self.log_frame.rowconfigure", "self.log_text.grid", "tk.font.nametofont", "tktextext.TextFrame", "ttk.Frame"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def init_log_frame(self):\n    self.log_frame = ttk.Frame(self)\n    self.log_frame.columnconfigure(1, weight=1)\n    self.log_frame.rowconfigure(1, weight=1)\n    fixed_font = tk.font.nametofont(\"TkFixedFont\")\n    font = fixed_font.copy()\n    font.configure(size=round(fixed_font.cget(\"size\") * 0.8))\n    self.log_text = tktextext.TextFrame(\n        self.log_frame,\n        horizontal_scrollbar=False,\n        wrap=\"word\",\n        borderwidth=1,\n        height=self.get_initial_log_line_count(),\n        width=20,\n        font=font,\n        read_only=True,\n    )\n\n    padding = self.get_large_padding()\n    self.log_text.grid(row=1, column=1, sticky=\"nsew\", padx=padding, pady=(0, padding))", "loc": 20}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "update_ui", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._ok_button.configure", "self._work_events_queue.empty", "self._work_events_queue.get", "self.handle_work_event", "self.is_ready_for_work", "set_text_if_different", "tr"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_ui(self):\n    if self._state == \"closed\":\n        return\n\n    while not self._work_events_queue.empty():\n        self.handle_work_event(*self._work_events_queue.get())\n        if self._state == \"closed\":\n            return\n\n    if self._state == \"idle\":\n        if self.is_ready_for_work():\n            self._ok_button.configure(state=\"normal\")\n        else:\n            self._ok_button.configure(state=\"disabled\")\n    else:\n        self._ok_button.configure(state=\"disabled\")\n\n    if self._state == \"done\":\n        set_text_if_different(self._cancel_button, tr(\"Close\"))\n    else:\n        set_text_if_different(self._cancel_button, tr(\"Cancel\"))", "loc": 21}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.after_cancel", "self.destroy"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self):\n    self._state = \"closed\"\n    if self._update_scheduler is not None:\n        try:\n            self.after_cancel(self._update_scheduler)\n        except tk.TclError:\n            pass\n\n    self.destroy()", "loc": 9}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "toggle_log_frame", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.hide_log_frame", "self.log_frame.winfo_ismapped", "self.show_log_frame"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def toggle_log_frame(self, event=None):\n    if self.log_frame.winfo_ismapped():\n        self.hide_log_frame()\n    else:\n        self.show_log_frame()", "loc": 5}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "start_work_and_update_ui", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._progress_bar.start", "self.grid_progress_widgets", "self.start_work", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start_work_and_update_ui(self, event=None):\n    assert self._state == \"idle\"\n    if self.start_work() is not False:\n        self._state = \"working\"\n        self.success = False\n        self.grid_progress_widgets()\n        self._progress_bar[\"mode\"] = \"indeterminate\"\n        self._progress_bar.start()\n        if not self._current_action_label[\"text\"]:\n            self._current_action_label[\"text\"] = tr(\"Starting\") + \"...\"", "loc": 10}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "on_cancel", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.cancel_work", "self.close", "self.confirm_cancel", "self.confirm_leaving_while_cancelling"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_cancel(self, event=None):\n    if self._state in (\"idle\", \"done\"):\n        self.close()\n    elif self._state == \"cancelling\" and self.confirm_leaving_while_cancelling():\n        self.close()\n    elif self.confirm_cancel():\n        self.cancel_work()", "loc": 7}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "set_action_text_smart", "parameters": ["self", "text"], "param_types": {"text": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.get_action_text_max_length", "self.set_action_text", "text.strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Updates text above the progress bar. May be called from another thread.", "source_code": "def set_action_text_smart(self, text: str) -> None:\n    \"\"\"Updates text above the progress bar. May be called from another thread.\"\"\"\n    text = text.strip()\n    if not text:\n        return\n    if len(text) > self.get_action_text_max_length():\n        text = text[: self.get_action_text_max_length() - 3] + \"...\"\n    self.set_action_text(text)", "loc": 8}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "handle_work_event", "parameters": ["self", "type", "args"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._progress_bar.configure", "self._progress_bar.start", "self._progress_bar.stop", "self.log_text.text.direct_delete", "self.log_text.text.direct_insert", "self.log_text.text.see", "self.on_done", "set_text_if_different"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_work_event(self, type, args):\n    if type in (\"append\", \"replace\"):\n        text, stream_name = args\n        if type == \"replace\":\n            self.log_text.text.direct_delete(\"end-1c linestart\", \"end-1c\")\n        self.log_text.text.direct_insert(\"end\", text, (stream_name,))\n        self.log_text.text.see(\"end\")\n    elif type == \"action\":\n        set_text_if_different(self._current_action_label, args[0])\n    elif type == \"progress\":\n        value, maximum = args\n        if value is None or maximum is None:\n            if self._progress_bar[\"mode\"] != \"indeterminate\":\n                self._progress_bar[\"mode\"] = \"indeterminate\"\n                self._progress_bar.start()\n        else:\n            if self._progress_bar[\"mode\"] != \"determinate\":\n                self._progress_bar[\"mode\"] = \"determinate\"\n                self._progress_bar.stop()\n            self._progress_bar.configure(value=value, maximum=maximum)\n    elif type == \"done\":\n        self.on_done(args[0])", "loc": 22}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "WorkDialog", "function_name": "on_done", "parameters": ["self", "success"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._cancel_button.focus_set", "self._progress_bar.stop", "self.allow_new_work", "self.allow_single_success", "self.close", "self.log_frame.winfo_ismapped", "self.show_log_frame"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "NB! Don't call from non-ui thread!", "source_code": "def on_done(self, success):\n    \"\"\"NB! Don't call from non-ui thread!\"\"\"\n    self.success = success\n    if self.success and self.allow_single_success() or self._autostart:\n        self._state = \"done\"\n        self._cancel_button.focus_set()\n        self._cancel_button[\"default\"] = \"active\"\n        self._ok_button[\"default\"] = \"normal\"\n    else:\n        # allows trying again when failed or wasn't final action\n        self.allow_new_work()\n\n    self._progress_bar.stop()\n    # need to put to determinate mode, otherwise it looks half done\n    self._progress_bar[\"mode\"] = \"determinate\"\n    if self.success and self._autostart and not self.log_frame.winfo_ismapped():\n        self.close()\n\n    if not self.success:\n        self.show_log_frame()", "loc": 20}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "SubprocessDialog", "function_name": "start_subprocess", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start_subprocess(self):\n    if self._prepared_proc:\n        return self._prepared_proc\n    else:\n        raise RuntimeError(\"No process provided\")", "loc": 5}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "SubprocessDialog", "function_name": "start_work", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "logger.warning", "self._start_listening_current_proc", "self.append_text", "self.start_subprocess", "subprocess.list2cmdline"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start_work(self):\n    self._proc = self.start_subprocess()\n    if hasattr(self._proc, \"cmd\"):\n        try:\n            self.append_text(subprocess.list2cmdline(self._proc.cmd) + \"\\n\")\n        except:\n            logger.warning(\"Could not extract cmd (%s)\", self._proc.cmd)\n    self._start_listening_current_proc()", "loc": 8}
{"file": "thonny\\thonny\\workdlg.py", "class_name": "SubprocessDialog", "function_name": "cancel_work", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.error", "messagebox.showerror", "os.kill", "running_on_windows", "self._proc.kill", "self._proc.poll", "self._proc.wait", "str", "super", "super().cancel_work"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cancel_work(self):\n    super().cancel_work()\n    # try gently first\n    try:\n        try:\n            if running_on_windows():\n                os.kill(self._proc.pid, signal.CTRL_BREAK_EVENT)  # pylint: disable=no-member\n            else:\n                os.kill(self._proc.pid, signal.SIGINT)\n\n            self._proc.wait(2)\n        except subprocess.TimeoutExpired:\n            if self._proc.poll() is None:\n                # now let's be more concrete\n                self._proc.kill()\n    except OSError as e:\n        messagebox.showerror(\"Error\", \"Could not kill subprocess: \" + str(e), master=self)\n        logger.error(\"Could not kill subprocess\", exc_info=e)", "loc": 18}
{"file": "thonny\\thonny\\workdlg.py", "class_name": null, "function_name": "listen_stream", "parameters": ["stream_name"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "logger.debug", "self._check_set_action_text_from_output_line", "self._finish_process", "self.append_text", "setattr", "stream.readline"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def listen_stream(stream_name):\n    stream = getattr(self._proc, stream_name)\n    while True:\n        data = stream.readline()\n        self.append_text(data, stream_name)\n        self._check_set_action_text_from_output_line(data)\n        setattr(self, stream_name, getattr(self, stream_name) + data)\n        if data == \"\":\n            logger.debug(\"Finished reading %s\", stream_name)\n            break\n\n    if stream_name == \"stdout\":\n        self._finish_process()\n\n    logger.debug(\"Returning from reading %s\", stream_name)", "loc": 15}
{"file": "thonny\\thonny\\__init__.py", "class_name": null, "function_name": "report_time", "parameters": ["label"], "param_types": {"label": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "list", "logger.info", "set", "sorted", "sys.modules.keys", "time.time"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Method for finding unwarranted imports and delays.", "source_code": "def report_time(label: str) -> None:\n    \"\"\"\n    Method for finding unwarranted imports and delays.\n    \"\"\"\n    global _last_time, _last_module_count, _last_modules\n\n    if not REPORT_TIME:\n        return\n\n    log_modules = True\n\n    t = time.time()\n    mod_count = len(sys.modules)\n    mod_delta = mod_count - _last_module_count\n    if mod_delta > 0:\n        mod_info = f\"(+{mod_count - _last_module_count} modules)\"\n    else:\n        mod_info = \"\"\n    logger.info(\"TIME/MODS %s %s %s\", f\"{t - _last_time:.3f}\", label, mod_info)\n\n    if log_modules and mod_delta > 0:\n        current_modules = set(sys.modules.keys())\n        logger.info(\"NEW MODS %s\", list(sorted(current_modules - _last_modules)))\n        _last_modules = current_modules\n\n    _last_time = t\n    _last_module_count = mod_count", "loc": 27}
{"file": "thonny\\thonny\\__init__.py", "class_name": null, "function_name": "in_debug_mode", "parameters": [], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_read_configured_debug_mode", "os.environ.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def in_debug_mode() -> bool:\n    global _in_debug_mode\n    if _in_debug_mode is None:\n        _in_debug_mode = (\n            os.environ.get(\"THONNY_DEBUG\", False)\n            in [\n                \"1\",\n                1,\n                \"True\",\n                True,\n                \"true\",\n            ]\n        ) or _read_configured_debug_mode()\n\n    return _in_debug_mode", "loc": 15}
{"file": "thonny\\thonny\\__init__.py", "class_name": null, "function_name": "get_thonny_user_dir", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_compute_thonny_user_dir"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_thonny_user_dir() -> str:\n    global _thonny_user_dir\n    if _thonny_user_dir is None:\n        _thonny_user_dir = _compute_thonny_user_dir()\n    return _thonny_user_dir", "loc": 5}
{"file": "thonny\\thonny\\__init__.py", "class_name": null, "function_name": "set_logging_level", "parameters": ["level"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["choose_logging_level", "logging.getLogger", "logging.getLogger('thonny').setLevel"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_logging_level(level=None):\n    if level is None:\n        level = choose_logging_level()\n\n    logging.getLogger(\"thonny\").setLevel(level)", "loc": 5}
{"file": "thonny\\thonny\\__init__.py", "class_name": null, "function_name": "choose_logging_level", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["in_debug_mode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def choose_logging_level():\n    if in_debug_mode():\n        return logging.DEBUG\n    else:\n        return logging.INFO", "loc": 5}
{"file": "thonny\\thonny\\__init__.py", "class_name": null, "function_name": "get_profile", "parameters": [], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "sys.argv.index"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_profile() -> str:\n    try:\n        idx = sys.argv.index(\"--profile\")\n    except ValueError:\n        return \"default\"\n\n    if len(sys.argv) > idx + 1:\n        return sys.argv[idx + 1]\n\n    return \"default\"", "loc": 10}
{"file": "thonny\\thonny\\locale\\register_updates.py", "class_name": null, "function_name": "register_locale", "parameters": ["name"], "param_types": {"name": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "entry.msgstr.strip", "entry.msgstr.strip().replace", "fp.write", "input", "json.dump", "json.load", "msg.endswith", "open", "os.path.exists", "os.path.join", "polib.pofile", "print", "pyperclip.copy", "review_messages.append"], "control_structures": ["For", "If"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def register_locale(name: str) -> None:\n    print(f\"Processing {name}\")\n    po_path = os.path.join(locale_dir, name, \"LC_MESSAGES\", \"thonny.po\")\n    po = polib.pofile(po_path)\n\n    registered_path = os.path.join(locale_dir, name, \"LC_MESSAGES\", \"registered.json\")\n    if not os.path.exists(registered_path):\n        with open(registered_path, \"w\", encoding=\"utf-8\") as fp:\n            fp.write(\"{}\")\n\n    with open(registered_path, encoding=\"utf-8\") as fp:\n        registered = json.load(fp)\n\n    new_registered = {}\n\n    review_messages = []\n\n    for entry in po:\n        if entry.msgstr and (\n            entry.msgid not in registered or registered[entry.msgid] != entry.msgstr\n        ):\n            msg = entry.msgstr.strip().replace(\"\\n\", \" \")\n            if not msg.endswith(\".\"):\n                msg = msg + \".\"\n\n            review_messages.append(msg)\n\n        if entry.msgstr:\n            new_registered[entry.msgid] = entry.msgstr\n\n    if review_messages:\n        print(\"\\n\".join(review_messages))\n        pyperclip.copy(\"\\n\".join(review_messages))\n\n        input(f\"... Press ENTER to confirm {name}! ...\")\n\n    with open(registered_path, \"w\", encoding=\"utf-8\") as fp:\n        json.dump(new_registered, fp, sort_keys=True, indent=4, ensure_ascii=False)\n\n    print(\"--------------------------------------\")", "loc": 40}
{"file": "thonny\\thonny\\plugins\\about.py", "class_name": "AboutDialog", "function_name": "get_os_word_size_suffix", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["platform.machine"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_os_word_size_suffix(self):\n    if \"32\" in platform.machine() and \"64\" not in platform.machine():\n        return \" (32-bit)\"\n    else:\n        return \"\"", "loc": 5}
{"file": "thonny\\thonny\\plugins\\assistant_config_page.py", "class_name": "AssistantConfigPage", "function_name": "apply", "parameters": ["self", "changed_options"], "param_types": {"changed_options": "List[str]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["disabled_checks_str.splitlines", "get_workbench", "get_workbench().set_option", "self.disabled_checks_box.text.get", "self.disabled_checks_box.text.get('1.0', 'end').replace", "self.disabled_checks_box.text.get('1.0', 'end').replace('\\r', '').replace", "self.disabled_checks_box.text.get('1.0', 'end').replace('\\r', '').replace('\"', '').replace", "self.disabled_checks_box.text.get('1.0', 'end').replace('\\r', '').replace('\"', '').replace(\"'\", '').strip"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def apply(self, changed_options: List[str]) -> bool:\n    disabled_checks_str = (\n        self.disabled_checks_box.text.get(\"1.0\", \"end\")\n        .replace(\"\\r\", \"\")\n        .replace('\"', \"\")\n        .replace(\"'\", \"\")\n        .strip()\n    )\n    get_workbench().set_option(\"assistance.disabled_checks\", disabled_checks_str.splitlines())\n\n    return True", "loc": 11}
{"file": "thonny\\thonny\\plugins\\ast_view.py", "class_name": null, "function_name": "pretty", "parameters": ["node", "key", "level"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n'.join", "ast.iter_fields", "enumerate", "fields.remove", "getattr", "hasattr", "isinstance", "len", "list", "pretty", "repr", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Used for exporting ASTView content", "source_code": "def pretty(node, key=\"/\", level=0):\n    \"\"\"Used for exporting ASTView content\"\"\"\n    if isinstance(node, ast.AST):\n        fields = list(ast.iter_fields(node))\n        value_label = node.__class__.__name__\n        if isinstance(node, ast.Call):\n            # Try to make 3.4 AST-s more similar to 3.5\n            if sys.version_info[:2] == (3, 4):\n                if (\"kwargs\", None) in fields:\n                    fields.remove((\"kwargs\", None))\n                if (\"starargs\", None) in fields:\n                    fields.remove((\"starargs\", None))\n\n            # TODO: translate also non-None kwargs and starargs\n\n    elif isinstance(node, list):\n        fields = list(enumerate(node))\n        if len(node) == 0:\n            value_label = \"[]\"\n        else:\n            value_label = \"[...]\"\n    else:\n        fields = []\n        value_label = repr(node)\n\n    item_text = level * \"    \" + str(key) + \"=\" + value_label\n\n    if hasattr(node, \"lineno\"):\n        item_text += \" @ \" + str(getattr(node, \"lineno\"))\n        if hasattr(node, \"col_offset\"):\n            item_text += \".\" + str(getattr(node, \"col_offset\"))\n\n        if hasattr(node, \"end_lineno\"):\n            item_text += \"  -  \" + str(getattr(node, \"end_lineno\"))\n            if hasattr(node, \"end_col_offset\"):\n                item_text += \".\" + str(getattr(node, \"end_col_offset\"))\n\n    lines = [item_text] + [\n        pretty(field_value, field_key, level + 1) for field_key, field_value in fields\n    ]\n\n    return \"\\n\".join(lines)", "loc": 42}
{"file": "thonny\\thonny\\plugins\\autocomplete.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Completer", "get_runner", "get_workbench", "get_workbench().add_command", "get_workbench().set_default", "runner.is_running", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    completer = Completer()\n\n    def can_complete():\n        runner = get_runner()\n        return runner and not runner.is_running()\n\n    get_workbench().add_command(\n        \"autocomplete\",\n        \"edit\",\n        tr(\"Auto-complete\"),\n        completer.request_completions,\n        default_sequence=\"<Control-space>\",\n        tester=can_complete,\n    )\n\n    get_workbench().set_default(\"edit.tab_request_completions_in_editors\", False)\n    get_workbench().set_default(\"edit.tab_request_completions_in_shell\", True)\n    get_workbench().set_default(\"edit.automatic_completions\", False)\n    get_workbench().set_default(\"edit.automatic_completion_details\", True)\n\n    CodeViewText.perform_midline_tab = completer.patched_perform_midline_tab\n    ShellText.perform_midline_tab = completer.patched_perform_midline_tab", "loc": 23}
{"file": "thonny\\thonny\\plugins\\autocomplete.py", "class_name": "CompletionsBox", "function_name": "present_completions", "parameters": ["self", "text", "completions"], "param_types": {"text": "SyntaxText", "completions": "List[lsp_types.CompletionItem]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["comp.label.startswith", "editor_helpers.get_cursor_position", "get_workbench", "get_workbench().event_generate", "isinstance", "label.lower", "label.lower().startswith", "label.startswith", "len", "min", "prefix.lower", "prefix.startswith", "print", "round", "self._check_bind_for_keypress", "self._check_request_details", "self._find_completion_insertion_index", "self._listbox.activate", "self._listbox.bbox", "self._listbox.delete", "self._listbox.insert", "self._listbox.selection_set", "self._listbox.size", "self._show_on_target_text", "self._target_text_widget.compare", "self._target_text_widget.get", "self.hide", "sorted", "text.get_current_column_ls_offset", "text.get_current_line_ls_offset"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def present_completions(\n    self, text: SyntaxText, completions: List[lsp_types.CompletionItem]\n) -> None:\n    # Next events need to know this\n    assert completions\n    self._target_text_widget = text\n    self._check_bind_for_keypress(text)\n\n    prefix_start_index = self._find_completion_insertion_index()\n    assert self._target_text_widget.compare(prefix_start_index, \"<=\", \"insert\")\n    prefix = self._target_text_widget.get(prefix_start_index, \"insert\")\n\n    def sort_key(completion: lsp_types.CompletionItem):\n        sort_text = completion.sortText or completion.label\n        label = completion.label\n        print(f\"{prefix=!r}, {label=!r}, {sort_text=!r}\")\n\n        if not prefix:\n            return (2 if label.startswith(\"_\") else 1, sort_text, label)\n        elif label.startswith(prefix):\n            return (1, sort_text, label)\n        elif label.lower().startswith(prefix.lower()):\n            return (2, sort_text, label)\n        else:\n            return (4 if label.startswith(\"_\") else 3, sort_text, label)\n\n    sorted_completions = sorted(completions, key=sort_key)\n    if not prefix.startswith(\"__\"):\n        sorted_completions = [\n            comp\n            for comp in sorted_completions\n            if not comp.label.startswith(\"__\")\n            and comp.textEdit is None  # TODO: support textEdit\n            and not comp.additionalTextEdits  # TODO: support this\n        ]\n    self._completions = sorted_completions\n\n    # broadcast logging info\n    row, column = editor_helpers.get_cursor_position(text)\n    if isinstance(text, ShellText):\n        row -= text.get_current_line_ls_offset()\n        column -= text.get_current_column_ls_offset()\n\n    get_workbench().event_generate(\n        \"AutocompleteProposal\",\n        text_widget=text,\n        row=row,\n        column=column,\n        proposal_count=len(sorted_completions),\n    )\n\n    # present\n    if len(sorted_completions) == 0:\n        self.hide()\n        return\n\n    self._listbox.delete(0, self._listbox.size())\n    self._listbox.insert(0, *[c.label for c in sorted_completions])\n    self._listbox.activate(0)\n    self._listbox.selection_set(0)\n\n    max_visible_items = 10\n    self._listbox[\"height\"] = min(len(sorted_completions), max_visible_items)\n\n    _, _, _, list_row_height = self._listbox.bbox(0)\n    # the measurement is not accurate, but good enough for deciding whether\n    # the box should be above or below the current line.\n    # Actual placement will be managed otherwise\n    approx_box_height = round(list_row_height * (self._listbox[\"height\"] + 0.5))\n\n    name_start_index = self._find_completion_insertion_index()\n\n    self._show_on_target_text(name_start_index, approx_box_height, \"below\")\n\n    self._check_request_details()", "loc": 75}
{"file": "thonny\\thonny\\plugins\\autocomplete.py", "class_name": "CompletionsBox", "function_name": "tweak_first_appearance", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["running_on_mac_os", "self._listbox.grid", "self._listbox.grid_remove", "self.update", "super", "super().tweak_first_appearance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def tweak_first_appearance(self):\n    super().tweak_first_appearance()\n    if running_on_mac_os():\n        self.update()\n        self._listbox.grid_remove()\n        self._listbox.grid()", "loc": 6}
{"file": "thonny\\thonny\\plugins\\autocomplete.py", "class_name": "CompletionsBox", "function_name": "request_details", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CompletionsDetailsBox", "get_workbench", "get_workbench().get_main_language_server_proxy", "ls_proxy.request_resolve_completion_item", "ls_proxy.unbind_request_handler", "self._details_box.set_content", "self._get_current_completion", "self._show_next_to_completions"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_details(self) -> None:\n    completion = self._get_current_completion()\n\n    if not self._details_box:\n        self._details_box = CompletionsDetailsBox(self)\n\n    self._details_box.set_content(completion)\n\n    ls_proxy = get_workbench().get_main_language_server_proxy()\n    if ls_proxy is not None:\n        # TODO: cancel previous request\n        ls_proxy.unbind_request_handler(self._handle_details_response)\n        ls_proxy.request_resolve_completion_item(completion, self._handle_details_response)\n\n    self._show_next_to_completions()", "loc": 15}
{"file": "thonny\\thonny\\plugins\\autocomplete.py", "class_name": "Completer", "function_name": "request_completions", "parameters": ["self", "event"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor_helpers.get_active_text_widget", "get_workbench", "get_workbench().bell", "self._box_is_visible", "self._completions_box.request_details", "self.request_completions_for_text"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_completions(self, event=None) -> None:\n    if self._box_is_visible():\n        self._completions_box.request_details()\n        return\n\n    text = editor_helpers.get_active_text_widget()\n    if text:\n        self.request_completions_for_text(text)\n    else:\n        get_workbench().bell()", "loc": 10}
{"file": "thonny\\thonny\\plugins\\autocomplete.py", "class_name": "Completer", "function_name": "cancel_active_request", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_main_language_server_proxy", "ls_proxy.unbind_request_handler"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cancel_active_request(self) -> None:\n    ls_proxy = get_workbench().get_main_language_server_proxy()\n    if ls_proxy is not None:\n        # TODO: actually cancel\n        ls_proxy.unbind_request_handler(self._handle_completions_response)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\autocomplete.py", "class_name": "Completer", "function_name": "request_completions_for_text", "parameters": ["self", "text"], "param_types": {"text": "SyntaxText"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CompletionParams", "TextDocumentIdentifier", "editor.get_text_widget", "editor.get_uri", "editor.send_changes_to_primed_servers", "editor_helpers.get_cursor_ls_position", "get_workbench", "get_workbench().get_editor_notebook", "get_workbench().get_editor_notebook().get_current_editor", "get_workbench().get_main_language_server_proxy", "isinstance", "logger.warning", "ls_proxy.request_completion", "ls_proxy.unbind_request_handler", "text.get_current_column_ls_offset", "text.get_current_line_ls_offset", "text.get_ls_uri", "text.send_changes_to_language_server"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_completions_for_text(self, text: SyntaxText) -> None:\n    ls_proxy = get_workbench().get_main_language_server_proxy()\n    if ls_proxy is None:\n        return\n\n    ls_proxy.unbind_request_handler(self._handle_completions_response)\n    # TODO: cancel last unhandled request\n\n    if isinstance(text, ShellText):\n        text.send_changes_to_language_server()\n        uri = text.get_ls_uri()\n        position = editor_helpers.get_cursor_ls_position(\n            text, text.get_current_line_ls_offset(), text.get_current_column_ls_offset()\n        )\n    else:\n        editor = get_workbench().get_editor_notebook().get_current_editor()\n        if editor.get_text_widget() is not text:\n            logger.warning(\"Unexpected completions request in %r\", text)\n            return\n\n        editor.send_changes_to_primed_servers()\n        uri = editor.get_uri()\n        position = editor_helpers.get_cursor_ls_position(text)\n\n    if uri is None:\n        # TODO:\n        return\n\n    self._last_request_text = text\n    ls_proxy.request_completion(\n        CompletionParams(textDocument=TextDocumentIdentifier(uri=uri), position=position),\n        self._handle_completions_response,\n    )", "loc": 33}
{"file": "thonny\\thonny\\plugins\\autocomplete.py", "class_name": "Completer", "function_name": "patched_perform_midline_tab", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "isinstance", "self.cancel_active_request", "self.request_completions_for_text", "text.has_selection", "text.is_python_text", "text.perform_dumb_tab"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def patched_perform_midline_tab(self, event):\n    self.cancel_active_request()\n\n    if not event or not isinstance(event.widget, SyntaxText):\n        return\n    text = event.widget\n\n    if text.is_python_text():\n        if isinstance(text, ShellText):\n            option_name = \"edit.tab_request_completions_in_shell\"\n        else:\n            option_name = \"edit.tab_request_completions_in_editors\"\n\n        if get_workbench().get_option(option_name):\n            if not text.has_selection():\n                self.request_completions_for_text(text)\n                return \"break\"\n            else:\n                return None\n\n    return text.perform_dumb_tab(event)", "loc": 21}
{"file": "thonny\\thonny\\plugins\\autocomplete.py", "class_name": null, "function_name": "sort_key", "parameters": ["completion"], "param_types": {"completion": "lsp_types.CompletionItem"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["label.lower", "label.lower().startswith", "label.startswith", "prefix.lower", "print"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def sort_key(completion: lsp_types.CompletionItem):\n    sort_text = completion.sortText or completion.label\n    label = completion.label\n    print(f\"{prefix=!r}, {label=!r}, {sort_text=!r}\")\n\n    if not prefix:\n        return (2 if label.startswith(\"_\") else 1, sort_text, label)\n    elif label.startswith(prefix):\n        return (1, sort_text, label)\n    elif label.lower().startswith(prefix.lower()):\n        return (2, sort_text, label)\n    else:\n        return (4 if label.startswith(\"_\") else 3, sort_text, label)", "loc": 13}
{"file": "thonny\\thonny\\plugins\\backend_config_page.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_command", "get_workbench().add_configuration_page", "get_workbench().show_options", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    def select_device():\n        get_workbench().show_options(\"interpreter\")\n\n    get_workbench().add_configuration_page(\n        \"interpreter\", tr(\"Interpreter\"), BackendConfigurationPage, 20\n    )\n    get_workbench().add_command(\n        \"select_interpreter\", \"run\", tr(\"Configure interpreter...\"), select_device, group=1\n    )", "loc": 10}
{"file": "thonny\\thonny\\plugins\\backend_config_page.py", "class_name": "TabbedBackendDetailsConfigurationPage", "function_name": "create_and_add_empty_page", "parameters": ["self", "caption", "weighty_column"], "param_types": {"caption": "str"}, "return_type": "ttk.Frame", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["page.columnconfigure", "self.get_tab_content_padding", "self.notebook.add", "ttk.Frame"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_and_add_empty_page(self, caption: str, weighty_column=1) -> ttk.Frame:\n    page = ttk.Frame(self.notebook, padding=self.get_tab_content_padding())\n    page.columnconfigure(weighty_column, weight=1)\n    self.notebook.add(page, text=caption)\n    return page", "loc": 5}
{"file": "thonny\\thonny\\plugins\\backend_config_page.py", "class_name": "TabbedBackendDetailsConfigurationPage", "function_name": "create_and_add_stubs_page", "parameters": ["self", "proxy_class"], "param_types": {"proxy_class": "type[BackendProxy]"}, "return_type": "ttk.Frame", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["StubsPipFrame", "self.get_tab_content_padding", "self.notebook.add", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_and_add_stubs_page(self, proxy_class: type[BackendProxy]) -> ttk.Frame:\n    from thonny.plugins.pip_gui import StubsPipFrame\n\n    page = StubsPipFrame(self.notebook, proxy_class, padding=self.get_tab_content_padding())\n    self.notebook.add(page, text=tr(\"Type stubs\"))\n    return page", "loc": 6}
{"file": "thonny\\thonny\\plugins\\backend_config_page.py", "class_name": "BackendConfigurationPage", "function_name": "apply", "parameters": ["self", "changed_options"], "param_types": {"changed_options": "List[str]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_editor_notebook", "get_workbench().get_editor_notebook().try_close_remote_files_from_another_machine", "getattr", "len", "logger.info", "logger.warning", "self._current_page.apply", "self._current_page.get_new_machine_id", "self._current_page.should_restart", "self.winfo_toplevel", "signature"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def apply(self, changed_options: List[str]) -> bool:\n    if self._current_page is None:\n        logger.warning(\"No current page\")\n        return True\n\n    result = self._current_page.apply(changed_options)\n\n    if result is False:\n        logger.info(\"Backend page %r responded False to apply\")\n        return False\n\n    # should_restart did not accept changed_options parameter before 5.0\n    from inspect import signature\n\n    if len(signature(self._current_page.should_restart).parameters) > 0:\n        should_restart_same_backend = self._current_page.should_restart(changed_options)\n    else:\n        should_restart_same_backend = self._current_page.should_restart()\n\n    if getattr(self._combo_variable, \"modified\") or should_restart_same_backend:\n        logger.info(\"Should restart\")\n\n        could_close = (\n            get_workbench()\n            .get_editor_notebook()\n            .try_close_remote_files_from_another_machine(\n                self.winfo_toplevel(), self._current_page.get_new_machine_id()\n            )\n        )\n\n        if not could_close:\n            logger.info(\"Can't apply because of open remote files of wrong machine\")\n            return False\n\n        self.dialog.backend_restart_required = True\n    else:\n        logger.info(\"Should not restart\")\n\n    return True", "loc": 39}
{"file": "thonny\\thonny\\plugins\\backend_config_page.py", "class_name": "BaseSshProxyConfigPage", "function_name": "apply", "parameters": ["self", "changed_options"], "param_types": {"changed_options": "List[str]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["delete_stored_ssh_password", "get_workbench", "get_workbench().set_option", "self.should_restart"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def apply(self, changed_options: List[str]) -> bool:\n    if self.should_restart(changed_options):\n        delete_stored_ssh_password()\n        # reset cwd setting to default\n        get_workbench().set_option(self.backend_name + \".cwd\", \"\")\n\n    return True", "loc": 7}
{"file": "thonny\\thonny\\plugins\\backend_config_page.py", "class_name": "BaseSshProxyConfigPage", "function_name": "should_restart", "parameters": ["self", "changed_options"], "param_types": {"changed_options": "List[str]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def should_restart(self, changed_options: List[str]):\n    for option in [\n        self.backend_name + \".host\",\n        self.backend_name + \".user\",\n        self.backend_name + \".auth_method\",\n        self.backend_name + \".executable\",\n    ]:\n        if option in changed_options:\n            return True\n    return False", "loc": 10}
{"file": "thonny\\thonny\\plugins\\base_syntax_themes.py", "class_name": null, "function_name": "default_sepia", "parameters": [], "param_types": {}, "return_type": "SyntaxThemeSettings", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["deepcopy", "default_light"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def default_sepia() -> SyntaxThemeSettings:\n    from copy import deepcopy\n\n    result = deepcopy(default_light())\n    result[\"TEXT\"][\"background\"] = \"#F7F6F0\"\n    result[\"GUTTER\"][\"background\"] = \"#E9E8DC\"\n    result[\"current_line\"][\"background\"] = \"#efeee8\"\n    result[\"unclosed_expression\"][\"background\"] = \"#d6d5cf\"\n    return result", "loc": 9}
{"file": "thonny\\thonny\\plugins\\base_syntax_themes.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_syntax_theme", "get_workbench().get_default_syntax_theme", "get_workbench().set_default"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    get_workbench().add_syntax_theme(\"Default Light\", None, default_light)\n    get_workbench().add_syntax_theme(\"Default Sepia\", None, default_sepia)\n    get_workbench().add_syntax_theme(\"Default Dark\", None, default_dark)\n    get_workbench().add_syntax_theme(\"Default Dark Green\", \"Default Dark\", default_dark_green)\n    get_workbench().add_syntax_theme(\"Default Dark Blue\", \"Default Dark\", default_dark_blue)\n    get_workbench().add_syntax_theme(\"Desert Sunset\", \"Default Dark\", desert_sunset)\n    get_workbench().add_syntax_theme(\"Zenburn\", \"Default Dark\", zenburn)\n    get_workbench().add_syntax_theme(\"IDLE Classic\", \"Default Light\", idle_classic)\n\n    # Comments in IDLE Dark really hurt the eyes\n    # get_workbench().add_syntax_theme(\"IDLE Dark\", \"Default Dark\", idle_dark)\n\n    get_workbench().set_default(\"view.syntax_theme\", get_workbench().get_default_syntax_theme())", "loc": 14}
{"file": "thonny\\thonny\\plugins\\base_ui_themes.py", "class_name": null, "function_name": "windows", "parameters": [], "param_types": {}, "return_type": "CompoundUiThemeSettings", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_button_notebook_settings", "_link_settings", "_menu_settings", "_menubutton_settings", "_paned_window_settings", "_text_settings", "_treeview_settings", "scale", "vista"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def windows() -> CompoundUiThemeSettings:\n    tip_background = \"#bbbbbb\"\n    return [\n        vista(),\n        _treeview_settings(),\n        _menubutton_settings(),\n        _paned_window_settings(),\n        _menu_settings(),\n        _text_settings(),\n        _link_settings(),\n        _button_notebook_settings(),\n        {\n            \"Tip.TLabel\": {\"configure\": {\"background\": tip_background, \"foreground\": \"black\"}},\n            \"Tip.TFrame\": {\"configure\": {\"background\": tip_background}},\n        },\n        {\n            \"TNotebook\": {\n                \"configure\": {\n                    # With tabmargins I can get a gray line below tab, which separates\n                    # tab content from label\n                    \"tabmargins\": [scale(2), scale(2), scale(2), scale(2)]\n                }\n            },\n            \"Tab\": {\"configure\": {\"padding\": [scale(3), scale(1), scale(3), 0]}},\n            \"ButtonNotebook.TNotebook.Tab\": {\n                \"configure\": {\"padding\": (scale(4), scale(1), scale(1), 0)}\n            },\n            \"TCombobox\": {\n                \"map\": {\n                    \"selectbackground\": [\n                        (\"readonly\", \"!focus\", \"SystemWindow\"),\n                        (\"readonly\", \"focus\", \"SystemHighlight\"),\n                    ],\n                    \"selectforeground\": [\n                        (\"readonly\", \"!focus\", \"SystemWindowText\"),\n                        (\"readonly\", \"focus\", \"SystemHighlightText\"),\n                    ],\n                }\n            },\n            \"Listbox\": {\n                \"configure\": {\n                    \"background\": \"SystemWindow\",\n                    \"foreground\": \"SystemWindowText\",\n                    \"disabledforeground\": \"SystemGrayText\",\n                    \"highlightbackground\": \"SystemActiveBorder\",\n                    \"highlightcolor\": \"SystemActiveBorder\",\n                    \"highlightthickness\": 0,\n                }\n            },\n            \"ViewBody.TFrame\": {\n                \"configure\": {\n                    \"background\": \"SystemButtonFace\"  # to create the fine line below toolbar\n                }\n            },\n            \"ViewToolbar.TFrame\": {\"configure\": {\"background\": \"SystemWindow\"}},\n            \"ViewToolbar.Toolbutton\": {\"configure\": {\"background\": \"SystemWindow\"}},\n            \"ViewTab.TLabel\": {\n                \"configure\": {\"background\": \"SystemWindow\", \"padding\": [scale(5), 0]}\n            },\n            \"ViewToolbar.TLabel\": {\n                \"configure\": {\"background\": \"SystemWindow\", \"padding\": [scale(5), 0]}\n            },\n            \"ViewToolbar.Link.TLabel\": {\n                \"configure\": {\"background\": \"SystemWindow\", \"padding\": [scale(5), 0]}\n            },\n            \"Active.ViewTab.TLabel\": {\n                \"configure\": {\n                    # \"font\" : \"BoldTkDefaultFont\",\n                    \"relief\": \"sunken\",\n                    \"borderwidth\": scale(1),\n                }\n            },\n            \"Inactive.ViewTab.TLabel\": {\"map\": {\"relief\": [(\"hover\", \"raised\")]}},\n            \"CustomToolbutton\": {\n                \"configure\": {\n                    \"background\": \"systemButtonFace\",\n                    \"activebackground\": \"#dadada\",\n                    \"foreground\": \"SystemWindowText\",\n                }\n            },\n            \"CustomNotebook\": {\n                \"configure\": {\n                    \"bordercolor\": \"system3dLight\",\n                }\n            },\n            \"CustomNotebook.Tab\": {\n                \"configure\": {\n                    \"background\": \"systemButtonFace\",\n                    \"activebackground\": \"systemWindow\",\n                    \"hoverbackground\": \"systemWindow\",\n                    #                    \"indicatorbackground\": \"systemHighlight\",\n                    \"indicatorbackground\": \"system3dLight\",\n                    \"indicatorheight\": 1,\n                }\n            },\n            \"TextPanedWindow\": {\"configure\": {\"background\": \"systemWindow\"}},\n        },\n    ]", "loc": 98}
{"file": "thonny\\thonny\\plugins\\base_ui_themes.py", "class_name": null, "function_name": "enhanced_clam", "parameters": [], "param_types": {}, "return_type": "CompoundUiThemeSettings", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_button_notebook_settings", "_link_settings", "_menu_settings", "_menubutton_settings", "_paned_window_settings", "_text_settings", "_treeview_settings", "clam", "scale"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def enhanced_clam() -> CompoundUiThemeSettings:\n    tip_background = \"#bab5ab\"\n    return [\n        clam(),\n        _treeview_settings(),\n        _menubutton_settings(),\n        _paned_window_settings(),\n        _menu_settings(),\n        _text_settings(),\n        _link_settings(),\n        {\n            \"Tip.TLabel\": {\"configure\": {\"background\": tip_background, \"foreground\": \"black\"}},\n            \"Tip.TFrame\": {\"configure\": {\"background\": tip_background}},\n        },\n        _button_notebook_settings(),\n        {\n            \"ButtonNotebook.Tab\": {\n                \"configure\": {\"padding\": (scale(6), scale(4), scale(2), scale(3))}\n            },\n            \"TScrollbar\": {\n                \"configure\": {\n                    \"gripcount\": 0,\n                    \"arrowsize\": scale(14),\n                    # \"arrowcolor\" : \"DarkGray\"\n                    # \"width\" : 99 # no effect\n                }\n            },\n            \"TCombobox\": {\n                \"configure\": {\"arrowsize\": scale(14)},\n                \"map\": {\n                    \"selectbackground\": [(\"readonly\", \"!focus\", \"#dcdad5\")],\n                    \"selectforeground\": [(\"readonly\", \"!focus\", \"#000000\")],\n                },\n            },\n            \"TCheckbutton\": {\"configure\": {\"indicatorsize\": scale(12)}},\n            \"TRadiobutton\": {\"configure\": {\"indicatorsize\": scale(12)}},\n            \"Listbox\": {\n                \"configure\": {\n                    \"background\": \"white\",\n                    \"foreground\": \"black\",\n                    \"disabledforeground\": \"#999999\",\n                    \"highlightbackground\": \"#4a6984\",\n                    \"highlightcolor\": \"#4a6984\",\n                    \"highlightthickness\": 0,\n                }\n            },\n            \"ViewTab.TLabel\": {\"configure\": {\"padding\": [scale(5), 0]}},\n            \"Active.ViewTab.TLabel\": {\n                \"configure\": {\n                    # \"font\" : \"BoldTkDefaultFont\",\n                    \"relief\": \"sunken\",\n                    \"borderwidth\": scale(1),\n                }\n            },\n            \"Inactive.ViewTab.TLabel\": {\"map\": {\"relief\": [(\"hover\", \"raised\")]}},\n            \"TextPanedWindow\": {\"configure\": {\"background\": \"white\"}},\n        },\n    ]", "loc": 58}
{"file": "thonny\\thonny\\plugins\\base_ui_themes.py", "class_name": null, "function_name": "enhanced_aqua", "parameters": [], "param_types": {}, "return_type": "CompoundUiThemeSettings", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_menu_settings", "_menubutton_settings", "scale"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def enhanced_aqua() -> CompoundUiThemeSettings:\n    return [\n        _menubutton_settings(),\n        # _paned_window_settings(),\n        _menu_settings(),\n        {\n            \"Tip.TLabel\": {\n                \"configure\": {\n                    \"background\": \"systemWindowBackgroundColor3\",\n                    \"foreground\": \"systemTextColor\",\n                }\n            },\n            \"Tip.TFrame\": {\"configure\": {\"background\": \"systemWindowBackgroundColor3\"}},\n        },\n        {\n            \"Text\": {\n                \"configure\": {\n                    \"background\": \"systemTextBackgroundColor\",\n                    \"foreground\": \"systemTextColor\",\n                }\n            },\n            \"Url.TLabel\": {\n                \"configure\": {\"foreground\": \"#003399\"}\n            },  # will be overridden by enhanced_aqua_dark_overrides\n            \"ViewToolbar.TFrame\": {\n                \"configure\": {\"background\": \"systemWindowBackgroundColor\"}\n            },  # TODO:\n            \"ViewToolbar.Toolbutton\": {\"configure\": {\"background\": \"systemWindowBackgroundColor\"}},\n            \"TPanedWindow\": {\"configure\": {\"background\": \"systemDialogBackgroundActive\"}},\n            \"TextPanedWindow\": {\"configure\": {\"background\": \"systemTextBackgroundColor\"}},\n            \"TFrame\": {\"configure\": {\"background\": \"systemDialogBackgroundActive\"}},\n            \"ViewTab.TLabel\": {\"configure\": {\"padding\": [scale(5), 0]}},\n            \"Tab\": {\"map\": {\"foreground\": [(\"selected\", \"systemSelectedTabTextColor\")]}},\n            \"Active.ViewTab.TLabel\": {\n                \"configure\": {\n                    # \"font\" : \"BoldTkDefaultFont\",\n                    \"relief\": \"sunken\",\n                    \"borderwidth\": scale(1),\n                }\n            },\n            \"Inactive.ViewTab.TLabel\": {\"map\": {\"relief\": [(\"hover\", \"raised\")]}},\n            \"TNotebook\": {\n                \"configure\": {\"tabmargins\": [10, 0], \"tabposition\": \"n\", \"padding\": [0, 0, 0, 0]}\n            },\n            \"CustomToolbutton\": {\n                \"configure\": {\n                    \"background\": \"systemWindowBackgroundColor\",\n                    \"activebackground\": \"systemWindowBackgroundColor3\",\n                    \"foreground\": \"systemLabelColor\",\n                }\n            },\n            \"CustomNotebook\": {\n                \"configure\": {\n                    \"bordercolor\": \"systemWindowBackgroundColor5\",\n                }\n            },\n            \"CustomNotebook.Tab\": {\n                \"configure\": {\n                    \"background\": \"systemWindowBackgroundColor\",\n                    \"activebackground\": \"systemWindowBackgroundColor\",\n                    \"hoverbackground\": \"systemWindowBackgroundColor3\",\n                    \"indicatorbackground\": \"systemWindowBackgroundColor\",\n                    \"dynamic_border\": 1,\n                }\n            },\n            \"Listbox\": {\n                \"configure\": {\n                    \"background\": \"SystemTextBackgroundColor\",\n                    \"foreground\": \"SystemTextColor\",\n                    \"selectbackground\": \"SystemSelectedTextBackgroundColor\",\n                    \"selectforeground\": \"SystemSelectedTextColor\",\n                }\n            },\n            \"TEntry\": {\n                \"map\": {\n                    \"background\": [(\"readonly\", \"systemWindowBackgroundColor\")],\n                },\n            },\n            \"Heading\": {\"configure\": {\"topmost_pixels_to_hide\": 2}},\n            \"Vertical.TScrollbar\": {\n                \"configure\": {\n                    \"rightmost_pixels_to_hide\": 1,\n                }\n            },\n        },\n    ]", "loc": 86}
{"file": "thonny\\thonny\\plugins\\base_ui_themes.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_ui_theme", "ttk.Style", "ttk.Style().theme_names"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    from tkinter import ttk\n\n    original_themes = ttk.Style().theme_names()\n\n    # load all base themes\n    for name in original_themes:\n        settings = {}  # type: Union[Dict, Callable[[], Dict]]\n        if name == \"clam\":\n            settings = clam\n        elif name == \"vista\":\n            settings = vista\n        elif name == \"aqua\":\n            settings = aqua\n\n        get_workbench().add_ui_theme(name, None, settings)\n\n    get_workbench().add_ui_theme(\n        \"Enhanced Clam\",\n        \"clam\",\n        enhanced_clam,\n    )\n\n    if \"vista\" in original_themes:\n        get_workbench().add_ui_theme(\"Windows\", \"vista\", windows)\n\n    if \"aqua\" in original_themes:\n        get_workbench().add_ui_theme(\"macOS\", \"aqua\", enhanced_aqua, enhanced_aqua_dark_overrides)", "loc": 28}
{"file": "thonny\\thonny\\plugins\\birdseye_frontend.py", "class_name": null, "function_name": "close_server", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_server_process.kill"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close_server():\n    if _server_process is not None:\n        try:\n            _server_process.kill()\n        except Exception:\n            pass", "loc": 6}
{"file": "thonny\\thonny\\plugins\\calltip.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Calltipper", "get_workbench", "get_workbench().add_command", "get_workbench().set_default", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    calltipper = Calltipper()\n\n    get_workbench().set_default(\"edit.automatic_calltips\", False)\n\n    get_workbench().add_command(\n        \"open_calltip\",\n        \"edit\",\n        tr(\"Show parameter info\"),\n        calltipper.request_calltip,\n        # TODO: tester\n        default_sequence=\"<<ShiftControlSpaceInText>>\",\n        accelerator=\"Ctrl-Shift-Space\",\n    )", "loc": 14}
{"file": "thonny\\thonny\\plugins\\calltip.py", "class_name": "CalltipBox", "function_name": "present_signatures", "parameters": ["self", "text", "signature_help"], "param_types": {"text": "SyntaxText", "signature_help": "SignatureHelp"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor_helpers.get_cursor_position", "ems_to_pixels", "isinstance", "max", "round", "self._check_bind_for_keypress", "self._show_on_target_text", "self.render_signature_help", "self.text.count", "self.text.direct_delete", "text.get_current_column_ls_offset", "text.get_current_line_ls_offset"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def present_signatures(self, text: SyntaxText, signature_help: SignatureHelp):\n    self._target_text_widget = text\n    self._check_bind_for_keypress(text)\n    self.text.direct_delete(\"1.0\", \"end\")\n    self.render_signature_help(signature_help)\n\n    char_count = self.text.count(\"1.0\", \"end\", \"chars\")[0]\n    extra_width_factor = 1.0\n    # NB! Width should be set here, not in update_size, so that it that on-screen\n    # height calculation already uses this\n    if char_count * extra_width_factor < self._max_width:\n        self.text[\"width\"] = max(round(char_count * extra_width_factor), 10)\n    else:\n        self.text[\"width\"] = self._max_width\n\n    self.text[\"height\"] = 3\n\n    expected_height = 10  # TODO\n    # call_bracket_start = ... # TODO\n    row, column = editor_helpers.get_cursor_position(text)\n    if isinstance(text, ShellText):\n        row -= text.get_current_line_ls_offset()\n        column -= text.get_current_column_ls_offset()\n\n    self._show_on_target_text(\n        \"%d.%d\" % (row, column),\n        expected_height,\n        \"above\",\n        y_offset=-ems_to_pixels(0.3),\n    )", "loc": 30}
{"file": "thonny\\thonny\\plugins\\calltip.py", "class_name": "CalltipBox", "function_name": "render_signature_help", "parameters": ["self", "signature_help"], "param_types": {"signature_help": "SignatureHelp"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enumerate", "self._append_chars", "self.render_signature"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def render_signature_help(self, signature_help: SignatureHelp) -> None:\n    for i, sig in enumerate(signature_help.signatures):\n        if i > 0:\n            self._append_chars(\"\\n\")\n        self.render_signature(\n            sig,\n            is_active=i == signature_help.activeSignature,\n            global_active_parameter=signature_help.activeParameter,\n        )", "loc": 9}
{"file": "thonny\\thonny\\plugins\\calltip.py", "class_name": "CalltipBox", "function_name": "render_signature", "parameters": ["self", "sig", "is_active", "global_active_parameter"], "param_types": {"sig": "SignatureInformation", "is_active": "bool", "global_active_parameter": "Optional[int]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self._append_chars"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def render_signature(\n    self, sig: SignatureInformation, is_active: bool, global_active_parameter: Optional[int]\n) -> None:\n    active_parameter = sig.activeParameter\n    if active_parameter is None:\n        active_parameter = global_active_parameter\n\n    if active_parameter is None or len(sig.parameters) <= active_parameter:\n        self._append_chars(sig.label)\n    else:\n        active_start, active_end = sig.parameters[active_parameter].label\n        self._append_chars(sig.label[:active_start])\n        self._append_chars(sig.label[active_start:active_end], tags=(\"active\",))\n        self._append_chars(sig.label[active_end:])", "loc": 14}
{"file": "thonny\\thonny\\plugins\\calltip.py", "class_name": "Calltipper", "function_name": "request_calltip", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_active_text_widget", "self.request_calltip_for_text"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_calltip(self) -> None:\n    text = get_active_text_widget()\n    if not text:\n        return\n    self.request_calltip_for_text(text)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\calltip.py", "class_name": "Calltipper", "function_name": "request_calltip_for_text", "parameters": ["self", "text"], "param_types": {"text": "SyntaxText"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SignatureHelpParams", "TextDocumentIdentifier", "editor.get_uri", "editor.send_changes_to_primed_servers", "editor_helpers.get_cursor_ls_position", "get_workbench", "get_workbench().get_main_language_server_proxy", "isinstance", "logger.warning", "ls_proxy.request_signature_help", "ls_proxy.unbind_request_handler", "text.get_current_column_ls_offset", "text.get_current_line_ls_offset", "text.get_ls_uri", "text.send_changes_to_language_server"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_calltip_for_text(self, text: SyntaxText) -> None:\n    ls_proxy = get_workbench().get_main_language_server_proxy()\n    if ls_proxy is None:\n        return\n\n    ls_proxy.unbind_request_handler(self.handle_response)\n\n    if isinstance(text, CodeViewText):\n        editor = text.master.master\n        assert isinstance(editor, Editor)\n\n        editor.send_changes_to_primed_servers()\n        uri = editor.get_uri()\n        position = editor_helpers.get_cursor_ls_position(text)\n    elif isinstance(text, ShellText):\n        text.send_changes_to_language_server()\n        uri = text.get_ls_uri()\n        position = editor_helpers.get_cursor_ls_position(\n            text, text.get_current_line_ls_offset(), text.get_current_column_ls_offset()\n        )\n\n    else:\n        logger.warning(\"Unexpected calltip request in %r\", text)\n        return\n\n    if uri is None:\n        # TODO:\n        return\n\n    self._last_request_text = text\n    ls_proxy.request_signature_help(\n        SignatureHelpParams(\n            textDocument=TextDocumentIdentifier(uri), position=position, context=None\n        ),\n        self.handle_response,\n    )\n    self._last_request_uri = uri\n    self._last_request_position = position", "loc": 38}
{"file": "thonny\\thonny\\plugins\\calltip.py", "class_name": "Calltipper", "function_name": "handle_response", "parameters": ["self", "response"], "param_types": {"response": "LspResponse[Optional[SignatureHelp]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CalltipBox", "editor.get_uri", "editor_helpers.get_cursor_ls_position", "get_workbench", "isinstance", "logger.info", "logger.warning", "messagebox.showerror", "response.get_error", "response.get_result_or_raise", "self._calltip_box.present_signatures", "self._hide_box", "self._last_request_text.get_current_column_ls_offset", "self._last_request_text.get_current_line_ls_offset", "self._last_request_text.get_ls_uri"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_response(self, response: LspResponse[Optional[SignatureHelp]]) -> None:\n    if not self._last_request_text:\n        logger.warning(\"SignatureHelp response without _last_request_text\")\n        return\n\n    if isinstance(self._last_request_text, CodeViewText):\n        editor = self._last_request_text.master.master\n        assert isinstance(editor, Editor)\n        uri = editor.get_uri()\n        position = editor_helpers.get_cursor_ls_position(self._last_request_text)\n    else:\n        assert isinstance(self._last_request_text, ShellText)\n        uri = self._last_request_text.get_ls_uri()\n        position = editor_helpers.get_cursor_ls_position(\n            self._last_request_text,\n            self._last_request_text.get_current_line_ls_offset(),\n            self._last_request_text.get_current_column_ls_offset(),\n        )\n\n    if uri != self._last_request_uri or position != self._last_request_position:\n        logger.warning(\"Got outdated SignatureHelp response: %r\", response)\n        return\n\n    if response.get_error():\n        self._hide_box()\n        messagebox.showerror(\n            \"Calltip error\", response.get_error().message, master=get_workbench()\n        )\n        return\n\n    result = response.get_result_or_raise()\n\n    if not result or not result.signatures:\n        logger.info(\"Server gave 0 signatures\")\n        self._hide_box()\n    else:\n        if not self._calltip_box:\n            self._calltip_box = CalltipBox(self)\n        self._calltip_box.present_signatures(self._last_request_text, result)", "loc": 39}
{"file": "thonny\\thonny\\plugins\\cells.py", "class_name": null, "function_name": "update_editor_cells", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cell_regex.finditer", "cells.append", "getattr", "match.end", "match.start", "text.compare", "text.get", "text.index", "text.tag_add", "text.tag_configure", "text.tag_lower", "text.tag_remove"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_editor_cells(event):\n    text = event.widget\n\n    if not getattr(text, \"cell_tags_configured\", False):\n        text.tag_configure(\"CURRENT_CELL\", borderwidth=1, relief=\"groove\", background=\"LightYellow\")\n        text.tag_configure(\"CELL_HEADER\", font=\"BoldEditorFont\", foreground=\"#665843\")\n\n        text.tag_lower(\"CELL_HEADER\")\n        text.tag_lower(\"CURRENT_CELL\")\n        text.cell_tags_configured = True\n\n    text.tag_remove(\"CURRENT_CELL\", \"0.1\", \"end\")\n    text.tag_remove(\"CELL_HEADER\", \"0.1\", \"end\")\n    source = text.get(\"1.0\", \"end\")\n    cells = []\n    prev_marker = 0\n    for match in cell_regex.finditer(source):\n        if match.start() == 0:\n            this_marker = match.start()\n        else:\n            this_marker = match.start() + 1\n\n        cell_start_index = text.index(\"1.0+%dc\" % prev_marker)\n        header_end_index = text.index(\"1.0+%dc\" % match.end())\n        cell_end_index = text.index(\"1.0+%dc\" % this_marker)\n        text.tag_add(\"CELL_HEADER\", cell_end_index, header_end_index)\n        cells.append((cell_start_index, cell_end_index))\n\n        prev_marker = this_marker\n\n    if prev_marker != 0:\n        cells.append((text.index(\"1.0+%dc\" % prev_marker), \"end\"))\n\n    # if get_workbench().focus_get() == text:\n    # It's nice to have cell highlighted even when focus\n    # is elsewhere ? This would act as kind of bookmark.\n\n    for start_index, end_index in cells:\n        if text.compare(start_index, \"<=\", \"insert\") and text.compare(end_index, \">\", \"insert\"):\n            text.tag_add(\"CURRENT_CELL\", start_index, end_index)\n            break", "loc": 41}
{"file": "thonny\\thonny\\plugins\\cells.py", "class_name": null, "function_name": "run_selection", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'{}.{}'.format", "_submit_code", "get_workbench", "get_workbench().focus_get", "isinstance", "map", "text.get", "text.has_selection", "text.index", "text.index('insert').split", "text.mark_set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run_selection(event=None):\n    widget = get_workbench().focus_get()\n    if isinstance(widget, CodeViewText):\n        text = widget\n\n        if text.has_selection():\n            code = text.get(\"sel.first\", \"sel.last\")\n        else:\n            code = text.get(\"insert linestart\", \"insert lineend\")\n\n        # move cursor to next row\n        row, col = map(int, text.index(\"insert\").split(\".\"))\n        text.mark_set(\"insert\", \"{}.{}\".format(row + 1, col))\n\n        _submit_code(code)", "loc": 15}
{"file": "thonny\\thonny\\plugins\\chat.py", "class_name": "ChatView", "function_name": "handle_assistant_chat_response_fragment", "parameters": ["self", "fragment_with_request_id"], "param_types": {"fragment_with_request_id": "ChatResponseFragmentWithRequestId"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChatMessage", "logger.info", "replace", "self._append_text", "self._chat_messages.append", "self._chat_messages.pop", "self._update_suggestions"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_assistant_chat_response_fragment(\n    self, fragment_with_request_id: ChatResponseFragmentWithRequestId\n) -> None:\n    if fragment_with_request_id.request_id != self._active_chat_request_id:\n        logger.info(\"Skipping chat fragment, because request has been cancelled\")\n        return\n\n    fragment = fragment_with_request_id.fragment\n    self._append_text(fragment.content, source=\"chat\")\n    last_msg = self._chat_messages.pop()\n    if last_msg.role == \"user\":\n        self._chat_messages.append(last_msg)\n        current_msg = ChatMessage(\"assistant\", \"\", [])\n    else:\n        current_msg = last_msg\n\n    current_msg = replace(current_msg, content=current_msg.content + fragment.content)\n    self._chat_messages.append(current_msg)\n    if fragment.is_final:\n        self._append_text(\"\\n\", source=\"chat\")\n        self._active_chat_request_id = None\n        self._update_suggestions()", "loc": 22}
{"file": "thonny\\thonny\\plugins\\chat.py", "class_name": "ChatView", "function_name": "submit_user_chat_message", "parameters": ["self", "message"], "param_types": {"message": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChatMessage", "message.rstrip", "self._append_text", "self._chat_messages.append", "self._current_assistant.format_attachments", "self._prepare_new_completion", "self._remove_suggestions", "self.compile_attachments", "self.query_text.delete", "self.select_assistants_for_user_message", "str", "threading.Thread", "threading.Thread(target=self._complete_chat_in_thread, daemon=True, args=(assistant, self._active_chat_request_id)).start", "uuid.uuid4"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def submit_user_chat_message(self, message: str):\n    self._remove_suggestions()\n    message = message.rstrip()\n    attachments, warnings = self.compile_attachments(message)\n    self._prepare_new_completion()\n\n    self._active_chat_request_id = str(uuid.uuid4())\n    self._append_text(\"\\n\")\n    self._append_text(message, tags=(\"user_message\",))\n    if attachments:\n        self._formatted_attachmets_per_message[self._active_chat_request_id] = (\n            self._current_assistant.format_attachments(attachments)\n        )\n        self._append_text(\n            \" \",\n            tags=(\"attachments_link\", f\"att_{self._active_chat_request_id}\", \"user_message\"),\n        )\n    self._append_text(\"\\n\", tags=(\"user_message\",))\n\n    self._append_text(\"\\n\")\n\n    for warning in warnings:\n        self._append_text(\"WARNING: \" + warning + \"\\n\\n\")\n\n    self._chat_messages.append(ChatMessage(\"user\", message, attachments))\n    self.query_text.delete(\"1.0\", \"end\")\n\n    for assistant in self.select_assistants_for_user_message(message):\n        threading.Thread(\n            target=self._complete_chat_in_thread,\n            daemon=True,\n            args=(\n                assistant,\n                self._active_chat_request_id,\n            ),\n        ).start()\n\n    return \"break\"", "loc": 38}
{"file": "thonny\\thonny\\plugins\\chat.py", "class_name": "ChatView", "function_name": "create_selection_attachment", "parameters": ["self", "text", "description", "tag"], "param_types": {"text": "EnhancedText", "description": "str", "tag": "str"}, "return_type": "Optional[Attachment]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Attachment", "text.get", "text.get_selection_indices"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_selection_attachment(\n    self,\n    text: EnhancedText,\n    description: str,\n    tag: str,\n) -> Optional[Attachment]:\n    sel_start_index, sel_end_index = text.get_selection_indices()\n    if sel_start_index is None:\n        return None\n\n    return Attachment(description, tag, text.get(sel_start_index, sel_end_index))", "loc": 11}
{"file": "thonny\\thonny\\plugins\\chat.py", "class_name": "ChatView", "function_name": "select_assistants_for_user_message", "parameters": ["self", "message"], "param_types": {"message": "str"}, "return_type": "List[Assistant]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "list", "map", "re.findall", "result.append", "s.lower", "self._append_text", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_assistants_for_user_message(self, message: str) -> List[Assistant]:\n    names = re.findall(r\"@(\\w+)\", message)\n    if not names:\n        return [self._current_assistant]\n\n    unique_norm_names = list(set(map(lambda s: s.lower(), names)))\n    result = []\n    for name in unique_norm_names:\n        if name in get_workbench().assistants:\n            result.append(get_workbench().assistants[name])\n\n        else:\n            # TODO:\n            self._append_text(f\"No assistant named {name}\")\n\n    return result", "loc": 16}
{"file": "thonny\\thonny\\plugins\\chat.py", "class_name": null, "function_name": "dir_tag_motion", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_active_range", "self.suggestions_text.tag_add", "self.suggestions_text.tag_remove"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def dir_tag_motion(event):\n    self.suggestions_text.tag_remove(\"active\", \"1.0\", \"end\")\n    active_range = get_active_range(event)\n    if active_range:\n        range_start, range_end = active_range\n        self.suggestions_text.tag_add(\"active\", range_start, range_end)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\clean_ui_themes.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["clean", "get_workbench", "get_workbench().add_ui_theme"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    dark_images = {\"tab-close-active\": \"tab-close-active-dark\"}\n\n    get_workbench().add_ui_theme(\n        \"Clean Dark\",\n        \"Enhanced Clam\",\n        clean(\n            frame_background=\"#252525\",\n            text_background=\"#2d2d2d\",\n            normal_detail=\"#3D3D3D\",\n            high_detail=\"#6E6E6E\",\n            low_detail=\"#404040\",\n            normal_foreground=\"#9f9f9f\",\n            high_foreground=\"#eeeeee\",\n            low_foreground=\"#666666\",\n        ),\n        images=dark_images,\n    )\n\n    dark_tip_background = (\"#b8c28d\",)\n\n    get_workbench().add_ui_theme(\n        \"Clean Dark Green\",\n        \"Enhanced Clam\",\n        clean(\n            frame_background=\"#1D291A\",\n            text_background=\"#273627\",\n            normal_detail=\"#2D452F\",\n            high_detail=\"#3C6E40\",\n            low_detail=\"#33402F\",\n            normal_foreground=\"#9E9E9E\",\n            high_foreground=\"#eeeeee\",\n            low_foreground=\"#5a725b\",\n        ),\n        images=dark_images,\n    )\n\n    get_workbench().add_ui_theme(\n        \"Clean Dark Blue\",\n        \"Enhanced Clam\",\n        clean(\n            frame_background=\"#1A1C29\",\n            text_background=\"#272936\",\n            normal_detail=\"#2D3345\",\n            high_detail=\"#3C436E\",\n            low_detail=\"#2F3640\",\n            normal_foreground=\"#9E9E9E\",\n            high_foreground=\"#eeeeee\",\n            low_foreground=\"#5a5c72\",\n        ),\n        images=dark_images,\n    )\n\n    get_workbench().add_ui_theme(\n        \"Clean Sepia\",\n        \"Enhanced Clam\",\n        clean(\n            frame_background=\"#E8E7DC\",\n            text_background=\"#F7F6F0\",\n            normal_detail=\"#DEDCC8\",\n            high_detail=\"#eeebe7\",\n            low_detail=\"#D4D0B8\",\n            normal_foreground=\"#222222\",\n            high_foreground=\"#000000\",\n            low_foreground=\"#999999\",\n            custom_menubar=0,\n        ),\n    )", "loc": 68}
{"file": "thonny\\thonny\\plugins\\codeium.py", "class_name": "CodeiumApiKeyDialog", "function_name": "populate_main_frame", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["create_url_label", "paste_button.grid", "self.key_entry.grid", "str", "ttk.Button", "ttk.Entry", "url_label.grid", "uuid.uuid4"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def populate_main_frame(self):\n    login_uuid = str(uuid.uuid4())\n    url_label = create_url_label(\n        self.main_frame,\n        text=\"Click here to request Codeium authorization key (ignore the VSCode talk)...\",\n        url=f\"https://www.codeium.com/profile?response_type=token&redirect_uri=show-auth-token&state={login_uuid}&scope=openid%20profile%20email&redirect_parameters_type=query\",\n    )\n    url_label.grid(row=1, column=1, columnspan=2)\n\n    self.key_entry = ttk.Entry(self.main_frame, width=50)\n    self.key_entry.grid(row=2, column=1)\n\n    paste_button = ttk.Button(self.main_frame, text=\"Paste the key\", command=self._paste)\n    paste_button.grid(row=1, column=2)", "loc": 14}
{"file": "thonny\\thonny\\plugins\\codeium.py", "class_name": "CodeiumAssistant", "function_name": "get_ready", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_saved_api_key", "self._request_new_api_key", "self._start_language_server"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_ready(self) -> bool:\n    if self._ls_proc is None:\n        self._start_language_server()\n\n    if self._get_saved_api_key() is None:\n        self._request_new_api_key()\n\n    return self._ls_proc is not None and self._get_saved_api_key() is not None", "loc": 8}
{"file": "thonny\\thonny\\plugins\\codeium.py", "class_name": "CodeiumAssistant", "function_name": "complete_chat", "parameters": ["self", "context"], "param_types": {"context": "ChatContext"}, "return_type": "Iterator[ChatResponseChunk]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChatMessage", "ChatMessageIntent", "ChatResponseChunk", "GetChatMessageRequest", "IntentGeneric", "floor", "isinstance", "len", "logger.info", "proto_msgs.append", "self._create_request_metadata", "self._ls_stub.GetChatMessage", "self._prepare_for_ls_call", "text.startswith", "time.time", "timestamp_pb2.Timestamp", "uuid.uuid4"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def complete_chat(self, context: ChatContext) -> Iterator[ChatResponseChunk]:\n    self._prepare_for_ls_call()\n\n    proto_msgs = []\n\n    for message in context.messages:\n\n        if message.role == \"user\":\n            source = ChatMessageSource.CHAT_MESSAGE_SOURCE_USER\n        else:\n            source = ChatMessageSource.CHAT_MESSAGE_SOURCE_SYSTEM\n\n        proto_msg = ChatMessage(\n            message_id=f\"user-{uuid.uuid4()}\",\n            source=source,\n            timestamp=timestamp_pb2.Timestamp(seconds=floor(time.time())),\n            conversation_id=self._conversation_id,\n            intent=ChatMessageIntent(generic=IntentGeneric(text=message.content)),\n        )\n\n        proto_msgs.append(proto_msg)\n\n    response_stream = self._ls_stub.GetChatMessage(\n        GetChatMessageRequest(\n            metadata=self._create_request_metadata(),\n            prompt=\"I want to learn programming\",\n            chat_messages=proto_msgs,\n        )\n    )\n\n    last_prefix = \"\"\n    for response in response_stream:\n        assert isinstance(response, GetChatMessageResponse)\n        resp_msg = response.chat_message\n        if resp_msg.action and resp_msg.action.generic:\n            text = resp_msg.action.generic.text\n            assert text.startswith(last_prefix)\n            yield ChatResponseChunk(text[len(last_prefix) :], False)\n            last_prefix = text\n        else:\n            logger.info(\"Got unexpected ChatMessage: %s\", resp_msg)\n\n    yield ChatResponseChunk(\"\", True)", "loc": 43}
{"file": "thonny\\thonny\\plugins\\coloring.py", "class_name": null, "function_name": "update_coloring_on_event", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "logger.error", "update_coloring_on_text"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_coloring_on_event(event):\n    if hasattr(event, \"text_widget\"):\n        text = event.text_widget\n    else:\n        text = event.widget\n\n    try:\n        update_coloring_on_text(text, event)\n    except Exception as e:\n        logger.error(\"Problem with coloring\", exc_info=e)", "loc": 10}
{"file": "thonny\\thonny\\plugins\\coloring.py", "class_name": null, "function_name": "update_coloring_on_text", "parameters": ["text", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["class_", "hasattr", "isinstance", "text.syntax_colorer.mark_dirty", "text.syntax_colorer.schedule_update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_coloring_on_text(text, event=None):\n    if not hasattr(text, \"syntax_colorer\"):\n        if isinstance(text, ShellText):\n            class_ = ShellSyntaxColorer\n        elif isinstance(text, CodeViewText):\n            class_ = CodeViewSyntaxColorer\n        else:\n            return\n\n        text.syntax_colorer = class_(text)\n        # mark whole text as unprocessed\n        text.syntax_colorer.mark_dirty()\n    else:\n        text.syntax_colorer.mark_dirty(event)\n\n    text.syntax_colorer.schedule_update()", "loc": 16}
{"file": "thonny\\thonny\\plugins\\coloring.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "wb.bind", "wb.bind_class", "wb.set_default"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    wb = get_workbench()\n\n    wb.set_default(\"view.syntax_coloring\", True)\n    wb.set_default(\"view.highlight_tabs\", True)\n    wb.bind(\"TextInsert\", update_coloring_on_event, True)\n    wb.bind(\"TextDelete\", update_coloring_on_event, True)\n    wb.bind_class(\"CodeViewText\", \"<<VerticalScroll>>\", update_coloring_on_event, True)\n    wb.bind(\"<<UpdateAppearance>>\", update_coloring_on_event, True)", "loc": 9}
{"file": "thonny\\thonny\\plugins\\coloring.py", "class_name": "SyntaxColorer", "function_name": "mark_dirty", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["event.text.count", "hasattr", "index.split", "int", "self.text.index", "self.text.tag_add"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def mark_dirty(self, event=None):\n    start_index = \"1.0\"\n    end_index = \"end\"\n\n    if hasattr(event, \"sequence\"):\n        if event.sequence == \"TextInsert\":\n            index = self.text.index(event.index)\n            start_row = int(index.split(\".\")[0])\n            end_row = start_row + event.text.count(\"\\n\")\n            start_index = \"%d.%d\" % (start_row, 0)\n            end_index = \"%d.%d\" % (end_row + 1, 0)\n            if not event.trivial_for_coloring:\n                self._multiline_dirty = True\n\n        elif event.sequence == \"TextDelete\":\n            index = self.text.index(event.index1)\n            start_row = int(index.split(\".\")[0])\n            start_index = \"%d.%d\" % (start_row, 0)\n            end_index = \"%d.%d\" % (start_row + 1, 0)\n            if not event.trivial_for_coloring:\n                self._multiline_dirty = True\n\n    self.text.tag_add(TODO, start_index, end_index)", "loc": 23}
{"file": "thonny\\thonny\\plugins\\coloring.py", "class_name": "SyntaxColorer", "function_name": "schedule_update", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "self.text.after_idle", "self.text.is_python_text", "self.text.is_pythonlike_text"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def schedule_update(self):\n    self._highlight_tabs = get_workbench().get_option(\"view.highlight_tabs\")\n    self._use_coloring = get_workbench().get_option(\"view.syntax_coloring\") and (\n        self.text.is_python_text() or self.text.is_pythonlike_text()\n    )\n\n    if not self._update_scheduled:\n        self._update_scheduled = True\n        self.text.after_idle(self.perform_update)", "loc": 9}
{"file": "thonny\\thonny\\plugins\\coloring.py", "class_name": "SyntaxColorer", "function_name": "perform_update", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._update_coloring"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_update(self):\n    try:\n        self._update_coloring()\n    finally:\n        self._update_scheduled = False", "loc": 5}
{"file": "thonny\\thonny\\plugins\\commenting_indenting.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_command", "select_sequence", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    get_workbench().add_command(\n        \"indent\",\n        \"edit\",\n        tr(\"Indent selected lines\"),\n        _cmd_indent_selection,\n        tester=_writable_text_is_focused,\n        accelerator=\"Tab\",\n        group=49,\n    )\n\n    get_workbench().add_command(\n        \"dedent\",\n        \"edit\",\n        tr(\"Dedent selected lines\"),\n        _cmd_dedent_selection,\n        tester=_writable_text_is_focused,\n        accelerator=\"Shift+Tab\",\n        group=49,\n    )\n\n    get_workbench().add_command(\n        \"replace_tabs\",\n        \"edit\",\n        tr(\"Replace tabs with spaces\"),\n        _cmd_replace_tabs,\n        tester=_writable_text_is_focused,\n        group=49,\n    )\n\n    get_workbench().add_command(\n        \"toggle_comment\",\n        \"edit\",\n        tr(\"Toggle comment\"),\n        _cmd_toggle_selection_comment,\n        default_sequence=select_sequence(\"<Control-Key-3>\", \"<Command-Key-3>\"),\n        tester=_writable_text_is_focused,\n        group=50,\n    )\n\n    get_workbench().add_command(\n        \"comment_selection\",\n        \"edit\",\n        tr(\"Comment out\"),\n        _cmd_comment_selection,\n        default_sequence=\"<Alt-Key-3>\",\n        tester=_writable_text_is_focused,\n        group=50,\n    )\n\n    get_workbench().add_command(\n        \"uncomment_selection\",\n        \"edit\",\n        tr(\"Uncomment\"),\n        _cmd_uncomment_selection,\n        default_sequence=\"<Alt-Key-4>\",\n        tester=_writable_text_is_focused,\n        group=50,\n    )", "loc": 59}
{"file": "thonny\\thonny\\plugins\\common_editing_commands.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["create_edit_command_handler", "get_workbench", "get_workbench().add_command", "get_workbench().focus_get", "select_sequence", "tr", "widget.event_generate"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    def create_edit_command_handler(virtual_event_sequence):\n        def handler(event=None):\n            widget = get_workbench().focus_get()\n            if widget:\n                return widget.event_generate(virtual_event_sequence)\n\n            return None\n\n        return handler\n\n    get_workbench().add_command(\n        \"undo\",\n        \"edit\",\n        tr(\"Undo\"),\n        create_edit_command_handler(\"<<Undo>>\"),\n        tester=None,  # TODO:\n        default_sequence=select_sequence(\"<Control-z>\", \"<Command-z>\"),\n        extra_sequences=[\"<Control-Greek_zeta>\"],\n        skip_sequence_binding=True,\n        group=10,\n    )\n\n    get_workbench().add_command(\n        \"redo\",\n        \"edit\",\n        tr(\"Redo\"),\n        create_edit_command_handler(\"<<Redo>>\"),\n        tester=None,  # TODO:\n        default_sequence=select_sequence(\"<Control-y>\", \"<Command-y>\"),\n        extra_sequences=[\n            select_sequence(\"<Control-Shift-Z>\", \"<Command-Shift-Z>\"),\n            \"<Control-Greek_upsilon>\",\n            \"<Control-Shift-Greek_ZETA>\",\n        ],\n        skip_sequence_binding=True,\n        group=10,\n    )\n\n    get_workbench().add_command(\n        \"Cut\",\n        \"edit\",\n        tr(\"Cut\"),\n        create_edit_command_handler(\"<<Cut>>\"),\n        tester=None,  # TODO:\n        default_sequence=select_sequence(\"<Control-x>\", \"<Command-x>\"),\n        extra_sequences=[\"<Control-Greek_chi>\"],\n        skip_sequence_binding=True,\n        group=20,\n    )\n\n    get_workbench().add_command(\n        \"Copy\",\n        \"edit\",\n        tr(\"Copy\"),\n        create_edit_command_handler(\"<<Copy>>\"),\n        tester=None,  # TODO:\n        default_sequence=select_sequence(\"<Control-c>\", \"<Command-c>\"),\n        extra_sequences=[\"<Control-Greek_psi>\"],\n        skip_sequence_binding=True,\n        group=20,\n    )\n\n    get_workbench().add_command(\n        \"Paste\",\n        \"edit\",\n        tr(\"Paste\"),\n        create_edit_command_handler(\"<<Paste>>\"),\n        tester=None,  # TODO:\n        default_sequence=select_sequence(\"<Control-v>\", \"<Command-v>\"),\n        extra_sequences=[\"<Control-Greek_omega>\"],\n        skip_sequence_binding=True,\n        group=20,\n    )\n\n    get_workbench().add_command(\n        \"SelectAll\",\n        \"edit\",\n        tr(\"Select all\"),\n        create_edit_command_handler(\"<<SelectAll>>\"),\n        tester=None,  # TODO:\n        default_sequence=select_sequence(\"<Control-a>\", \"<Command-a>\"),\n        extra_sequences=[\"<Control-Greek_alpha>\"],\n        skip_sequence_binding=True,\n        group=20,\n    )", "loc": 86}
{"file": "thonny\\thonny\\plugins\\common_editing_commands.py", "class_name": null, "function_name": "create_edit_command_handler", "parameters": ["virtual_event_sequence"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().focus_get", "widget.event_generate"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_edit_command_handler(virtual_event_sequence):\n    def handler(event=None):\n        widget = get_workbench().focus_get()\n        if widget:\n            return widget.event_generate(virtual_event_sequence)\n\n        return None\n\n    return handler", "loc": 9}
{"file": "thonny\\thonny\\plugins\\common_editing_commands.py", "class_name": null, "function_name": "handler", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().focus_get", "widget.event_generate"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handler(event=None):\n    widget = get_workbench().focus_get()\n    if widget:\n        return widget.event_generate(virtual_event_sequence)\n\n    return None", "loc": 6}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": null, "function_name": "run_preferred_debug_command", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_request_debug", "debug_with_birdseye", "get_workbench", "get_workbench().get_option", "get_workbench().get_option('debugger.preferred_debugger').lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def run_preferred_debug_command():\n    preferred_debugger = get_workbench().get_option(\"debugger.preferred_debugger\").lower()\n    if preferred_debugger == \"faster\":\n        return _request_debug(\"FastDebug\")\n    elif preferred_debugger == \"birdseye\":\n        from thonny.plugins.birdseye_frontend import debug_with_birdseye\n\n        return debug_with_birdseye()\n    else:\n        return _request_debug(\"Debug\")", "loc": 10}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "Debugger", "function_name": "check_issue_command", "parameters": ["self", "command"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DebuggerCommand", "cmd.setdefault", "get_runner", "get_runner().is_waiting_debugger_command", "get_runner().send_command", "get_workbench", "get_workbench().get_option", "logger.debug", "self.clear_last_frame", "self.get_effective_breakpoints", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_issue_command(self, command, **kwargs):\n    cmd = DebuggerCommand(command, **kwargs)\n    self._last_debugger_command = cmd\n\n    if get_runner().is_waiting_debugger_command():\n        logger.debug(\"_check_issue_debugger_command: %s\", cmd)\n\n        # tell MainCPythonBackend the state we are seeing\n        cmd.setdefault(\n            frame_id=self._last_progress_message.stack[-1].id,\n            breakpoints=self.get_effective_breakpoints(command),\n            state=self._last_progress_message.stack[-1].event,\n            focus=self._last_progress_message.stack[-1].focus,\n            allow_stepping_into_libraries=get_workbench().get_option(\n                \"debugger.allow_stepping_into_libraries\"\n            ),\n        )\n        if command == \"run_to_cursor\":\n            # cursor position was added as another breakpoint\n            cmd.name = \"resume\"\n\n        get_runner().send_command(cmd)\n        if command == \"resume\":\n            self.clear_last_frame()\n    else:\n        logger.debug(\"Bad state for sending debugger command \" + str(command))", "loc": 26}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "Debugger", "function_name": "get_effective_breakpoints", "parameters": ["self", "command"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editors.get_current_breakpoints", "result.setdefault", "result[filename].add", "self.get_run_to_cursor_breakpoint", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_effective_breakpoints(self, command):\n    result = editors.get_current_breakpoints()\n\n    if command == \"run_to_cursor\":\n        bp = self.get_run_to_cursor_breakpoint()\n        if bp is not None:\n            filename, lineno = bp\n            result.setdefault(filename, set())\n            result[filename].add(lineno)\n\n    return result", "loc": 11}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "Debugger", "function_name": "command_enabled", "parameters": ["self", "command"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().is_waiting_debugger_command", "self.get_run_to_cursor_breakpoint"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def command_enabled(self, command):\n    if not get_runner().is_waiting_debugger_command():\n        return False\n\n    if command == \"run_to_cursor\":\n        return self.get_run_to_cursor_breakpoint() is not None\n    elif command == \"step_back\":\n        return (\n            self._last_progress_message\n            and self._last_progress_message[\"tracer_class\"] == \"NiceTracer\"\n        )\n    else:\n        return True", "loc": 13}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "Debugger", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "get_workbench().hide_view"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self) -> None:\n    self._last_brought_out_frame_id = None\n\n    if get_workbench().get_option(\"debugger.automatic_stack_view\"):\n        get_workbench().hide_view(\"StackView\")", "loc": 5}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "Debugger", "function_name": "get_frame_by_id", "parameters": ["self", "frame_id"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_frame_by_id(self, frame_id):\n    for frame_info in self._last_progress_message.stack:\n        if frame_info.id == frame_id:\n            return frame_info\n\n    raise ValueError(\"Could not find frame %d\" % frame_id)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "Debugger", "function_name": "get_editor_context_menu", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["create_edit_command_handler", "get_workbench", "get_workbench().focus_get", "menu.add", "self.check_issue_command", "tk.Menu", "tr", "widget.event_generate"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_editor_context_menu(self):\n    def create_edit_command_handler(virtual_event_sequence):\n        def handler(event=None):\n            widget = get_workbench().focus_get()\n            if widget:\n                return widget.event_generate(virtual_event_sequence)\n\n            return None\n\n        return handler\n\n    if self._editor_context_menu is None:\n        menu = tk.Menu(get_workbench())\n        menu.add(\n            \"command\",\n            label=tr(\"Run to cursor\"),\n            command=lambda: self.check_issue_command(\"run_to_cursor\"),\n        )\n        menu.add(\"separator\")\n        menu.add(\"command\", label=\"Copy\", command=create_edit_command_handler(\"<<Copy>>\"))\n        menu.add(\n            \"command\",\n            label=tr(\"Select all\"),\n            command=create_edit_command_handler(\"<<SelectAll>>\"),\n        )\n        self._editor_context_menu = menu\n\n    return self._editor_context_menu", "loc": 28}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "SingleWindowDebugger", "function_name": "get_run_to_cursor_breakpoint", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.get_code_view", "editor.get_code_view().get_selected_range", "editor.get_target_path", "editor.is_local", "get_workbench", "get_workbench().get_editor_notebook", "get_workbench().get_editor_notebook().get_current_editor"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_run_to_cursor_breakpoint(self):\n    editor = get_workbench().get_editor_notebook().get_current_editor()\n    if editor and editor.is_local():\n        selection = editor.get_code_view().get_selected_range()\n        lineno = selection.lineno\n        if editor.get_target_path() and lineno:\n            return editor.get_target_path(), lineno\n\n    return None", "loc": 9}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "SingleWindowDebugger", "function_name": "handle_debugger_progress", "parameters": ["self", "msg"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "get_workbench().get_view", "get_workbench().get_view('ExceptionView').set_exception", "get_workbench().show_view", "len", "self.bring_out_frame", "super", "super().handle_debugger_progress"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_debugger_progress(self, msg):\n    super().handle_debugger_progress(msg)\n    self._last_progress_message = msg\n    self.bring_out_frame(self._last_progress_message.stack[-1].id, force=True)\n\n    if get_workbench().get_option(\"debugger.automatic_stack_view\"):\n        if len(msg.stack) > 1:\n            get_workbench().show_view(\"StackView\")\n\n    get_workbench().get_view(\"ExceptionView\").set_exception(\n        msg[\"exception_info\"][\"lines_with_frame_info\"]\n    )", "loc": 12}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "SingleWindowDebugger", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._last_frame_visualizer.close", "super", "super().close"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self):\n    super().close()\n    if self._last_frame_visualizer is not None:\n        self._last_frame_visualizer.close()\n        self._last_frame_visualizer = None", "loc": 5}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "SingleWindowDebugger", "function_name": "bring_out_frame", "parameters": ["self", "frame_id", "force"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EditorVisualizer", "get_workbench", "get_workbench().get_view", "self._last_frame_visualizer._update_this_frame", "self._last_frame_visualizer.close", "self.get_frame_by_id", "var_view.show_frame_variables", "var_view.show_globals"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def bring_out_frame(self, frame_id, force=False):\n    if not force and frame_id == self._last_brought_out_frame_id:\n        return\n\n    self._last_brought_out_frame_id = frame_id\n\n    frame_info = self.get_frame_by_id(frame_id)\n\n    if (\n        self._last_frame_visualizer is not None\n        and self._last_frame_visualizer._frame_id != frame_info.id\n    ):\n        self._last_frame_visualizer.close()\n        self._last_frame_visualizer = None\n\n    if self._last_frame_visualizer is None:\n        self._last_frame_visualizer = EditorVisualizer(frame_info)\n\n    self._last_frame_visualizer._update_this_frame(self._last_progress_message, frame_info)\n\n    # show variables\n    var_view = get_workbench().get_view(\"VariablesView\")\n    if frame_info.code_name == \"<module>\":\n        var_view.show_globals(frame_info.globals, frame_info.module_name)\n    else:\n        var_view.show_frame_variables(\n            frame_info.locals,\n            frame_info.globals,\n            frame_info.freevars,\n            (\n                frame_info.module_name\n                if frame_info.code_name == \"<module>\"\n                else frame_info.code_name\n            ),\n        )", "loc": 35}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "SingleWindowDebugger", "function_name": "handle_debugger_return", "parameters": ["self", "msg"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["msg.get", "self._last_frame_visualizer.close", "self._last_frame_visualizer.get_frame_id"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_debugger_return(self, msg):\n    if (\n        self._last_frame_visualizer is not None\n        and self._last_frame_visualizer.get_frame_id() == msg.get(\"frame_id\")\n    ):\n        self._last_frame_visualizer.close()", "loc": 6}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "StackedWindowsDebugger", "function_name": "get_run_to_cursor_breakpoint", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["code_view.get_selected_range", "isinstance", "self._get_topmost_selected_visualizer"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_run_to_cursor_breakpoint(self):\n    visualizer = self._get_topmost_selected_visualizer()\n    if visualizer:\n        assert isinstance(visualizer._text_frame, CodeView)\n        code_view = visualizer._text_frame\n        selection = code_view.get_selected_range()\n\n        target_lineno = visualizer._firstlineno - 1 + selection.lineno\n        return visualizer._filename, target_lineno\n    else:\n        return None", "loc": 11}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "StackedWindowsDebugger", "function_name": "handle_debugger_progress", "parameters": ["self", "msg"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EditorVisualizer", "get_workbench", "get_workbench().get_view", "get_workbench().get_view('ExceptionView').set_exception", "self._main_frame_visualizer.close", "self._main_frame_visualizer.get_frame_id", "self._main_frame_visualizer.update_this_and_next_frames", "self.bring_out_frame", "super", "super().handle_debugger_progress"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_debugger_progress(self, msg):\n    super().handle_debugger_progress(msg)\n\n    self._last_progress_message = msg\n\n    main_frame_id = msg.stack[0].id\n\n    # clear obsolete main frame visualizer\n    if (\n        self._main_frame_visualizer\n        and self._main_frame_visualizer.get_frame_id() != main_frame_id\n    ):\n        self._main_frame_visualizer.close()\n        self._main_frame_visualizer = None\n\n    if not self._main_frame_visualizer:\n        self._main_frame_visualizer = EditorVisualizer(msg.stack[0])\n\n    self._main_frame_visualizer.update_this_and_next_frames(msg)\n\n    self.bring_out_frame(msg.stack[-1].id, force=True)\n\n    get_workbench().get_view(\"ExceptionView\").set_exception(\n        msg[\"exception_info\"][\"lines_with_frame_info\"]\n    )", "loc": 25}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "StackedWindowsDebugger", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._main_frame_visualizer.close", "super", "super().close"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self):\n    super().close()\n    if self._main_frame_visualizer is not None:\n        self._main_frame_visualizer.close()\n        self._main_frame_visualizer = None", "loc": 5}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "StackedWindowsDebugger", "function_name": "bring_out_frame", "parameters": ["self", "frame_id", "force"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_view", "self._main_frame_visualizer.bring_out_frame", "self.get_frame_by_id", "var_view.show_globals"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def bring_out_frame(self, frame_id, force=False):\n    if not force and frame_id == self._last_brought_out_frame_id:\n        return\n\n    self._last_brought_out_frame_id = frame_id\n\n    self._main_frame_visualizer.bring_out_frame(frame_id)\n\n    # show variables\n    var_view = get_workbench().get_view(\"VariablesView\")\n    frame_info = self.get_frame_by_id(frame_id)\n    var_view.show_globals(frame_info.globals, frame_info.module_name)", "loc": 12}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "StackedWindowsDebugger", "function_name": "handle_debugger_return", "parameters": ["self", "msg"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._main_frame_visualizer.close", "self._main_frame_visualizer.get_frame_id"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_debugger_return(self, msg):\n    if self._main_frame_visualizer is None:\n        return\n\n    self._main_frame_visualizer.close(msg[\"frame_id\"])\n    if msg[\"frame_id\"] == self._main_frame_visualizer.get_frame_id():\n        self._main_frame_visualizer = None", "loc": 7}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "FrameVisualizer", "function_name": "close", "parameters": ["self", "frame_id"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._next_frame_visualizer.close", "self._next_frame_visualizer.get_frame_id", "self._text.set_read_only", "self.clear"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self, frame_id=None):\n    if self._next_frame_visualizer:\n        self._next_frame_visualizer.close(frame_id)\n        if frame_id is None or self._next_frame_visualizer.get_frame_id() == frame_id:\n            self._next_frame_visualizer = None\n\n    if frame_id is None or frame_id == self._frame_id:\n        self._text.set_read_only(False)\n        self.clear()", "loc": 9}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "FrameVisualizer", "function_name": "update_this_and_next_frames", "parameters": ["self", "msg"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._create_next_frame_visualizer", "self._find_this_and_next_frame", "self._next_frame_visualizer.close", "self._next_frame_visualizer.get_frame_id", "self._next_frame_visualizer.update_this_and_next_frames", "self._update_this_frame"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Must not be used on obsolete frame", "source_code": "def update_this_and_next_frames(self, msg):\n    \"\"\"Must not be used on obsolete frame\"\"\"\n\n    # debug(\"State: %s, focus: %s\", msg.state, msg.focus)\n\n    frame_info, next_frame_info = self._find_this_and_next_frame(msg.stack)\n    self._update_this_frame(msg, frame_info)\n\n    # clear obsolete next frame visualizer\n    if self._next_frame_visualizer and (\n        not next_frame_info or self._next_frame_visualizer.get_frame_id() != next_frame_info.id\n    ):\n        self._next_frame_visualizer.close()\n        self._next_frame_visualizer = None\n\n    if next_frame_info and not self._next_frame_visualizer:\n        self._next_frame_visualizer = self._create_next_frame_visualizer(next_frame_info)\n        self._next_frame_visualizer._prev_frame_visualizer = self\n\n    if self._next_frame_visualizer:\n        self._next_frame_visualizer.update_this_and_next_frames(msg)", "loc": 21}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "FrameVisualizer", "function_name": "remove_focus_tags", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._text.tag_remove"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_focus_tags(self):\n    for name in [\n        \"exception_focus\",\n        \"active_focus\",\n        \"completed_focus\",\n        \"suspended_focus\",\n        \"sel\",\n    ]:\n        self._text.tag_remove(name, \"0.0\", \"end\")", "loc": 9}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "FrameVisualizer", "function_name": "bring_out_frame", "parameters": ["self", "frame_id"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._next_frame_visualizer.bring_out_frame", "self.bring_out_this_frame"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def bring_out_frame(self, frame_id):\n    if self._frame_id == frame_id:\n        self.bring_out_this_frame()\n    elif self._next_frame_visualizer is not None:\n        self._next_frame_visualizer.bring_out_frame(frame_id)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "FrameVisualizer", "function_name": "show_note", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._note_box.show_note"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_note(self, *content_items: Union[str, List], target=None, focus=None) -> None:\n    if target is None:\n        target = self._text\n\n    self._note_box.show_note(*content_items, target=target, focus=focus)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "BaseExpressionBox", "function_name": "get_text_options", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dict", "get_syntax_options_for_tag", "opts.update"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_text_options(self):\n    opts = dict(\n        height=1,\n        width=1,\n        relief=tk.RAISED,\n        background=\"#DCEDF2\",\n        borderwidth=1,\n        highlightthickness=0,\n        padx=7,\n        pady=7,\n        wrap=tk.NONE,\n        font=\"EditorFont\",\n    )\n    opts.update(get_syntax_options_for_tag(\"expression_box\"))\n    return opts", "loc": 15}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "BaseExpressionBox", "function_name": "get_focused_text", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_mark_name", "self.text.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_focused_text(self):\n    if self._last_focus:\n        start_mark = self._get_mark_name(self._last_focus.lineno, self._last_focus.col_offset)\n        end_mark = self._get_mark_name(\n            self._last_focus.end_lineno, self._last_focus.end_col_offset\n        )\n        return self.text.get(start_mark, end_mark)\n    else:\n        return \"\"", "loc": 9}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "PlacedExpressionBox", "function_name": "clear_debug_view", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.place_forget", "self.winfo_ismapped", "super", "super().clear_debug_view"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def clear_debug_view(self):\n    if self.winfo_ismapped():\n        self.place_forget()\n\n    super().clear_debug_view()", "loc": 5}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "ToplevelExpressionBox", "function_name": "clear_debug_view", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.winfo_ismapped", "self.withdraw", "super", "super().clear_debug_view"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def clear_debug_view(self):\n    if self.winfo_ismapped():\n        self.withdraw()\n\n    super().clear_debug_view()", "loc": 5}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "ToplevelExpressionBox", "function_name": "get_text_options", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["super", "super().get_text_options"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_text_options(self):\n    opts = super().get_text_options()\n    opts[\"relief\"] = \"flat\"\n    opts[\"borderwidth\"] = 0\n    return opts", "loc": 5}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "DialogVisualizer", "function_name": "close", "parameters": ["self", "frame_id"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.destroy", "super", "super().close"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self, frame_id=None):\n    super().close()\n\n    if frame_id is None or frame_id == self._frame_id:\n        self.destroy()", "loc": 5}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": "StackView", "function_name": "on_select", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_current_debugger.bring_out_frame", "self.tree.focus", "self.tree.item"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_select(self, event):\n    iid = self.tree.focus()\n    if iid != \"\":\n        # assuming id is in the last column\n        frame_id = self.tree.item(iid)[\"values\"][-1]\n        if _current_debugger is not None:\n            _current_debugger.bring_out_frame(frame_id)", "loc": 7}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": null, "function_name": "create_edit_command_handler", "parameters": ["virtual_event_sequence"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().focus_get", "widget.event_generate"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_edit_command_handler(virtual_event_sequence):\n    def handler(event=None):\n        widget = get_workbench().focus_get()\n        if widget:\n            return widget.event_generate(virtual_event_sequence)\n\n        return None\n\n    return handler", "loc": 9}
{"file": "thonny\\thonny\\plugins\\debugger.py", "class_name": null, "function_name": "handler", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().focus_get", "widget.event_generate"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handler(event=None):\n    widget = get_workbench().focus_get()\n    if widget:\n        return widget.event_generate(virtual_event_sequence)\n\n    return None", "loc": 6}
{"file": "thonny\\thonny\\plugins\\dock_user_windows_frontend.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_command", "get_workbench().bind", "get_workbench().set_default", "tr", "update_environment"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    get_workbench().set_default(_OPTION_NAME, False)\n    get_workbench().add_command(\n        \"toggle_dock_user_windows\",\n        \"run\",\n        tr(\"Dock user windows\"),\n        toggle_variable,\n        flag_name=_OPTION_NAME,\n        group=40,\n    )\n    update_environment()\n\n    get_workbench().bind(\"UserWindowAppeared\", on_window_appear, True)", "loc": 13}
{"file": "thonny\\thonny\\plugins\\editor_config_page.py", "class_name": "EditorConfigurationPage", "function_name": "apply", "parameters": ["self", "changed_options"], "param_types": {"changed_options": "List[str]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_shell", "get_workbench", "get_workbench().get_editor_notebook", "get_workbench().get_editor_notebook().update_appearance", "shell.update_appearance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def apply(self, changed_options: List[str]) -> bool:\n    get_workbench().get_editor_notebook().update_appearance()\n    shell = get_shell(create=False)\n    if shell is not None:\n        shell.update_appearance()\n\n    return True", "loc": 7}
{"file": "thonny\\thonny\\plugins\\event_logging.py", "class_name": null, "function_name": "export", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_menu_char", "messagebox.showinfo"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def export():\n    messagebox.showinfo(\n        \"Info\",\n        \"For exporting usage logs, please select 'Tools => Open Replayer...'\\n\"\n        \"and click on the \" + get_menu_char() + \" button in the upper-right corner of the window\",\n    )", "loc": 6}
{"file": "thonny\\thonny\\plugins\\event_logging.py", "class_name": null, "function_name": "format_time_range", "parameters": ["start_time", "end_time"], "param_types": {"start_time": "time.struct_time", "end_time": "Optional[time.struct_time]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["time.strftime"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_time_range(\n    start_time: time.struct_time, end_time: Optional[time.struct_time] = None\n) -> str:\n    start_str = time.strftime(TIMESTAMP_FORMAT, start_time)\n    if end_time is not None:\n        end_str = time.strftime(TIMESTAMP_FORMAT, end_time)\n    else:\n        end_str = \"unknown\"\n    return start_str + \"__\" + end_str", "loc": 9}
{"file": "thonny\\thonny\\plugins\\event_logging.py", "class_name": null, "function_name": "parse_time_range", "parameters": ["s"], "param_types": {"s": "str"}, "return_type": "Tuple[time.struct_time, Optional[time.struct_time]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "s.split", "time.strptime"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_time_range(s: str) -> Tuple[time.struct_time, Optional[time.struct_time]]:\n    parts = s.split(\"__\")\n    assert len(parts) == 2\n    start_time = time.strptime(parts[0], TIMESTAMP_FORMAT)\n    if parts[1] == \"unknown\":\n        end_time = None\n    else:\n        end_time = time.strptime(parts[1], TIMESTAMP_FORMAT)\n\n    return start_time, end_time", "loc": 10}
{"file": "thonny\\thonny\\plugins\\event_logging.py", "class_name": null, "function_name": "save_events_to_file", "parameters": ["events", "path"], "param_types": {"events": "List[Dict]", "path": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EventsInputOutputFileError", "fp.write", "json.dumps", "open", "os.path.basename", "path.lower", "path.lower().endswith", "zipf.writestr", "zipfile.ZipFile"], "control_structures": ["If"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def save_events_to_file(events: List[Dict], path: str) -> None:\n    import json\n\n    data = json.dumps(events, indent=4)\n    if path.lower().endswith(\".zip\"):\n        import zipfile\n\n        with zipfile.ZipFile(path, \"w\", compression=zipfile.ZIP_DEFLATED) as zipf:\n            zipf.writestr(os.path.basename(path)[:-4] + \".txt\", data=data)\n    elif path.lower().endswith(\".txt\") or path.lower().endswith(\".json\"):\n        # import/export Json format\n        with open(path, mode=\"wt\", encoding=\"utf-8\") as fp:\n            fp.write(data)\n    else:\n        raise EventsInputOutputFileError(\"Unsupported output format\")", "loc": 15}
{"file": "thonny\\thonny\\plugins\\event_logging.py", "class_name": null, "function_name": "load_events_from_file", "parameters": ["path"], "param_types": {"path": "str"}, "return_type": "List[Dict]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EventsInputOutputFileError", "data.decode", "data.decode('utf-8').splitlines", "json.load", "json.loads", "len", "name.lower", "name.lower().endswith", "open", "open_fun", "path.lower", "path.lower().endswith", "result.append", "zipf.namelist", "zipf.read", "zipfile.ZipFile"], "control_structures": ["For", "If"], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def load_events_from_file(path: str) -> List[Dict]:\n    import json\n\n    if path.lower().endswith(\".zip\"):\n        import zipfile\n\n        with zipfile.ZipFile(path, \"r\") as zipf:\n            names = zipf.namelist()\n            if len(names) > 1:\n                raise EventsInputOutputFileError(\n                    \"The zip contains several files.\\nPlease extract the files and load one of them!\"\n                )\n            name = names[0]\n            data = zipf.read(name)\n\n            if name.lower().endswith(\".jsonl\"):\n                return [json.loads(line) for line in data.decode(\"utf-8\").splitlines()]\n            elif name.lower().endswith(\".json\") or name.lower().endswith(\".txt\"):\n                return json.loads(data.decode(\"utf-8\"))\n            else:\n                raise EventsInputOutputFileError(f\"Don't know how to open {name}\")\n\n    elif path.lower().endswith(\".txt\") or path.lower().endswith(\".json\"):\n        # import/export JSON format\n        with open(path, encoding=\"utf-8\") as fp:\n            return json.load(fp)\n    else:\n        # internal, JSON lines format\n        if path.lower().endswith(\".jsonl.gz\"):\n            import gzip\n\n            open_fun = gzip.open\n        elif path.lower().endswith(\".jsonl\"):\n            # internal format may remain uncompressed in case of crashes\n            open_fun = open\n\n        else:\n            raise EventsInputOutputFileError(\"Can't determine file format\")\n\n        result = []\n        with open_fun(path, mode=\"rt\", encoding=\"utf-8\") as fp:\n            for line in fp:\n                result.append(json.loads(line))\n\n        return result", "loc": 45}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": null, "function_name": "transpose_path", "parameters": ["source_path", "source_dir", "target_dir", "source_path_class", "target_path_class"], "param_types": {"source_path": "str", "source_dir": "str", "target_dir": "str", "source_path_class": "Type[PurePath]", "target_path_class": "Type[PurePath]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "source_dir.endswith", "source_path_class", "str", "target_path_class", "target_path_class(target_dir).joinpath"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def transpose_path(\n    source_path: str,\n    source_dir: str,\n    target_dir: str,\n    source_path_class: Type[PurePath],\n    target_path_class: Type[PurePath],\n) -> str:\n    assert not source_dir.endswith(\":\")\n    source_path_parts = source_path_class(source_path).parts\n    source_dir_parts = source_path_class(source_dir).parts\n    assert source_path_parts[: len(source_dir_parts)] == source_dir_parts\n    source_suffix_parts = source_path_parts[len(source_dir_parts) :]\n\n    target = target_path_class(target_dir).joinpath(*source_suffix_parts)\n    return str(target)", "loc": 15}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": null, "function_name": "pick_transfer_items", "parameters": ["prepared_items", "existing_target_items", "master"], "param_types": {"prepared_items": "List[Dict]", "existing_target_items": "Dict[str, Dict]"}, "return_type": "List[Dict]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["askokcancel", "errors.append", "format_items", "overwrites.append", "showerror", "sizeof_fmt", "tr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def pick_transfer_items(\n    prepared_items: List[Dict], existing_target_items: Dict[str, Dict], master\n) -> List[Dict]:\n    if not existing_target_items:\n        return prepared_items\n\n    errors = []\n    overwrites = []\n\n    for item in prepared_items:\n        if item[\"target_path\"] in existing_target_items:\n            target_info = existing_target_items[item[\"target_path\"]]\n            if item[\"kind\"] != target_info[\"kind\"]:\n                errors.append(\n                    \"Can't overwrite '%s' with '%s', because former is a %s but latter is a %s\"\n                    % (item[\"target_path\"], item[\"source_path\"], target_info[\"kind\"], item[\"kind\"])\n                )\n            elif item[\"kind\"] == \"file\":\n                size_diff = item[\"size_bytes\"] - target_info[\"size_bytes\"]\n                if size_diff > 0:\n                    replacement = \"a larger file (%s + %s)\" % (\n                        sizeof_fmt(target_info[\"size_bytes\"]),\n                        sizeof_fmt(size_diff),\n                    )\n                elif size_diff < 0:\n                    replacement = \"a smaller file (%s - %s)\" % (\n                        sizeof_fmt(target_info[\"size_bytes\"]),\n                        sizeof_fmt(-size_diff),\n                    )\n                else:\n                    replacement = \"a file of same size (%s)\" % sizeof_fmt(target_info[\"size_bytes\"])\n\n                overwrites.append(\"'%s' with %s\" % (item[\"target_path\"], replacement))\n\n    if errors:\n        showerror(\"Error\", format_items(errors), master=master)\n        return []\n    elif overwrites:\n        if askokcancel(\n            tr(\"Overwrite?\"),\n            tr(\"This operation will overwrite %s\") % format_items(overwrites) + \"\\n\\n\",\n            master=master,\n        ):\n            return prepared_items\n        else:\n            return []\n    else:\n        return prepared_items", "loc": 48}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": null, "function_name": "format_items", "parameters": ["items"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n '.join", "len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def format_items(items):\n    max_count = 10\n    if len(items) == 1:\n        return items[0]\n    msg = \" \" + \"\\n \".join(items[:max_count])\n    if len(items) > max_count:\n        msg += \"\\n ... %d more ...\" % (len(items) - max_count)\n\n    return msg", "loc": 9}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": null, "function_name": "get_transfer_description", "parameters": ["verb", "paths", "target_dir"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_transfer_description(verb, paths, target_dir):\n    if len(paths) == 1:\n        subject = \"'%s'\" % paths[0]\n    else:\n        subject = \"%d items\" % len(paths)\n\n    return \"%s %s to %s\" % (verb, subject, target_dir)", "loc": 7}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "FilesView", "function_name": "reset_remote", "parameters": ["self", "msg"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "logger.info", "proxy.supports_remote_files", "runner.get_backend_proxy", "self.add", "self.hide_remote", "self.remote_files.check_update_focus", "self.remote_files.clear", "self.restore_split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def reset_remote(self, msg=None):\n    runner = get_runner()\n    if not runner:\n        logger.info(\"No runner in reset_remote\")\n        return\n\n    proxy = runner.get_backend_proxy()\n    if not proxy:\n        logger.info(\"No proxy in reset_remote\")\n        self.hide_remote()\n        return\n\n    if proxy.supports_remote_files():\n        if not self.remote_added:\n            logger.info(\"Adding remote browser\")\n            self.add(self.remote_files, minsize=minsize)\n            self.remote_added = True\n            self.restore_split()\n        self.remote_files.clear()\n        self.remote_files.check_update_focus()\n    else:\n        self.hide_remote()", "loc": 22}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "FilesView", "function_name": "hide_remote", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.info", "self.remove", "self.save_split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def hide_remote(self):\n    if self.remote_added:\n        logger.info(\"Hiding remote browser\")\n        self.save_split()\n        self.remove(self.remote_files)\n        self.remote_added = False", "loc": 6}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "FilesView", "function_name": "restore_split", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "int", "self.sash_place", "self.winfo_height"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def restore_split(self):\n    split = get_workbench().get_option(\"view.files_split\", None)\n    if split is None:\n        if self.winfo_height() > 5:\n            split = int(self.winfo_height() * 0.66)\n        else:\n            split = 600\n\n    self.sash_place(0, 0, split)", "loc": 9}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "FilesView", "function_name": "get_active_remote_dir", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.remote_files.get_active_directory"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_active_remote_dir(self):\n    if self.remote_added:\n        return self.remote_files.get_active_directory()\n    else:\n        return None", "loc": 5}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "FilesView", "function_name": "destroy", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().unbind", "super", "super().destroy"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def destroy(self):\n    get_workbench().unbind(\"BackendTerminated\", self.on_backend_terminate)\n    get_workbench().unbind(\"BackendRestart\", self.on_backend_restart)\n    get_workbench().unbind(\"WorkbenchClose\", self.on_workbench_close)\n    super().destroy()", "loc": 5}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "ActiveLocalFileBrowser", "function_name": "check_add_upload_command", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().get_backend_proxy", "messagebox.showerror", "proxy.get_node_label", "proxy.supports_remote_directories", "self.get_selection_info", "self.master.get_active_remote_dir", "self.master.remote_files.refresh_tree", "self.menu.add_command", "tr", "upload"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_add_upload_command(self):\n    target_dir = self.master.get_active_remote_dir()\n    if target_dir is None:\n        return\n\n    proxy = get_runner().get_backend_proxy()\n\n    if not proxy.supports_remote_directories():\n        target_dir_desc = proxy.get_node_label()\n    else:\n        target_dir_desc = target_dir\n\n    def _upload():\n        selection = self.get_selection_info(True)\n        if not selection:\n            return\n\n        if \"dir\" in selection[\"kinds\"] and not proxy.supports_remote_directories():\n            messagebox.showerror(\n                \"Can't upload directory\",\n                \"%s does not support directories.\\n\" % proxy.get_node_label()\n                + \"You can only upload files.\",\n                master=self,\n            )\n        else:\n            if upload(selection[\"paths\"], target_dir, master=self):\n                self.master.remote_files.refresh_tree()\n\n    self.menu.add_command(label=tr(\"Upload to %s\") % target_dir_desc, command=_upload)", "loc": 29}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "ActiveLocalFileBrowser", "function_name": "add_first_menu_items", "parameters": ["self", "context"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.check_for_venv", "self.do_activate_venv", "self.menu.add_command", "self.menu.add_separator", "super", "super().add_first_menu_items", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_first_menu_items(self, context):\n    if self.check_for_venv():\n        self.menu.add_command(\n            label=tr(\"Activate virtual environment\"), command=lambda: self.do_activate_venv()\n        )\n        self.menu.add_separator()\n\n    super().add_first_menu_items(context)", "loc": 8}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "ActiveRemoteFileBrowser", "function_name": "on_toplevel_response", "parameters": ["self", "msg"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().get_backend_proxy", "get_runner().get_backend_proxy().supports_remote_files", "logger.info", "msg.get", "self.check_update_focus", "self.winfo_ismapped"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_toplevel_response(self, msg):\n    if not self.winfo_ismapped():\n        logger.info(\"ActiveRemoteFileBrowser not mapped on_toplevel_response\")\n        return\n    if get_runner().get_backend_proxy().supports_remote_files():\n        # pass cwd, as proxy may not yet know it\n        self.check_update_focus(msg.get(\"cwd\"))", "loc": 7}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "ActiveRemoteFileBrowser", "function_name": "on_remote_files_changed", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().get_backend_proxy", "get_runner().get_backend_proxy().supports_remote_files", "self.refresh_tree", "self.winfo_ismapped"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_remote_files_changed(self, event=None):\n    if not self.winfo_ismapped():\n        return\n\n    if get_runner().get_backend_proxy().supports_remote_files():\n        self.refresh_tree()", "loc": 6}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "ActiveRemoteFileBrowser", "function_name": "check_update_focus", "parameters": ["self", "new_cwd"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().get_backend_proxy", "logger.info", "proxy.get_cwd", "self.focus_into"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_update_focus(self, new_cwd=None):\n    if new_cwd is None:\n        proxy = get_runner().get_backend_proxy()\n        new_cwd = proxy.get_cwd()\n\n    if new_cwd is None:\n        logger.info(\"Can't update focus, proxy doesn't have cwd yet\")\n    else:\n        if self.current_focus != new_cwd:\n            logger.info(\n                \"Changing focus, current_focus=%r, new_cwd=%r\", self.current_focus, new_cwd\n            )\n            self.focus_into(new_cwd)", "loc": 13}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": "ActiveRemoteFileBrowser", "function_name": "add_download_command", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DownloadDialog", "self.get_selection_info", "self.master.get_active_local_dir", "self.master.local_files.refresh_tree", "self.menu.add_command", "tr", "ui_utils.show_dialog"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_download_command(self):\n    target_dir = self.master.get_active_local_dir()\n\n    def download():\n        selection = self.get_selection_info(True)\n        if not selection:\n            return\n\n        dlg = DownloadDialog(\n            self,\n            selection[\"paths\"],\n            selection[\"description\"],\n            target_dir,\n        )\n        ui_utils.show_dialog(dlg)\n        if dlg.response is not None:\n            self.master.local_files.refresh_tree()\n\n    self.menu.add_command(label=tr(\"Download to %s\") % target_dir, command=download)", "loc": 19}
{"file": "thonny\\thonny\\plugins\\files.py", "class_name": null, "function_name": "download", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DownloadDialog", "self.get_selection_info", "self.master.local_files.refresh_tree", "ui_utils.show_dialog"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def download():\n    selection = self.get_selection_info(True)\n    if not selection:\n        return\n\n    dlg = DownloadDialog(\n        self,\n        selection[\"paths\"],\n        selection[\"description\"],\n        target_dir,\n    )\n    ui_utils.show_dialog(dlg)\n    if dlg.response is not None:\n        self.master.local_files.refresh_tree()", "loc": 14}
{"file": "thonny\\thonny\\plugins\\find_replace.py", "class_name": null, "function_name": "cmd_open_find_dialog", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FindDialog", "_active_find_dialog.focus_set", "get_workbench", "get_workbench().get_editor_notebook", "get_workbench().get_editor_notebook().get_current_editor", "show_dialog"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cmd_open_find_dialog(event=None):\n    if _active_find_dialog is not None:\n        _active_find_dialog.focus_set()\n    else:\n        editor = get_workbench().get_editor_notebook().get_current_editor()\n        if editor:\n            dlg = FindDialog(editor._code_view)\n            show_dialog(dlg, modal=False)", "loc": 8}
{"file": "thonny\\thonny\\plugins\\general_config_page.py", "class_name": "GeneralConfigurationPage", "function_name": "apply", "parameters": ["self", "changed_options"], "param_types": {"changed_options": "List[str]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "entry.endswith", "entry.strip", "env.append", "get_workbench", "get_workbench().set_option", "get_workbench().update_debug_mode", "messagebox.askyesno", "self.env_box.text.get", "self.env_box.text.get('1.0', 'end').strip", "self.env_box.text.get('1.0', 'end').strip('\\r\\n').splitlines", "tr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def apply(self, changed_options: List[str]) -> bool:\n    get_workbench().update_debug_mode()\n\n    env = []\n    for entry in self.env_box.text.get(\"1.0\", \"end\").strip(\"\\r\\n\").splitlines():\n        entry = entry.strip(\"\\r\\n\")\n        env.append(entry)\n\n    if any(entry.endswith(\"'\") or entry.endswith('\"') for entry in env):\n        if not messagebox.askyesno(\n            tr(\"Warning\"),\n            tr(\n                \"If you quote the value of an environment variable, the quotes will\"\n                \" be part of the value.\\nDid you intend this?\"\n            ),\n            parent=self,\n        ):\n            return False\n\n    get_workbench().set_option(\"general.environment\", env)\n    return True", "loc": 21}
{"file": "thonny\\thonny\\plugins\\github_copilot.py", "class_name": "GithubAccessTokenDialog", "function_name": "populate_main_frame", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["code_label.grid", "copy_button.grid", "self.code_entry.grid", "ttk.Button", "ttk.Entry", "ttk.Label", "visit_label.grid"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def populate_main_frame(self):\n    visit_label = ttk.Label(\n        self.main_frame,\n        text=f\"Visit following URL to connect Thonny to your GitHub Copilot account:\",\n    )\n    visit_label.grid(row=1, column=1, columnspan=2)\n\n    self.url_label = None\n\n    code_label = ttk.Label(self.main_frame, text=\"When asked, enter following code:\")\n    code_label.grid(row=3, column=1, columnspan=2)\n\n    self.code_entry = ttk.Entry(self.main_frame, state=\"readonly\")\n    self.code_entry.grid(row=4, column=1)\n\n    copy_button = ttk.Button(\n        self.main_frame, text=\"Copy the code\", command=self._copy_code_to_clipboard\n    )\n    copy_button.grid(row=4, column=2)", "loc": 19}
{"file": "thonny\\thonny\\plugins\\github_copilot.py", "class_name": "GithubAccessTokenDialog", "function_name": "try_get_token_in_thread", "parameters": ["self"], "param_types": {}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.debug", "logger.warning", "post_and_parse_json", "response.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def try_get_token_in_thread(self) -> Optional[str]:\n    url = \"https://github.com/login/oauth/access_token\"\n\n    response = post_and_parse_json(\n        url,\n        headers=BASE_HEADERS,\n        data={\n            \"client_id\": CLIENT_ID,\n            \"device_code\": self.login_spec[\"device_code\"],\n            \"grant_type\": \"urn:ietf:params:oauth:grant-type:device_code\",\n        },\n    )\n\n    if \"error\" in response:\n        logger.warning(\"Got error when querying access token: %r\", response)\n    else:\n        # TODO: don't log private info!\n        logger.debug(\"Got following response when querying access token: %r\", response)\n\n    return response.get(\"access_token\", None)", "loc": 20}
{"file": "thonny\\thonny\\plugins\\github_copilot.py", "class_name": "GithubAccessTokenDialog", "function_name": "update_ui", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["create_url_label", "self.code_entry.configure", "self.code_entry.get", "self.code_entry.insert", "self.report_done", "self.url_label.grid", "super", "super().update_ui"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_ui(self):\n    super().update_ui()\n    if self.state == \"closed\":\n        return\n\n    if self.access_token is not None:\n        self.report_done(True)\n        return\n\n    if self.login_spec is not None and self.code_entry.get() == \"\":\n        self.code_entry.configure(state=\"normal\")\n        self.code_entry.insert(0, self.login_spec[\"user_code\"])\n        self.code_entry.configure(state=\"readonly\")\n\n        self.url_label = create_url_label(\n            self.main_frame, url=self.login_spec[\"verification_uri\"]\n        )\n        self.url_label.grid(row=2, column=1, columnspan=2)", "loc": 18}
{"file": "thonny\\thonny\\plugins\\github_copilot.py", "class_name": "GitHubCopilotAssistant", "function_name": "get_ready", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_saved_access_token", "self._request_new_access_token"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_ready(self) -> bool:\n    if self._get_saved_access_token() is not None:\n        return True\n\n    self._request_new_access_token()\n    return self._get_saved_access_token() is not None", "loc": 6}
{"file": "thonny\\thonny\\plugins\\github_copilot.py", "class_name": "GitHubCopilotAssistant", "function_name": "complete_chat", "parameters": ["self", "context"], "param_types": {"context": "ChatContext"}, "return_type": "Iterator[ChatResponseChunk]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChatResponseChunk", "CopilotError", "e.read", "json.loads", "len", "line.startswith", "line[len(line_prefix):].strip", "line_bytes.decode", "line_bytes.strip", "logger.error", "logger.exception", "logger.info", "messages_by_code.get", "post_and_return_stream", "self._get_api_headers", "self._prepare_for_api_call"], "control_structures": ["For", "If", "Try"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def complete_chat(self, context: ChatContext) -> Iterator[ChatResponseChunk]:\n    self._prepare_for_api_call()\n\n    api_messages = [{\"role\": msg.role, \"content\": msg.content} for msg in context.messages]\n    body = {\n        \"intent\": True,\n        \"model\": \"gpt-4\",\n        \"n\": 1,\n        \"stream\": True,\n        \"temperature\": 0.1,\n        \"top_p\": 1,\n        \"messages\": api_messages,\n    }\n    try:\n        stream = post_and_return_stream(\n            \"https://api.githubcopilot.com/chat/completions\",\n            data=body,\n            headers=self._get_api_headers(),\n        )\n    except HTTPError as e:\n        messages_by_code = {\n            401: \"Unauthorized. Make sure you have access to Copilot Chat.\",\n            500: \"Internal server error. Try again later.\",\n            400: \"Your prompt has been rejected by Copilot Chat.\",\n            419: \"You have been rate limited. Try again later.\",\n        }\n        response_body = e.read()\n        logger.error(\"complete_chat got error %r with body %r\", e.code, response_body)\n        user_message = messages_by_code.get(e.code, None)\n        if user_message is None:\n            user_message = f\"Copilot returned error code {e.code} with following response:\\n{response_body}\"\n        raise CopilotError(user_message) from e\n\n    line_prefix = \"data: \"\n    for line_bytes in stream:\n        logger.info(\"Processing %r\", line_bytes)\n        if not line_bytes.strip():\n            continue\n\n        line = line_bytes.decode(\"utf-8\")\n        assert line.startswith(line_prefix)\n        line_content = line[len(line_prefix) :].strip()\n        if line_content == \"[DONE]\":\n            break\n\n        try:\n            fragment = json.loads(line_content)\n        except JSONDecodeError:\n            logger.exception(\"Could not decode %r\", line_content)\n            raise\n\n        choices = fragment[\"choices\"]\n        if len(choices) == 0:\n            continue\n        delta_content = choices[0][\"delta\"][\"content\"]\n        if delta_content is None:\n            continue\n\n        yield ChatResponseChunk(delta_content, False)\n\n    yield ChatResponseChunk(\"\", True)", "loc": 61}
{"file": "thonny\\thonny\\plugins\\goto_definition.py", "class_name": "GotoHandler", "function_name": "request_definitions", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DefinitionParams", "TextDocumentIdentifier", "editor.get_uri", "get_cursor_ls_position", "get_workbench", "get_workbench().get_main_language_server_proxy", "isinstance", "ls_proxy.request_definition", "ls_proxy.unbind_request_handler", "self.proper_modifier_is_pressed"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_definitions(self, event=None):\n    if not self.proper_modifier_is_pressed(event):\n        return\n\n    assert isinstance(event.widget, CodeViewText)\n    text = event.widget\n\n    editor = text.master.master\n    assert isinstance(editor, Editor)\n    uri = editor.get_uri()\n    if uri is None:\n        return  # TODO\n    pos = get_cursor_ls_position(text)\n\n    ls_proxy = get_workbench().get_main_language_server_proxy()\n    if ls_proxy is None:\n        return\n\n    ls_proxy.unbind_request_handler(self.handle_definitions_response)\n\n    ls_proxy.request_definition(\n        DefinitionParams(TextDocumentIdentifier(uri=uri), position=pos),\n        self.handle_definitions_response,\n    )", "loc": 24}
{"file": "thonny\\thonny\\plugins\\goto_definition.py", "class_name": "GotoHandler", "function_name": "proper_modifier_is_pressed", "parameters": ["self", "event"], "param_types": {"event": "tk.Event"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["command_is_pressed", "control_is_pressed", "running_on_mac_os"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def proper_modifier_is_pressed(self, event: tk.Event) -> bool:\n    if running_on_mac_os():\n        return command_is_pressed(event)\n    else:\n        return control_is_pressed(event)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\goto_definition.py", "class_name": "GotoHandler", "function_name": "handle_definitions_response", "parameters": ["self", "response"], "param_types": {"response": "LspResponse[Union[lsp_types.Definition, List[lsp_types.LocationLink], None]]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "get_workbench", "get_workbench().get_editor_notebook", "get_workbench().get_editor_notebook().show_file", "isinstance", "logger.info", "messagebox.showerror", "response.get_result_or_raise", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_definitions_response(\n    self, response: LspResponse[Union[lsp_types.Definition, List[lsp_types.LocationLink], None]]\n) -> None:\n\n    result = response.get_result_or_raise()\n    if not result:\n        messagebox.showerror(\n            tr(\"Problem\"), tr(\"Could not find definition\"), master=get_workbench()\n        )\n        return\n\n    if isinstance(result, list):\n        # TODO: handle multiple results like PyCharm\n        first_def = result[0]\n    else:\n        first_def = cast(lsp_types.Location, result)\n\n    if isinstance(first_def, lsp_types.LocationLink):\n        uri = first_def.targetUri\n        range = first_def.targetRange\n    else:\n        assert isinstance(first_def, lsp_types.Location)\n        uri = first_def.uri\n        range = first_def.range\n\n    if range is not None:\n        # TODO: Select range instead?\n        line = range.start.line + 1\n    else:\n        line = None\n\n    logger.info(\"Going to %s, line %s\", uri, line)\n    get_workbench().get_editor_notebook().show_file(uri, line)", "loc": 33}
{"file": "thonny\\thonny\\plugins\\goto_definition.py", "class_name": "GotoHandler", "function_name": "on_motion", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "end_index.split", "get_hyperlink_cursor", "getattr", "self._index_doesnt_have_tags", "self.proper_modifier_is_pressed", "self.remove_underline", "start_index.split", "text.get", "text.index", "text.tag_add", "word[0].isalpha"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_motion(self, event):\n    text = cast(SyntaxText, event.widget)\n    if self.proper_modifier_is_pressed(event):\n        self.remove_underline(event)\n        start_index = text.index(f\"@{event.x},{event.y} wordstart\")\n        end_index = text.index(f\"@{event.x},{event.y} wordend\")\n        # sometimes, start_index will contain wrong line number\n        start_line, start_col = start_index.split(\".\")\n        end_line, end_col = end_index.split(\".\")\n        if start_line != end_line:\n            start_index = end_line + \".\" + start_col\n\n        word = text.get(start_index, end_index)\n        if (\n            word\n            and (word[0].isalpha() or word[0] == \"_\")\n            # and not iskeyword(word)\n            and self._index_doesnt_have_tags(\n                text,\n                start_index,\n                {\"string\", \"string3\", \"open_string\", \"open_string3\", \"comment\"},\n            )\n        ):\n            text.tag_add(\"name_link\", start_index, end_index)\n            text[\"cursor\"] = get_hyperlink_cursor()\n            text.underlined = True\n    else:\n        if getattr(text, \"underlined\", False):\n            self.remove_underline(event)", "loc": 29}
{"file": "thonny\\thonny\\plugins\\goto_definition.py", "class_name": "GotoHandler", "function_name": "remove_underline", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "text.tag_remove"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_underline(self, event=None):\n    text = cast(SyntaxText, event.widget)\n    text.tag_remove(\"name_link\", \"1.0\", \"end\")\n    text[\"cursor\"] = \"\"\n    text.underlined = False", "loc": 5}
{"file": "thonny\\thonny\\plugins\\heap.py", "class_name": "HeapView", "function_name": "get_object_id", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["parse_object_id", "self.tree.focus", "self.tree.item"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_object_id(self):\n    iid = self.tree.focus()\n    if iid != \"\":\n        return parse_object_id(self.tree.item(iid)[\"values\"][0])\n\n    return None", "loc": 6}
{"file": "thonny\\thonny\\plugins\\highlight_names.py", "class_name": null, "function_name": "update_highlighting", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["OccurrencesHighlighter", "get_runner", "get_runner().get_backend_proxy", "get_workbench", "hasattr", "isinstance", "text.name_highlighter.trigger"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_highlighting(event):\n    if not get_workbench().ready:\n        # don't slow down loading process\n        return\n\n    if not get_runner() or not get_runner().get_backend_proxy():\n        # too early\n        return\n\n    assert isinstance(event.widget, tk.Text)\n    text = event.widget\n    if not hasattr(text, \"name_highlighter\"):\n        text.name_highlighter = OccurrencesHighlighter(text)\n\n    text.name_highlighter.trigger()", "loc": 15}
{"file": "thonny\\thonny\\plugins\\highlight_names.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "wb.bind", "wb.bind_class", "wb.set_default"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    wb = get_workbench()\n    wb.set_default(\"view.name_highlighting\", True)\n    wb.bind_class(\"EditorCodeViewText\", \"<<CursorMove>>\", update_highlighting, True)\n    wb.bind_class(\"EditorCodeViewText\", \"<<TextChange>>\", update_highlighting, True)\n    wb.bind(\"<<UpdateAppearance>>\", update_highlighting, True)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\highlight_names.py", "class_name": "OccurrencesHighlighter", "function_name": "get_positions", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["index.split", "int", "self.get_positions_for", "self.text.get", "self.text.index", "self.text.tag_prevrange", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_positions(self):\n    index = self.text.index(\"insert\")\n\n    # ignore if cursor in open string\n    if self.text.tag_prevrange(\"open_string\", index) or self.text.tag_prevrange(\n        \"open_string3\", index\n    ):\n        return set()\n\n    source = self.text.get(\"1.0\", \"end\")\n    index_parts = index.split(\".\")\n    line, column = int(index_parts[0]), int(index_parts[1])\n\n    return self.get_positions_for(source, line, column)", "loc": 14}
{"file": "thonny\\thonny\\plugins\\highlight_names.py", "class_name": "OccurrencesHighlighter", "function_name": "trigger", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "self._clear", "self._request", "self.text.after", "self.text.after_idle", "self.text.get_last_operation_time", "self.text.is_python_text", "time.time"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def trigger(self):\n    self._clear()\n\n    if (\n        not get_workbench().get_option(\"view.name_highlighting\")\n        or not self.text.is_python_text()\n    ):\n        return\n\n    def consider_request():\n        if time.time() - self.text.get_last_operation_time() < 0.3:\n            # wait a bit more, there may be more keypresses or cursor location changes coming\n            self.text.after(100, consider_request)\n        else:\n            try:\n                self._request()\n            finally:\n                self._request_scheduled = False\n\n    if not self._request_scheduled:\n        self._request_scheduled = True\n        self.text.after_idle(consider_request)", "loc": 22}
{"file": "thonny\\thonny\\plugins\\highlight_names.py", "class_name": null, "function_name": "consider_request", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._request", "self.text.after", "self.text.get_last_operation_time", "time.time"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def consider_request():\n    if time.time() - self.text.get_last_operation_time() < 0.3:\n        # wait a bit more, there may be more keypresses or cursor location changes coming\n        self.text.after(100, consider_request)\n    else:\n        try:\n            self._request()\n        finally:\n            self._request_scheduled = False", "loc": 9}
{"file": "thonny\\thonny\\plugins\\locals_marker.py", "class_name": null, "function_name": "is_scope", "parameters": ["node"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Copied from jedi", "source_code": "def is_scope(node):\n    \"\"\"Copied from jedi\"\"\"\n    t = node.type\n    if t == \"comp_for\":\n        # Starting with Python 3.8, async is outside of the statement.\n        return node.children[1].type != \"sync_comp_for\"\n\n    return t in (\"file_input\", \"classdef\", \"funcdef\", \"lambdef\", \"sync_comp_for\")", "loc": 8}
{"file": "thonny\\thonny\\plugins\\locals_marker.py", "class_name": null, "function_name": "update_highlighting", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["LocalsHighlighter", "get_workbench", "hasattr", "isinstance", "text.local_highlighter.schedule_update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_highlighting(event):\n    if not get_workbench().ready:\n        # don't slow down initial loading process by importing parso\n        return\n\n    assert isinstance(event.widget, tk.Text)\n    text = event.widget\n\n    if not hasattr(text, \"local_highlighter\"):\n        text.local_highlighter = LocalsHighlighter(text)\n\n    text.local_highlighter.schedule_update()", "loc": 12}
{"file": "thonny\\thonny\\plugins\\locals_marker.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "wb.bind", "wb.bind_class", "wb.set_default"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    wb = get_workbench()\n    wb.set_default(\"view.locals_highlighting\", False)\n    wb.bind_class(\"CodeViewText\", \"<<TextChange>>\", update_highlighting, True)\n    wb.bind(\"<<UpdateAppearance>>\", update_highlighting, True)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\locals_marker.py", "class_name": "LocalsHighlighter", "function_name": "get_positions", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["global_names.update", "hasattr", "is_scope", "isinstance", "len", "local_names.add", "locs.append", "node.get_global_names", "node.is_definition", "parso.parse", "process_node", "process_scope", "self.text.get", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_positions(self):\n    import parso\n    from parso.python import tree\n\n    locs = []\n\n    def process_scope(scope):\n        if isinstance(scope, tree.Function):\n            # process all children after name node,\n            # (otherwise name of global function will be marked as local def)\n            local_names = set()\n            global_names = set()\n            for child in scope.children[2:]:\n                process_node(child, local_names, global_names)\n        else:\n            if hasattr(scope, \"subscopes\"):\n                for child in scope.subscopes:\n                    process_scope(child)\n            elif hasattr(scope, \"children\"):\n                for child in scope.children:\n                    process_scope(child)\n\n    def process_node(node, local_names, global_names):\n        if isinstance(node, tree.GlobalStmt):\n            global_names.update([n.value for n in node.get_global_names()])\n\n        elif isinstance(node, tree.Name):\n            if node.value in global_names:\n                return\n\n            if node.is_definition():  # local def\n                locs.append(node)\n                local_names.add(node.value)\n            elif node.value in local_names:  # use of local\n                locs.append(node)\n\n        elif isinstance(node, tree.BaseNode):\n            # ref: parso/python/grammar*.txt\n            if node.type == \"trailer\" and node.children[0].value == \".\":\n                # this is attribute\n                return\n\n            if isinstance(node, tree.Function):\n                global_names = set()  # outer global statement doesn't have effect anymore\n\n            for child in node.children:\n                process_node(child, local_names, global_names)\n\n    source = self.text.get(\"1.0\", \"end\")\n    module = parso.parse(source)\n    for child in module.children:\n        if isinstance(child, tree.BaseNode) and is_scope(child):\n            process_scope(child)\n\n    loc_pos = set(\n        (\n            \"%d.%d\" % (usage.start_pos[0], usage.start_pos[1]),\n            \"%d.%d\" % (usage.start_pos[0], usage.start_pos[1] + len(usage.value)),\n        )\n        for usage in locs\n    )\n\n    return loc_pos", "loc": 63}
{"file": "thonny\\thonny\\plugins\\locals_marker.py", "class_name": "LocalsHighlighter", "function_name": "schedule_update", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.text.after_idle", "self.update"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def schedule_update(self):\n    def perform_update():\n        try:\n            self.update()\n        finally:\n            self._update_scheduled = False\n\n    if not self._update_scheduled:\n        self._update_scheduled = True\n        self.text.after_idle(perform_update)", "loc": 10}
{"file": "thonny\\thonny\\plugins\\locals_marker.py", "class_name": "LocalsHighlighter", "function_name": "update", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "logger.exception", "self._highlight", "self.get_positions", "self.text.is_python_text", "self.text.tag_remove"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update(self):\n    self.text.tag_remove(\"local_name\", \"1.0\", \"end\")\n\n    if get_workbench().get_option(\"view.locals_highlighting\") and self.text.is_python_text():\n        try:\n            highlight_positions = self.get_positions()\n            self._highlight(highlight_positions)\n        except Exception:\n            logger.exception(\"Problem when updating local variable tags\")", "loc": 9}
{"file": "thonny\\thonny\\plugins\\locals_marker.py", "class_name": null, "function_name": "process_scope", "parameters": ["scope"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "isinstance", "process_node", "process_scope", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_scope(scope):\n    if isinstance(scope, tree.Function):\n        # process all children after name node,\n        # (otherwise name of global function will be marked as local def)\n        local_names = set()\n        global_names = set()\n        for child in scope.children[2:]:\n            process_node(child, local_names, global_names)\n    else:\n        if hasattr(scope, \"subscopes\"):\n            for child in scope.subscopes:\n                process_scope(child)\n        elif hasattr(scope, \"children\"):\n            for child in scope.children:\n                process_scope(child)", "loc": 15}
{"file": "thonny\\thonny\\plugins\\locals_marker.py", "class_name": null, "function_name": "process_node", "parameters": ["node", "local_names", "global_names"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["global_names.update", "isinstance", "local_names.add", "locs.append", "node.get_global_names", "node.is_definition", "process_node", "set"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_node(node, local_names, global_names):\n    if isinstance(node, tree.GlobalStmt):\n        global_names.update([n.value for n in node.get_global_names()])\n\n    elif isinstance(node, tree.Name):\n        if node.value in global_names:\n            return\n\n        if node.is_definition():  # local def\n            locs.append(node)\n            local_names.add(node.value)\n        elif node.value in local_names:  # use of local\n            locs.append(node)\n\n    elif isinstance(node, tree.BaseNode):\n        # ref: parso/python/grammar*.txt\n        if node.type == \"trailer\" and node.children[0].value == \".\":\n            # this is attribute\n            return\n\n        if isinstance(node, tree.Function):\n            global_names = set()  # outer global statement doesn't have effect anymore\n\n        for child in node.children:\n            process_node(child, local_names, global_names)", "loc": 25}
{"file": "thonny\\thonny\\plugins\\locals_marker.py", "class_name": null, "function_name": "perform_update", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.update"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_update():\n    try:\n        self.update()\n    finally:\n        self._update_scheduled = False", "loc": 5}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "ObjectInspector", "function_name": "navigate_back", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self._show_object_by_id", "self.back_links.pop", "self.forward_links.append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def navigate_back(self):\n    if len(self.back_links) == 0:\n        return\n\n    self.forward_links.append(self.object_id)\n    self._show_object_by_id(self.back_links.pop(), True)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "ObjectInspector", "function_name": "navigate_forward", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self._show_object_by_id", "self.back_links.append", "self.forward_links.pop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def navigate_forward(self):\n    if len(self.forward_links) == 0:\n        return\n\n    self.back_links.append(self.object_id)\n    self._show_object_by_id(self.forward_links.pop(), True)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "ObjectInspector", "function_name": "request_object_info", "parameters": ["self", "context_id"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InlineCommand", "get_runner", "get_runner().send_command", "self.active_page.winfo_height", "self.active_page.winfo_width"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_object_info(self, context_id=None):\n    # current width and height of the frame are required for\n    # some content providers\n    if self.active_page is not None:\n        frame_width = self.active_page.winfo_width()\n        frame_height = self.active_page.winfo_height()\n\n        # in some cases measures are inaccurate\n        if frame_width < 5 or frame_height < 5:\n            frame_width = None\n            frame_height = None\n    else:\n        frame_width = None\n        frame_height = None\n\n    get_runner().send_command(\n        InlineCommand(\n            \"get_object_info\",\n            object_id=self.object_id,\n            context_id=context_id,\n            back_links=self.back_links,\n            forward_links=self.forward_links,\n            include_attributes=self.active_page == self.attributes_page,\n            all_attributes=True,\n            frame_width=frame_width,\n            frame_height=frame_height,\n        )\n    )", "loc": 28}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "ObjectInspector", "function_name": "set_object_info", "parameters": ["self", "object_info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._set_title", "self.attributes_page.clear", "self.attributes_page.update_variables", "self.current_content_inspector.grid_remove", "self.update_type_specific_info", "thonny.memory.format_object_id"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_object_info(self, object_info):\n    self.object_info = object_info\n    if object_info is None or \"error\" in object_info:\n        if object_info is None:\n            self._set_title(\"\")\n        else:\n            self._set_title(object_info[\"error\"])\n        if self.current_content_inspector is not None:\n            self.current_content_inspector.grid_remove()\n            self.current_content_inspector = None\n        self.attributes_page.clear()\n    else:\n        self._set_title(\n            object_info[\"full_type_name\"]\n            + \" @ \"\n            + thonny.memory.format_object_id(object_info[\"id\"])\n        )\n        self.attributes_page.update_variables(object_info[\"attributes\"])\n        self.attributes_page.context_id = object_info[\"id\"]\n        self.update_type_specific_info(object_info)\n\n        # update layout\n        # self._expose(None)\n        # if not self.grid_frame.winfo_ismapped():\n        #    self.grid_frame.grid()\n\n    \"\"\"\n    if self.back_links == []:\n        self.back_label.config(foreground=\"lightgray\", cursor=\"arrow\")\n    else:\n        self.back_label.config(foreground=\"blue\", cursor=get_hyperlink_cursor())\n\n    if self.forward_links == []:\n        self.forward_label.config(foreground=\"lightgray\", cursor=\"arrow\")\n    else:\n        self.forward_label.config(foreground=\"blue\", cursor=get_hyperlink_cursor())\n    \"\"\"", "loc": 37}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "ObjectInspector", "function_name": "update_type_specific_info", "parameters": ["self", "object_info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["content_inspector.grid", "insp.applies_to", "self.current_content_inspector.grid_remove", "self.current_content_inspector.set_object_info"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_type_specific_info(self, object_info):\n    content_inspector = None\n    for insp in self.content_inspectors:\n        if insp.applies_to(object_info):\n            content_inspector = insp\n            break\n\n    if content_inspector != self.current_content_inspector:\n        if self.current_content_inspector is not None:\n            self.current_content_inspector.grid_remove()  # TODO: or forget?\n            self.current_content_inspector = None\n\n        if content_inspector is not None:\n            content_inspector.grid(row=0, column=0, sticky=tk.NSEW, padx=(0, 0))\n\n        self.current_content_inspector = content_inspector\n\n    if self.current_content_inspector is not None:\n        self.current_content_inspector.set_object_info(object_info)", "loc": 19}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "FileHandleInspector", "function_name": "set_object_info", "parameters": ["self", "object_info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytes_read.decode", "content.encode", "content.split", "len", "logger.exception", "min", "self.text.configure", "self.text.see", "self.text.set_content", "self.text.tag_add", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_object_info(self, object_info):\n    if \"file_content\" not in object_info:\n        logger.exception(\"File error: \" + object_info[\"file_error\"])\n        return\n\n    assert \"file_content\" in object_info\n    content = object_info[\"file_content\"]\n    line_count_sep = len(content.split(\"\\n\"))\n    # line_count_term = len(content.splitlines())\n    # char_count = len(content)\n    self.text.configure(height=min(line_count_sep, 10))\n    self.text.set_content(content)\n\n    assert \"file_tell\" in object_info\n    # f.tell() gives num of bytes read (minus some magic with linebreaks)\n\n    file_bytes = content.encode(encoding=object_info[\"file_encoding\"])\n    bytes_read = file_bytes[0 : object_info[\"file_tell\"]]\n    read_content = bytes_read.decode(encoding=object_info[\"file_encoding\"])\n    read_char_count = len(read_content)\n    # read_line_count_term = (len(content.splitlines())\n    #                        - len(content[read_char_count:].splitlines()))\n\n    pos_index = \"1.0+\" + str(read_char_count) + \"c\"\n    self.text.tag_add(\"read\", \"1.0\", pos_index)\n    self.text.see(pos_index)\n\n    # TODO: show this info somewhere\n    \"\"\"\n    label.configure(text=\"Read %d/%d %s, %d/%d %s\"\n                    % (read_char_count,\n                       char_count,\n                       \"symbol\" if char_count == 1 else \"symbols\",\n                       read_line_count_term,\n                       line_count_term,\n                       \"line\" if line_count_term == 1 else \"lines\"))\n    \"\"\"", "loc": 37}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "StringInspector", "function_name": "set_object_info", "parameters": ["self", "object_info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.literal_eval", "content.split", "len", "min", "self.text.configure", "self.text.set_content"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_object_info(self, object_info):\n    # TODO: don't show too big string\n    try:\n        content = ast.literal_eval(object_info[\"repr\"])\n    except SyntaxError:\n        try:\n            # can be shortened\n            content = ast.literal_eval(object_info[\"repr\"] + object_info[\"repr\"][0:1])\n        except SyntaxError:\n            content = \"<can't show string content>\"\n\n    line_count_sep = len(content.split(\"\\n\"))\n    # line_count_term = len(content.splitlines())\n    self.text.configure(height=min(line_count_sep, 10))\n    self.text.set_content(content)\n    \"\"\" TODO:\n    label.configure(text=\"%d %s, %d %s\"\n                    % (len(content),\n                       \"symbol\" if len(content) == 1 else \"symbols\",\n                       line_count_term,\n                       \"line\" if line_count_term == 1 else \"lines\"))\n    \"\"\"", "loc": 22}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "IntInspector", "function_name": "set_object_info", "parameters": ["self", "object_info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.literal_eval", "bin", "hex", "oct", "self.text.set_content"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_object_info(self, object_info):\n    content = ast.literal_eval(object_info[\"repr\"])\n    self.text.set_content(\n        object_info[\"repr\"]\n        + \"\\n\\n\"\n        + \"bin: \"\n        + bin(content)\n        + \"\\n\"\n        + \"oct: \"\n        + oct(content)\n        + \"\\n\"\n        + \"hex: \"\n        + hex(content)\n        + \"\\n\"\n    )", "loc": 15}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "FloatInspector", "function_name": "set_object_info", "parameters": ["self", "object_info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Decimal", "self.text.set_content", "str", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_object_info(self, object_info):\n    content = object_info[\"repr\"] + \"\\n\\n\\n\"\n\n    if \"as_integer_ratio\" in object_info:\n        ratio = object_info[\"as_integer_ratio\"]\n        from decimal import Decimal\n\n        ratio_dec_str = str(Decimal(ratio[0]) / Decimal(ratio[1]))\n\n        if ratio_dec_str != object_info[\"repr\"]:\n            explanation = tr(\n                \"The representation above is an approximate value of this float. \"\n                \"The exact stored value is %s which is about %s\"\n            )\n\n            content += explanation % (\n                \"\\n\\n  %d / %d\\n\\n\" % ratio,\n                \"\\n\\n  %s\\n\\n\" % ratio_dec_str,\n            )\n\n    self.text.set_content(content)", "loc": 21}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "ElementsInspector", "function_name": "set_object_info", "parameters": ["self", "object_info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "repr", "self._clear_tree", "self._update_columns", "self.len_label.configure", "self.tree.insert", "self.tree.set", "shorten_repr", "thonny.memory.format_object_id"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_object_info(self, object_info):\n    assert \"elements\" in object_info\n\n    self.elements_have_indices = object_info[\"type\"] in (repr(tuple), repr(list))\n    self._update_columns()\n    self.context_id = object_info[\"id\"]\n\n    self._clear_tree()\n    index = 0\n    # TODO: don't show too big number of elements\n    for element in object_info[\"elements\"]:\n        node_id = self.tree.insert(\"\", \"end\")\n        if self.elements_have_indices:\n            self.tree.set(node_id, \"index\", index)\n        else:\n            self.tree.set(node_id, \"index\", \"\")\n\n        self.tree.set(node_id, \"id\", thonny.memory.format_object_id(element.id))\n        self.tree.set(\n            node_id, \"value\", shorten_repr(element.repr, thonny.memory.MAX_REPR_LENGTH_IN_GRID)\n        )\n        index += 1\n\n    count = len(object_info[\"elements\"])\n    self.len_label.configure(text=\" len: %d\" % count)", "loc": 25}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "DictInspector", "function_name": "update_memory_model", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().in_heap_mode", "self.tree.configure"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_memory_model(self, event=None):\n    if get_workbench().in_heap_mode():\n        self.tree.configure(displaycolumns=(\"key_id\", \"id\"))\n    else:\n        self.tree.configure(displaycolumns=(\"key\", \"value\"))", "loc": 5}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "DictInspector", "function_name": "set_object_info", "parameters": ["self", "object_info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self._clear_tree", "self.len_label.configure", "self.tree.insert", "self.tree.set", "self.update_memory_model", "shorten_repr", "thonny.memory.format_object_id"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_object_info(self, object_info):\n    assert \"entries\" in object_info\n    self.context_id = object_info[\"id\"]\n\n    self._clear_tree()\n    # TODO: don't show too big number of elements\n    for key, value in object_info[\"entries\"]:\n        node_id = self.tree.insert(\"\", \"end\")\n        self.tree.set(node_id, \"key_id\", thonny.memory.format_object_id(key.id))\n        self.tree.set(\n            node_id, \"key\", shorten_repr(key.repr, thonny.memory.MAX_REPR_LENGTH_IN_GRID)\n        )\n        self.tree.set(node_id, \"id\", thonny.memory.format_object_id(value.id))\n        self.tree.set(\n            node_id, \"value\", shorten_repr(value.repr, thonny.memory.MAX_REPR_LENGTH_IN_GRID)\n        )\n\n    count = len(object_info[\"entries\"])\n    self.len_label.configure(text=\" len: %d\" % count)\n    self.update_memory_model()", "loc": 20}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "ImageInspector", "function_name": "set_object_info", "parameters": ["self", "object_info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["base64.b64encode", "isinstance", "self.label.configure", "tk.PhotoImage", "type"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_object_info(self, object_info):\n    if isinstance(object_info[\"image_data\"], bytes):\n        import base64\n\n        data = base64.b64encode(object_info[\"image_data\"])\n    elif isinstance(object_info[\"image_data\"], str):\n        data = object_info[\"image_data\"]\n    else:\n        self.label.configure(\n            image=None, text=\"Unsupported image data (%s)\" % type(object_info[\"image_data\"])\n        )\n        return\n\n    try:\n        self.image = tk.PhotoImage(data=data)\n        self.label.configure(image=self.image)\n    except Exception as e:\n        self.label.configure(image=None, text=\"Unsupported image data (%s)\" % e)", "loc": 18}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": "AttributesFrame", "function_name": "show_selected_object_info", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().get_backend_proxy", "get_workbench", "get_workbench().event_generate", "isinstance", "messagebox.showinfo", "self.get_object_id", "self.tree.focus", "self.tree.item"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_selected_object_info(self):\n    object_id = self.get_object_id()\n    if object_id is None:\n        return\n\n    iid = self.tree.focus()\n    if not iid:\n        return\n    repr_str = self.tree.item(iid)[\"values\"][2]\n\n    if repr_str == \"<bound_method>\":\n        from thonny.plugins.micropython import MicroPythonProxy\n\n        if isinstance(get_runner().get_backend_proxy(), MicroPythonProxy):\n            messagebox.showinfo(\n                \"Not supported\",\n                \"Inspecting bound methods is not supported with MicroPython\",\n                master=self,\n            )\n            return\n\n    get_workbench().event_generate(\"ObjectSelect\", object_id=object_id)", "loc": 22}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": null, "function_name": "create_tab", "parameters": ["col", "caption", "page"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["page.grid", "self.active_page.grid_forget", "self.active_page.tab.configure", "self.object_info.get", "self.request_object_info", "self.tabs.append", "tab.bind", "tab.configure", "tab.grid", "ttk.Label"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_tab(col, caption, page):\n    if page == self.active_page:\n        style = \"Active.ViewTab.TLabel\"\n    else:\n        style = \"Inactive.ViewTab.TLabel\"\n    tab = ttk.Label(toolbar, text=caption, style=style)\n    tab.grid(row=0, column=col, pady=5, padx=5, sticky=\"nsew\")\n    self.tabs.append(tab)\n    page.tab = tab\n\n    def on_click(event):\n        if self.active_page == page:\n            return\n        else:\n            if self.active_page is not None:\n                self.active_page.grid_forget()\n                self.active_page.tab.configure(style=\"Inactive.ViewTab.TLabel\")\n\n            self.active_page = page\n            page.grid(row=1, column=0, sticky=\"nsew\", padx=0)\n            tab.configure(style=\"Active.ViewTab.TLabel\")\n            if (\n                self.active_page == self.attributes_page\n                and (self.object_info is None or not self.object_info.get(\"attributes\"))\n                and self.object_id is not None\n            ):\n                self.request_object_info()\n\n    tab.bind(\"<1>\", on_click)", "loc": 29}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": null, "function_name": "create_navigation_link", "parameters": ["col", "image_filename", "action", "tooltip", "padx"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CustomToolbutton", "button.grid", "ems_to_pixels", "get_workbench", "get_workbench().get_image", "ui_utils.create_tooltip"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_navigation_link(col, image_filename, action, tooltip, padx=0):\n    button = CustomToolbutton(\n        toolbar,\n        command=action,\n        style=\"ViewToolbar.Toolbutton\",\n        image=get_workbench().get_image(image_filename),\n        state=tk.NORMAL,\n        pad=ems_to_pixels(0.2),\n    )\n    ui_utils.create_tooltip(button, tooltip)\n\n    button.grid(row=0, column=col, sticky=tk.NE, padx=padx, pady=4)\n    return button", "loc": 13}
{"file": "thonny\\thonny\\plugins\\object_inspector.py", "class_name": null, "function_name": "on_click", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["page.grid", "self.active_page.grid_forget", "self.active_page.tab.configure", "self.object_info.get", "self.request_object_info", "tab.configure"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_click(event):\n    if self.active_page == page:\n        return\n    else:\n        if self.active_page is not None:\n            self.active_page.grid_forget()\n            self.active_page.tab.configure(style=\"Inactive.ViewTab.TLabel\")\n\n        self.active_page = page\n        page.grid(row=1, column=0, sticky=\"nsew\", padx=0)\n        tab.configure(style=\"Active.ViewTab.TLabel\")\n        if (\n            self.active_page == self.attributes_page\n            and (self.object_info is None or not self.object_info.get(\"attributes\"))\n            and self.object_id is not None\n        ):\n            self.request_object_info()", "loc": 17}
{"file": "thonny\\thonny\\plugins\\ollama.py", "class_name": "OllamaAssistant", "function_name": "complete_chat", "parameters": ["self", "context"], "param_types": {"context": "ChatContext"}, "return_type": "Iterator[ChatResponseChunk]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChatResponseChunk", "ollama.chat"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def complete_chat(self, context: ChatContext) -> Iterator[ChatResponseChunk]:\n    import ollama\n\n    api_messages = [{\"role\": msg.role, \"content\": msg.content} for msg in context.messages]\n    stream = ollama.chat(\n        model=\"codellama:7b-instruct\",\n        messages=api_messages,\n        stream=True,\n    )\n\n    for chunk in stream:\n        yield ChatResponseChunk(chunk[\"message\"][\"content\"], is_final=False)\n\n    yield ChatResponseChunk(\"\", is_final=True)", "loc": 14}
{"file": "thonny\\thonny\\plugins\\openai.py", "class_name": "OpenAIApiKeyDialog", "function_name": "init_main_frame", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["create_url_label", "key_label.grid", "paste_button.grid", "self.key_entry.grid", "super", "super().init_main_frame", "ttk.Button", "ttk.Entry", "ttk.Label", "url_label.grid"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def init_main_frame(self):\n    super().init_main_frame()\n    url_label = create_url_label(self.main_frame, url=\"https://platform.openai.com/api-keys\")\n    url_label.grid(row=1, column=1, columnspan=3)\n\n    key_label = ttk.Label(self.main_frame, text=\"API key\")\n    key_label.grid(row=2, column=1)\n\n    self.key_entry = ttk.Entry(self.main_frame, width=50)\n    self.key_entry.grid(row=2, column=2)\n\n    paste_button = ttk.Button(self.main_frame, text=\"Paste\", command=self._paste_from_clipboard)\n    paste_button.grid(row=2, column=3)", "loc": 13}
{"file": "thonny\\thonny\\plugins\\openai.py", "class_name": "OpenAIAssistant", "function_name": "get_ready", "parameters": ["self"], "param_types": {}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_saved_api_key", "self._request_new_api_key"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_ready(self) -> bool:\n    if self._get_saved_api_key() is None:\n        self._request_new_api_key()\n\n    return self._get_saved_api_key() is not None", "loc": 5}
{"file": "thonny\\thonny\\plugins\\openai.py", "class_name": "OpenAIAssistant", "function_name": "complete_chat", "parameters": ["self", "context"], "param_types": {"context": "ChatContext"}, "return_type": "Iterator[ChatResponseChunk]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ChatResponseChunk", "OpenAI", "client.chat.completions.create", "self._get_saved_api_key", "self.format_message"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def complete_chat(self, context: ChatContext) -> Iterator[ChatResponseChunk]:\n    from openai import OpenAI\n\n    client = OpenAI(api_key=self._get_saved_api_key())\n\n    out_msgs = [\n        {\"role\": \"system\", \"content\": \"You are a helpful programming coach.\"},\n    ] + [{\"role\": msg.role, \"content\": self.format_message(msg)} for msg in context.messages]\n\n    response = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=out_msgs,\n        stream=True,\n    )\n\n    for chunk in response:\n        chunk_message = chunk.choices[0].delta.content or \"\"\n        yield ChatResponseChunk(chunk_message, is_final=False)\n\n    yield ChatResponseChunk(\"\", is_final=True)", "loc": 20}
{"file": "thonny\\thonny\\plugins\\outline.py", "class_name": "OutlineView", "function_name": "destroy", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_editor_notebook", "get_workbench().get_editor_notebook().unbind", "get_workbench().get_editor_notebook().winfo_exists", "ttk.Frame.destroy"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def destroy(self):\n    if get_workbench().get_editor_notebook().winfo_exists():\n        get_workbench().get_editor_notebook().unbind(\n            \"<<NotebookTabChanged>>\", self._tab_changed_binding\n        )\n    self.vert_scrollbar[\"command\"] = None\n    ttk.Frame.destroy(self)", "loc": 7}
{"file": "thonny\\thonny\\plugins\\paren_matcher.py", "class_name": null, "function_name": "update_highlighting_move", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_update_highlighting", "time.time"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_highlighting_move(event):\n    global _last_move_time\n    # needs delay because selecting with mouse causes many events\n    # and I don't know how to distinguish selection from other moves\n    t = time.time()\n    if t - _last_move_time > 0.1:\n        delay = None\n    else:\n        delay = 300\n    _last_move_time = t\n    _update_highlighting(event, False, True, delay=delay)", "loc": 11}
{"file": "thonny\\thonny\\plugins\\paren_matcher.py", "class_name": null, "function_name": "update_highlighting_edit_cw", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_update_highlighting", "event.get", "event.text_widget.tag_remove", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_highlighting_edit_cw(event):\n    if isinstance(event.text_widget, CodeViewText):\n        event.widget = event.text_widget\n        trivial = event.get(\"trivial_for_parens\", False)\n        _update_highlighting(event, True, not trivial)\n        if trivial:\n            event.text_widget.tag_remove(\"surrounding_parens\", \"0.1\", \"end\")", "loc": 7}
{"file": "thonny\\thonny\\plugins\\paren_matcher.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "wb.bind", "wb.bind_class", "wb.set_default"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    wb = get_workbench()\n\n    wb.set_default(\"view.paren_highlighting\", True)\n    wb.bind(\"TextInsert\", update_highlighting_edit_cw, True)\n    wb.bind(\"TextDelete\", update_highlighting_edit_cw, True)\n    wb.bind_class(\"CodeViewText\", \"<<VerticalScroll>>\", update_highlighting_move, True)\n    wb.bind_class(\"CodeViewText\", \"<<CursorMove>>\", update_highlighting_move, True)\n    wb.bind_class(\"ShellText\", \"<<TextChange>>\", update_highlighting_full, True)\n    wb.bind_class(\"ShellText\", \"<<CursorMove>>\", update_highlighting_full, True)\n    wb.bind(\"<<UpdateAppearance>>\", update_highlighting_full, True)", "loc": 11}
{"file": "thonny\\thonny\\plugins\\paren_matcher.py", "class_name": "ParenMatcher", "function_name": "schedule_update", "parameters": ["self", "delay"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.text.after", "self.text.after_cancel", "self.text.after_idle"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def schedule_update(self, delay=None):\n    if self._update_scheduling_id is not None:\n        self.text.after_cancel(self._update_scheduling_id)\n\n    if delay is not None:\n        self._update_scheduling_id = self.text.after(delay, self.perform_update)\n    else:\n        self._update_scheduling_id = self.text.after_idle(self.perform_update)", "loc": 8}
{"file": "thonny\\thonny\\plugins\\paren_matcher.py", "class_name": "ParenMatcher", "function_name": "perform_update", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.update_highlighting"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_update(self):\n    try:\n        self.update_highlighting()\n    finally:\n        self._update_scheduled = False", "loc": 5}
{"file": "thonny\\thonny\\plugins\\paren_matcher.py", "class_name": "ParenMatcher", "function_name": "update_highlighting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["clear_highlighting", "get_workbench", "get_workbench().get_option", "self._update_highlighting_for_active_range", "self.text.is_python_text", "self.text.is_pythonlike_text"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_highlighting(self):\n    clear_highlighting(self.text)\n\n    if get_workbench().get_option(\"view.paren_highlighting\") and (\n        self.text.is_python_text() or self.text.is_pythonlike_text()\n    ):\n        self._update_highlighting_for_active_range()", "loc": 7}
{"file": "thonny\\thonny\\plugins\\pgzero_frontend.py", "class_name": null, "function_name": "update_environment", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "get_workbench().in_simple_mode", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_environment():\n    if get_workbench().in_simple_mode():\n        os.environ[\"PGZERO_MODE\"] = \"auto\"\n    else:\n        os.environ[\"PGZERO_MODE\"] = str(get_workbench().get_option(_OPTION_NAME))", "loc": 5}
{"file": "thonny\\thonny\\plugins\\pgzero_frontend.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_command", "get_workbench().set_default", "tr", "update_environment"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    get_workbench().set_default(_OPTION_NAME, False)\n    get_workbench().add_command(\n        \"toggle_pgzero_mode\",\n        \"run\",\n        tr(\"Pygame Zero mode\"),\n        toggle_variable,\n        flag_name=_OPTION_NAME,\n        group=40,\n    )\n    update_environment()", "loc": 11}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": null, "function_name": "perform_pypi_search", "parameters": ["query", "data_url", "common_tokens"], "param_types": {"query": "str", "data_url": "str", "common_tokens": "List[str]"}, "return_type": "List[DistInfo]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DistInfo", "canonical_query.split", "canonicalize_name", "compute_dist_name_similarity", "download_bytes", "download_dist_info_from_pypi", "json.loads", "logger.info", "p.get", "packages.insert", "packages.sort"], "control_structures": ["For", "If", "Try"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def perform_pypi_search(query: str, data_url: str, common_tokens: List[str]) -> List[DistInfo]:\n    logger.info(\"Performing PyPI search for %r\", query)\n\n    data = download_bytes(data_url)\n    packages: List[Dict] = json.loads(data)\n\n    canonical_query = canonicalize_name(query)\n    query_parts = canonical_query.split(\"-\")\n    for package in packages:\n        package[\"score\"] = compute_dist_name_similarity(package[\"name\"], query_parts, common_tokens)\n\n    packages.sort(key=lambda p: p[\"score\"], reverse=True)\n\n    if not packages or packages[0][\"score\"] < 1.0:\n        # test for exact match\n        try:\n            dist_info = download_dist_info_from_pypi(canonical_query, None)\n            packages.insert(0, {\"name\": dist_info.name, \"summary\": dist_info.summary, \"score\": 1.0})\n        except Exception:\n            logger.info(\"No luck with exact match %r\", canonical_query)\n\n    return [\n        DistInfo(\n            name=p[\"name\"],\n            version=None,\n            summary=p.get(\"summary\"),\n            source=\"PyPI\",\n        )\n        for p in packages[:20]\n        if p[\"score\"] > 0.6\n    ]", "loc": 31}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": null, "function_name": "compute_dist_name_similarity", "parameters": ["name", "query_parts", "common_tokens"], "param_types": {"name": "str", "query_parts": "List[str]", "common_tokens": "List[str]"}, "return_type": "float", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'-'.join", "_get_sublists_of_length", "abs", "canonicalize_name", "canonicalize_name(name).split", "itertools.permutations", "itertools.product", "jaro_similarity", "len", "list", "max", "min", "name_parts.remove"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def compute_dist_name_similarity(\n    name: str, query_parts: List[str], common_tokens: List[str]\n) -> float:\n    name_parts = canonicalize_name(name).split(\"-\")\n\n    for common_token in common_tokens:\n        if common_token in name_parts and common_token not in query_parts:\n            # don't penalize omitting this part\n            name_parts.remove(common_token)\n\n    common_count = min(len(query_parts), len(name_parts))\n    name_perms = list(itertools.permutations(name_parts, common_count))\n    query_perms = list(itertools.permutations(query_parts, common_count))\n\n    if len(name_perms) * len(query_perms) > 36:\n        # 36 corresponds to 3-part name and 3-part query.\n        # More than that would be too much effort. Assume correct order and match sub-lists instead.\n        name_perms = _get_sublists_of_length(name_parts, common_count)\n        query_perms = _get_sublists_of_length(query_parts, common_count)\n\n    best_score = 0\n    for name_perm, query_perm in itertools.product(name_perms, query_perms):\n        score = jaro_similarity(\"-\".join(name_perm), \"-\".join(query_perm))\n        best_score = max(score, best_score)\n\n    parts_length_penalty = 1.0 - abs(len(query_parts) - len(name_parts)) * 0.05\n    return best_score * parts_length_penalty", "loc": 27}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": null, "function_name": "download_dist_info_from_pypi", "parameters": ["name", "version"], "param_types": {"name": "str", "version": "Optional[str]"}, "return_type": "DistInfo", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DistInfo", "download_dist_data_from_pypi", "info.get"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def download_dist_info_from_pypi(name: str, version: Optional[str]) -> DistInfo:\n    # versioned data does not have releases, so need to make 2 downloads\n    info = download_dist_data_from_pypi(name, version)[\"info\"]\n\n    return DistInfo(\n        name=info[\"name\"],\n        version=info[\"version\"],\n        summary=info[\"summary\"] or None,\n        license=info[\"license\"] or None,\n        author=info[\"author\"] or None,\n        classifiers=info[\"classifiers\"] or None,\n        home_page=info[\"home_page\"] or info[\"project_url\"],\n        package_url=info[\"package_url\"],\n        project_urls=info.get(\"project_urls\", None),\n        requires=info[\"requires_dist\"],\n        source=\"PyPI\",\n        installed_location=None,\n    )", "loc": 18}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": null, "function_name": "try_download_version_list_from_pypi", "parameters": ["name"], "param_types": {"name": "str"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["download_dist_data_from_pypi", "list", "releases.keys"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def try_download_version_list_from_pypi(name: str) -> List[str]:\n    try:\n        releases = download_dist_data_from_pypi(name, None)[\"releases\"]\n        return list(releases.keys())\n    except urllib.error.HTTPError as e:\n        if e.code == 404:\n            # package is not at PyPI\n            return []\n        else:\n            raise", "loc": 10}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PluginsPipDialog", "get_workbench", "get_workbench().add_command", "get_workbench().add_view", "get_workbench().show_view", "tr", "ui_utils.show_dialog"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    def open_backend_pip_gui(*args):\n        get_workbench().show_view(\"PackagesView\")\n\n    def open_plugins_pip_gui(*args):\n        pg = PluginsPipDialog(get_workbench())\n        ui_utils.show_dialog(pg)\n\n    get_workbench().add_view(PackagesView, tr(\"Packages\"), \"s\")\n\n    get_workbench().add_command(\n        \"backendpipgui\",\n        \"tools\",\n        tr(\"Manage packages...\"),\n        open_backend_pip_gui,\n        group=80,\n    )\n    get_workbench().add_command(\n        \"pluginspipgui\", \"tools\", tr(\"Manage plug-ins...\"), open_plugins_pip_gui, group=180\n    )", "loc": 20}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": "PipFrame", "function_name": "unload_content", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._clear_current_package_or_info", "self._set_state", "self.listbox.delete"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unload_content(self):\n    self._installed_dists = None\n    self._version_list_cache = {}\n    self._current_dist_info = None\n    self._last_search_results = None\n\n    self._clear_current_package_or_info()\n    self.listbox.delete(0, \"end\")\n    self._set_state(\"inactive\")", "loc": 9}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": "PipFrame", "function_name": "show_button_menu", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._installer_runs_locally", "self.button_menu.add_command", "self.button_menu.delete", "self.button_menu.tk_popup", "self.menu_button.winfo_height", "self.menu_button.winfo_rootx", "self.menu_button.winfo_rooty", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_button_menu(self, event=None):\n    self.button_menu.delete(0, \"end\")\n    self.button_menu.add_command(\n        label=tr(\"Install from requirements file\") + \"...\",\n        command=self._handle_install_requirements_click,\n        state=\"normal\" if self._installer_runs_locally() else \"disabled\",\n    )\n    self.button_menu.add_command(\n        label=tr(\"Install from package file\") + \"...\",\n        command=self._handle_install_file_click,\n        state=\"normal\" if self._installer_runs_locally() else \"disabled\",\n    )\n    post_x = self.menu_button.winfo_rootx()\n    post_y = self.menu_button.winfo_rooty() + self.menu_button.winfo_height()\n    self.button_menu.tk_popup(post_x, post_y)", "loc": 15}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": null, "function_name": "poll_fetch_complete", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dist_info_future.done", "dist_info_future.result", "get_workbench", "get_workbench().after", "logger.exception", "self._append_info_text", "self._complete_show_package_info", "self._set_state", "str", "version_list_future.done", "version_list_future.result"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def poll_fetch_complete():\n    if dist_info_future.done() and version_list_future.done():\n        try:\n            info = dist_info_future.result()\n            version_list_future.result()  # will be cached\n        except Exception as e:\n            logger.exception(\"Error downloading\")\n            self._append_info_text(\n                \"Could not download package info or list of versions: \" + str(e)\n            )\n            self._set_state(\"idle\")\n        else:\n            self._complete_show_package_info(info)\n    else:\n        get_workbench().after(200, poll_fetch_complete)", "loc": 15}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": null, "function_name": "write_att", "parameters": ["caption", "value", "value_tags"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._append_info_text"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write_att(caption, value, value_tags=()):\n    if value is None:\n        return\n\n    self._append_info_text(caption + \": \", \"caption\")\n    self._append_info_text(value, tags=value_tags)\n    self._append_info_text(\"\\n\")", "loc": 7}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": null, "function_name": "parse_version", "parameters": ["ver_str"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["packaging.version.Version"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_version(ver_str):\n    try:\n        ver = packaging.version.Version(ver_str)\n    except packaging.version.InvalidVersion:\n        ver = packaging.version.Version(\"0.0.1\")\n\n    return ver, ver_str", "loc": 7}
{"file": "thonny\\thonny\\plugins\\pip_gui.py", "class_name": null, "function_name": "poll_fetch_complete", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().after", "logger.exception", "results_future.done", "results_future.result", "self._show_search_results"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def poll_fetch_complete():\n    if results_future.done():\n        try:\n            results = results_future.result()\n        except Exception as e:\n            logger.exception(\"Error when searching packages\")\n            self._show_search_results(query, e)\n        else:\n            self._show_search_results(query, results)\n\n    else:\n        get_workbench().after(200, poll_fetch_complete)", "loc": 12}
{"file": "thonny\\thonny\\plugins\\problems.py", "class_name": null, "function_name": "append_editor_link", "parameters": ["text", "uri", "target_line", "extra_tags"], "param_types": {"text": "str", "uri": "str", "target_line": "Optional[int]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["append"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def append_editor_link(text: str, uri: str, target_line: Optional[int], extra_tags=()):\n    url = uri\n    if target_line is not None:\n        url += f\"#{target_line}\"\n\n    append(text, (\"link\", url) + extra_tags)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\pythontutor.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_command", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    get_workbench().add_command(\n        \"visualize_in_pythontutor\",\n        \"run\",\n        tr(\"Visualize current script at Python Tutor\"),\n        _do_visualize,\n        tester=_can_visualize,\n        group=11,\n    )", "loc": 9}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "post_menu", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.menu.tk_popup", "self.menu.winfo_reqwidth", "self.menu_button.winfo_height", "self.menu_button.winfo_rootx", "self.menu_button.winfo_rooty", "self.menu_button.winfo_width"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def post_menu(self) -> None:\n    post_x = (\n        self.menu_button.winfo_rootx()\n        + self.menu_button.winfo_width()\n        - self.menu.winfo_reqwidth()\n    )\n    post_y = self.menu_button.winfo_rooty() + self.menu_button.winfo_height()\n    self.menu.tk_popup(post_x, post_y)", "loc": 8}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "cmd_export", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["asksaveasfilename", "format_time_range", "get_workbench", "get_workbench().get_local_cwd", "logger.info", "logger.warning", "messagebox.showerror", "path.lower", "path.lower().endswith", "save_events_to_file", "self._export_event", "tk.StringVar", "tr", "type_var.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cmd_export(self, event=None):\n    from thonny.plugins.event_logging import save_events_to_file\n\n    if not self.events:\n        logger.warning(\"Attempting to export without events\")\n        return\n\n    COMPRESSED = tr(\"compressed event logs\")\n    UNCOMPRESSED = tr(\"uncompressed event logs\")\n\n    filetypes = [(COMPRESSED, \".zip\"), (UNCOMPRESSED, \".json\"), (tr(\"all files\"), \".*\")]\n\n    assert self.session_start_time is not None and self.session_end_time is not None\n    time_range = format_time_range(self.session_start_time, self.session_end_time)\n    initialdir = get_workbench().get_local_cwd()\n    initialfile = f\"{time_range}.zip\"\n    type_var = tk.StringVar(value=\"\")\n    path = asksaveasfilename(\n        filetypes=filetypes,\n        defaultextension=None,\n        initialdir=initialdir,\n        initialfile=initialfile,\n        parent=get_workbench(),\n        typevariable=type_var,\n    )\n    logger.info(\"Save dialog returned %r with typevariable %r\", path, type_var.get())\n\n    if (\n        not path.lower().endswith(\".zip\")\n        and not path.lower().endswith(\".json\")\n        and not path.lower().endswith(\".txt\")\n    ):\n        if type_var.get() == COMPRESSED:\n            path += \".zip\"\n        elif type_var.get() == UNCOMPRESSED:\n            path += \".json\"\n        else:\n            messagebox.showerror(\n                tr(\"Error\"), \"Filename should have .zip, .json or .txt extension\", parent=self\n            )\n            return\n\n    prepared_events = [self._export_event(e) for e in self.events if e is not None]\n    save_events_to_file(prepared_events, path)", "loc": 44}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "load_session", "parameters": ["self", "events"], "param_types": {"events": "List[Dict]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cmd.button.configure", "datetime.datetime.strptime", "event_time.timestamp", "events.copy", "legacy_filename_to_uri", "len", "logger.info", "range", "reversed", "self.events.insert", "self.reset_session", "self.scrubber.config", "self.scrubber.focus_set", "self.select_event"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_session(self, events: List[Dict]) -> None:\n    logger.info(\"Loading session with %d events\", len(events))\n    self.loading = True\n    # Need a fixed copy. The source list can be appended to, and we want to tweak things.\n    self.events = events.copy()\n\n    # Generate InsertEditorToNotebook events for old format logs\n    for event in self.events:\n        if event[\"sequence\"] == \"InsertEditorToNotebook\":\n            break\n    else:\n        for i in reversed(range(0, len(self.events) - 1)):\n            event = self.events[i]\n            if event[\"sequence\"] == \"EditorTextCreated\":\n                self.events.insert(\n                    i + 1,\n                    {\n                        \"sequence\": \"InsertEditorToNotebook\",\n                        \"pos\": \"end\",\n                        \"time\": event[\"time\"],\n                        \"editor_id\": event[\"editor_id\"],\n                        \"text_widget_id\": event[\"text_widget_id\"],\n                        \"fictional\": True,\n                    },\n                )\n\n    # Generate ToplevelResponse events for old format logs\n    for event in self.events:\n        if event[\"sequence\"] == \"ToplevelResponse\":\n            break\n    else:\n        for i in reversed(range(0, len(self.events) - 1)):\n            event = self.events[i]\n            if (\n                event[\"sequence\"] == \"TextInsert\"\n                and event[\"text\"] == \">>> \"\n                and \"prompt\" in event[\"tags\"]\n            ):\n                self.events.insert(\n                    i + 1,\n                    {\n                        \"event_type\": \"ToplevelResponse\",\n                        \"sequence\": \"ToplevelResponse\",\n                        \"time\": event[\"time\"],\n                        \"fictional\": True,\n                    },\n                )\n\n    try:\n        for event in self.events:\n            event_time_str = event[\"time\"]\n            if len(event_time_str) == 19:\n                # 0 fraction may have been skipped\n                event_time_str += \".0\"\n            event_time = datetime.datetime.strptime(event_time_str, \"%Y-%m-%dT%H:%M:%S.%f\")\n            # yes, I'm modifying the argument. I'll live with this hack.\n            event[\"_epoch_time\"] = event_time.timestamp()\n\n            if \"filename\" in event and \"uri\" not in event:\n                event[\"uri\"] = legacy_filename_to_uri(event[\"filename\"])\n\n        self.reset_session()\n        self.scrubber.config(state=\"normal\")\n        for cmd in self.commands:\n            cmd.button.configure(state=\"normal\")\n\n        self.scrubber.config(\n            from_=self.events[0][\"_epoch_time\"], to=self.events[-1][\"_epoch_time\"]\n        )\n        # need to apply all events in order to record reversion information\n        self.select_event(len(self.events) - 1)\n        self.scrubber.focus_set()\n    finally:\n        self.loading = False", "loc": 74}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "select_prev_key_event", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.bell", "self.select_event"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_prev_key_event(self):\n    index = self.last_event_index\n    while index > 0:\n        index -= 1\n        if self.events[index][\"sequence\"] in KEY_EVENTS:\n            self.select_event(index)\n            return\n    else:\n        self.bell()", "loc": 9}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "select_next_key_event", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.bell", "self.select_event"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_next_key_event(self):\n    index = self.last_event_index\n    while index < len(self.events) - 1:\n        index += 1\n        if self.events[index][\"sequence\"] in KEY_EVENTS:\n            self.select_event(index)\n            return\n    else:\n        self.bell()", "loc": 9}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "select_prev_event", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.bell", "self.select_event"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_prev_event(self):\n    if self.last_event_index == 0:\n        self.bell()\n        return\n\n    self.select_event(self.last_event_index - 1)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "select_next_event", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.bell", "self.select_event"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_next_event(self):\n    if self.last_event_index == len(self.events) - 1:\n        self.bell()\n        return\n\n    self.select_event(self.last_event_index + 1)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "find_closest_index", "parameters": ["self", "target_timestamp", "start_index", "end_index"], "param_types": {"target_timestamp": "float", "start_index": "int", "end_index": "int"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["abs", "self.find_closest_index"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_closest_index(self, target_timestamp: float, start_index: int, end_index: int) -> int:\n    if start_index == end_index:\n        return start_index\n\n    if end_index - start_index == 1:\n        start_timestamp = self.events[start_index][\"_epoch_time\"]\n        end_timestamp = self.events[end_index][\"_epoch_time\"]\n        if abs(start_timestamp - target_timestamp) < abs(end_timestamp - target_timestamp):\n            return start_index\n        else:\n            return end_index\n\n    middle_index = (start_index + end_index) // 2\n    middle_timestamp = self.events[middle_index][\"_epoch_time\"]\n    if target_timestamp < middle_timestamp:\n        return self.find_closest_index(target_timestamp, start_index, middle_index)\n    else:\n        return self.find_closest_index(target_timestamp, middle_index, end_index)", "loc": 18}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "select_event", "parameters": ["self", "index", "from_scrubber"], "param_types": {"index": "int", "from_scrubber": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.editor_notebook.complete_select_event", "self.process_events_towards", "self.scrubber.set", "self.shell.complete_select_event", "self.update_details", "self.update_title"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def select_event(self, index: int, from_scrubber: bool = False) -> None:\n    assert not self._selecting_event\n    self._selecting_event = True\n    try:\n        self.process_events_towards(index)\n        assert self.last_event_index == index\n        event = self.events[self.last_event_index]\n        if not from_scrubber:\n            self.scrubber.set(event[\"_epoch_time\"])\n\n        # process_event did the minimal amount of UI changes, because the intermediate\n        # states were not visible.\n        # Now need to finish up updates for the visible state.\n        self.editor_notebook.complete_select_event()\n        self.shell.complete_select_event()\n\n        self.update_title()\n        self.update_details()\n        # self.update_idletasks()\n    finally:\n        self._selecting_event = False", "loc": 21}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "process_events_towards", "parameters": ["self", "index"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.process_event"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_events_towards(self, index):\n    if index > self.last_event_index:\n        # replay all events between last replayed event up to and including this event\n        while self.last_event_index < index:\n            self.process_event(self.events[self.last_event_index + 1], reverse=False)\n            self.last_event_index += 1\n\n    elif index < self.last_event_index:\n        # undo events up to and including the event following the desired event\n        while self.last_event_index > index:\n            self.process_event(self.events[self.last_event_index], reverse=True)\n            self.last_event_index -= 1", "loc": 12}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "update_title", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["datetime.datetime.fromtimestamp", "dt.strftime", "editor.get_uri", "float", "self.editor_notebook.get_current_child", "self.scrubber.cget", "self.session_combo.get", "self.title", "session_label.startswith", "tr", "uri_to_long_title"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_title(self, event=None):\n    session_label = self.session_combo.get()\n    if session_label and session_label.startswith(FILE_TOKEN):\n        s = session_label\n    else:\n        s = tr(\"Thonny Replayer\")\n\n    if self.last_event_index is not None and self.last_event_index > -1:\n        event = self.events[self.last_event_index]\n        timestamp = float(self.scrubber.cget(\"value\"))\n        dt = datetime.datetime.fromtimestamp(timestamp)\n        time_s = dt.strftime(\"%X\")\n        s += f\"  Event {self.last_event_index} @ {time_s}\"\n\n    editor: Optional[ReplayerEditor] = self.editor_notebook.get_current_child()\n    if editor is not None:\n        s += f\"  {uri_to_long_title(editor.get_uri())}\"\n\n    self.title(s)", "loc": 19}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "update_details", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["pformat", "self._details_frame.text.direct_delete", "self._details_frame.text.direct_insert"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_details(self):\n    if self._details_frame is None:\n        return\n\n    self._details_frame.text.direct_delete(\"1.0\", \"end\")\n\n    if not self.events:\n        return\n\n    event = self.events[self.last_event_index]\n    event_str = pformat(event, indent=2)\n    self._details_frame.text.direct_insert(\"1.0\", event_str)", "loc": 12}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "on_scrub", "parameters": ["self", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["float", "len", "self.find_closest_index", "self.select_event"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_scrub(self, value):\n    if self.loading or self._selecting_event:\n        return\n\n    index = self.find_closest_index(float(value), 0, len(self.events) - 1)\n    self.select_event(index, from_scrubber=True)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "create_details_frame", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TextFrame", "self._details_frame.text.set_read_only", "self.shell_book.add", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_details_frame(self):\n    assert self._details_frame is None\n    self._details_frame = TextFrame(self, vertical_scrollbar=False, relief=\"flat\")\n    self._details_frame.text.set_read_only(True)\n    self.shell_book.add(self._details_frame, text=tr(\"Event details\"))", "loc": 5}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "destroy_details_frame", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._details_frame.destroy", "self.shell_book.forget"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def destroy_details_frame(self):\n    assert self._details_frame is not None\n    self.shell_book.forget(self._details_frame)\n    self._details_frame.destroy()\n    self._details_frame = None", "loc": 5}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "update_event_frame_visibility", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._details_frame_visibility_var.get", "self.create_details_frame", "self.destroy_details_frame"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_event_frame_visibility(self):\n    if self._details_frame is None:\n        assert self._details_frame_visibility_var.get()\n        self.create_details_frame()\n    else:\n        assert not self._details_frame_visibility_var.get()\n        self.destroy_details_frame()", "loc": 7}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "close", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().set_option", "int", "re.findall", "running_on_mac_os", "self.destroy", "self.editor_notebook.winfo_height", "self.wm_geometry", "ui_utils.get_zoomed"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self, event=None):\n    global instance\n\n    get_workbench().set_option(\"replayer.zoomed\", ui_utils.get_zoomed(self))\n    if not ui_utils.get_zoomed(self) or running_on_mac_os():\n        # can't restore zoom on mac without setting actual dimensions\n        gparts = re.findall(r\"\\d+\", self.wm_geometry())\n        get_workbench().set_option(\"replayer.width\", int(gparts[0]))\n        get_workbench().set_option(\"replayer.height\", int(gparts[1]))\n        get_workbench().set_option(\"replayer.left\", int(gparts[2]))\n        get_workbench().set_option(\"replayer.top\", int(gparts[3]))\n\n    get_workbench().set_option(\"replayer.sash_position\", self.editor_notebook.winfo_height())\n\n    self.destroy()\n    instance = None\n\n    \"\"\"Alternative:\n    # self.withdraw()\n\n    get_workbench().winfo_toplevel().lift()\n    get_workbench().winfo_toplevel().focus_force()\n    get_workbench().winfo_toplevel().grab_set()\n    if running_on_mac_os():\n        get_workbench().winfo_toplevel().grab_release()\n    \"\"\"", "loc": 26}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "Replayer", "function_name": "show", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'{0}x{1}+{2}+{3}'.format", "ems_to_pixels", "get_workbench", "get_workbench().get_option", "get_workbench().set_default", "logger.info", "max", "min", "self.deiconify", "self.geometry", "self.lift", "self.title", "self.winfo_screenheight", "self.winfo_screenwidth", "ui_utils.set_zoomed"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show(self):\n    self.title(\"Thonny\")\n\n    get_workbench().set_default(\"replayer.zoomed\", False)\n    get_workbench().set_default(\"replayer.width\", ems_to_pixels(70))\n    get_workbench().set_default(\"replayer.height\", ems_to_pixels(50))\n    get_workbench().set_default(\"replayer.left\", ems_to_pixels(20))\n    get_workbench().set_default(\"replayer.top\", ems_to_pixels(10))\n\n    logger.info(\n        \"height: %r, %r, %r\",\n        get_workbench().get_option(\"replayer.height\"),\n        ems_to_pixels(20),\n        self.winfo_screenheight(),\n    )\n\n    geometry = \"{0}x{1}+{2}+{3}\".format(\n        min(\n            max(get_workbench().get_option(\"replayer.width\"), ems_to_pixels(30)),\n            self.winfo_screenwidth(),\n        ),\n        min(\n            max(get_workbench().get_option(\"replayer.height\"), ems_to_pixels(20)),\n            self.winfo_screenheight(),\n        ),\n        min(\n            max(get_workbench().get_option(\"replayer.left\"), 0),\n            self.winfo_screenwidth() - ems_to_pixels(10),\n        ),\n        min(\n            max(get_workbench().get_option(\"replayer.top\"), 0),\n            self.winfo_screenheight() - ems_to_pixels(10),\n        ),\n    )\n    logger.info(\"Replayer geometry: %r\", geometry)\n    self.geometry(geometry)\n\n    if get_workbench().get_option(\"replayer.zoomed\"):\n        ui_utils.set_zoomed(self, True)\n\n    self.lift()\n    self.deiconify()", "loc": 42}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "ReplayerEditor", "function_name": "process_event", "parameters": ["self", "event", "reverse"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.apply_event", "self.revert_event"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_event(self, event, reverse):\n    if not reverse:\n        self.apply_event(event)\n    else:\n        self.revert_event(event)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "ReplayerEditor", "function_name": "apply_event", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_apply_event_on_text", "self._code_view.text.edit_modified", "self.is_modified"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def apply_event(self, event):\n    if \"_previous_modified\" not in event and event[\"sequence\"] in [\n        \"TextInsert\",\n        \"TextDelete\",\n        \"Opened\",\n        \"Saved\",\n    ]:\n        # Mark the state change\n        event[\"_previous_modified\"] = self.is_modified()\n\n    if event[\"sequence\"] in [\"TextInsert\", \"TextDelete\"]:\n        _apply_event_on_text(event, self._code_view.text)\n        self._code_view.text.edit_modified(True)\n    elif event[\"sequence\"] in [\"Opened\", \"Saved\"]:\n        # Can't use old events Open, Save and SaveAs as they are not aligned with edit_modified\n        self._code_view.text.edit_modified(False)\n\n    if \"uri\" in event:\n        if \"_previous_uri\" not in event:\n            # store information for reverting this event\n            event[\"_previous_uri\"] = self._uri\n\n        self._uri = event[\"uri\"]", "loc": 23}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "ReplayerEditor", "function_name": "revert_event", "parameters": ["self", "event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_revert_event_on_text", "self._code_view.text.edit_modified"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def revert_event(self, event):\n    _revert_event_on_text(event, self._code_view.text)\n    if \"_previous_modified\" in event:\n        self._code_view.text.edit_modified(event[\"_previous_modified\"])\n\n    if \"_previous_uri\" in event:\n        self._uri = event[\"_previous_uri\"]", "loc": 7}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "ReplayerEditorNotebook", "function_name": "clear", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["child.destroy", "self.forget", "self.winfo_children"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def clear(self):\n    for child in self.winfo_children():\n        self.forget(child)\n        child.destroy()\n\n    assert self.current_page is None\n\n    self._editors_by_text_widget_id = {}", "loc": 8}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "ReplayerEditorNotebook", "function_name": "get_editor_for_event", "parameters": ["self", "event"], "param_types": {}, "return_type": "Optional[ReplayerEditor]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ReplayerEditor", "event.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_editor_for_event(self, event) -> Optional[ReplayerEditor]:\n    text_widget_id = event.get(\"text_widget_id\", None)\n    if text_widget_id is None:\n        return None\n    if text_widget_id in self._editors_by_text_widget_id:\n        return self._editors_by_text_widget_id[text_widget_id]\n\n    if \"editor_id\" in event or \"Editor\" in event[\"sequence\"]:\n        editor = ReplayerEditor(self)\n        self._editors_by_text_widget_id[text_widget_id] = editor\n        return editor\n\n    return None", "loc": 13}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "ReplayerEditorNotebook", "function_name": "get_editor_by_text_widget_id", "parameters": ["self", "text_widget_id"], "param_types": {}, "return_type": "Optional[ReplayerEditor]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ReplayerEditor"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_editor_by_text_widget_id(self, text_widget_id) -> Optional[ReplayerEditor]:\n    if text_widget_id not in self._editors_by_text_widget_id:\n        editor = ReplayerEditor(self)\n        self._editors_by_text_widget_id[text_widget_id] = editor\n\n    return self._editors_by_text_widget_id[text_widget_id]", "loc": 6}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "ReplayerEditorNotebook", "function_name": "process_event", "parameters": ["self", "event", "reverse"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["editor.get_title", "editor.process_event", "self.forget", "self.get_current_child", "self.get_editor_for_event", "self.has_content", "self.insert", "self.select"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_event(self, event, reverse):\n    editor = self.get_editor_for_event(event)\n    if editor is None:\n        return\n\n    editor.process_event(event, reverse)\n\n    # change visibility and active editor\n    if (\n        event[\"sequence\"] == \"InsertEditorToNotebook\"\n        and not reverse\n        or event[\"sequence\"] == \"RemoveEditorFromNotebook\"\n        and reverse\n    ):\n        self.insert(event[\"pos\"], editor, text=editor.get_title())\n\n    elif (\n        event[\"sequence\"] == \"InsertEditorToNotebook\"\n        and reverse\n        or event[\"sequence\"] == \"RemoveEditorFromNotebook\"\n        and not reverse\n    ):\n        self.forget(editor)\n\n    elif event[\"sequence\"] in [\"TextInsert\", \"TextDelete\"]:\n        if not reverse:\n            if \"_previous_active_editor\" not in event:\n                event[\"_previous_active_editor\"] = self.get_current_child()\n            # TODO: is it slow?\n            if self.has_content(self):\n                self.select(editor)\n        else:\n            self.select(event[\"_previous_active_editor\"])", "loc": 33}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "ReplayerEditorNotebook", "function_name": "complete_select_event", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cast", "editor.complete_select_event", "editor.get_title", "self.tab"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def complete_select_event(self):\n    for editor_page in self.pages:\n        editor = cast(ReplayerEditor, editor_page.content)\n        editor.complete_select_event()\n        self.tab(editor, text=editor.get_title())", "loc": 5}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": "ShellFrame", "function_name": "process_event", "parameters": ["self", "event", "reverse"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_apply_event_on_text", "_revert_event_on_text", "self.is_shell_event"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def process_event(self, event, reverse):\n    if not self.is_shell_event(event):\n        return\n\n    if event[\"sequence\"] in [\"TextInsert\", \"TextDelete\"]:\n        if not reverse:\n            _apply_event_on_text(event, self.text)\n        else:\n            _revert_event_on_text(event, self.text)", "loc": 9}
{"file": "thonny\\thonny\\plugins\\replayer.py", "class_name": null, "function_name": "tested_command", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["command", "self.bell", "tester"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def tested_command(event=None):\n    if tester():\n        command()\n    else:\n        self.bell()", "loc": 5}
{"file": "thonny\\thonny\\plugins\\shell_macro.py", "class_name": null, "function_name": "execute_macro", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().is_waiting_toplevel_command", "get_workbench", "get_workbench().get_option", "get_workbench().show_view", "shell.submit_python_code", "source.strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def execute_macro():\n    if get_runner().is_waiting_toplevel_command():\n        source = get_workbench().get_option(\"run.shell_macro_main\")\n        if source is not None:\n            shell = get_workbench().show_view(\"ShellView\")\n            shell.submit_python_code(source.strip() + \"\\n\")", "loc": 6}
{"file": "thonny\\thonny\\plugins\\statement_boxes.py", "class_name": null, "function_name": "configure_text", "parameters": ["text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["base_predicate", "create_bitmap_file", "font.nametofont", "get_syntax_options_for_tag", "get_syntax_options_for_tag('GUTTER').get", "isinstance", "print", "text.bbox", "text.configure", "text.master._gutter.configure", "text.tag_configure", "text_font.measure"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def configure_text(text):\n    spacing1 = 2\n    spacing3 = 3\n    text_font = text[\"font\"]\n    text.configure(spacing1=spacing1, spacing3=spacing3)\n    text.master._gutter.configure(spacing1=spacing1, spacing3=spacing3)\n    if isinstance(text_font, str):\n        text_font = font.nametofont(text_font)\n\n    indent_width = text_font.measure(\"    \")\n    bbox = text.bbox(\"1.0\")\n    if bbox is None or bbox[3] < 5:\n        # text not ready yet\n        # TODO: Text in Tk 8.6 has sync method\n        return False\n\n    line_height = bbox[3] + spacing1 + spacing3\n\n    print(indent_width, line_height)\n\n    def ver(x: int, y: int, top: bool, bottom: bool) -> bool:\n        # tells where to show pixels in vertical border of the statement\n        # It would be convenient if tiling started from the start of\n        # 1st char, but it is offset a bit\n        # In order to make computation easier, I'm offsetting x as well\n        x = (x - 5) % indent_width\n\n        stripe_width = 8\n        gap = 3\n        left = indent_width - stripe_width - gap\n\n        return (\n            left <= x < left + stripe_width\n            or top\n            and y == 0\n            and x >= left\n            or bottom\n            and y == line_height - 1\n            and x >= left\n        )\n\n    def hor(x: int, y: int, top: bool, bottom: bool) -> bool:\n        # tells where to show pixels in statement line\n        return top and y == 0 or bottom and y == line_height - 1\n\n    color = get_syntax_options_for_tag(\"GUTTER\").get(\"background\", \"gray\")\n    for orient, base_predicate in [(\"hor\", hor), (\"ver\", ver)]:\n        for top in [False, True]:\n            for bottom in [False, True]:\n\n                def predicate(\n                    x,\n                    y,\n                    # need to make base_predicate, top and bottom local\n                    base_predicate=base_predicate,\n                    top=top,\n                    bottom=bottom,\n                ):\n                    return base_predicate(x, y, top, bottom)\n\n                tag_name = \"%s_%s_%s\" % (orient, top, bottom)\n                bitmap_path = create_bitmap_file(indent_width, line_height, predicate, tag_name)\n                text.tag_configure(tag_name, background=color, bgstipple=\"@\" + bitmap_path)\n\n    return True", "loc": 65}
{"file": "thonny\\thonny\\plugins\\statement_boxes.py", "class_name": null, "function_name": "print_tree", "parameters": ["node", "level"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "isinstance", "print", "print_tree"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def print_tree(node, level=0):\n    from parso.python import tree as python_tree\n\n    indent = \"  \" * level\n    # if (isinstance(node, python_tree.PythonNode) and node.type == \"sim\"\n    if node.type in (\"simple_stmt\",) or isinstance(node, python_tree.Flow):\n        print(indent, node.type, node.start_pos, node.end_pos)\n\n    if hasattr(node, \"children\"):\n        for child in node.children:\n            print_tree(child, level + 1)", "loc": 11}
{"file": "thonny\\thonny\\plugins\\statement_boxes.py", "class_name": null, "function_name": "clear_tags", "parameters": ["text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["text.tag_remove"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def clear_tags(text):\n    for pos in [\"ver\", \"hor\"]:\n        for top in [True, False]:\n            for bottom in [True, False]:\n                text.tag_remove(\"%s_%s_%s\" % (pos, top, bottom), \"1.0\", \"end\")", "loc": 5}
{"file": "thonny\\thonny\\plugins\\statement_boxes.py", "class_name": null, "function_name": "add_tags", "parameters": ["text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["clear_tags", "hasattr", "isinstance", "print", "print_tree", "range", "tag_tree", "text.get", "text.tag_add"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_tags(text):\n    source = text.get(\"1.0\", \"end\")\n    clear_tags(text)\n    tree = ...  # TODO\n\n    print_tree(tree)\n    last_line = 0\n    last_col = 0\n\n    def tag_tree(node):\n        nonlocal last_line, last_col\n        from parso.python import tree as python_tree\n\n        if node.type == \"simple_stmt\" or isinstance(node, (python_tree.Flow, python_tree.Scope)):\n            start_line, start_col = node.start_pos\n            end_line, end_col = node.end_pos\n\n            # Before dealing with this node,\n            # handle the case, where last vertical tag was meant for\n            # same column, but there were empty or comment lines between\n            if start_col == last_col:\n                for i in range(last_line + 1, start_line):\n                    # NB! tag not visible when logically empty line\n                    # doesn't have indent prefix\n                    text.tag_add(\n                        \"ver_False_False\", \"%d.%d\" % (i, last_col - 1), \"%d.%d\" % (i, last_col)\n                    )\n                    print(\"ver_False_False\", \"%d.%d\" % (i, last_col - 1), \"%d.%d\" % (i, last_col))\n\n            print(node)\n\n            # usually end_col is 0\n            # exceptions: several statements on the same line (semicoloned statements)\n            # also unclosed parens in if-header\n            for lineno in range(start_line, end_line if end_col == 0 else end_line + 1):\n                top = lineno == start_line and lineno > 1\n                bottom = False  # start_line == end_line-1\n\n                # horizontal line (only for first or last line)\n                if top or bottom:\n                    text.tag_add(\n                        \"hor_%s_%s\" % (top, bottom),\n                        \"%d.%d\" % (lineno, start_col),\n                        \"%d.%d\" % (lineno + 1 if end_col == 0 else lineno, 0),\n                    )\n\n                    print(\n                        \"hor_%s_%s\" % (top, bottom),\n                        \"%d.%d\" % (lineno, start_col),\n                        \"%d.%d\" % (lineno + 1, 0),\n                    )\n\n                # vertical line (only for indented statements)\n                # Note that I'm using start col for all lines\n                # (statement's indent shouldn't decrease in continuation lines)\n                if start_col > 0:\n                    text.tag_add(\n                        \"ver_%s_%s\" % (top, bottom),\n                        \"%d.%d\" % (lineno, start_col - 1),\n                        \"%d.%d\" % (lineno, start_col),\n                    )\n                    print(\n                        \"ver_%s_%s\" % (top, bottom),\n                        \"%d.%d\" % (lineno, start_col - 1),\n                        \"%d.%d\" % (lineno, start_col),\n                    )\n\n                    last_line = lineno\n                    last_col = start_col\n\n        # Recurse\n        if node.type != \"simple_stmt\" and hasattr(node, \"children\"):\n            for child in node.children:\n                tag_tree(child)\n\n    tag_tree(tree)", "loc": 76}
{"file": "thonny\\thonny\\plugins\\statement_boxes.py", "class_name": null, "function_name": "handle_events", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["configure_and_add_tags", "hasattr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_events(event):\n    if hasattr(event, \"text_widget\"):\n        text = event.text_widget\n    else:\n        text = event.widget\n\n    configure_and_add_tags(text)", "loc": 7}
{"file": "thonny\\thonny\\plugins\\statement_boxes.py", "class_name": null, "function_name": "configure_and_add_tags", "parameters": ["text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["add_tags", "configure_and_add_tags", "configure_text", "getattr", "logger.exception", "text.after"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def configure_and_add_tags(text):\n    if not getattr(text, \"structure_tags_configured\", False):\n        try:\n            if configure_text(text):\n                text.structure_tags_configured = True\n            else:\n                text.after(500, lambda: configure_and_add_tags(text))\n                return\n        except Exception:\n            logger.exception(\"Problem with defining structure tags\")\n            return\n\n    add_tags(text)", "loc": 13}
{"file": "thonny\\thonny\\plugins\\statement_boxes.py", "class_name": null, "function_name": "tag_tree", "parameters": ["node"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "isinstance", "print", "range", "tag_tree", "text.tag_add"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def tag_tree(node):\n    nonlocal last_line, last_col\n    from parso.python import tree as python_tree\n\n    if node.type == \"simple_stmt\" or isinstance(node, (python_tree.Flow, python_tree.Scope)):\n        start_line, start_col = node.start_pos\n        end_line, end_col = node.end_pos\n\n        # Before dealing with this node,\n        # handle the case, where last vertical tag was meant for\n        # same column, but there were empty or comment lines between\n        if start_col == last_col:\n            for i in range(last_line + 1, start_line):\n                # NB! tag not visible when logically empty line\n                # doesn't have indent prefix\n                text.tag_add(\n                    \"ver_False_False\", \"%d.%d\" % (i, last_col - 1), \"%d.%d\" % (i, last_col)\n                )\n                print(\"ver_False_False\", \"%d.%d\" % (i, last_col - 1), \"%d.%d\" % (i, last_col))\n\n        print(node)\n\n        # usually end_col is 0\n        # exceptions: several statements on the same line (semicoloned statements)\n        # also unclosed parens in if-header\n        for lineno in range(start_line, end_line if end_col == 0 else end_line + 1):\n            top = lineno == start_line and lineno > 1\n            bottom = False  # start_line == end_line-1\n\n            # horizontal line (only for first or last line)\n            if top or bottom:\n                text.tag_add(\n                    \"hor_%s_%s\" % (top, bottom),\n                    \"%d.%d\" % (lineno, start_col),\n                    \"%d.%d\" % (lineno + 1 if end_col == 0 else lineno, 0),\n                )\n\n                print(\n                    \"hor_%s_%s\" % (top, bottom),\n                    \"%d.%d\" % (lineno, start_col),\n                    \"%d.%d\" % (lineno + 1, 0),\n                )\n\n            # vertical line (only for indented statements)\n            # Note that I'm using start col for all lines\n            # (statement's indent shouldn't decrease in continuation lines)\n            if start_col > 0:\n                text.tag_add(\n                    \"ver_%s_%s\" % (top, bottom),\n                    \"%d.%d\" % (lineno, start_col - 1),\n                    \"%d.%d\" % (lineno, start_col),\n                )\n                print(\n                    \"ver_%s_%s\" % (top, bottom),\n                    \"%d.%d\" % (lineno, start_col - 1),\n                    \"%d.%d\" % (lineno, start_col),\n                )\n\n                last_line = lineno\n                last_col = start_col\n\n    # Recurse\n    if node.type != \"simple_stmt\" and hasattr(node, \"children\"):\n        for child in node.children:\n            tag_tree(child)", "loc": 65}
{"file": "thonny\\thonny\\plugins\\theme_and_font_config_page.py", "class_name": "ThemeAndFontConfigurationPage", "function_name": "cancel", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().reload_themes", "get_workbench().update_fonts", "getattr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cancel(self):\n    if (\n        getattr(self._editor_family_variable, \"modified\")\n        or getattr(self._editor_size_variable, \"modified\")\n        or getattr(self._ui_theme_variable, \"modified\")\n        or getattr(self._syntax_theme_variable, \"modified\")\n    ):\n        get_workbench().reload_themes()\n        get_workbench().update_fonts()", "loc": 9}
{"file": "thonny\\thonny\\plugins\\todo_view.py", "class_name": null, "function_name": "delay_update", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._current_code_view.text.after", "self._last_op_delta", "self._update"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def delay_update():\n    if self._last_op_delta() < 0.3:\n        # still typing\n        self._current_code_view.text.after(100, delay_update)\n        return\n\n    self._current_code_view._update_already_scheduled = False\n    self._update(None)", "loc": 8}
{"file": "thonny\\thonny\\plugins\\tomorrow_syntax_theme.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_syntax_theme", "tomorrow_night_eighties"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    get_workbench().add_syntax_theme(\"Tomorrow\", \"Default Light\", tomorrow)\n    get_workbench().add_syntax_theme(\"Tomorrow Night\", \"Default Dark\", tomorrow_night)\n    get_workbench().add_syntax_theme(\"Tomorrow Night Blue\", \"Tomorrow Night\", tomorrow_night_blue)\n    get_workbench().add_syntax_theme(\n        \"Tomorrow Night Bright\", \"Tomorrow Night\", tomorrow_night_bright\n    )\n    get_workbench().add_syntax_theme(\n        \"Tomorrow Night Eighties\", \"Tomorrow Night\", tomorrow_night_eighties()\n    )", "loc": 10}
{"file": "thonny\\thonny\\plugins\\variables.py", "class_name": "VariablesView", "function_name": "show_globals", "parameters": ["self", "globals_", "module_name", "is_active"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_default_tab_text", "self._update_back_button", "self.clear_error", "self.containing_notebook.tab", "self.update_variables"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_globals(self, globals_, module_name, is_active=True):\n    self.clear_error()\n    # TODO: update only if something has changed\n    self.update_variables(globals_)\n\n    if self.containing_notebook is not None:\n        if module_name == \"__main__\":\n            self.containing_notebook.tab(self, text=get_default_tab_text())\n        else:\n            self.containing_notebook.tab(\n                self, text=get_default_tab_text() + \" (%s)\" % module_name\n            )\n\n    if is_active:\n        self._last_active_info = (globals_, module_name)\n\n    self._update_back_button(not is_active)", "loc": 17}
{"file": "thonny\\thonny\\plugins\\variables.py", "class_name": "VariablesView", "function_name": "show_frame_variables", "parameters": ["self", "locals_", "globals_", "freevars", "frame_name", "is_active"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_default_tab_text", "groups.insert", "self._update_back_button", "self.containing_notebook.tab", "self.update_variables"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_frame_variables(self, locals_, globals_, freevars, frame_name, is_active=True):\n    # TODO: update only if something has changed\n    actual_locals = {}\n    nonlocals = {}\n    for name in locals_:\n        if name in freevars:\n            nonlocals[name] = locals_[name]\n        else:\n            actual_locals[name] = locals_[name]\n\n    groups = [(\"LOCALS\", actual_locals), (\"GLOBALS\", globals_)]\n    if nonlocals:\n        groups.insert(1, (\"NONLOCALS\", nonlocals))\n\n    self.update_variables(groups)\n    if self.containing_notebook is not None:\n        self.containing_notebook.tab(self, text=get_default_tab_text() + \" (%s)\" % frame_name)\n\n    if is_active:\n        self._last_active_info = (locals_, globals_, freevars, frame_name)\n\n    self._update_back_button(not is_active)", "loc": 22}
{"file": "thonny\\thonny\\plugins\\backend\\birdseye_backend.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_backend", "get_backend().add_command"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    try:\n        os.environ[\"OUTDATED_IGNORE\"] = \"1\"\n        # TODO: it would be good to do this here, but it's slow\n        # import birdseye.bird  # need to import at plugin load time, because later it may not be in path\n    except ImportError:\n        pass\n    get_backend().add_command(\"Birdseye\", _cmd_Birdseye)", "loc": 8}
{"file": "thonny\\thonny\\plugins\\backend\\dock_user_windows_backend.py", "class_name": null, "function_name": "on_configure", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BackendEvent", "get_backend", "get_backend().send_message", "get_backend().set_option"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_configure(event):\n    global _last_pos, _notification_is_sent\n    pos = event.x, event.y\n    if pos != _last_pos:\n        get_backend().set_option(_LAST_POS_SETTING, pos)\n\n    if not _notification_is_sent:\n        get_backend().send_message(BackendEvent(\"UserWindowAppeared\"))\n        _notification_is_sent = True", "loc": 9}
{"file": "thonny\\thonny\\plugins\\backend\\dock_user_windows_backend.py", "class_name": null, "function_name": "patch_tkinter", "parameters": ["module"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_backend", "get_backend().get_option", "getattr", "isinstance", "original_constructor", "self.bind_class", "self.geometry", "self.wm_attributes", "setattr"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def patch_tkinter(module):\n    flag_name = \"has_docking_patch\"\n    if getattr(module, flag_name, False):\n        return\n\n    original_constructor = module.Tk.__init__\n\n    def patched_Tk_constructor(self, *args, **kw):\n        original_constructor(self, *args, **kw)\n\n        try:\n            # move window to the same place it was previously\n            last_pos = get_backend().get_option(_LAST_POS_SETTING)\n            if isinstance(last_pos, tuple):\n                self.geometry(\"+%d+%d\" % last_pos)\n\n            self.wm_attributes(\"-topmost\", 1)\n            # self.overrideredirect(1)\n\n            # I'm using bind_class because turtle._Screen later overwrites the bind handler\n            self.bind_class(\"Tk\", \"<Configure>\", on_configure, True)\n        except Exception:\n            # expected to fail when constructing Tcl for _cmd_process_gui_events\n            pass\n\n    module.Tk.__init__ = patched_Tk_constructor\n    setattr(module, flag_name, True)", "loc": 27}
{"file": "thonny\\thonny\\plugins\\backend\\dock_user_windows_backend.py", "class_name": null, "function_name": "patch_turtle", "parameters": ["module"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_backend", "get_backend().get_option", "getattr", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def patch_turtle(module):\n    # Turtle needs more tweaking because it later overrides the position set in the Tk constructor\n    turtle_config = getattr(module, \"_CFG\", None)\n    if isinstance(turtle_config, dict):\n        last_pos = get_backend().get_option(_LAST_POS_SETTING)\n        if isinstance(last_pos, tuple):\n            turtle_config[\"leftright\"], turtle_config[\"topbottom\"] = last_pos", "loc": 7}
{"file": "thonny\\thonny\\plugins\\backend\\dock_user_windows_backend.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["backend.add_import_handler", "get_backend", "os.environ.get", "os.environ.get('DOCK_USER_WINDOWS', 'False').lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    if os.environ.get(\"DOCK_USER_WINDOWS\", \"False\").lower() == \"true\":\n        backend = get_backend()\n        backend.add_import_handler(\"tkinter\", patch_tkinter)\n        backend.add_import_handler(\"turtle\", patch_turtle)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\backend\\dock_user_windows_backend.py", "class_name": null, "function_name": "patched_Tk_constructor", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_backend", "get_backend().get_option", "isinstance", "original_constructor", "self.bind_class", "self.geometry", "self.wm_attributes"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def patched_Tk_constructor(self, *args, **kw):\n    original_constructor(self, *args, **kw)\n\n    try:\n        # move window to the same place it was previously\n        last_pos = get_backend().get_option(_LAST_POS_SETTING)\n        if isinstance(last_pos, tuple):\n            self.geometry(\"+%d+%d\" % last_pos)\n\n        self.wm_attributes(\"-topmost\", 1)\n        # self.overrideredirect(1)\n\n        # I'm using bind_class because turtle._Screen later overwrites the bind handler\n        self.bind_class(\"Tk\", \"<Configure>\", on_configure, True)\n    except Exception:\n        # expected to fail when constructing Tcl for _cmd_process_gui_events\n        pass", "loc": 17}
{"file": "thonny\\thonny\\plugins\\backend\\flask_backend.py", "class_name": null, "function_name": "augment_source", "parameters": ["source", "cmd"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n\\nif \"{app_name}\" in globals():\\n    # Conservative options for minimum technical risks.\\n    # Users who need more control should call run explicitly.\\n    print(\" # Running the app with options chosen by Thonny. See Help for details.\")\\n    {app_name}.run(threaded=False, debug=False, use_reloader=False)\\n'.format", "ast.parse", "ast.walk", "isinstance", "len"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def augment_source(source, cmd):\n    if \"Flask\" not in source:\n        # don't bother analyzing further\n        return source\n\n    try:\n        tree = ast.parse(source)\n    except SyntaxError:\n        return source\n\n    var_name = None\n    found_run = False\n\n    for node in ast.walk(tree):\n        if (\n            isinstance(node, ast.Assign)\n            and isinstance(node.value, ast.Call)\n            and isinstance(node.value.func, ast.Name)  # TODO: could be also flask.Flask\n            and node.value.func.id == \"Flask\"\n            and len(node.targets) == 1\n            and isinstance(node.targets[0], ast.Name)\n        ):\n            var_name = node.targets[0].id\n        elif (\n            isinstance(node, ast.Call)\n            and isinstance(node.func, ast.Attribute)\n            and isinstance(node.func.value, ast.Name)\n            and node.func.value.id == var_name\n            and node.func.attr == \"run\"\n        ):\n            found_run = True\n\n    if not var_name or found_run:\n        return source\n    else:\n        return (\n            source\n            + \"\"\"\n\nif \"{app_name}\" in globals():\n    # Conservative options for minimum technical risks.\n    # Users who need more control should call run explicitly.\n    print(\" # Running the app with options chosen by Thonny. See Help for details.\")\n    {app_name}.run(threaded=False, debug=False, use_reloader=False)\n\"\"\".format(\n                app_name=var_name\n            )\n        )", "loc": 48}
{"file": "thonny\\thonny\\plugins\\backend\\matplotlib_backend.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["backend.add_import_handler", "get_backend"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    if sys.platform == \"darwin\":\n        # https://github.com/thonny/thonny/issues/676\n        backend = get_backend()\n        backend.add_import_handler(\"matplotlib\", set_default_backend)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\backend\\pgzero_backend.py", "class_name": null, "function_name": "augment_ast", "parameters": ["root"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.Attribute", "ast.Call", "ast.Expr", "ast.Import", "ast.Load", "ast.Name", "ast.alias", "ast.fix_missing_locations", "ast.walk", "isinstance", "os.environ.get", "print", "root.body.append", "root.body.insert"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def augment_ast(root):\n    mode = os.environ.get(\"PGZERO_MODE\", \"False\")\n    assert mode != \"False\"\n\n    warning_prelude = \"WARNING: Pygame Zero mode is turned on (Run  Pygame Zero mode)\"\n    try:\n        import pgzero  # @UnusedImport\n    except ImportError:\n        if mode == \"True\":\n            print(\n                warning_prelude\n                + \",\\nbut pgzero module is not found. Running program in regular mode.\\n\",\n                file=sys.stderr,\n            )\n        else:\n            assert mode == \"auto\"\n\n        return\n\n    # Check if draw is defined\n    for stmt in root.body:\n        if isinstance(stmt, ast.FunctionDef) and stmt.name == \"draw\":\n            break\n    else:\n        if mode == \"auto\":\n            return\n        else:\n            print(\n                warning_prelude\n                + \",\\nbut your program doesn't look like usual Pygame Zero program\\n\"\n                + \"(draw function is missing).\\n\",\n                file=sys.stderr,\n            )\n\n    # need more checks in auto mode\n    if mode == \"auto\":\n        # check that draw method is not called in the code\n        for node in ast.walk(root):\n            if (\n                isinstance(node, ast.Call)\n                and isinstance(node.func, ast.Name)\n                and node.func.id == \"draw\"\n            ):\n                return\n\n    # prepend \"import pgzrun as __pgzrun\"\n    imp = ast.Import([ast.alias(\"pgzrun\", \"__pgzrun\")])\n    imp.lineno = 0\n    imp.col_offset = 0\n    ast.fix_missing_locations(imp)\n    imp.tags = {\"ignore\"}\n    root.body.insert(0, imp)\n\n    # append \"__pgzrun.go()\"\n    go = ast.Expr(\n        ast.Call(ast.Attribute(ast.Name(\"__pgzrun\", ast.Load()), \"go\", ast.Load()), [], [])\n    )\n    go.lineno = 1000000\n    go.end_lineno = 1000000\n    go.col_offset = 0\n    ast.fix_missing_locations(go)\n    go.tags = {\"ignore\"}\n    root.body.append(go)", "loc": 63}
{"file": "thonny\\thonny\\plugins\\backend\\pgzero_backend.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_backend", "get_backend().add_ast_postprocessor", "os.environ.get", "os.environ.get('PGZERO_MODE', 'False').lower"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    if os.environ.get(\"PGZERO_MODE\", \"False\").lower() == \"false\":\n        return\n\n    get_backend().add_ast_postprocessor(augment_ast)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\circuitpython\\__init__.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["add_micropython_backend", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    add_micropython_backend(\n        \"CircuitPython\",\n        CircuitPythonProxy,\n        tr(\"CircuitPython (generic)\"),\n        CircuitPythonConfigPage,\n        sort_key=\"50\",\n    )", "loc": 8}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": null, "function_name": "prepare_hooks", "parameters": ["method"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["functools.wraps", "hasattr", "method", "self._backend._install_custom_import", "self._backend._restore_original_import", "sys.meta_path.insert"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def prepare_hooks(method):\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        try:\n            sys.meta_path.insert(0, self)\n            self._backend._install_custom_import()\n            return method(self, *args, **kwargs)\n        finally:\n            del sys.meta_path[0]\n            if hasattr(self._backend, \"_original_import\"):\n                self._backend._restore_original_import()\n\n    return wrapper", "loc": 13}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": null, "function_name": "return_execution_result", "parameters": ["method"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["functools.wraps", "method", "self._backend._prepare_user_exception"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def return_execution_result(method):\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        try:\n            result = method(self, *args, **kwargs)\n            if result is not None:\n                return result\n            return {}\n        except (Exception, KeyboardInterrupt):\n            return {\"user_exception\": self._backend._prepare_user_exception()}\n\n    return wrapper", "loc": 12}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": null, "function_name": "format_exception_with_frame_info", "parameters": ["e_type", "e_value", "e_traceback", "shorten_filenames"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "'\\n'.join", "entry.filename.endswith", "entry.filename.replace", "getattr", "id", "isinstance", "len", "line.endswith", "line.splitlines", "list", "partlines[-2].strip", "rec_format_exception_with_frame_info", "traceback.extract_tb", "traceback.format_exception", "traceback.format_list", "type"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "Need to suppress thonny frames to avoid confusion", "source_code": "def format_exception_with_frame_info(e_type, e_value, e_traceback, shorten_filenames=False):\n    \"\"\"Need to suppress thonny frames to avoid confusion\"\"\"\n\n    _traceback_message = \"Traceback (most recent call last):\\n\"\n\n    _cause_message = getattr(\n        traceback,\n        \"_cause_message\",\n        (\"\\nThe above exception was the direct cause \" + \"of the following exception:\") + \"\\n\\n\",\n    )\n\n    _context_message = getattr(\n        traceback,\n        \"_context_message\",\n        (\"\\nDuring handling of the above exception, \" + \"another exception occurred:\") + \"\\n\\n\",\n    )\n\n    def rec_format_exception_with_frame_info(etype, value, tb, chain=True):\n        # Based on\n        # https://www.python.org/dev/peps/pep-3134/#enhanced-reporting\n        # and traceback.format_exception\n\n        if etype is None:\n            etype = type(value)\n\n        if tb is None:\n            tb = value.__traceback__\n\n        if chain:\n            if value.__cause__ is not None:\n                yield from rec_format_exception_with_frame_info(None, value.__cause__, None)\n                yield (_cause_message, None, None, None)\n            elif value.__context__ is not None and not value.__suppress_context__:\n                yield from rec_format_exception_with_frame_info(None, value.__context__, None)\n                yield (_context_message, None, None, None)\n\n        if tb is not None:\n            yield (_traceback_message, None, None, None)\n\n            tb_temp = tb\n            for entry in traceback.extract_tb(tb):\n                assert tb_temp is not None  # actual tb doesn't end before extract_tb\n                if (\n                    \"cpython_backend\" not in entry.filename\n                    and \"thonny/backend\" not in entry.filename.replace(\"\\\\\", \"/\")\n                    and (\n                        not entry.filename.endswith(os.sep + \"ast.py\")\n                        or entry.name != \"parse\"\n                        or not isinstance(e_value, SyntaxError)\n                    )\n                ):\n                    fmt = \"\".join(traceback.format_list([entry]))\n                    yield (fmt, id(tb_temp.tb_frame), entry.filename, entry.lineno)\n\n                tb_temp = tb_temp.tb_next\n\n            assert tb_temp is None  # tb was exhausted\n\n        # using format_exception with limit instead of format_exception_only because latter doesn't give extended info\n        for line in traceback.format_exception(etype, value, tb, limit=0):\n            if etype is SyntaxError and line.endswith(\"^\\n\"):\n                # for some reason it may add several empty lines before ^-line\n                partlines = line.splitlines()\n                while len(partlines) >= 2 and partlines[-2].strip() == \"\":\n                    del partlines[-2]\n                line = \"\\n\".join(partlines) + \"\\n\"\n\n            yield (line, None, None, None)\n\n    items = rec_format_exception_with_frame_info(e_type, e_value, e_traceback)\n\n    return list(items)", "loc": 72}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": "MainCPythonBackend", "function_name": "import_audit_hook", "parameters": ["self", "event", "args"], "param_types": {"event": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.debug", "module_name.split", "self._check_warn_sys_path_conflict"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def import_audit_hook(self, event: str, args):\n    if event == \"import\":\n        logger.debug(\"detected Import event with args %r\", args)\n        module_name = args[0]\n        self._check_warn_sys_path_conflict(module_name.split(\".\")[0])", "loc": 5}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": "MainCPythonBackend", "function_name": "get_option", "parameters": ["self", "name", "default"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.literal_eval", "self._get_ini", "self._get_ini().get", "self._parse_option_name"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_option(self, name, default=None):\n    section, subname = self._parse_option_name(name)\n    val = self._get_ini().get(section, subname, fallback=default)\n    try:\n        return ast.literal_eval(val)\n    except Exception:\n        return val", "loc": 7}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": "MainCPythonBackend", "function_name": "set_option", "parameters": ["self", "name", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ini.add_section", "ini.has_section", "ini.set", "isinstance", "repr", "self._get_ini", "self._parse_option_name", "self.save_settings"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_option(self, name, value):\n    ini = self._get_ini()\n    section, subname = self._parse_option_name(name)\n    if not ini.has_section(section):\n        ini.add_section(section)\n    if not isinstance(value, str):\n        value = repr(value)\n    ini.set(section, subname, value)\n    self.save_settings()", "loc": 9}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": "MainCPythonBackend", "function_name": "send_message", "parameters": ["self", "msg"], "param_types": {"msg": "MessageFromBackend"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "os.getcwd", "report_time", "self._original_stdout.flush", "self._original_stdout.write", "self.export_globals", "serialize_message", "sys.stdout.flush"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def send_message(self, msg: MessageFromBackend) -> None:\n    report_time(f\"Sending message {msg.event_type}\")\n    sys.stdout.flush()\n\n    if isinstance(msg, ToplevelResponse):\n        if \"cwd\" not in msg:\n            msg[\"cwd\"] = os.getcwd()\n        if \"globals\" not in msg:\n            msg[\"globals\"] = self.export_globals()\n\n    self._original_stdout.write(serialize_message(msg) + \"\\n\")\n    self._original_stdout.flush()", "loc": 12}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": "MainCPythonBackend", "function_name": "export_value", "parameters": ["self", "value", "max_repr_length"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueInfo", "id", "len", "repr"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def export_value(self, value, max_repr_length=5000):\n    self._heap[id(value)] = value\n    try:\n        rep = repr(value)\n    except Exception:\n        # See https://bitbucket.org/plas/thonny/issues/584/problem-with-thonnys-back-end-obj-no\n        rep = \"??? <repr error>\"\n\n    if len(rep) > max_repr_length:\n        rep = rep[:max_repr_length] + \"\"\n\n    return ValueInfo(id(value), rep)", "loc": 12}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": "MainCPythonBackend", "function_name": "export_variables", "parameters": ["self", "variables", "all_variables"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["name.startswith", "self.export_value", "warnings.catch_warnings", "warnings.simplefilter"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def export_variables(self, variables, all_variables=False):\n    result = {}\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        for name in variables:\n            if not name.startswith(\"__\") or all_variables:\n                result[name] = self.export_value(variables[name], 100)\n\n    return result", "loc": 9}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": "MainCPythonBackend", "function_name": "export_globals", "parameters": ["self", "module_name"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["\"Module '{0}' is not loaded\".format", "RuntimeError", "self.export_variables"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def export_globals(self, module_name=\"__main__\"):\n    if module_name in sys.modules:\n        return self.export_variables(sys.modules[module_name].__dict__)\n    else:\n        raise RuntimeError(\"Module '{0}' is not loaded\".format(module_name))", "loc": 5}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": "FakeOutputStream", "function_name": "write", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.decode", "isinstance", "len", "self._backend._enter_io_function", "self._backend._exit_io_function", "self._backend._send_output"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write(self, data):\n    try:\n        self._backend._enter_io_function()\n        # click may send bytes instead of strings\n        if isinstance(data, bytes):\n            data = data.decode(errors=\"replace\")\n\n        if data != \"\":\n            self._backend._send_output(data=data, stream_name=self._stream_name)\n            self._processed_symbol_count += len(data)\n    finally:\n        self._backend._exit_io_function()\n\n    return len(data)", "loc": 14}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": "FakeOutputStream", "function_name": "writelines", "parameters": ["self", "lines"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "self._backend._enter_io_function", "self._backend._exit_io_function", "self.write"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def writelines(self, lines):\n    try:\n        self._backend._enter_io_function()\n        self.write(\"\".join(lines))\n    finally:\n        self._backend._exit_io_function()", "loc": 6}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": null, "function_name": "wrapper", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["functools.wraps", "hasattr", "method", "self._backend._install_custom_import", "self._backend._restore_original_import", "sys.meta_path.insert"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wrapper(self, *args, **kwargs):\n    try:\n        sys.meta_path.insert(0, self)\n        self._backend._install_custom_import()\n        return method(self, *args, **kwargs)\n    finally:\n        del sys.meta_path[0]\n        if hasattr(self._backend, \"_original_import\"):\n            self._backend._restore_original_import()", "loc": 9}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": null, "function_name": "wrapper", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["functools.wraps", "method", "self._backend._prepare_user_exception"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wrapper(self, *args, **kwargs):\n    try:\n        result = method(self, *args, **kwargs)\n        if result is not None:\n            return result\n        return {}\n    except (Exception, KeyboardInterrupt):\n        return {\"user_exception\": self._backend._prepare_user_exception()}", "loc": 8}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": null, "function_name": "rec_format_exception_with_frame_info", "parameters": ["etype", "value", "tb", "chain"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "'\\n'.join", "entry.filename.endswith", "entry.filename.replace", "id", "isinstance", "len", "line.endswith", "line.splitlines", "partlines[-2].strip", "rec_format_exception_with_frame_info", "traceback.extract_tb", "traceback.format_exception", "traceback.format_list", "type"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def rec_format_exception_with_frame_info(etype, value, tb, chain=True):\n    # Based on\n    # https://www.python.org/dev/peps/pep-3134/#enhanced-reporting\n    # and traceback.format_exception\n\n    if etype is None:\n        etype = type(value)\n\n    if tb is None:\n        tb = value.__traceback__\n\n    if chain:\n        if value.__cause__ is not None:\n            yield from rec_format_exception_with_frame_info(None, value.__cause__, None)\n            yield (_cause_message, None, None, None)\n        elif value.__context__ is not None and not value.__suppress_context__:\n            yield from rec_format_exception_with_frame_info(None, value.__context__, None)\n            yield (_context_message, None, None, None)\n\n    if tb is not None:\n        yield (_traceback_message, None, None, None)\n\n        tb_temp = tb\n        for entry in traceback.extract_tb(tb):\n            assert tb_temp is not None  # actual tb doesn't end before extract_tb\n            if (\n                \"cpython_backend\" not in entry.filename\n                and \"thonny/backend\" not in entry.filename.replace(\"\\\\\", \"/\")\n                and (\n                    not entry.filename.endswith(os.sep + \"ast.py\")\n                    or entry.name != \"parse\"\n                    or not isinstance(e_value, SyntaxError)\n                )\n            ):\n                fmt = \"\".join(traceback.format_list([entry]))\n                yield (fmt, id(tb_temp.tb_frame), entry.filename, entry.lineno)\n\n            tb_temp = tb_temp.tb_next\n\n        assert tb_temp is None  # tb was exhausted\n\n    # using format_exception with limit instead of format_exception_only because latter doesn't give extended info\n    for line in traceback.format_exception(etype, value, tb, limit=0):\n        if etype is SyntaxError and line.endswith(\"^\\n\"):\n            # for some reason it may add several empty lines before ^-line\n            partlines = line.splitlines()\n            while len(partlines) >= 2 and partlines[-2].strip() == \"\":\n                del partlines[-2]\n            line = \"\\n\".join(partlines) + \"\\n\"\n\n        yield (line, None, None, None)", "loc": 51}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": null, "function_name": "lookup_from_stack", "parameters": ["frame"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["id", "lookup_from_stack"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def lookup_from_stack(frame):\n    if frame is None:\n        return None\n    elif id(frame) == frame_id:\n        return frame\n    else:\n        return lookup_from_stack(frame.f_back)", "loc": 7}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_back.py", "class_name": null, "function_name": "lookup_from_tb", "parameters": ["entry"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["id", "lookup_from_tb"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def lookup_from_tb(entry):\n    if entry is None:\n        return None\n    elif id(entry.tb_frame) == frame_id:\n        return entry.tb_frame\n    else:\n        return lookup_from_tb(entry.tb_next)", "loc": 7}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_tracers.py", "class_name": "NiceTracer", "function_name": "find_spec", "parameters": ["self", "fullname", "path", "target"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FancySourceFileLoader", "PathFinder.find_spec", "getattr", "isinstance", "self._is_interesting_module_file", "super", "super().find_spec"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_spec(self, fullname, path=None, target=None):\n    spec = PathFinder.find_spec(fullname, path, target)\n\n    if (\n        spec is not None\n        and isinstance(spec.loader, SourceFileLoader)\n        and getattr(spec, \"origin\", None)\n        and self._is_interesting_module_file(spec.origin)\n    ):\n        spec.loader = FancySourceFileLoader(fullname, spec.origin, self)\n        return spec\n    else:\n        return super().find_spec(fullname, path, target)", "loc": 13}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_tracers.py", "class_name": "FancySourceFileLoader", "function_name": "source_to_code", "parameters": ["self", "data", "path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._tracer._prepare_ast", "super", "super().source_to_code", "sys.gettrace", "sys.settrace"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def source_to_code(self, data, path, *, _optimize=-1):\n    old_tracer = sys.gettrace()\n    sys.settrace(None)\n    try:\n        root = self._tracer._prepare_ast(data, path, \"exec\")\n        return super().source_to_code(root, path)\n    finally:\n        sys.settrace(old_tracer)", "loc": 8}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_tracers.py", "class_name": null, "function_name": "export_globals", "parameters": ["module_name", "frame"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._backend.export_variables"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def export_globals(module_name, frame):\n    if module_name not in exported_globals_per_module:\n        exported_globals_per_module[module_name] = self._backend.export_variables(\n            frame.f_globals\n        )\n    return exported_globals_per_module[module_name]", "loc": 6}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_tracers.py", "class_name": null, "function_name": "add_tag", "parameters": ["node", "tag"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "node.tags.add", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_tag(node, tag):\n    if not hasattr(node, \"tags\"):\n        node.tags = set()\n        node.tags.add(\"class=\" + node.__class__.__name__)\n    node.tags.add(tag)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\cpython_backend\\cp_tracers.py", "class_name": "ExpressionVisitor", "function_name": "generic_visit", "parameters": ["self", "node"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ast.Call", "ast.Load", "ast.Name", "ast.NodeTransformer.generic_visit", "ast.copy_location", "ast.fix_missing_locations", "hasattr", "isinstance", "tracer._create_simple_marker_call", "tracer._is_case_pattern", "tracer._should_instrument_as_expression"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def generic_visit(self, node):\n    if isinstance(node, _ast.expr):\n        if isinstance(node, ast.Starred):\n            # keep this node as is, but instrument its children\n            return ast.NodeTransformer.generic_visit(self, node)\n        elif tracer._should_instrument_as_expression(node):\n            # before marker\n            before_marker = tracer._create_simple_marker_call(\n                node, BEFORE_EXPRESSION_MARKER\n            )\n            ast.copy_location(before_marker, node)\n\n            if \"ignore_children\" in node.tags:\n                transformed_node = node\n            else:\n                transformed_node = ast.NodeTransformer.generic_visit(self, node)\n\n            # after marker\n            after_marker = ast.Call(\n                func=ast.Name(id=AFTER_EXPRESSION_MARKER, ctx=ast.Load()),\n                args=[before_marker, transformed_node],\n                keywords=[],\n            )\n            ast.copy_location(after_marker, node)\n            ast.fix_missing_locations(after_marker)\n            # further transformations may query original node location from after marker\n            if hasattr(node, \"end_lineno\"):\n                after_marker.end_lineno = node.end_lineno\n                after_marker.end_col_offset = node.end_col_offset\n\n            return after_marker\n        else:\n            # This expression (and its children) should be ignored\n            return node\n    elif tracer._is_case_pattern(node):\n        # ignore this and children\n        return node\n    else:\n        # Descend into statements\n        return ast.NodeTransformer.generic_visit(self, node)", "loc": 40}
{"file": "thonny\\thonny\\plugins\\cpython_frontend\\cp_front.py", "class_name": "LocalCPythonProxy", "function_name": "interrupt", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.exception", "os.kill", "running_on_windows", "self._proc.poll", "self._proc.send_signal"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def interrupt(self):\n    import signal\n\n    if self._proc is not None and self._proc.poll() is None:\n        if running_on_windows():\n            try:\n                os.kill(self._proc.pid, signal.CTRL_BREAK_EVENT)  # pylint: disable=no-member\n            except Exception:\n                logger.exception(\"Could not interrupt backend process\")\n        else:\n            self._proc.send_signal(signal.SIGINT)", "loc": 11}
{"file": "thonny\\thonny\\plugins\\cpython_frontend\\cp_front.py", "class_name": "LocalCPythonProxy", "function_name": "fetch_next_message", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "super", "super().fetch_next_message"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fetch_next_message(self):\n    while True:\n        msg = super().fetch_next_message()\n        if isinstance(msg, InlineResponse) and msg.command_name == \"process_gui_events\":\n            # Only wanted to know that the command was processed\n            # Don't pass upstream\n            self._expecting_response_for_gui_update = False\n        else:\n            break\n\n    return msg", "loc": 11}
{"file": "thonny\\thonny\\plugins\\cpython_frontend\\cp_front.py", "class_name": "LocalCPythonProxy", "function_name": "get_switcher_configuration_label", "parameters": ["cls", "conf"], "param_types": {"conf": "Dict[str, Any]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_default_cpython_executable_for_backend", "is_private_python", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_switcher_configuration_label(cls, conf: Dict[str, Any]) -> str:\n    exe = conf[f\"{cls.backend_name}.executable\"]\n    if is_private_python(exe) and exe == get_default_cpython_executable_for_backend():\n        exe_label = tr(\"Thonny's Python\")\n    else:\n        exe_label = exe\n    # \n    return cls.backend_description + \"    \" + exe_label", "loc": 8}
{"file": "thonny\\thonny\\plugins\\cpython_frontend\\cp_front.py", "class_name": "LocalCPythonProxy", "function_name": "get_packages_target_dir_with_comment", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["normpath_with_actual_case", "os.makedirs", "self._prefer_user_install", "self.get_externally_managed_message", "self.get_site_packages", "self.get_user_site_packages", "self.is_externally_managed"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_packages_target_dir_with_comment(self):\n    if self.is_externally_managed():\n        return None, self.get_externally_managed_message()\n\n    if self._prefer_user_install():\n        usp = self.get_user_site_packages()\n        os.makedirs(usp, exist_ok=True)\n        return normpath_with_actual_case(usp), \"user site-packages\"\n    else:\n        sp = self.get_site_packages()\n        if sp is None:\n            return None, \"could not find target directory\"\n        return normpath_with_actual_case(sp), \"site-packages\"", "loc": 13}
{"file": "thonny\\thonny\\plugins\\cpython_frontend\\__init__.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_default_cpython_executable_for_backend", "get_workbench", "tr", "wb.add_backend", "wb.get_option", "wb.set_default", "wb.set_option"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    wb = get_workbench()\n    wb.set_default(\"run.backend_name\", \"LocalCPython\")\n    wb.set_default(\"LocalCPython.last_executables\", [])\n    wb.set_default(\"LocalCPython.executable\", get_default_cpython_executable_for_backend())\n\n    if wb.get_option(\"run.backend_name\") in [\"PrivateVenv\", \"SameAsFrontend\", \"CustomCPython\"]:\n        # Removed in Thonny 4.0\n        wb.set_option(\"run.backend_name\", \"LocalCPython\")\n        wb.set_option(\"LocalCPython.executable\", get_default_cpython_executable_for_backend())\n\n    wb.add_backend(\n        \"LocalCPython\",\n        LocalCPythonProxy,\n        tr(\"Local Python 3\"),\n        LocalCPythonConfigurationPage,\n        \"02\",\n    )", "loc": 18}
{"file": "thonny\\thonny\\plugins\\cpython_ssh\\cps_front.py", "class_name": "SshCPythonProxy", "function_name": "fetch_next_message", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "super", "super().fetch_next_message"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fetch_next_message(self):\n    msg = super().fetch_next_message()\n    if msg and \"welcome_text\" in msg:\n        assert hasattr(self, \"_reported_executable\")\n        msg[\"welcome_text\"] += \" (\" + self._reported_executable + \" on \" + self._host + \")\"\n    return msg", "loc": 6}
{"file": "thonny\\thonny\\plugins\\cpython_ssh\\cps_front.py", "class_name": "SshCPythonProxy", "function_name": "destroy", "parameters": ["self", "for_restart"], "param_types": {"for_restart": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ImmediateCommand", "self.send_command", "super", "super().destroy"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def destroy(self, for_restart: bool = False):\n    try:\n        self.send_command(ImmediateCommand(\"kill\"))\n    except BrokenPipeError:\n        pass\n    except OSError:\n        pass\n    super().destroy()", "loc": 8}
{"file": "thonny\\thonny\\plugins\\cpython_ssh\\cps_front.py", "class_name": "SshCPythonProxy", "function_name": "get_current_switcher_configuration", "parameters": ["self"], "param_types": {}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_current_switcher_configuration(self) -> Dict[str, Any]:\n    return {\n        \"run.backend_name\": self.backend_name,\n        f\"{self.backend_name}.executable\": get_workbench().get_option(\n            f\"{self.backend_name}.executable\"\n        ),\n        f\"{self.backend_name}.host\": get_workbench().get_option(f\"{self.backend_name}.host\"),\n        f\"{self.backend_name}.user\": get_workbench().get_option(f\"{self.backend_name}.user\"),\n    }", "loc": 9}
{"file": "thonny\\thonny\\plugins\\cpython_ssh\\cps_front.py", "class_name": "SshCPythonProxy", "function_name": "get_switcher_entries", "parameters": ["cls"], "param_types": {}, "return_type": "List[Tuple[Dict[str, Any], str, str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls.get_last_configurations", "cls.get_switcher_configuration_label", "sorted"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_switcher_entries(cls) -> List[Tuple[Dict[str, Any], str, str]]:\n    confs = sorted(cls.get_last_configurations(), key=cls.get_switcher_configuration_label)\n    return [\n        (conf, cls.get_switcher_configuration_label(conf), conf[cls.backend_name + \".host\"])\n        for conf in confs\n    ]", "loc": 6}
{"file": "thonny\\thonny\\plugins\\cpython_ssh\\cps_front.py", "class_name": "SshCPythonProxy", "function_name": "open_custom_system_shell", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_local_cwd", "messagebox.showerror", "shutil.which", "terminal.run_in_terminal"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def open_custom_system_shell(self):\n    if not shutil.which(\"ssh\"):\n        messagebox.showerror(\n            \"Command not found\", \"Command 'ssh' not found\", master=get_workbench()\n        )\n        return\n\n    from thonny import terminal\n\n    userhost = \"%s@%s\" % (self._user, self._host)\n    terminal.run_in_terminal(\n        [\"ssh\", userhost], cwd=get_workbench().get_local_cwd(), keep_open=False, title=userhost\n    )", "loc": 13}
{"file": "thonny\\thonny\\plugins\\cpython_ssh\\__init__.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_backend", "get_workbench().set_default", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    get_workbench().set_default(\"SshCPython.host\", \"\")\n    get_workbench().set_default(\"SshCPython.port\", \"22\")\n    get_workbench().set_default(\"SshCPython.user\", \"\")\n    get_workbench().set_default(\"SshCPython.auth_method\", \"password\")\n    get_workbench().set_default(\"SshCPython.executable\", \"python3\")\n    get_workbench().set_default(\"SshCPython.cwd\", \"~\")\n    get_workbench().set_default(\"SshCPython.last_executables\", [])\n    get_workbench().set_default(\"SshCPython.make_uploaded_shebang_scripts_executable\", True)\n    get_workbench().add_backend(\n        \"SshCPython\",\n        SshCPythonProxy,\n        tr(\"Remote Python 3 (SSH)\"),\n        SshProxyConfigPage,\n        sort_key=\"15\",\n    )", "loc": 16}
{"file": "thonny\\thonny\\plugins\\ev3\\__init__.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["add_micropython_backend", "get_workbench", "get_workbench().set_default", "running_on_windows"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    add_micropython_backend(\n        \"EV3MicroPython\",\n        EV3MicroPythonProxy,\n        \"MicroPython (EV3)\",\n        EV3MicroPythonConfigPage,\n        bare_metal=False,\n        sort_key=\"23\",\n    )\n    get_workbench().set_default(\"EV3MicroPython.executable\", \"pybricks-micropython\")\n    get_workbench().set_default(\"EV3MicroPython.make_uploaded_shebang_scripts_executable\", True)\n    get_workbench().set_default(\"EV3MicroPython.cwd\", None)\n    get_workbench().set_default(\n        \"EV3MicroPython.host\", \"ev3dev\" if running_on_windows() else \"ev3dev.local\"\n    )\n    get_workbench().set_default(\"EV3MicroPython.port\", \"22\")\n    get_workbench().set_default(\"EV3MicroPython.user\", \"robot\")\n    get_workbench().set_default(\"EV3MicroPython.auth_method\", \"password\")", "loc": 18}
{"file": "thonny\\thonny\\plugins\\ev3\\api_stubs\\pybricks\\ev3devices\\__stub\\__infraredsensor.py", "class_name": "InfraredSensor", "function_name": "beacon", "parameters": ["self", "channel"], "param_types": {"channel": "int"}, "return_type": "Tuple[int, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "range"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Measures the relative distance and angle between the remote and the infrared sensor.", "source_code": "def beacon(self, channel: int) -> Tuple[int, int]:\n    \"\"\"\n    Measures the relative distance and angle between the remote and the infrared sensor.\n\n    Args:\n        channel (int): Channel number of the remote.\n\n    Returns:\n        Tuple of relative distance (0 to 100) and approximate angle (-75 to 75 degrees) between remote and infrared sensor or (None,None) if no remote is detected.\n    \"\"\"\n    if not channel in range(1,5):\n        raise ValueError('Channel must be 1, 2, 3, or 4.')\n    return (0, 0)", "loc": 13}
{"file": "thonny\\thonny\\plugins\\ev3\\api_stubs\\pybricks\\ev3devices\\__stub\\__infraredsensor.py", "class_name": "InfraredSensor", "function_name": "buttons", "parameters": ["self", "channel"], "param_types": {"channel": "int"}, "return_type": "List[Button]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValueError", "range"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Checks which buttons on the infrared remote are pressed. This method can detect up to two buttons at once. If you press more buttons, you may not get useful data.", "source_code": "def buttons(self, channel: int) -> List[Button]:\n    \"\"\"\n    Checks which buttons on the infrared remote are pressed.\n\n    This method can detect up to two buttons at once. If you press more buttons, you may not get useful data.\n\n    Args:\n        channel (int): Channel number of the remote.\n\n    Returns:\n        List of pressed buttons on the remote on the specified channel.\n    \"\"\"\n    if not channel in range(1,5):\n        raise ValueError('Channel must be 1, 2, 3, or 4.') \n    return []", "loc": 15}
{"file": "thonny\\thonny\\plugins\\ev3\\api_stubs\\pybricks\\robotics\\__stub\\__drivebase.py", "class_name": "DriveBase", "function_name": "settings", "parameters": ["self", "straight_speed", "straight_acceleration", "turn_rate", "turn_acceleration"], "param_types": {"straight_speed": "int", "straight_acceleration": "int", "turn_rate": "int", "turn_acceleration": "int"}, "return_type": "Tuple[int, int, int, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Configures the speed and acceleration used by straight() and turn(). If you give no arguments, this returns the current values as a tuple. You can only change the settings while the robot is stopped. This is either before you begin driving or after you call stop().", "source_code": "def settings(self, straight_speed: int = None, straight_acceleration: int = None, turn_rate: int = None, turn_acceleration: int = None) -> Tuple[int, int, int, int]:\n    \"\"\"\n    Configures the speed and acceleration used by straight() and turn().\n\n    If you give no arguments, this returns the current values as a tuple.\n\n    You can only change the settings while the robot is stopped. This is either before you begin driving or after you call stop().\n\n    Args:\n        straight_speed (int):  Speed of the robot during straight() in millimeters/second.\n        straight_acceleration (int): Acceleration and deceleration of the robot at the start and end of straight() in millimeters/second^2.\n        turn_rate (int): Turn rate of the robot during turn() in degrees/second.\n        turn_acceleration (int): Angular acceleration and deceleration of the robot at the start and end of turn() in degrees/second^2.\n\n    Returns:\n        Straight speed (millimeters/second), straight acceleration (millimeters/second^2), turn rate (degrees/second), and turn acceleration (degrees/second^2) (if no arguments are provided), None otherwise.\n    \"\"\"\n    if straight_speed is None and straight_acceleration is None and turn_rate is None and turn_acceleration is None:\n        return (0, 0, 0, 0)\n    else:\n        return None", "loc": 21}
{"file": "thonny\\thonny\\plugins\\ev3\\api_stubs\\pybricks\\__stub\\__control.py", "class_name": "Control", "function_name": "limits", "parameters": ["self", "speed", "acceleration", "actuation"], "param_types": {"speed": "int", "acceleration": "int", "actuation": "int"}, "return_type": "Tuple[int, int, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Configures the maximum speed, acceleration, and actuation. If no arguments are given, this will return the current values.", "source_code": "def limits(self, speed: int = None, acceleration: int = None, actuation: int = None) -> Tuple[int, int, int]:\n    \"\"\"\n    Configures the maximum speed, acceleration, and actuation.\n\n    If no arguments are given, this will return the current values.\n\n    Args:\n        speed (int): Maximum speed. All speed commands will be capped to this value. Rotational (degrees/second) or Linear (millimeters/second).\n        acceleration (int): Maximum acceleration. Rotational (degrees/second^2) or Linear (millimeters/second^2).\n        actuation (int): Maximum actuation as percentage (0 - 100) of absolute maximum.\n\n    Returns:\n        Speed, acceleration, and actuation (if no arguments are provided). None, otherwise.\n    \"\"\"\n    if speed is None and acceleration is None and actuation is None:\n        return (0, 0, 0)\n    else:\n        return None", "loc": 18}
{"file": "thonny\\thonny\\plugins\\ev3\\api_stubs\\pybricks\\__stub\\__control.py", "class_name": "Control", "function_name": "pid", "parameters": ["self", "kp", "ki", "kd", "integral_range", "integral_rate", "feed_forward"], "param_types": {"kp": "int", "ki": "int", "kd": "int", "integral_range": "int", "integral_rate": "int", "feed_forward": "int"}, "return_type": "Tuple[int, int, int, int, int, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Gets or sets the PID values for position and speed control. If no arguments are given, this will return the current values.", "source_code": "def pid(self, kp: int = None, ki: int = None, kd: int = None, integral_range: int = None, integral_rate: int = None, feed_forward: int = None) -> Tuple[int, int, int, int, int, int]:\n    \"\"\"\n    Gets or sets the PID values for position and speed control.\n\n    If no arguments are given, this will return the current values.\n\n    Args:\t\n        kp (int): Proportional position (or integral speed) control constant.\n        ki (int): Integral position control constant.\n        kd (int): Derivative position (or proportional speed) control constant.\n        integral_range (int): Region around the target angle (degrees) or distance (millimeters), in which integral control errors are accumulated.\n        integral_rate (int): Maximum rate at which the error integral is allowed to grow. Rotational (degrees/second) or Linear (millimeters/second).\n        feed_forward (int): This adds a feed forward signal to the PID feedback signal, in the direction of the speed reference. This value is expressed as a percentage (0 - 100) of the absolute maximum duty cycle.\n\n    Returns:\n        kp, ki, kd, integral range, integral rate, and feed forward (if no arguments are provided), None otherwise.\n    \"\"\"\n    if kp is None and ki is None and kd is None and integral_range is None and integral_rate is None and feed_forward is None:\n        return (0, 0, 0, 0, 0, 0)\n    else:\n        return None", "loc": 21}
{"file": "thonny\\thonny\\plugins\\ev3\\api_stubs\\pybricks\\__stub\\__control.py", "class_name": "Control", "function_name": "target_tolerances", "parameters": ["self", "speed", "position"], "param_types": {"speed": "int", "position": "int"}, "return_type": "Tuple[int, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Gets or sets the tolerances that say when a maneuver is done. If no arguments are given, this will return the current values.", "source_code": "def target_tolerances(self, speed: int = None, position: int = None) -> Tuple[int, int]:\n    \"\"\"\n    Gets or sets the tolerances that say when a maneuver is done.\n\n    If no arguments are given, this will return the current values.\n\n    Args:\t\n        speed (int): Allowed deviation from zero speed before motion is considered complete. Linear (millimeters/second) or Rotational (degrees/second)\n        position (init): Allowed deviation from the target before motion is considered complete. Linear (millimeters) or Rotational (degrees).\n\n    Returns:\n        Allowed deviation from zero speed and allowed deviation from the target (if no arguments are provided), None otherwise.\n    \"\"\"\n    if speed is None and position is None:\n        return (0, 0)\n    else:\n        return None", "loc": 17}
{"file": "thonny\\thonny\\plugins\\ev3\\api_stubs\\pybricks\\__stub\\__control.py", "class_name": "Control", "function_name": "stall_tolerances", "parameters": ["self", "speed", "time"], "param_types": {"speed": "int", "time": "int"}, "return_type": "Tuple[int, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Gets or sets stalling tolerances. If no arguments are given, this will return the current values.", "source_code": "def stall_tolerances(self, speed: int = None, time: int = None) -> Tuple[int, int]:\n    \"\"\"\n    Gets or sets stalling tolerances.\n\n    If no arguments are given, this will return the current values.\n\n    Args:\t\n        speed (int): If the controller cannot reach this speed for some time even with maximum actuation, it is stalled. Rotational (degrees/second) or Linear (millimeters/second).\n        time (int): How long the controller has to be below this minimum speed before we say it is stalled in milliseconds.\n\n    Returns:\n        Threshold speed and time limit (if no arguments are provided), None otherwise.\n    \"\"\"\n    if speed is None and time is None:\n        return (0, 0)\n    else:\n        return None", "loc": 17}
{"file": "thonny\\thonny\\plugins\\microbit\\__init__.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["MicrobitProxy.get_known_usb_vids_pids", "add_micropython_backend", "thonny.plugins.circuitpython.cirpy_front.VIDS_PIDS_TO_AVOID.update", "thonny.plugins.esp.VIDS_PIDS_TO_AVOID_IN_ESP_BACKENDS.update", "thonny.plugins.micropython.mp_front.VIDS_PIDS_TO_AVOID_IN_GENERIC_BACKEND.update", "thonny.plugins.rp2040.VIDS_PIDS_TO_AVOID_IN_RP2040.update"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    add_micropython_backend(\n        \"microbit\",\n        MicrobitProxy,\n        \"MicroPython (BBC micro:bit)\",\n        MicrobitConfigPage,\n        sort_key=\"31\",\n        validate_time=False,\n        sync_time=False,\n        submit_mode=PASTE_SUBMIT_MODE,\n        write_block_size=128,\n    )\n\n    # Don't consider micro:bit in generic backends\n    # The main reason is to reduce the number of items in the backend switcher menu\n    import thonny.plugins.circuitpython\n    import thonny.plugins.esp\n    import thonny.plugins.micropython\n    import thonny.plugins.rp2040\n\n    thonny.plugins.circuitpython.cirpy_front.VIDS_PIDS_TO_AVOID.update(\n        MicrobitProxy.get_known_usb_vids_pids()\n    )\n    thonny.plugins.micropython.mp_front.VIDS_PIDS_TO_AVOID_IN_GENERIC_BACKEND.update(\n        MicrobitProxy.get_known_usb_vids_pids()\n    )\n    thonny.plugins.esp.VIDS_PIDS_TO_AVOID_IN_ESP_BACKENDS.update(\n        MicrobitProxy.get_known_usb_vids_pids()\n    )\n    thonny.plugins.rp2040.VIDS_PIDS_TO_AVOID_IN_RP2040.update(\n        MicrobitProxy.get_known_usb_vids_pids()\n    )", "loc": 32}
{"file": "thonny\\thonny\\plugins\\micropython\\bare_metal_backend.py", "class_name": null, "function_name": "launch_bare_metal_backend", "parameters": ["backend_class"], "param_types": {"backend_class": "Callable[..., BareMetalMicroPythonBackend]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["BackendEvent", "SerialConnection", "WebReplConnection", "args.get", "ast.literal_eval", "backend_class", "logger.info", "print", "serialize_message", "str", "sys.exit", "sys.stdout.flush", "sys.stdout.write", "thonny.configure_backend_logging"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def launch_bare_metal_backend(backend_class: Callable[..., BareMetalMicroPythonBackend]) -> None:\n    thonny.configure_backend_logging()\n    print(PROCESS_ACK)\n\n    import ast\n\n    args = ast.literal_eval(sys.argv[1])\n    logger.info(\"Starting backend, args: %r\", args)\n\n    try:\n        if args[\"port\"] is None:\n            print(\"\\nPort not defined\", file=sys.stderr)\n            sys.exit(ALL_EXPLAINED_STATUS_CODE)\n        elif args[\"port\"] == \"webrepl\":\n            connection = WebReplConnection(args[\"url\"], args[\"password\"])\n        else:\n            from thonny.plugins.micropython.serial_connection import (\n                DifficultSerialConnection,\n                SerialConnection,\n            )\n\n            connection = SerialConnection(\n                args[\"port\"], BAUDRATE, dtr=args.get(\"dtr\"), rts=args.get(\"rts\")\n            )\n            # connection = DifficultSerialConnection(args[\"port\"], BAUDRATE)\n\n        backend = backend_class(connection, clean=args[\"clean\"], args=args)\n\n    except ConnectionError as e:\n        text = \"\\n\" + str(e) + \"\\n\"\n        msg = BackendEvent(event_type=\"ProgramOutput\", stream_name=\"stderr\", data=text)\n        sys.stdout.write(serialize_message(msg) + \"\\n\")\n        sys.stdout.flush()\n        sys.exit(ALL_EXPLAINED_STATUS_CODE)", "loc": 34}
{"file": "thonny\\thonny\\plugins\\micropython\\base_flashing_dialog.py", "class_name": null, "function_name": "find_uf2_property", "parameters": ["lines", "prop_name"], "param_types": {"lines": "List[str]", "prop_name": "str"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "line.startswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_uf2_property(lines: List[str], prop_name: str) -> Optional[str]:\n    marker = prop_name + \": \"\n    for line in lines:\n        if line.startswith(marker):\n            return line[len(marker) :]\n\n    return None", "loc": 7}
{"file": "thonny\\thonny\\plugins\\micropython\\base_flashing_dialog.py", "class_name": "BaseFlashingDialog", "function_name": "populate_main_frame", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AdvancedLabel", "MappingCombobox", "family_label.grid", "self._family_combo.bind", "self._family_combo.grid", "self._target_combo.bind", "self._target_combo.grid", "self._target_info_content_label.grid", "self._target_info_label.grid", "self._variant_combo.bind", "self._variant_combo.grid", "self._variant_info_content_label.grid", "self._version_combo.bind", "self._version_combo.grid", "self.get_families_mapping", "self.get_large_padding", "self.get_small_padding", "self.get_target_label", "self.main_frame.columnconfigure", "target_label.grid", "tr", "ttk.Label", "variant_info_label.grid", "variant_label.grid", "version_label.grid"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def populate_main_frame(self):\n    epadx = self.get_large_padding()\n    ipadx = self.get_small_padding()\n    epady = epadx\n    ipady = ipadx\n\n    target_label = ttk.Label(self.main_frame, text=self.get_target_label())\n    target_label.grid(row=1, column=1, sticky=\"e\", padx=(epadx, 0), pady=(epady, 0))\n    self._target_combo = MappingCombobox(self.main_frame, mapping={}, exportselection=False)\n    self._target_combo.grid(\n        row=1, column=2, sticky=\"nsew\", padx=(ipadx, epadx), pady=(epady, 0)\n    )\n    self._target_combo.bind(\"<<ComboboxSelected>>\", self.register_settings_changed, True)\n\n    self._target_info_label = ttk.Label(self.main_frame, text=tr(\"model\"))\n    self._target_info_label.grid(row=2, column=1, sticky=\"e\", padx=(epadx, 0), pady=(ipady, 0))\n    self._target_info_content_label = ttk.Label(self.main_frame)\n    self._target_info_content_label.grid(\n        row=2, column=2, sticky=\"w\", padx=(ipadx, epadx), pady=(ipady, 0)\n    )\n\n    family_label = ttk.Label(self.main_frame, text=f\"{self.firmware_name} family\")\n    family_label.grid(row=5, column=1, sticky=\"e\", padx=(epadx, 0), pady=(epady, 0))\n    self._family_combo = MappingCombobox(\n        self.main_frame,\n        exportselection=False,\n        state=\"enabled\",\n        mapping=self.get_families_mapping(),\n    )\n    self._family_combo.grid(\n        row=5, column=2, sticky=\"nsew\", padx=(ipadx, epadx), pady=(epady, 0)\n    )\n    self._family_combo.bind(\"<<ComboboxSelected>>\", self.register_settings_changed, True)\n\n    variant_label = ttk.Label(self.main_frame, text=f\"variant\")\n    variant_label.grid(row=6, column=1, sticky=\"e\", padx=(epadx, 0), pady=(ipady, 0))\n    self._variant_combo = MappingCombobox(\n        self.main_frame, mapping={}, exportselection=False, state=\"disabled\"\n    )\n    self._variant_combo.grid(\n        row=6, column=2, sticky=\"nsew\", padx=(ipadx, epadx), pady=(ipady, 0)\n    )\n    self._variant_combo.bind(\"<<ComboboxSelected>>\", self.register_settings_changed, True)\n\n    version_label = ttk.Label(self.main_frame, text=tr(\"version\"))\n    version_label.grid(row=7, column=1, sticky=\"e\", padx=(epadx, 0), pady=(ipady, 0))\n    self._version_combo = MappingCombobox(\n        self.main_frame, mapping={}, exportselection=False, state=\"disabled\"\n    )\n    self._version_combo.grid(\n        row=7, column=2, sticky=\"nsew\", padx=(ipadx, epadx), pady=(ipady, 0)\n    )\n    self._version_combo.bind(\"<<ComboboxSelected>>\", self.register_settings_changed, True)\n\n    variant_info_label = ttk.Label(self.main_frame, text=tr(\"info\"))\n    variant_info_label.grid(row=8, column=1, sticky=\"e\", padx=(epadx, 0), pady=(ipady, 0))\n    self._variant_info_content_label = AdvancedLabel(self.main_frame)\n    self._variant_info_content_label.grid(\n        row=8, column=2, sticky=\"w\", padx=(ipadx, epadx), pady=(ipady, 0)\n    )\n\n    self.main_frame.columnconfigure(2, weight=1)", "loc": 62}
{"file": "thonny\\thonny\\plugins\\micropython\\base_flashing_dialog.py", "class_name": "BaseFlashingDialog", "function_name": "update_ui", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "logger.debug", "self._family_combo.get_selected_value", "self._family_combo.select_value", "self._present_versions_for_variant", "self._target_combo.get_selected_value", "self._try_preselect_a_variant", "self._update_target_info", "self._update_variant_info", "self._variant_combo.get_selected_value", "self._version_combo.select_none", "self._version_combo.set_mapping", "self.find_targets", "self.main_frame.winfo_children", "self.on_change_family", "self.show_new_targets", "super", "super().update_ui", "widget.state"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_ui(self):\n    for widget in self.main_frame.winfo_children():\n        if isinstance(widget, (ttk.Combobox, ttk.Checkbutton)):\n            if self._state == \"working\" or not self._downloaded_variants:\n                widget.state([\"disabled\", \"readonly\"])\n            else:\n                widget.state([\"!disabled\", \"readonly\"])\n\n    if self._state == \"idle\":\n        targets = self.find_targets()\n        if targets != self._target_combo.mapping:\n            self.show_new_targets(targets)\n            self._last_handled_target = None\n            self._last_handled_family_target = None\n\n        current_target = self._target_combo.get_selected_value()\n        if current_target != self._last_handled_target:\n            if current_target.family:\n                self._family_combo.select_value(current_target.family)\n            self._update_target_info()\n            self._last_handled_target = current_target\n            self._last_handled_family_target = None\n\n        current_family = self._family_combo.get_selected_value()\n        if self._last_handled_family != current_family:\n            logger.debug(\n                \"Changing family from %r to %r\", self._last_handled_family, current_family\n            )\n            self.on_change_family(current_family)\n            if self._downloaded_variants:\n                # not handled yet if still downloading\n                self._last_handled_family = current_family\n\n        if self._last_handled_family_target != (current_family, current_target):\n            if current_family and current_target and self._downloaded_variants:\n                self._try_preselect_a_variant(current_target)\n                self._last_handled_family_target = (current_family, current_target)\n\n        current_variant = self._variant_combo.get_selected_value()\n        if current_variant != self._last_handled_variant:\n            if not current_variant:\n                self._version_combo.select_none()\n                self._version_combo.set_mapping({})\n            else:\n                self._present_versions_for_variant(current_variant)\n            self._last_handled_variant = current_variant\n\n        # always updating the multipurpose label\n        self._update_variant_info()\n\n    super().update_ui()", "loc": 51}
{"file": "thonny\\thonny\\plugins\\micropython\\base_flashing_dialog.py", "class_name": "BaseFlashingDialog", "function_name": "show_new_targets", "parameters": ["self", "targets"], "param_types": {"targets": "Dict[str, TargetInfo]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "list", "self._target_combo.select_none", "self._target_combo.select_value", "self._target_combo.set_mapping", "targets.values"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_new_targets(self, targets: Dict[str, TargetInfo]) -> None:\n    self._target_combo.set_mapping(targets)\n    if len(targets) == 1:\n        self._target_combo.select_value(list(targets.values())[0])\n    else:\n        self._target_combo.select_none()", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\base_flashing_dialog.py", "class_name": "BaseFlashingDialog", "function_name": "on_change_family", "parameters": ["self", "family"], "param_types": {"family": "Optional[str]"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["enhanced_mapping.update", "filtered_mapping.items", "len", "populars.values", "self._create_variant_description", "self._variant_combo.select_none", "self._variant_combo.set_mapping", "tr", "variant.copy", "variant.get", "whole_mapping.items"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def on_change_family(self, family: Optional[str]) -> None:\n    self._variant_combo.select_none()\n\n    if not family or not self._downloaded_variants:\n        self._variant_combo.set_mapping({})\n        return\n\n    whole_mapping = {self._create_variant_description(v): v for v in self._downloaded_variants}\n\n    filtered_mapping = {\n        item[0]: item[1] for item in whole_mapping.items() if item[1][\"family\"] == family\n    }\n\n    populars = {\n        key: variant\n        for key, variant in filtered_mapping.items()\n        if variant.get(\"popular\", False)\n    }\n    if populars and len(populars) < len(filtered_mapping):\n        enhanced_mapping = {\"--- \" + tr(\"MOST POPULAR\") + \" \" + \"-\" * 100: {}}\n        for variant in populars.values():\n            popular_variant = variant.copy()\n            # need different title to distinguish it from the same item in ALL VARIANTS\n            popular_title = self._create_variant_description(variant) + \" \"\n            popular_variant[\"title\"] = popular_title\n            enhanced_mapping[popular_title] = popular_variant\n\n        enhanced_mapping[\"--- \" + tr(\"ALL VARIANTS\") + \" \" + \"-\" * 100] = {}\n        enhanced_mapping.update(filtered_mapping)\n    else:\n        enhanced_mapping = filtered_mapping\n\n    self._variant_combo.set_mapping(enhanced_mapping)", "loc": 33}
{"file": "thonny\\thonny\\plugins\\micropython\\base_flashing_dialog.py", "class_name": "BaseFlashingDialog", "function_name": "start_work", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._target_combo.get_selected_value", "self._variant_combo.get_selected_value", "self._version_combo.get_selected_value", "self.clear_log", "self.prepare_work_get_options", "self.report_progress", "threading.Thread", "threading.Thread(target=self._perform_work_and_update_status, args=[variant_info, download_info, target_info, work_options], daemon=True).start"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start_work(self):\n    from thonny.plugins.micropython import BareMetalMicroPythonProxy\n\n    variant_info: Dict[str, Any] = self._variant_combo.get_selected_value()\n    download_info: Dict[str, Any] = self._version_combo.get_selected_value()\n    target_info: TargetInfo = self._target_combo.get_selected_value()\n\n    self.report_progress(0, 100)\n\n    work_options = self.prepare_work_get_options()\n    self.clear_log()\n    threading.Thread(\n        target=self._perform_work_and_update_status,\n        args=[variant_info, download_info, target_info, work_options],\n        daemon=True,\n    ).start()\n    return True", "loc": 17}
{"file": "thonny\\thonny\\plugins\\micropython\\connection.py", "class_name": "MicroPythonConnection", "function_name": "read", "parameters": ["self", "size", "timeout", "timeout_is_soft"], "param_types": {"size": "int", "timeout": "float", "timeout_is_soft": "bool"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ReadingTimeoutError", "TimeHelper", "len", "logger.error", "self._read_buffer.extend", "self._read_queue.get", "self.check_for_error"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read(self, size: int, timeout: float = 10, timeout_is_soft: bool = False) -> bytes:\n    if timeout == 0:\n        if timeout_is_soft:\n            return b\"\"\n        else:\n            raise ReadingTimeoutError(read_bytes=b\"\")\n\n    timer = TimeHelper(timeout)\n\n    while len(self._read_buffer) < size:\n        self.check_for_error()\n\n        try:\n            self._read_buffer.extend(self._read_queue.get(True, timer.time_left))\n        except queue.Empty:\n            if timeout_is_soft:\n                return b\"\"\n            else:\n                logger.error(\n                    \"Could not read expected %s bytes in %s seconds. Bytes read: %r\",\n                    size,\n                    timeout,\n                    self._read_buffer,\n                )\n                raise ReadingTimeoutError(read_bytes=self._read_buffer)\n\n    try:\n        data = self._read_buffer[:size]\n        return data\n    finally:\n        del self._read_buffer[:size]", "loc": 31}
{"file": "thonny\\thonny\\plugins\\micropython\\connection.py", "class_name": "MicroPythonConnection", "function_name": "read_until", "parameters": ["self", "terminator", "timeout", "timeout_is_soft"], "param_types": {"terminator": "Union[bytes, re.Pattern]", "timeout": "float", "timeout_is_soft": "bool"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ReadingTimeoutError", "TimeHelper", "isinstance", "len", "match.end", "re.compile", "re.escape", "re.search", "self._read_buffer.extend", "self._read_queue.get", "self.check_for_error"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_until(\n    self,\n    terminator: Union[bytes, re.Pattern],\n    timeout: float = 1000000,\n    timeout_is_soft: bool = False,\n) -> bytes:\n    timer = TimeHelper(timeout)\n\n    if isinstance(terminator, bytes):\n        terminator = re.compile(re.escape(terminator))\n\n    assert isinstance(terminator, re.Pattern)\n\n    while True:\n        self.check_for_error()\n\n        match = re.search(terminator, self._read_buffer)\n        if match:\n            break\n\n        try:\n            data = self._read_queue.get(True, timer.time_left)\n            # print(\"RR\", repr(data), file=sys.stderr)\n            assert len(data) > 0\n            self._read_buffer.extend(data)\n        except queue.Empty:\n            if timeout_is_soft:\n                break\n            else:\n                raise ReadingTimeoutError(read_bytes=self._read_buffer)\n\n    if match:\n        size = match.end()\n    else:\n        assert timeout_is_soft\n        size = len(self._read_buffer)\n\n    data = self._read_buffer[:size]\n    del self._read_buffer[:size]\n    return data", "loc": 40}
{"file": "thonny\\thonny\\plugins\\micropython\\connection.py", "class_name": "MicroPythonConnection", "function_name": "read_all", "parameters": ["self", "check_error"], "param_types": {"check_error": "bool"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytearray", "len", "self._fetch_to_buffer", "self.check_for_error"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_all(self, check_error: bool = True) -> bytes:\n    self._fetch_to_buffer()\n\n    if len(self._read_buffer) == 0 and check_error:\n        self.check_for_error()\n\n    try:\n        return self._read_buffer\n    finally:\n        self._read_buffer = bytearray()", "loc": 10}
{"file": "thonny\\thonny\\plugins\\micropython\\connection.py", "class_name": "MicroPythonConnection", "function_name": "read_all_expected", "parameters": ["self", "expected", "timeout"], "param_types": {"expected": "bytes", "timeout": "float"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.read", "self.read_all"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_all_expected(self, expected: bytes, timeout: float = None) -> bytes:\n    actual = self.read(len(expected), timeout=timeout)\n    actual += self.read_all()\n    assert expected == actual, \"Expected %r, got %r\" % (expected, actual)\n    return actual", "loc": 5}
{"file": "thonny\\thonny\\plugins\\micropython\\connection.py", "class_name": "MicroPythonConnection", "function_name": "check_for_error", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ConnectionError", "logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_for_error(self) -> None:\n    if self._error is None:\n        return\n    logger.info(\"Detected connection error\")\n    raise ConnectionError(self._error)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\micropython\\connection.py", "class_name": "MicroPythonConnection", "function_name": "unread", "parameters": ["self", "data"], "param_types": {"data": "bytes"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytearray", "data.encode", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unread(self, data: bytes) -> None:\n    if not data:\n        return\n\n    if isinstance(data, str):\n        data = data.encode(self.encoding)\n    elif isinstance(data, bytes):\n        data = bytearray(data)\n\n    self._read_buffer = data + self._read_buffer", "loc": 10}
{"file": "thonny\\thonny\\plugins\\micropython\\daplink_flasher.py", "class_name": "DaplinkFlashingDialog", "function_name": "perform_post_installation_steps", "parameters": ["self", "ports_before"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.append_text", "self.set_action_text", "time.sleep"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def perform_post_installation_steps(self, ports_before):\n    # can't check the ports as in the superclass, because the port is always there\n    # simply wait for a couple of seconds, just in case\n    self.append_text(\"\\nWaiting for device to restart...\\n\")\n    self.set_action_text(\"Waiting for device to restart...\")\n    time.sleep(5)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\esptool_dialog.py", "class_name": null, "function_name": "try_launch_esptool_dialog", "parameters": ["master", "firmware_name"], "param_types": {"firmware_name": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ESPFlashingDialog", "get_front_interpreter_for_subprocess", "master.winfo_toplevel", "messagebox.showerror", "ui_utils.show_dialog"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def try_launch_esptool_dialog(master, firmware_name: str):\n    try:\n        import esptool\n    except ImportError:\n        messagebox.showerror(\n            \"Can't find esptool\",\n            \"esptool not found.\\n\" + \"Install it via 'Tools => Manage plug-ins'\",\n            master=master,\n        )\n        return\n\n    cmd = [get_front_interpreter_for_subprocess(), \"-u\", \"-m\", \"esptool\"]\n    dlg = ESPFlashingDialog(master.winfo_toplevel(), firmware_name, cmd)\n    ui_utils.show_dialog(dlg)", "loc": 14}
{"file": "thonny\\thonny\\plugins\\micropython\\esptool_dialog.py", "class_name": "ESPFlashingDialog", "function_name": "get_families_mapping", "parameters": ["self"], "param_types": {}, "return_type": "Dict[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["codes.append", "codes.insert", "family_code_to_name"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_families_mapping(self) -> Dict[str, str]:\n    codes = [\n        \"esp32\",\n        \"esp32c2\",\n        \"esp32c3\",\n        \"esp32c6\",\n        \"esp32h2\",\n        \"esp32p4\",\n        \"esp32s2\",\n        \"esp32s3\",\n    ]\n    if self.firmware_name == \"MicroPython\":\n        codes.insert(0, \"esp8266\")\n    if self.firmware_name == \"CircuitPython\":\n        codes.append(\"esp32c6\")\n        codes.append(\"esp32h2\")\n\n    return {family_code_to_name(code): code for code in codes}", "loc": 18}
{"file": "thonny\\thonny\\plugins\\micropython\\esptool_dialog.py", "class_name": "ESPFlashingDialog", "function_name": "find_targets", "parameters": ["self"], "param_types": {}, "return_type": "Dict[str, TargetInfo]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TargetInfo", "get_serial_port_label", "len", "list_serial_ports", "name.replace", "name.startswith", "sorted"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_targets(self) -> Dict[str, TargetInfo]:\n    def port_order(p):\n        name = p.device\n        if name is None:\n            return \"\"\n        elif name.startswith(\"COM\") and len(name) == 4:\n            # Make one-digit COM ports go before COM10\n            return name.replace(\"COM\", \"COM0\")\n        else:\n            return name\n\n    sorted_ports = sorted(list_serial_ports(max_cache_age=0, skip_logging=True), key=port_order)\n\n    result = {}\n    for p in sorted_ports:\n        desc = get_serial_port_label(p)\n        result[desc] = TargetInfo(\n            title=desc, path=None, board_id=None, family=None, model=None, port=p\n        )\n\n    return result", "loc": 21}
{"file": "thonny\\thonny\\plugins\\micropython\\esptool_dialog.py", "class_name": "ESPFlashingDialog", "function_name": "prepare_work_get_options", "parameters": ["self"], "param_types": {}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().get_backend_proxy", "isinstance", "logger.info", "proxy.disconnect", "self._address_combo.get_selected_value", "self._erase_variable.get", "self._family_combo.get_selected_value", "self._flash_mode_combo.get_selected_value", "self._flash_size_combo.get_selected_value", "self._no_stub_variable.get", "self._speed_combo.get_selected_value", "self._target_combo.get_selected_value", "self._work_needs_disconnect", "self.show_log_frame"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def prepare_work_get_options(self) -> Dict[str, Any]:\n    target = self._target_combo.get_selected_value()\n    proxy = get_runner().get_backend_proxy()\n    port_was_used_in_thonny = (\n        isinstance(proxy, BareMetalMicroPythonProxy) and proxy._port == target.port.device\n    )\n    if port_was_used_in_thonny and self._work_needs_disconnect():\n        logger.info(\"Disconnecting\")\n        proxy.disconnect()\n\n    if self._work_mode in [\"device_info\", \"image_info\", \"esptool_version\"]:\n        self.show_log_frame()\n\n    return {\n        \"erase_flash\": self._erase_variable.get(),\n        \"family\": self._family_combo.get_selected_value(),\n        \"address\": self._address_combo.get_selected_value(),\n        \"speed\": self._speed_combo.get_selected_value(),\n        \"flash_mode\": self._flash_mode_combo.get_selected_value(),\n        \"flash_size\": self._flash_size_combo.get_selected_value(),\n        \"no_stub\": self._no_stub_variable.get(),\n        \"port_was_used_in_thonny\": port_was_used_in_thonny,\n    }", "loc": 23}
{"file": "thonny\\thonny\\plugins\\micropython\\esptool_dialog.py", "class_name": "ESPFlashingDialog", "function_name": "cancel_work", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.error", "messagebox.showerror", "os.kill", "running_on_windows", "self._proc.kill", "self._proc.poll", "self._proc.wait", "str", "super", "super().cancel_work"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cancel_work(self):\n    super().cancel_work()\n    if not self._proc:\n        return\n\n    # try gently first\n    try:\n        try:\n            if running_on_windows():\n                os.kill(self._proc.pid, signal.CTRL_BREAK_EVENT)  # pylint: disable=no-member\n            else:\n                os.kill(self._proc.pid, signal.SIGINT)\n\n            self._proc.wait(2)\n        except subprocess.TimeoutExpired:\n            if self._proc.poll() is None:\n                # now let's be more concrete\n                self._proc.kill()\n    except OSError as e:\n        messagebox.showerror(\"Error\", \"Could not kill subprocess: \" + str(e), master=self)\n        logger.error(\"Could not kill subprocess\", exc_info=e)", "loc": 21}
{"file": "thonny\\thonny\\plugins\\micropython\\esptool_dialog.py", "class_name": "ESPFlashingDialog", "function_name": "populate_action_menu", "parameters": ["self", "action_menu"], "param_types": {"action_menu": "tk.Menu"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["action_menu.add_command", "action_menu.add_separator", "self._advanced_widgets[0].winfo_ismapped", "self._can_query_device_info", "self._can_query_image_info", "self._can_show_esptool_version"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def populate_action_menu(self, action_menu: tk.Menu) -> None:\n    action_menu.add_command(\n        label=\"Select local MicroPython image ...\", command=self._browse_image\n    )\n    action_menu.add_separator()\n\n    action_menu.add_command(\n        label=\"Query device info\",\n        command=self._query_device_info,\n        state=\"normal\" if self._can_query_device_info() else \"disabled\",\n    )\n    action_menu.add_command(\n        label=\"Show image info\",\n        command=self._show_image_info,\n        state=\"normal\" if self._can_query_image_info() else \"disabled\",\n    )\n    action_menu.add_command(\n        label=\"Show esptool version\",\n        command=self._show_esptool_version,\n        state=\"normal\" if self._can_show_esptool_version() else \"disabled\",\n    )\n\n    action_menu.add_separator()\n    if self._advanced_widgets[0].winfo_ismapped():\n        action_menu.add_command(\n            label=\"Hide install options\",\n            command=self._hide_advanced_options,\n        )\n    else:\n        action_menu.add_command(\n            label=\"Show install options\",\n            command=self._show_advanced_options,\n        )", "loc": 33}
{"file": "thonny\\thonny\\plugins\\micropython\\esptool_dialog.py", "class_name": null, "function_name": "port_order", "parameters": ["p"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "name.replace", "name.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def port_order(p):\n    name = p.device\n    if name is None:\n        return \"\"\n    elif name.startswith(\"COM\") and len(name) == 4:\n        # Make one-digit COM ports go before COM10\n        return name.replace(\"COM\", \"COM0\")\n    else:\n        return name", "loc": 9}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_back.py", "class_name": null, "function_name": "unix_dirname_basename", "parameters": ["path"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["path.rsplit", "path.rstrip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unix_dirname_basename(path):\n    if path == \"/\":\n        return (\"/\", \"\")\n\n    if \"/\" not in path:  # micro:bit\n        return \"\", path\n\n    path = path.rstrip(\"/\")\n    dir_, file_ = path.rsplit(\"/\", maxsplit=1)\n    if dir_ == \"\":\n        dir_ = \"/\"\n\n    return dir_, file_", "loc": 13}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_back.py", "class_name": null, "function_name": "ends_overlap", "parameters": ["left", "right"], "param_types": {}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["left.endswith", "len", "min", "range"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ends_overlap(left, right) -> int:\n    \"\"\"Returns the length of maximum overlap between end of the first and start of the second\"\"\"\n    max_overlap = min(len(left), len(right))\n    for i in range(max_overlap, 0, -1):\n        if left.endswith(right[:i]):\n            return i\n\n    return 0", "loc": 8}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_back.py", "class_name": "MicroPythonBackend", "function_name": "send_message", "parameters": ["self", "msg"], "param_types": {"msg": "MessageFromBackend"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._get_library_paths", "super", "super().send_message"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def send_message(self, msg: MessageFromBackend) -> None:\n    if \"cwd\" not in msg:\n        msg[\"cwd\"] = self._cwd\n\n    if \"sys_path\" not in msg:\n        msg[\"sys_path\"] = self._sys_path\n\n    if \"lib_dirs\" not in msg:\n        msg[\"lib_dirs\"] = self._get_library_paths()\n\n    super().send_message(msg)", "loc": 11}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_back.py", "class_name": "MicroPythonBackend", "function_name": "handle_connection_error", "parameters": ["self", "error"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.warning", "self._forward_unexpected_output", "super", "super().handle_connection_error"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_connection_error(self, error=None):\n    try:\n        self._forward_unexpected_output(\"stderr\")\n    except:\n        logger.warning(\"Could not forward output\", exc_info=True)\n    super().handle_connection_error(error)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": null, "function_name": "get_serial_port_label", "parameters": ["p"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["desc.replace", "desc.replace('\\x00', '').strip", "p.description.replace"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_serial_port_label(p) -> str:\n    # On Windows, port is given also in description\n    if p.product:\n        desc = p.product\n    elif p.interface:\n        desc = p.interface\n    else:\n        desc = p.description.replace(f\" ({p.device})\", \"\")\n\n    desc = desc.replace(\"\\x00\", \"\").strip()\n\n    return f\"{desc} @ {p.device}\"", "loc": 12}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": null, "function_name": "get_machine_id_for_current_conf", "parameters": ["backend_name"], "param_types": {"backend_name": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_machine_id_for_conf", "get_workbench", "get_workbench().get_option"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_machine_id_for_current_conf(backend_name: str) -> str:\n    conf = {}\n    for name in [\"port\", \"webrepl_url\"]:\n        key = backend_name + \".\" + name\n        conf[key] = get_workbench().get_option(key)\n    return get_machine_id_for_conf(backend_name, conf)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": null, "function_name": "get_machine_id_for_conf", "parameters": ["backend_name", "conf"], "param_types": {"backend_name": "str", "conf": "Dict[str, Any]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_port_info", "get_workbench", "get_workbench().get_option", "logger.exception"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_machine_id_for_conf(backend_name: str, conf: Dict[str, Any]) -> str:\n    port = conf[backend_name + \".port\"]\n    if port == WEBREPL_PORT_VALUE:\n        return get_workbench().get_option(conf[backend_name + \".webrepl_url\"])\n    try:\n        return get_port_info(port).serial_number\n    except Exception:\n        logger.exception(\"Could not get port_info for %r\", port)\n        return \"<unknown>\"", "loc": 9}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": null, "function_name": "list_serial_ports", "parameters": ["max_cache_age", "skip_logging"], "param_types": {"max_cache_age": "float", "skip_logging": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_list_serial_ports_uncached", "time.time"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def list_serial_ports(max_cache_age: float = 0.5, skip_logging: bool = False):\n    global _PORTS_CACHE, _PORTS_CACHE_TIME\n\n    cur_time = time.time()\n    if cur_time - _PORTS_CACHE_TIME > max_cache_age:\n        _PORTS_CACHE = _list_serial_ports_uncached(skip_logging=skip_logging)\n        _PORTS_CACHE_TIME = cur_time\n\n    return _PORTS_CACHE", "loc": 9}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": null, "function_name": "get_port_info", "parameters": ["port"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "list_serial_ports"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_port_info(port):\n    for info in list_serial_ports():\n        if info.device == port:\n            return info\n    raise RuntimeError(\"Port %s not found\" % port)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": null, "function_name": "add_micropython_backend", "parameters": ["name", "proxy_class", "description", "config_page", "bare_metal", "sort_key", "validate_time", "sync_time", "local_rtc", "submit_mode", "write_block_size", "write_block_delay", "webrepl_submit_mode", "webrepl_write_block_size", "webrepl_write_block_delay", "dtr", "rts"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_backend", "get_workbench().set_default"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_micropython_backend(\n    name,\n    proxy_class,\n    description,\n    config_page,\n    bare_metal=True,\n    sort_key=None,\n    validate_time=False,\n    sync_time=None,\n    local_rtc=True,\n    submit_mode=\"raw_paste\",\n    write_block_size=256,\n    write_block_delay=0.01,\n    webrepl_submit_mode=\"paste\",\n    webrepl_write_block_size=255,\n    webrepl_write_block_delay=0.5,\n    dtr=True,\n    rts=True,\n):\n    if bare_metal:\n        get_workbench().set_default(name + \".port\", \"auto\")\n        get_workbench().set_default(name + \".webrepl_url\", DEFAULT_WEBREPL_URL)\n        get_workbench().set_default(name + \".webrepl_password\", \"\")\n        get_workbench().set_default(name + \".submit_mode\", submit_mode)\n        get_workbench().set_default(name + \".write_block_size\", write_block_size)\n        get_workbench().set_default(name + \".write_block_delay\", write_block_delay)\n        get_workbench().set_default(name + \".webrepl_submit_mode\", webrepl_submit_mode)\n        get_workbench().set_default(name + \".webrepl_write_block_size\", webrepl_write_block_size)\n        get_workbench().set_default(name + \".webrepl_write_block_delay\", webrepl_write_block_delay)\n        get_workbench().set_default(name + \".dtr\", dtr)\n        get_workbench().set_default(name + \".rts\", rts)\n        get_workbench().set_default(name + \".interrupt_on_connect\", True)\n        get_workbench().set_default(name + \".restart_interpreter_before_run\", True)\n        get_workbench().set_default(name + \".populate_argv\", False)\n\n        if sync_time is None:\n            sync_time = True\n    else:\n        if sync_time is None:\n            sync_time = False\n\n    get_workbench().set_default(name + \".sync_time\", sync_time)\n    get_workbench().set_default(name + \".local_rtc\", local_rtc)\n    get_workbench().set_default(name + \".validate_time\", validate_time)\n    get_workbench().add_backend(name, proxy_class, description, config_page, sort_key=sort_key)", "loc": 45}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "MicroPythonProxy", "function_name": "get_packages_target_dir_with_comment", "parameters": ["self"], "param_types": {}, "return_type": "Tuple[Optional[str], Optional[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["path.startswith", "self.get_lib_dirs"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_packages_target_dir_with_comment(self) -> Tuple[Optional[str], Optional[str]]:\n    lib_dirs = self.get_lib_dirs()\n    if not lib_dirs:\n        return None, \"could not determine target directory\"\n\n    for path in lib_dirs:\n        if path.startswith(\"/home/\"):\n            return path, None\n\n    for path in [\"/lib\", \"/flash/lib\"]:\n        if path in lib_dirs:\n            return path, None\n\n    return lib_dirs[0], None", "loc": 14}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "MicroPythonProxy", "function_name": "get_package_installation_confirmations", "parameters": ["self", "dist_info"], "param_types": {"dist_info": "DistInfo"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["result.append", "self.looks_like_suitable_package", "super", "super().get_package_installation_confirmations", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_package_installation_confirmations(self, dist_info: DistInfo) -> List[str]:\n    result = super().get_package_installation_confirmations(dist_info)\n\n    if not self.looks_like_suitable_package(dist_info):\n        result.append(\n            tr(\n                \"This doesn't look like MicroPython/CircuitPython package.\\n\"\n                \"Are you sure you want to install it?\"\n            )\n        )\n    return result", "loc": 11}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "MicroPythonProxy", "function_name": "looks_like_suitable_package", "parameters": ["self", "dist_info"], "param_types": {"dist_info": "DistInfo"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dist_info.name.lower", "logger.debug"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def looks_like_suitable_package(self, dist_info: DistInfo) -> bool:\n    if dist_info.source == \"micropython-lib\":\n        return True\n\n    for token in [\"micropython\", \"circuitpython\", \"pycopy\"]:\n        if token in dist_info.name.lower():\n            return True\n\n    logger.debug(\"package classifiers: %s\", dist_info.classifiers)\n    for classifier in [\n        \"Programming Language :: Python :: Implementation :: MicroPython\",\n        \"Programming Language :: Python :: Implementation :: CircuitPython\",\n    ]:\n        if classifier in dist_info.classifiers:\n            return True\n\n    return False", "loc": 17}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "MicroPythonProxy", "function_name": "search_packages", "parameters": ["cls", "query"], "param_types": {"query": "str"}, "return_type": "List[DistInfo]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["any", "canonicalize_name", "cls._get_micropython_lib_dist_infos", "cls.get_pypi_common_tokens", "combined_result.append", "compute_dist_name_similarity", "filter", "get_workbench", "get_workbench().get_data_url", "item.summary.lower", "list", "mp_lib_names.add", "norm_query.split", "perform_pypi_search", "query.strip", "set", "similarity", "sorted"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def search_packages(cls, query: str) -> List[DistInfo]:\n    from thonny.plugins.pip_gui import compute_dist_name_similarity, perform_pypi_search\n\n    norm_query = canonicalize_name(query.strip())\n    query_parts = norm_query.split(\"-\")\n\n    def similarity(item: DistInfo) -> float:\n        return compute_dist_name_similarity(\n            item.name, query_parts, cls.get_pypi_common_tokens()\n        )\n\n    mp_lib_result = cls._get_micropython_lib_dist_infos()\n    pypi_result = perform_pypi_search(\n        query,\n        get_workbench().get_data_url(\"pypi_summaries_microcircuit.json\"),\n        cls.get_pypi_common_tokens(),\n    )\n\n    combined_result = []\n    mp_lib_names = set()\n\n    for item in mp_lib_result:\n        combined_result.append(item)\n        mp_lib_names.add(canonicalize_name(item.name))\n\n    for item in pypi_result:\n        norm_name = canonicalize_name(item.name)\n        if norm_name in mp_lib_names:\n            # will be shadowed by micropython-lib\n            continue\n\n        if item in combined_result:\n            # avoid duplicates\n            continue\n\n        lower_summary = (item.summary and item.summary.lower()) or \"\"\n        mentions_right_tokens = any(\n            (\n                token in norm_name or token in lower_summary\n                for token in [\"micropython\", \"circuitpython\"]\n            )\n        )\n        if norm_name == norm_query or mentions_right_tokens:\n            combined_result.append(item)\n\n    sorted_result = sorted(combined_result, key=similarity, reverse=True)\n    filtered_result = filter(lambda x: similarity(x) > 0.6, sorted_result[:20])\n\n    return list(filtered_result)", "loc": 49}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "MicroPythonProxy", "function_name": "get_package_info_from_index", "parameters": ["cls", "name", "version"], "param_types": {"name": "str", "version": "str"}, "return_type": "DistInfo", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DistInfo", "RuntimeError", "canonicalize_name", "cls._augment_dist_info", "cls._get_micropython_lib_index_data", "package.get", "super", "super().get_package_info_from_index"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_package_info_from_index(cls, name: str, version: str) -> DistInfo:\n    # Try mp.org first\n    index_data = cls._get_micropython_lib_index_data()\n\n    for package in index_data[\"packages\"]:\n        if canonicalize_name(package[\"name\"]) == canonicalize_name(name):\n            if version not in package[\"versions\"][\"py\"]:\n                raise RuntimeError(\n                    f\"Could not find version {version} of {name} in micropython-lib index\"\n                )\n\n            return cls._augment_dist_info(\n                DistInfo(\n                    name=package[\"name\"],\n                    version=version,\n                    source=\"micropython-lib\",\n                    author=package.get(\"author\") or None,\n                    summary=package.get(\"description\") or None,\n                    license=package.get(\"license\") or None,\n                )\n            )\n            # TODO: deps?\n\n    return super().get_package_info_from_index(name, version)", "loc": 24}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "MicroPythonProxy", "function_name": "get_version_list_from_index", "parameters": ["cls", "name"], "param_types": {"name": "str"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["canonicalize_name", "cls._get_micropython_lib_index_data", "package['versions'].get", "super", "super().get_version_list_from_index"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_version_list_from_index(cls, name: str) -> List[str]:\n    # Try mp.org first\n    index_data = cls._get_micropython_lib_index_data()\n\n    for package in index_data[\"packages\"]:\n        if canonicalize_name(package[\"name\"]) == canonicalize_name(name):\n            return package[\"versions\"].get(\"py\", [])\n\n    return super().get_version_list_from_index(name)", "loc": 9}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonProxy", "function_name": "destroy", "parameters": ["self", "for_restart"], "param_types": {"for_restart": "bool"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["super", "super().destroy", "time.sleep"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def destroy(self, for_restart: bool = False):\n    super().destroy(for_restart=for_restart)\n    if self._port != WEBREPL_PORT_VALUE:\n        # let the OS release the port\n        time.sleep(0.1)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonProxy", "function_name": "send_command", "parameters": ["self", "cmd"], "param_types": {"cmd": "CommandToBackend"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cmd.name.lower", "get_runner", "get_runner().is_running", "get_shell", "get_shell().restart", "get_workbench", "get_workbench().get_option", "isinstance", "super", "super().send_command"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def send_command(self, cmd: CommandToBackend) -> Optional[str]:\n    if isinstance(cmd, EOFCommand):\n        # Runner doesn't notice restart\n        get_shell().restart(was_running=get_runner().is_running())\n\n    if cmd.name.lower() == \"run\":\n        cmd.populate_argv = get_workbench().get_option(self.backend_name + \".populate_argv\")\n\n    return super().send_command(cmd)", "loc": 9}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonProxy", "function_name": "disconnect", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._show_error", "self.destroy"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def disconnect(self):\n    self.destroy()\n    self._show_error(\n        \"\\nDisconnected.\\n\\nClick  at the bottom of the window or use Stop/Restart to reconnect.\"\n    )", "loc": 5}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonProxy", "function_name": "get_node_label", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._welcome_text.lower", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_node_label(self):\n    if \"CircuitPython\" in self._welcome_text:\n        return tr(\"CircuitPython device\")\n    elif \"micro:bit\" in self._welcome_text.lower():\n        return \"micro:bit\"\n    else:\n        return tr(\"MicroPython device\")", "loc": 7}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonProxy", "function_name": "get_full_label", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.get_node_label", "self.is_connected", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_full_label(self):\n    if self.is_connected():\n        return self.get_node_label() + \" @ \" + self._port\n    else:\n        return self.get_node_label() + \" (\" + tr(\"Not connected\") + \")\"", "loc": 5}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonProxy", "function_name": "get_current_switcher_configuration", "parameters": ["self"], "param_types": {}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_current_switcher_configuration(self) -> Dict[str, Any]:\n    conf = {\n        \"run.backend_name\": self.backend_name,\n        f\"{self.backend_name}.port\": self._port,\n    }\n    if self._port == WEBREPL_PORT_VALUE:\n        conf[f\"{self.backend_name}.webrepl_url\"] = get_workbench().get_option(\n            f\"{self.backend_name}.webrepl_url\"\n        )\n\n    return conf", "loc": 11}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonProxy", "function_name": "get_switcher_configuration_label", "parameters": ["cls", "conf"], "param_types": {"conf": "Dict[str, Any]"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_port_info", "get_serial_port_label", "logger.exception"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_switcher_configuration_label(cls, conf: Dict[str, Any]) -> str:\n    port = conf[f\"{cls.backend_name}.port\"]\n    if port is None:\n        return f\"{cls.backend_description}    <no port>\"\n    elif port == WEBREPL_PORT_VALUE:\n        url = conf[f\"{cls.backend_name}.webrepl_url\"]\n        return f\"{cls.backend_description}    {url}\"\n    else:\n        try:\n            p = get_port_info(port)\n        except Exception:\n            p = None\n            logger.exception(\"Could not get port info for %r\", port)\n\n        if p:\n            return f\"{cls.backend_description}    {get_serial_port_label(p)}\"\n        else:\n            return f\"{cls.backend_description}    {port}\"", "loc": 18}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonProxy", "function_name": "get_switcher_entries", "parameters": ["cls"], "param_types": {}, "return_type": "List[Tuple[Dict[str, Any], str, str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls._detect_potential_ports", "cls.get_last_configurations", "cls.get_switcher_configuration_label", "filter", "get_machine_id_for_conf", "list", "list_serial_ports", "relevant_confs.append", "sorted"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_switcher_entries(cls) -> List[Tuple[Dict[str, Any], str, str]]:\n    def should_show(conf):\n        port = conf[f\"{cls.backend_name}.port\"]\n        if port == \"auto\":\n            # may come from pre-Thonny 5 conf\n            port = None\n\n        if port == WEBREPL_PORT_VALUE:\n            return True\n        else:\n            for p in list_serial_ports():\n                if p.device == port:\n                    return True\n\n            return False\n\n    relevant_confs = list(filter(should_show, cls.get_last_configurations()))\n\n    for device, desc in cls._detect_potential_ports():\n        conf = {\"run.backend_name\": cls.backend_name, f\"{cls.backend_name}.port\": device}\n        if conf not in relevant_confs:\n            relevant_confs.append(conf)\n\n    sorted_confs = sorted(relevant_confs, key=cls.get_switcher_configuration_label)\n    return [\n        (\n            conf,\n            cls.get_switcher_configuration_label(conf),\n            get_machine_id_for_conf(cls.backend_name, conf),\n        )\n        for conf in sorted_confs\n    ]", "loc": 32}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonProxy", "function_name": "open_custom_system_shell", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["InlineCommand", "get_runner", "get_runner().send_command_and_wait", "get_workbench", "get_workbench().get_local_cwd", "running.get_front_interpreter_for_subprocess", "self.disconnect", "terminal.run_in_terminal"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def open_custom_system_shell(self):\n    from thonny import terminal\n\n    get_runner().send_command_and_wait(InlineCommand(\"prepare_disconnect\"), \"Disconnecting\")\n\n    self.disconnect()\n\n    terminal.run_in_terminal(\n        [\n            running.get_front_interpreter_for_subprocess(sys.executable),\n            \"-m\",\n            # \"serial.tools.miniterm\",\n            \"thonny.plugins.micropython.miniterm_wrapper\",\n            \"--exit-char\",\n            \"20\",\n            \"--menu-char\",\n            \"29\",\n            \"--filter\",\n            \"direct\",\n            \"--quiet\",\n            self._port,\n            \"115200\",\n        ],\n        cwd=get_workbench().get_local_cwd(),\n        keep_open=False,\n        title=self._port,\n    )", "loc": 27}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonConfigPage", "function_name": "get_stored_port_desc", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_stored_port_desc(self):\n    name = get_workbench().get_option(self.backend_name + \".port\")\n    for desc in self._port_names_by_desc:\n        if self._port_names_by_desc[desc] == name:\n            return desc\n\n    return \"\"", "loc": 7}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonConfigPage", "function_name": "get_selected_port_name", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._port_desc_variable.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_selected_port_name(self):\n    port_desc = self._port_desc_variable.get()\n    if not port_desc:\n        return None\n    return self._port_names_by_desc[port_desc]", "loc": 5}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonConfigPage", "function_name": "get_selected_port", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._port_desc_variable.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_selected_port(self):\n    port_desc = self._port_desc_variable.get()\n    if not port_desc or port_desc not in self._ports_by_desc:\n        return None\n    return self._ports_by_desc[port_desc]", "loc": 5}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonConfigPage", "function_name": "apply", "parameters": ["self", "changed_options"], "param_types": {"changed_options": "List[str]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().set_option", "messagebox.showerror", "self._connection_is_modified", "self._webrepl_password_var.get", "self._webrepl_url_var.get", "self._webrepl_url_var.get().lower", "self._webrepl_url_var.get().lower().startswith", "self.get_selected_port_name", "self.webrepl_selected"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def apply(self, changed_options: List[str]) -> bool:\n    if not self._connection_is_modified():\n        return True\n\n    else:\n        port_name = self.get_selected_port_name()\n        get_workbench().set_option(self.backend_name + \".port\", port_name)\n        if self.webrepl_selected():\n            if not self._webrepl_url_var.get().lower().startswith(\"ws://\"):\n                messagebox.showerror(\n                    \"Bad URL\", \"WebREPL URL should start with ws://\", parent=self\n                )\n                return False\n\n            get_workbench().set_option(\n                self.backend_name + \".webrepl_url\", self._webrepl_url_var.get()\n            )\n            get_workbench().set_option(\n                self.backend_name + \".webrepl_password\", self._webrepl_password_var.get()\n            )\n\n    return True", "loc": 22}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "BareMetalMicroPythonConfigPage", "function_name": "destroy", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.after_cancel", "super", "super().destroy"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def destroy(self):\n    if self._port_polling_after_id is not None:\n        self.after_cancel(self._port_polling_after_id)\n        self._port_polling_after_id = None\n\n    super().destroy()", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "LocalMicroPythonProxy", "function_name": "send_command", "parameters": ["self", "cmd"], "param_types": {"cmd": "CommandToBackend"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().is_running", "get_shell", "get_shell().restart", "isinstance", "super", "super().send_command"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def send_command(self, cmd: CommandToBackend) -> Optional[str]:\n    if isinstance(cmd, EOFCommand):\n        # Runner doesn't notice restart\n        get_shell().restart(was_running=get_runner().is_running())\n\n    return super().send_command(cmd)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "SshMicroPythonProxy", "function_name": "send_command", "parameters": ["self", "cmd"], "param_types": {"cmd": "CommandToBackend"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_runner", "get_runner().is_running", "get_shell", "get_shell().restart", "isinstance", "super", "super().send_command"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def send_command(self, cmd: CommandToBackend) -> Optional[str]:\n    if isinstance(cmd, EOFCommand):\n        # Runner doesn't notice restart\n        get_shell().restart(was_running=get_runner().is_running())\n\n    return super().send_command(cmd)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "SshMicroPythonProxy", "function_name": "get_current_switcher_configuration", "parameters": ["self"], "param_types": {}, "return_type": "Dict[str, Any]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_current_switcher_configuration(self) -> Dict[str, Any]:\n    return {\n        \"run.backend_name\": self.backend_name,\n        f\"{self.backend_name}.executable\": get_workbench().get_option(\n            f\"{self.backend_name}.executable\"\n        ),\n        f\"{self.backend_name}.host\": get_workbench().get_option(f\"{self.backend_name}.host\"),\n        f\"{self.backend_name}.user\": get_workbench().get_option(f\"{self.backend_name}.user\"),\n    }", "loc": 9}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "SshMicroPythonProxy", "function_name": "get_switcher_entries", "parameters": ["cls"], "param_types": {}, "return_type": "List[Tuple[Dict[str, Any], str, str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls.get_last_configurations", "cls.get_switcher_configuration_label", "sorted"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_switcher_entries(cls) -> List[Tuple[Dict[str, Any], str, str]]:\n    confs = sorted(cls.get_last_configurations(), key=cls.get_switcher_configuration_label)\n    return [\n        (conf, cls.get_switcher_configuration_label(conf), conf[cls.backend_name + \".host\"])\n        for conf in confs\n    ]", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": "SshMicroPythonProxy", "function_name": "open_custom_system_shell", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_local_cwd", "messagebox.showerror", "shutil.which", "terminal.run_in_terminal"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def open_custom_system_shell(self):\n    if not shutil.which(\"ssh\"):\n        messagebox.showerror(\n            \"Command not found\", \"Command 'ssh' not found\", master=get_workbench()\n        )\n        return\n\n    from thonny import terminal\n\n    userhost = \"%s@%s\" % (self._user, self._host)\n    terminal.run_in_terminal(\n        [\"ssh\", userhost], cwd=get_workbench().get_local_cwd(), keep_open=False, title=userhost\n    )", "loc": 13}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": null, "function_name": "should_show", "parameters": ["conf"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["list_serial_ports"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def should_show(conf):\n    port = conf[f\"{cls.backend_name}.port\"]\n    if port == \"auto\":\n        # may come from pre-Thonny 5 conf\n        port = None\n\n    if port == WEBREPL_PORT_VALUE:\n        return True\n    else:\n        for p in list_serial_ports():\n            if p.device == port:\n                return True\n\n        return False", "loc": 14}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": null, "function_name": "add_submit_mode_widgets", "parameters": ["option_name_qualifier", "raw_paste_comment", "paste_comment", "raw_comment"], "param_types": {"option_name_qualifier": "str", "raw_paste_comment": "str", "paste_comment": "str", "raw_comment": "str"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["add_option_combobox", "delay_combobox.grid", "delay_combobox.grid_remove", "delay_label.grid", "delay_label.grid_remove", "ems_to_pixels", "get_last_grid_row", "mode_combobox.bind", "mode_combobox.get_selected_value", "self.advanced_page.grid_slaves", "size_combobox.grid", "size_combobox.grid_remove", "size_label.grid", "size_label.grid_remove", "update_visible_fields"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def add_submit_mode_widgets(\n    option_name_qualifier: str,\n    raw_paste_comment: str,\n    paste_comment: str,\n    raw_comment: str,\n):\n    mode_combobox = add_option_combobox(\n        self.advanced_page,\n        f\"{self.backend_name}.{option_name_qualifier}submit_mode\",\n        \"Submit mode\",\n        choices={\n            f\"raw-paste   ({raw_paste_comment})\": \"raw_paste\",\n            f\"paste   ({paste_comment})\": \"paste\",\n            f\"raw   ({raw_comment})\": \"raw\",\n        },\n        column=0,\n        width=30,\n    )\n\n    row = get_last_grid_row(self.advanced_page)\n\n    size_combobox = add_option_combobox(\n        self.advanced_page,\n        f\"{self.backend_name}.{option_name_qualifier}write_block_size\",\n        \"block size\",\n        choices={\n            f\"512\": 512,\n            f\"256\": 256,\n            f\"255\": 255,\n            f\"128\": 128,\n            f\"64\": 64,\n            f\"32\": 32,\n            f\"30\": 30,\n        },\n        width=4,\n        label_padx=ems_to_pixels(0.5),\n        row=row,\n        column=2,\n    )\n    size_label = self.advanced_page.grid_slaves(row=row, column=2)[0]\n\n    delay_combobox = add_option_combobox(\n        self.advanced_page,\n        f\"{self.backend_name}.{option_name_qualifier}write_block_delay\",\n        \"block delay\",\n        choices={\n            f\"0.01\": 0.01,\n            f\"0.02\": 0.02,\n            f\"0.05\": 0.05,\n            f\"0.1\": 0.1,\n            f\"0.2\": 0.2,\n            f\"0.5\": 0.5,\n        },\n        width=4,\n        label_padx=ems_to_pixels(0.5),\n        row=row,\n        column=4,\n    )\n    delay_label = self.advanced_page.grid_slaves(row=row, column=4)[0]\n\n    def update_visible_fields(event=None):\n        if mode_combobox.get_selected_value() == \"raw\":\n            delay_combobox.grid()\n            delay_label.grid()\n        else:\n            delay_combobox.grid_remove()\n            delay_label.grid_remove()\n\n        if mode_combobox.get_selected_value() in [\"paste\", \"raw\"]:\n            size_combobox.grid()\n            size_label.grid()\n        else:\n            size_combobox.grid_remove()\n            size_label.grid_remove()\n\n    mode_combobox.bind(\"<<ComboboxSelected>>\", update_visible_fields, True)\n    update_visible_fields()", "loc": 77}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": null, "function_name": "port_order", "parameters": ["p"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "name.replace", "name.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def port_order(p):\n    _, name = p\n    if name is None:\n        return \"\"\n    elif name.startswith(\"COM\") and len(name) == 4:\n        # Make one-digit COM ports go before COM10\n        return name.replace(\"COM\", \"COM0\")\n    else:\n        return name", "loc": 9}
{"file": "thonny\\thonny\\plugins\\micropython\\mp_front.py", "class_name": null, "function_name": "update_visible_fields", "parameters": ["event"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["delay_combobox.grid", "delay_combobox.grid_remove", "delay_label.grid", "delay_label.grid_remove", "mode_combobox.get_selected_value", "size_combobox.grid", "size_combobox.grid_remove", "size_label.grid", "size_label.grid_remove"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def update_visible_fields(event=None):\n    if mode_combobox.get_selected_value() == \"raw\":\n        delay_combobox.grid()\n        delay_label.grid()\n    else:\n        delay_combobox.grid_remove()\n        delay_label.grid_remove()\n\n    if mode_combobox.get_selected_value() in [\"paste\", \"raw\"]:\n        size_combobox.grid()\n        size_label.grid()\n    else:\n        size_combobox.grid_remove()\n        size_label.grid_remove()", "loc": 14}
{"file": "thonny\\thonny\\plugins\\micropython\\serial_connection.py", "class_name": "SerialConnection", "function_name": "write", "parameters": ["self", "data"], "param_types": {"data": "bytes"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self._serial.write"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write(self, data: bytes) -> int:\n    size = self._serial.write(data)\n    # print(data.decode(), end=\"\")\n    assert size == len(data)\n    return len(data)", "loc": 5}
{"file": "thonny\\thonny\\plugins\\micropython\\serial_connection.py", "class_name": "SerialConnection", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.exception", "self._reading_thread.join", "self._serial.cancel_read", "self._serial.close"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self):\n    if self._serial is not None:\n        try:\n            self._serial.cancel_read()\n            if self._reading_thread:\n                self._reading_thread.join()\n        finally:\n            try:\n                self._serial.close()\n                self._serial = None\n            except Exception:\n                logger.exception(\"Couldn't close serial\")", "loc": 12}
{"file": "thonny\\thonny\\plugins\\micropython\\ssh_connection.py", "class_name": "SshProcessConnection", "function_name": "write", "parameters": ["self", "data"], "param_types": {"data": "bytes"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.encode", "isinstance", "len", "self._stdin.flush", "self._stdin.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write(self, data: bytes) -> int:\n    if isinstance(data, str):\n        data = data.encode(self.encoding)\n    self._stdin.write(data)\n    self._stdin.flush()\n    return len(data)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\ssh_connection.py", "class_name": "SshProcessConnection", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._client.exec_command", "self._reading_thread.join"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self):\n    self._client.exec_command(\"kill -s SIGKILL %s\" % self._pid)\n    self._reading_thread.join()\n    self._client = None\n    self._reading_thread = None", "loc": 5}
{"file": "thonny\\thonny\\plugins\\micropython\\subprocess_connection.py", "class_name": "SubprocessConnection", "function_name": "write", "parameters": ["self", "data"], "param_types": {"data": "bytes"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.decode", "isinstance", "len", "self._proc.flush", "self._proc.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write(self, data: bytes) -> int:\n    if isinstance(data, (bytes, bytearray)):\n        data = data.decode(self.encoding)\n    self._proc.write(data)\n    self._proc.flush()\n    return len(data)", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\subprocess_connection.py", "class_name": "SubprocessConnection", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._proc.kill"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self):\n    if self._proc is not None:\n        self._proc.kill(signal.SIGKILL)\n        # self._reading_thread.join() # 0.2 secs!\n        self._proc = None\n        self._reading_thread = None", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\uf2dialog.py", "class_name": null, "function_name": "find_uf2_property", "parameters": ["lines", "prop_name"], "param_types": {"lines": "List[str]", "prop_name": "str"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "line.startswith"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def find_uf2_property(lines: List[str], prop_name: str) -> Optional[str]:\n    marker = prop_name + \": \"\n    for line in lines:\n        if line.startswith(marker):\n            return line[len(marker) :]\n\n    return None", "loc": 7}
{"file": "thonny\\thonny\\plugins\\micropython\\uf2dialog.py", "class_name": null, "function_name": "show_uf2_installer", "parameters": ["master", "firmware_name"], "param_types": {"firmware_name": "str"}, "return_type": "Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Uf2FlashingDialog", "ui_utils.show_dialog"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def show_uf2_installer(master, firmware_name: str) -> Optional[str]:\n    dlg = Uf2FlashingDialog(master, firmware_name=firmware_name)\n    from thonny import ui_utils\n\n    ui_utils.show_dialog(dlg)\n    return dlg.new_port", "loc": 6}
{"file": "thonny\\thonny\\plugins\\micropython\\uf2dialog.py", "class_name": null, "function_name": "create_volume_description", "parameters": ["path"], "param_types": {"path": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_win_volume_name", "logger.error", "path.strip"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_volume_description(path: str) -> str:\n    if sys.platform == \"win32\":\n        try:\n            label = get_win_volume_name(path)\n            disk = path.strip(\"\\\\\")\n            return f\"{label} ({disk})\"\n        except Exception:\n            logger.error(\"Could not query volume name for %r\", path)\n            return path\n    else:\n        return path", "loc": 11}
{"file": "thonny\\thonny\\plugins\\micropython\\uf2dialog.py", "class_name": "Uf2FlashingDialog", "function_name": "compute_target_info_text_and_label", "parameters": ["self", "target"], "param_types": {"target": "TargetInfo"}, "return_type": "Tuple[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["family_code_to_name"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def compute_target_info_text_and_label(self, target: TargetInfo) -> Tuple[str, str]:\n    if target.model:\n        if target.model == \"Raspberry Pi RP2\":\n            # too general to be called model\n            return \"RP2\", \"family\"\n        else:\n            text = target.model\n            if target.family:\n                text += f\"   ({family_code_to_name(target.family)})\"\n            return text, \"model\"\n    elif target.board_id:\n        text = target.board_id\n        if target.family:\n            text += f\"   ({family_code_to_name(target.family)})\"\n        return text, \"board id\"\n    elif target.family:\n        return target.family, \"family\"\n    else:\n        return \"Unknown board\", \"info\"", "loc": 19}
{"file": "thonny\\thonny\\plugins\\micropython\\__init__.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["add_micropython_backend", "get_workbench", "get_workbench().set_default", "platform.system", "tr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    add_micropython_backend(\n        \"GenericMicroPython\",\n        GenericBareMetalMicroPythonProxy,\n        tr(\"MicroPython (generic)\"),\n        GenericBareMetalMicroPythonConfigPage,\n        sort_key=\"49\",\n    )\n\n    get_workbench().set_default(\"serial.last_backend_per_vid_pid\", {})\n\n    if platform.system() in (\"Linux\", \"Darwin\"):\n        add_micropython_backend(\n            \"LocalMicroPython\",\n            LocalMicroPythonProxy,\n            tr(\"MicroPython (local)\"),\n            LocalMicroPythonConfigPage,\n            bare_metal=False,\n            local_rtc=False,\n            sort_key=\"21\",\n        )\n        get_workbench().set_default(\"LocalMicroPython.executable\", \"micropython\")\n\n    add_micropython_backend(\n        \"SshMicroPython\",\n        SshMicroPythonProxy,\n        tr(\"MicroPython (SSH)\"),\n        SshMicroPythonConfigPage,\n        bare_metal=False,\n        local_rtc=False,\n        sort_key=\"22\",\n    )\n    get_workbench().set_default(\"SshMicroPython.executable\", \"micropython\")\n    get_workbench().set_default(\"SshMicroPython.cwd\", None)\n    get_workbench().set_default(\"SshMicroPython.host\", \"\")\n    get_workbench().set_default(\"SshMicroPython.port\", \"22\")\n    get_workbench().set_default(\"SshMicroPython.user\", \"\")\n    get_workbench().set_default(\"SshMicroPython.auth_method\", \"password\")\n    get_workbench().set_default(\"SshMicroPython.make_uploaded_shebang_scripts_executable\", True)\n\n    get_workbench().set_default(\"esptool.show_advanced_options\", False)", "loc": 41}
{"file": "thonny\\thonny\\plugins\\mypy\\__init__.py", "class_name": "MyPyAnalyzer", "function_name": "parse_output_line", "parameters": ["self", "line"], "param_types": {"line": "str"}, "return_type": "Optional[ProgramAnalyzerResponseItem]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ProgramAnalyzerResponseItem", "int", "line.strip", "logger.error", "m.group", "m.group(5).strip", "m.group(6).strip", "max", "print", "re.match"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_output_line(self, line: str) -> Optional[ProgramAnalyzerResponseItem]:\n    print(\"MP PARSONG\", line)\n    m = re.match(r\"(.*?):(\\d+)(:(\\d+))?:(.*?):(.*)\", line.strip())\n    if m is not None:\n        message = m.group(6).strip()\n        if message == \"invalid syntax\":\n            return None\n\n        filename = m.group(1)\n\n        line_num = int(m.group(2))\n        kind = (m.group(5).strip(),)  # always \"error\" ?\n\n        if m.group(3):\n            # https://github.com/thonny/thonny/issues/598\n            column = max(int(m.group(4)) - 1, 0)\n        else:\n            column = None\n\n        # TODO: find the way to link to the explanation at https://mypy.readthedocs.io/en/stable/error_code_list.html\n        return ProgramAnalyzerResponseItem(\n            message, ProgramAnalyzerResponseItemType.WARNING, filename, line_num, column\n        )\n    else:\n        logger.error(\"Can't parse MyPy line: \" + line.strip())\n        return None", "loc": 26}
{"file": "thonny\\thonny\\plugins\\mypy\\__init__.py", "class_name": "MyPyAnalyzer", "function_name": "get_command_line", "parameters": ["self", "main_file_path"], "param_types": {"main_file_path": "str"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_front_interpreter_for_subprocess", "get_runner", "get_runner().get_backend_proxy", "get_runner().get_backend_proxy().get_target_executable", "print"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_command_line(self, main_file_path: str) -> List[str]:\n    print(\"GETTTTING\")\n    return [\n        get_front_interpreter_for_subprocess(),\n        \"-m\",\n        \"mypy\",\n        \"--ignore-missing-imports\",\n        \"--check-untyped-defs\",\n        \"--warn-redundant-casts\",\n        \"--warn-unused-ignores\",\n        \"--show-column-numbers\",\n        \"--no-implicit-optional\",\n        \"--python-executable\",\n        get_runner().get_backend_proxy().get_target_executable(),\n        \"--warn-unreachable\",\n        \"--allow-redefinition\",\n        \"--strict-equality\",\n        \"--no-color-output\",\n        \"--no-error-summary\",\n        \"--show-absolute-path\",\n        main_file_path,\n    ]", "loc": 22}
{"file": "thonny\\thonny\\plugins\\mypy\\__init__.py", "class_name": "MyPyAnalyzer", "function_name": "get_env", "parameters": ["self"], "param_types": {}, "return_type": "Dict[str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "super", "super().get_env"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_env(self) -> Dict[str, str]:\n    env = super().get_env()\n    mypypath = get_workbench().get_option(\"assistance.mypypath\")\n    if mypypath:\n        return env | {\"MYPYPATH\": mypypath}\n\n    return env", "loc": 7}
{"file": "thonny\\thonny\\plugins\\printing\\__init__.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_command", "select_sequence", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    get_workbench().add_command(\n        \"printcurrent\",\n        \"file\",\n        tr(\"Print...\"),\n        print_current_script,\n        can_print_current_script,\n        default_sequence=select_sequence(\"<Control-p>\", \"<Command-p>\"),\n        extra_sequences=[\"<Control-Greek_pi>\"],\n        group=11,\n    )", "loc": 11}
{"file": "thonny\\thonny\\plugins\\pylint\\__init__.py", "class_name": "PylintAnalyzer", "function_name": "get_command_line", "parameters": ["self", "main_file_path"], "param_types": {"main_file_path": "str"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["','.join", "get_front_interpreter_for_subprocess", "get_workbench", "get_workbench().get_option", "relevant_symbols.remove", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_command_line(self, main_file_path: str) -> List[str]:\n    relevant_symbols = {\n        checks_by_id[key][\"msg_sym\"]\n        for key in checks_by_id\n        if checks_by_id[key][\"usage\"] == \"warning\"\n    }\n\n    if \"bad-python3-import\" in relevant_symbols:\n        # https://github.com/PyCQA/pylint/issues/2453\n        # TODO: allow if this is fixed in minimum version\n        relevant_symbols.remove(\"bad-python3-import\")\n\n    # remove user-disabled checks\n    relevant_symbols = relevant_symbols - set(\n        get_workbench().get_option(\"assistance.disabled_checks\")\n    )\n\n    # TODO:\n    ignored_modules = {\"turtle\"}  # has dynamically generated attributes\n\n    options = [\n        # \"--rcfile=None\", # TODO: make it ignore any rcfiles that can be somewhere\n        \"--persistent=n\",\n        # \"--confidence=HIGH\", # Leave empty to show all. Valid levels: HIGH, INFERENCE, INFERENCE_FAILURE, UNDEFINED\n        # \"--disable=missing-docstring,invalid-name,trailing-whitespace,trailing-newlines,missing-final-newline,locally-disabled,suppressed-message\",\n        \"--disable=all\",\n        \"--enable=\" + \",\".join(relevant_symbols),\n        \"--ignored-modules=\" + \",\".join(ignored_modules),\n        \"--max-line-length=120\",\n        \"--output-format=text\",\n        \"--reports=n\",\n        \"--msg-template=\"\n        + RESULT_MARKER\n        + \"{abspath},,{line},,{column},,{symbol},,{msg},,{msg_id},,{C}\",\n    ]\n\n    return [get_front_interpreter_for_subprocess(), \"-m\", \"pylint\"] + options + [main_file_path]", "loc": 37}
{"file": "thonny\\thonny\\plugins\\pylint\\__init__.py", "class_name": "PylintAnalyzer", "function_name": "parse_output_line", "parameters": ["self", "line"], "param_types": {"line": "str"}, "return_type": "Optional[ProgramAnalyzerResponseItem]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ProgramAnalyzerResponseItem", "check.get", "explanation.startswith", "int", "len", "line.startswith", "line[len(RESULT_MARKER):].strip", "line[len(RESULT_MARKER):].strip().split", "logger.error", "logger.exception", "logger.warning"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "err = ( \"\".join(err_lines) .replace(\"No config file found, using default configuration\", \"\")", "source_code": "def parse_output_line(self, line: str) -> Optional[ProgramAnalyzerResponseItem]:\n    # TODO: get rid of non-error\n    \"\"\"\n    err = (\n        \"\".join(err_lines)\n        .replace(\"No config file found, using default configuration\", \"\")\n        .strip()\n    )\n    \"\"\"\n    if line.startswith(RESULT_MARKER):\n        # See https://github.com/thonny/thonny/issues/2359 for the background of this format\n        atts_tuple = line[len(RESULT_MARKER) :].strip().split(\",,\")\n        if len(atts_tuple) != 7:\n            logger.error(\"Can't parse Pylint line %r (%r)\", line, atts_tuple)\n            return None\n        try:\n            filename = atts_tuple[0]\n            lineno = int(atts_tuple[1])\n            col_offset = int(atts_tuple[2])\n            symbol = atts_tuple[3]\n            msg = atts_tuple[4]\n            msg_id = atts_tuple[5]\n            category = atts_tuple[6]\n        except ValueError:\n            logger.exception(\"Can't parse Pylint line %r (%r)\", line, atts_tuple)\n            return None\n\n        if msg_id not in checks_by_id:\n            logger.warning(\"Unknown msg_id %r\", msg_id)\n            return None\n\n        check = checks_by_id[msg_id]\n        if check.get(\"tho_xpln\"):\n            explanation = check[\"tho_xpln\"]\n        else:\n            explanation = check[\"msg_xpln\"]\n\n        if explanation.startswith(\"Used when an \"):\n            explanation = \"It looks like the \" + explanation[(len(\"Used when an \")) :]\n        elif explanation.startswith(\"Emitted when an \"):\n            explanation = \"It looks like the \" + explanation[(len(\"Emitted when an \")) :]\n        elif explanation.startswith(\"Used when a \"):\n            explanation = \"It looks like the \" + explanation[(len(\"Used when a \")) :]\n        elif explanation.startswith(\"Emitted when a \"):\n            explanation = \"It looks like the \" + explanation[(len(\"Emitted when a \")) :]\n        elif explanation.startswith(\"Used when \"):\n            explanation = \"It looks like \" + explanation[(len(\"Used when \")) :]\n        elif explanation.startswith(\"Emitted when \"):\n            explanation = \"It looks like \" + explanation[(len(\"Emitted when \")) :]\n\n        if check.get(\"tho_xpln_rst\"):\n            explanation_rst = check[\"tho_xpln_rst\"]\n\n        if category in (\"I\", \"F\"):\n            msg = \"INTERNAL ERROR when analyzing the code: \" + msg\n\n        # atts[\"more_info_url\"] = \"http://pylint-messages.wikidot.com/messages:%s\" % atts[\"msg_id\"].lower()\n        return ProgramAnalyzerResponseItem(\n            msg, ProgramAnalyzerResponseItemType.WARNING, filename, lineno, col_offset\n        )", "loc": 60}
{"file": "thonny\\thonny\\plugins\\rpi_pico\\__init__.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RaspberryPiPicoBackendProxy.get_known_usb_vids_pids", "add_micropython_backend", "thonny.plugins.circuitpython.cirpy_front.VIDS_PIDS_TO_AVOID.update", "thonny.plugins.esp.VIDS_PIDS_TO_AVOID_IN_ESP_BACKENDS.update", "thonny.plugins.micropython.mp_front.VIDS_PIDS_TO_AVOID_IN_GENERIC_BACKEND.update"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    add_micropython_backend(\n        \"RPiPico\",\n        RaspberryPiPicoBackendProxy,\n        \"MicroPython (Raspberry Pi Pico)\",\n        RaspberryPiPicoBackendConfigPage,\n        bare_metal=True,\n        sort_key=\"32\",\n        validate_time=False,\n        sync_time=True,\n        submit_mode=RAW_PASTE_SUBMIT_MODE,\n        write_block_size=64,\n    )\n\n    # Don't consider Pico in generic backends\n    # The main reason is to reduce the number of items in the backend switcher menu\n    import thonny.plugins.circuitpython\n    import thonny.plugins.esp\n    import thonny.plugins.micropython\n\n    thonny.plugins.circuitpython.cirpy_front.VIDS_PIDS_TO_AVOID.update(\n        RaspberryPiPicoBackendProxy.get_known_usb_vids_pids()\n    )\n    thonny.plugins.micropython.mp_front.VIDS_PIDS_TO_AVOID_IN_GENERIC_BACKEND.update(\n        RaspberryPiPicoBackendProxy.get_known_usb_vids_pids()\n    )\n    thonny.plugins.esp.VIDS_PIDS_TO_AVOID_IN_ESP_BACKENDS.update(\n        RaspberryPiPicoBackendProxy.get_known_usb_vids_pids()\n    )", "loc": 29}
{"file": "thonny\\thonny\\plugins\\system_shell\\explain_environment.py", "class_name": null, "function_name": "wrap_in_ansi_code", "parameters": ["text", "code"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["can_use_ansi_codes"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wrap_in_ansi_code(text, code):\n    if can_use_ansi_codes():\n        return \"\\033[\" + code + \"m\" + text + \"\\033[0m\"\n    else:\n        return text", "loc": 5}
{"file": "thonny\\thonny\\plugins\\system_shell\\explain_environment.py", "class_name": null, "function_name": "can_use_ansi_codes", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["float", "platform.win32_ver", "warnings.warn"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def can_use_ansi_codes():\n    if sys.platform == \"win32\":\n        ver = platform.win32_ver()\n        try:\n            return float(ver[0]) >= 10\n        except Exception:\n            warnings.warn(\"Can't determine Windows version %s\" % (ver,))\n            return False\n    else:\n        return True", "loc": 10}
{"file": "thonny\\thonny\\plugins\\system_shell\\__init__.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_command", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin() -> None:\n    get_workbench().add_command(\n        \"OpenSystemShell\",\n        \"tools\",\n        tr(\"Open system shell...\"),\n        _open_system_shell,\n        group=80,\n        image=\"terminal\",\n    )", "loc": 9}
{"file": "thonny\\thonny\\plugins\\uv\\uv_front.py", "class_name": "LocalCPythonUvProxy", "function_name": "get_mgmt_executable_special_switches", "parameters": ["self"], "param_types": {}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().get_option", "self.get_cwd"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_mgmt_executable_special_switches(self) -> List[str]:\n    cmd = [\"run\", \"--project\", self.get_cwd()]\n\n    python = get_workbench().get_option(f\"{self.backend_name}.python\")\n    if python != \"auto\":\n        cmd += [\"--python\", python]\n    cmd += [\"python\"]\n    return cmd", "loc": 8}
{"file": "thonny\\thonny\\plugins\\uv\\uv_front.py", "class_name": "LocalCPythonUvProxy", "function_name": "get_switcher_entries", "parameters": ["cls"], "param_types": {}, "return_type": "List[Tuple[Dict[str, Any], str, str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls._get_switcher_conf_for_python", "cls.get_last_configurations", "cls.get_switcher_configuration_label", "cls.is_valid_configuration", "confs.append", "confs.insert", "map", "python.startswith", "sorted", "tuple", "version_str_to_tuple_of_ints"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_switcher_entries(cls) -> List[Tuple[Dict[str, Any], str, str]]:\n    def order(conf):\n        python = conf[f\"{cls.backend_name}.python\"]\n        if python == \"auto\":\n            return (0, (0,), python)\n        elif python.startswith(\"3.\"):\n            return (1, tuple(map(lambda x: -x, version_str_to_tuple_of_ints(python))), python)\n        else:\n            return (2, (0,), python)\n\n    confs = cls.get_last_configurations()\n    for ver in thonny.SUPPORTED_VERSIONS:\n        conf = cls._get_switcher_conf_for_python(ver)\n        if conf not in confs:\n            confs.append(conf)\n\n    confs = sorted(confs, key=order)\n    default_conf = cls._get_switcher_conf_for_python(\"auto\")\n    if default_conf not in confs:\n        confs.insert(0, default_conf)\n\n    return [\n        (conf, cls.get_switcher_configuration_label(conf), \"localhost\")\n        for conf in confs\n        if cls.is_valid_configuration(conf)\n    ]", "loc": 26}
{"file": "thonny\\thonny\\plugins\\uv\\uv_front.py", "class_name": "LocalCPythonUvProxy", "function_name": "is_valid_configuration", "parameters": ["cls", "conf"], "param_types": {"conf": "Dict[str, Any]"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cls.is_valid_python", "traceback.print_stack"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def is_valid_configuration(cls, conf: Dict[str, Any]) -> bool:\n    if \"LocalCPythonUv.executable\" in conf:\n        import traceback\n\n        traceback.print_stack()\n    return cls.is_valid_python(conf[f\"{cls.backend_name}.python\"])", "loc": 6}
{"file": "thonny\\thonny\\plugins\\uv\\uv_front.py", "class_name": null, "function_name": "order", "parameters": ["conf"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["map", "python.startswith", "tuple", "version_str_to_tuple_of_ints"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def order(conf):\n    python = conf[f\"{cls.backend_name}.python\"]\n    if python == \"auto\":\n        return (0, (0,), python)\n    elif python.startswith(\"3.\"):\n        return (1, tuple(map(lambda x: -x, version_str_to_tuple_of_ints(python))), python)\n    else:\n        return (2, (0,), python)", "loc": 8}
{"file": "thonny\\thonny\\plugins\\uv\\__init__.py", "class_name": null, "function_name": "load_plugin", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_workbench", "get_workbench().add_backend", "get_workbench().set_default", "tr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def load_plugin():\n    from thonny.plugins.uv.uv_front import LocalCPythonUvConfigurationPage, LocalCPythonUvProxy\n\n    backend_name = \"LocalCPythonUv\"\n    get_workbench().set_default(f\"{backend_name}.python\", \"auto\")\n\n    get_workbench().add_backend(\n        backend_name,\n        LocalCPythonUvProxy,\n        tr(\"Local Python 3\") + \" (uv)\",\n        LocalCPythonUvConfigurationPage,\n        \"03\",\n    )", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\circuitpython-typeshed\\circuitpython_setboard\\__init__.py", "class_name": null, "function_name": "get_definitions_or_exit", "parameters": ["board"], "param_types": {"board": "str"}, "return_type": "Traversable", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["file.is_file", "path.joinpath", "resources.files", "resources.files('board_definitions').joinpath", "sys.exit", "sys.stderr.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Get the definitions file for a board given its name.", "source_code": "def get_definitions_or_exit(board: str) -> Traversable:\n    \"\"\"Get the definitions file for a board given its name.\"\"\"\n\n    path = resources.files(\"board_definitions\").joinpath(board)\n\n    file = path.joinpath(\"__init__.pyi\")\n    if not file.is_file():\n        sys.stderr.write(f\"Definitions for: '{board}' were not found\\n\")\n        sys.exit(1)\n\n    return file", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\circuitpython-typeshed\\circuitpython_setboard\\__init__.py", "class_name": null, "function_name": "set_board", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n  * '.join", "argparse.ArgumentParser", "args.chosen_board.lower", "board.name.lower", "defaultdict", "get_definitions_or_exit", "get_doc_or_exit", "get_doc_or_exit(board).split", "header", "lines[2].split", "lines[2].split('-')[1].split", "lines[2].split('-')[1].split(':')[1].strip", "parser.add_argument", "parser.parse_args", "port.lower", "port_boards.items", "port_boards[port].append", "resources.files", "resources.files('board_definitions').iterdir", "resources.files('stdlib.board').joinpath", "shutil.copyfile", "sorted", "sys.exit", "sys.stderr.write", "sys.stdout.write"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_board():\n    parser = argparse.ArgumentParser(\n        prog=__name__,\n        usage=\"Install CircuitPython board-specific stubs\",\n    )\n    parser.add_argument(\"chosen_board\", help=\"selected board\", nargs=\"?\")\n    parser.add_argument(\n        \"-l\",\n        \"--list\",\n        help=f\"show available boards. can filter eg: '{__name__} -l feather'\",\n        action=\"store_true\",\n    )\n\n    args = parser.parse_args()\n\n    if args.list:\n        port_boards: defaultdict[str, list[str]] = defaultdict(list)\n\n        # NOTE: \"\" in some_str == True\n        looking_for = \"\" if args.chosen_board is None else args.chosen_board.lower()\n\n        for board in resources.files(\"board_definitions\").iterdir():\n            # NOTE: For the hand-crafted finding of port in the docstring, its\n            #       format is assumed to be:\n            #\n            # <empty line>\n            # Board stub for ...\n            #  - port: ...\n            #  - board_id: ...\n            #  - NVM size: ...\n            #  - Included modules: ...\n            #  - Frozen libraries: ...\n            #\n\n            lines = get_doc_or_exit(board).split(\"\\n\")\n            port = lines[2].split(\"-\")[1].split(\":\")[1].strip()\n\n            if looking_for not in board.name.lower() and looking_for not in port.lower():\n                continue\n\n            port_boards[port].append(board.name)\n\n        if not port_boards:\n            sys.stdout.write(\"Nothing found, check out your filter.\\n\")\n            sys.exit(0)\n\n        sys.stdout.write(\"Available boards are: \\n\")\n        # sort by port name\n        for port, boards in sorted(port_boards.items(), key=lambda kv: kv[0]):\n            sys.stdout.write(\n                header(port)\n                + \"  * \"\n                # sort by board name\n                + \"\\n  * \".join(sorted(boards))\n                + \"\\n\\n\"\n            )\n\n        sys.exit(0)\n\n    if args.chosen_board is None:\n        sys.stderr.write(\"Must select a board\\n\")\n        sys.exit(1)\n\n    board_definitions_file = get_definitions_or_exit(args.chosen_board)\n\n    board_stubs_file = resources.files(\"stdlib.board\").joinpath(\"__init__.pyi\")\n    shutil.copyfile(board_definitions_file, board_stubs_file)", "loc": 67}
{"file": "thonny\\thonny\\vendored_libs\\filelock\\_api.py", "class_name": "BaseFileLock", "function_name": "acquire", "parameters": ["self", "timeout", "poll_interval"], "param_types": {"timeout": "float | None", "poll_interval": "float"}, "return_type": "AcquireReturnProxy", "param_doc": {"timeout": "maximum wait time for acquiring the lock, ``None`` means use the default :attr:`~timeout` is and", "poll_interval": "interval of trying to acquire the lock file", "poll_intervall": "deprecated, kept for backwards compatibility, use ``poll_interval`` instead", "blocking": "defaults to True. If False, function will return immediately if it cannot obtain a lock on the"}, "return_doc": "a context object that will unlock the file when the context is exited", "raises_doc": [{"type": "Timeout", "desc": "if fails to acquire lock within the timeout period"}], "called_functions": ["AcquireReturnProxy", "Timeout", "_LOGGER.debug", "id", "max", "self._acquire", "time.monotonic", "time.sleep", "warnings.warn"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Try to acquire the file lock.", "source_code": "def acquire(\n    self,\n    timeout: float | None = None,\n    poll_interval: float = 0.05,\n    *,\n    poll_intervall: float | None = None,\n    blocking: bool = True,\n) -> AcquireReturnProxy:\n    \"\"\"\n    Try to acquire the file lock.\n\n    :param timeout: maximum wait time for acquiring the lock, ``None`` means use the default :attr:`~timeout` is and\n     if ``timeout < 0``, there is no timeout and this method will block until the lock could be acquired\n    :param poll_interval: interval of trying to acquire the lock file\n    :param poll_intervall: deprecated, kept for backwards compatibility, use ``poll_interval`` instead\n    :param blocking: defaults to True. If False, function will return immediately if it cannot obtain a lock on the\n     first attempt. Otherwise this method will block until the timeout expires or the lock is acquired.\n    :raises Timeout: if fails to acquire lock within the timeout period\n    :return: a context object that will unlock the file when the context is exited\n\n    .. code-block:: python\n\n        # You can use this method in the context manager (recommended)\n        with lock.acquire():\n            pass\n\n        # Or use an equivalent try-finally construct:\n        lock.acquire()\n        try:\n            pass\n        finally:\n            lock.release()\n\n    .. versionchanged:: 2.0.0\n\n        This method returns now a *proxy* object instead of *self*,\n        so that it can be used in a with statement without side effects.\n\n    \"\"\"\n    # Use the default timeout, if no timeout is provided.\n    if timeout is None:\n        timeout = self.timeout\n\n    if poll_intervall is not None:\n        msg = \"use poll_interval instead of poll_intervall\"\n        warnings.warn(msg, DeprecationWarning, stacklevel=2)\n        poll_interval = poll_intervall\n\n    # Increment the number right at the beginning. We can still undo it, if something fails.\n    with self._thread_lock:\n        self._lock_counter += 1\n\n    lock_id = id(self)\n    lock_filename = self._lock_file\n    start_time = time.monotonic()\n    try:\n        while True:\n            with self._thread_lock:\n                if not self.is_locked:\n                    _LOGGER.debug(\"Attempting to acquire lock %s on %s\", lock_id, lock_filename)\n                    self._acquire()\n\n            if self.is_locked:\n                _LOGGER.debug(\"Lock %s acquired on %s\", lock_id, lock_filename)\n                break\n            elif blocking is False:\n                _LOGGER.debug(\"Failed to immediately acquire lock %s on %s\", lock_id, lock_filename)\n                raise Timeout(self._lock_file)\n            elif 0 <= timeout < time.monotonic() - start_time:\n                _LOGGER.debug(\"Timeout on acquiring lock %s on %s\", lock_id, lock_filename)\n                raise Timeout(self._lock_file)\n            else:\n                msg = \"Lock %s not acquired on %s, waiting %s seconds ...\"\n                _LOGGER.debug(msg, lock_id, lock_filename, poll_interval)\n                time.sleep(poll_interval)\n    except BaseException:  # Something did go wrong, so decrement the counter.\n        with self._thread_lock:\n            self._lock_counter = max(0, self._lock_counter - 1)\n        raise\n    return AcquireReturnProxy(lock=self)", "loc": 80}
{"file": "thonny\\thonny\\vendored_libs\\filelock\\_api.py", "class_name": "BaseFileLock", "function_name": "release", "parameters": ["self", "force"], "param_types": {"force": "bool"}, "return_type": "None", "param_doc": {"force": "If true, the lock counter is ignored and the lock is released in every case/"}, "return_doc": "", "raises_doc": [], "called_functions": ["_LOGGER.debug", "id", "self._release"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Releases the file lock. Please note, that the lock is only completely released, if the lock counter is 0. Also note, that the lock file itself is not automatically deleted.", "source_code": "def release(self, force: bool = False) -> None:\n    \"\"\"\n    Releases the file lock. Please note, that the lock is only completely released, if the lock counter is 0. Also\n    note, that the lock file itself is not automatically deleted.\n\n    :param force: If true, the lock counter is ignored and the lock is released in every case/\n    \"\"\"\n    with self._thread_lock:\n\n        if self.is_locked:\n            self._lock_counter -= 1\n\n            if self._lock_counter == 0 or force:\n                lock_id, lock_filename = id(self), self._lock_file\n\n                _LOGGER.debug(\"Attempting to release lock %s on %s\", lock_id, lock_filename)\n                self._release()\n                self._lock_counter = 0\n                _LOGGER.debug(\"Lock %s released on %s\", lock_id, lock_filename)", "loc": 19}
{"file": "thonny\\thonny\\vendored_libs\\filelock\\_util.py", "class_name": null, "function_name": "raise_on_exist_ro_file", "parameters": ["filename"], "param_types": {"filename": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PermissionError", "os.stat"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def raise_on_exist_ro_file(filename: str) -> None:\n    try:\n        file_stat = os.stat(filename)  # use stat to do exists + can write to check without race condition\n    except OSError:\n        return None  # swallow does not exist or other errors\n\n    if file_stat.st_mtime != 0:  # if os.stat returns but modification is zero that's an invalid os.stat - ignore it\n        if not (file_stat.st_mode & stat.S_IWUSR):\n            raise PermissionError(f\"Permission denied: {filename!r}\")", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\adapters.py", "class_name": null, "function_name": "create_adapter", "parameters": ["port", "mount", "dir"], "param_types": {"port": "Optional[str]", "mount": "Optional[str]", "dir": "Optional[str]"}, "return_type": "Adapter", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DirAdapter", "MountAdapter", "_infer_adapter", "bare_metal.SerialPortAdapter", "serial_connection.SerialConnection"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_adapter(port: Optional[str], mount: Optional[str], dir: Optional[str], **kw) -> Adapter:\n    if port:\n        from pipkin import bare_metal, serial_connection\n\n        connection = serial_connection.SerialConnection(port)\n        return bare_metal.SerialPortAdapter(connection)\n    elif dir:\n        return DirAdapter(dir)\n    elif mount:\n        return MountAdapter(mount)\n    else:\n        return _infer_adapter()", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\adapters.py", "class_name": "BaseAdapter", "function_name": "get_mpy_cross_args", "parameters": ["self"], "param_types": {}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["args.append", "self.get_sys_implementation"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_mpy_cross_args(self) -> List[str]:\n    impl = self.get_sys_implementation()\n    sys_mpy = impl[2]\n    if sys_mpy is None:\n        return []\n\n    # https://docs.micropython.org/en/latest/reference/mpyfiles.html#versioning-and-compatibility-of-mpy-files\n    args = []\n    arch = [\n        None,\n        \"x86\",\n        \"x64\",\n        \"armv6\",\n        \"armv6m\",\n        \"armv7m\",\n        \"armv7em\",\n        \"armv7emsp\",\n        \"armv7emdp\",\n        \"xtensa\",\n        \"xtensawin\",\n    ][sys_mpy >> 10]\n    if arch:\n        args.append(\"-march=\" + arch)\n    if not sys_mpy & 0x200:\n        args.append(\"-mno-unicode\")\n\n    return args", "loc": 27}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\adapters.py", "class_name": "BaseAdapter", "function_name": "get_default_target", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AssertionError", "self.get_sys_path"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_default_target(self) -> str:\n    sys_path = self.get_sys_path()\n    # M5-Flow 2.0.0 has both /lib and /flash/libs\n    for candidate in [\"/flash/lib\", \"/flash/libs\", \"/lib\"]:\n        if candidate in sys_path:\n            return candidate\n\n    for entry in sys_path:\n        if \"lib\" in entry:\n            return entry\n    raise AssertionError(\"Could not determine default target\")", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\adapters.py", "class_name": "BaseAdapter", "function_name": "list_dists", "parameters": ["self", "paths"], "param_types": {"paths": "List[str]"}, "return_type": "Dict[str, Tuple[str, str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["entry.startswith", "parse_meta_dir_name", "self.get_sys_path", "self.list_meta_dir_names"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def list_dists(self, paths: List[str] = None) -> Dict[str, Tuple[str, str]]:\n    if not paths:\n        # TODO: Consider considering only single directory\n        paths = [entry for entry in self.get_sys_path() if entry.startswith(\"/\")]\n\n    result = {}\n    for path in paths:\n        for dir_name in self.list_meta_dir_names(path):\n            dist_name, _ = parse_meta_dir_name(dir_name)\n            if dist_name not in result:\n                result[dist_name] = dir_name, path\n\n    return result", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\adapters.py", "class_name": "BaseAdapter", "function_name": "remove_dist", "parameters": ["self", "dist_name", "target", "above_target"], "param_types": {"dist_name": "str", "target": "Optional[str]", "above_target": "bool"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["entry.startswith", "logger.warning", "self.check_remove_dist_from_path", "self.get_sys_path"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_dist(\n    self, dist_name: str, target: Optional[str] = None, above_target: bool = False\n) -> None:\n    could_remove = False\n    if target:\n        result = self.check_remove_dist_from_path(dist_name, target)\n        could_remove = could_remove or result\n        if above_target and target in self.get_sys_path():\n            for entry in self.get_sys_path():\n                if entry == \"\":\n                    continue\n                elif entry == target:\n                    break\n                else:\n                    result = self.check_remove_dist_from_path(dist_name, entry)\n                    could_remove = could_remove or result\n\n    else:\n        for entry in self.get_sys_path():\n            if entry.startswith(\"/\"):\n                result = self.check_remove_dist_from_path(dist_name, entry)\n                could_remove = could_remove or result\n                if result:\n                    break\n\n    if not could_remove:\n        logger.warning(\"Could not find %r for removing\", dist_name)", "loc": 27}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\adapters.py", "class_name": "BaseAdapter", "function_name": "check_remove_dist_from_path", "parameters": ["self", "dist_name", "path"], "param_types": {"dist_name": "str", "path": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.list_meta_dir_names", "self.remove_dist_by_meta_dir"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_remove_dist_from_path(self, dist_name: str, path: str) -> bool:\n    meta_dirs = self.list_meta_dir_names(path, dist_name)\n    result = False\n    for meta_dir_name in meta_dirs:\n        self.remove_dist_by_meta_dir(path, meta_dir_name)\n        result = True\n\n    return result", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\adapters.py", "class_name": "BaseAdapter", "function_name": "remove_dist_by_meta_dir", "parameters": ["self", "containing_dir", "meta_dir_name"], "param_types": {"containing_dir": "str", "meta_dir_name": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "line.split", "logger.debug", "package_dirs.add", "record_bytes.decode", "record_bytes.decode(META_ENCODING).splitlines", "self._ensured_directories.remove", "self.join_path", "self.read_file", "self.remove_dir_if_empty", "self.remove_file_if_exists", "self.split_dir_and_basename", "set", "sorted"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_dist_by_meta_dir(self, containing_dir: str, meta_dir_name: str) -> None:\n    record_bytes = self.read_file(self.join_path(containing_dir, meta_dir_name, \"RECORD\"))\n    record_lines = record_bytes.decode(META_ENCODING).splitlines()\n\n    package_dirs = set()\n    for line in record_lines:\n        rel_path, _, _ = line.split(\",\")\n        abs_path = self.join_path(containing_dir, rel_path)\n        logger.debug(\"Removing file %s\", abs_path)\n        self.remove_file_if_exists(abs_path)\n        abs_dir, _ = self.split_dir_and_basename(abs_path)\n        while len(abs_dir) > len(containing_dir):\n            package_dirs.add(abs_dir)\n            abs_dir, _ = self.split_dir_and_basename(abs_dir)\n\n    for abs_dir in sorted(package_dirs, reverse=True):\n        did_remove = self.remove_dir_if_empty(abs_dir)\n        if did_remove and abs_dir in self._ensured_directories:\n            self._ensured_directories.remove(abs_dir)", "loc": 19}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\adapters.py", "class_name": "BaseAdapter", "function_name": "ensure_dir_exists", "parameters": ["self", "path"], "param_types": {"path": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["path.endswith", "self._ensured_directories.add", "self.ensure_dir_exists", "self.mkdir_in_existing_parent_exists_ok", "self.split_dir_and_basename"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def ensure_dir_exists(self, path: str) -> None:\n    if (\n        path in self._ensured_directories\n        or path == \"/\"\n        or path.endswith(\":\")\n        or path.endswith(\":\\\\\")\n    ):\n        return\n    else:\n        parent, _ = self.split_dir_and_basename(path)\n        if parent:\n            self.ensure_dir_exists(parent)\n        self.mkdir_in_existing_parent_exists_ok(path)\n        self._ensured_directories.add(path)", "loc": 14}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\adapters.py", "class_name": "LocalMirrorAdapter", "function_name": "list_meta_dir_names", "parameters": ["self", "path", "dist_name"], "param_types": {"path": "str", "dist_name": "Optional[str]"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["name.endswith", "name.startswith", "os.listdir", "self.convert_to_local_path"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def list_meta_dir_names(self, path: str, dist_name: Optional[str] = None) -> List[str]:\n    local_path = self.convert_to_local_path(path)\n    try:\n        return [\n            name\n            for name in os.listdir(local_path)\n            if name.endswith(\".dist-info\")\n            and (dist_name is None or name.startswith(dist_name + \"-\"))\n        ]\n    except FileNotFoundError:\n        # skipping non-existing dirs\n        return []", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\adapters.py", "class_name": "MountAdapter", "function_name": "fetch_sys_implementation", "parameters": ["self"], "param_types": {}, "return_type": "Tuple[str, str, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["UserError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def fetch_sys_implementation(self) -> Tuple[str, str, int]:\n    if self._circuitpython_version:\n        return (\"circuitpython\", self._circuitpython_version, 0)\n    else:\n        raise UserError(\"Could not determine sys.implementation\")", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\bare_metal.py", "class_name": "BareMetalAdapter", "function_name": "read_file", "parameters": ["self", "path"], "param_types": {"path": "str"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FileNotFoundError", "ManagementError", "any", "b''.join", "binascii.unhexlify", "blocks.append", "dedent", "len", "out + err.strip", "self._evaluate", "self._execute_and_capture_output", "self._execute_without_output", "self._should_hexlify", "str"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_file(self, path: str) -> bytes:\n    hex_mode = self._should_hexlify(path)\n\n    open_script = f\"__pipkin_fp = __pipkin_helper.builtins.open({path!r}, 'rb')\"\n    out, err = self._execute_and_capture_output(open_script)\n\n    if (out + err).strip():\n        if any(str(nr) in out + err for nr in [errno.ENOENT, errno.ENODEV]):\n            raise FileNotFoundError(f\"Can't find {path} on target\")\n        else:\n            raise ManagementError(\n                f\"Could not open file {path} for reading\", script=open_script, out=out, err=err\n            )\n\n    if hex_mode:\n        self._execute_without_output(\"from binascii import hexlify as __temp_hexlify\")\n\n    block_size = 1024\n    num_bytes_read = 0\n    blocks = []\n    while True:\n        if hex_mode:\n            block = binascii.unhexlify(\n                self._evaluate(\"__temp_hexlify(__pipkin_fp.read(%s))\" % block_size)\n            )\n        else:\n            block = self._evaluate(\"__pipkin_fp.read(%s)\" % block_size)\n\n        if block:\n            blocks.append(block)\n            num_bytes_read += len(block)\n\n        if len(block) < block_size:\n            break\n\n    self._execute_without_output(\n        dedent(\n            \"\"\"\n        __pipkin_fp.close()\n        del __pipkin_fp\n        try:\n            del __temp_hexlify\n        except:\n            pass\n        \"\"\"\n        )\n    )\n\n    return b\"\".join(blocks)", "loc": 49}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\bare_metal.py", "class_name": "BareMetalAdapter", "function_name": "remove_file_if_exists", "parameters": ["self", "path"], "param_types": {"path": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dedent", "self._execute_without_output"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_file_if_exists(self, path: str) -> None:\n    self._execute_without_output(\n        dedent(\n            f\"\"\"\n        try:\n            __pipkin_helper.os.stat({path!r}) and None\n        except __pipkin_helper.builtins.OSError:\n            pass\n        else:\n            __pipkin_helper.os.remove({path!r})            \n    \"\"\"\n        )\n    )", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\bare_metal.py", "class_name": "BareMetalAdapter", "function_name": "remove_dir_if_empty", "parameters": ["self", "path"], "param_types": {"path": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dedent", "self._evaluate"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_dir_if_empty(self, path: str) -> bool:\n    return self._evaluate(\n        dedent(\n            f\"\"\"\n        if __pipkin_helper.os.listdir({path!r}):\n            __pipkin_helper.print_mgmt_value(False)\n        else:\n            __pipkin_helper.os.remove({path!r})\n            __pipkin_helper.print_mgmt_value(True)\n    \"\"\"\n        )\n    )", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\bare_metal.py", "class_name": "BareMetalAdapter", "function_name": "mkdir_in_existing_parent_exists_ok", "parameters": ["self", "path"], "param_types": {"path": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dedent", "self._execute_without_output"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def mkdir_in_existing_parent_exists_ok(self, path: str) -> None:\n    self._execute_without_output(\n        dedent(\n            f\"\"\"\n        try:\n            __pipkin_helper.os.stat({path!r}) and None\n        except __pipkin_helper.builtins.OSError:\n            __pipkin_helper.os.mkdir({path!r})\n    \"\"\"\n        )\n    )", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\bare_metal.py", "class_name": "BareMetalAdapter", "function_name": "list_meta_dir_names", "parameters": ["self", "path", "dist_name"], "param_types": {"path": "str", "dist_name": "Optional[str]"}, "return_type": "List[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dedent", "self._evaluate"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "    def list_meta_dir_names(self, path: str, dist_name: Optional[str] = None) -> List[str]:\n        if dist_name:\n            dist_name_condition = f\"and name.startswith({dist_name+'-'!r})\"\n        else:\n            dist_name_condition = \"\"\n\n        return self._evaluate(\n            dedent(\n                f\"\"\"\n            try:\n                __pipkin_helper.print_mgmt_value([\n                    name for name \n                    in __pipkin_helper.os.listdir({path!r}) \n                    if name.endswith('.dist-info') {dist_name_condition}\n                ])\n            except __pipkin_helper.builtins.OSError as e:\n                __pipkin_helper.print_mgmt_value([])\n\"\"\"\n            )\n        )", "loc": 20}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\bare_metal.py", "class_name": "SerialPortAdapter", "function_name": "write_file_in_existing_dir", "parameters": ["self", "path", "content"], "param_types": {"path": "str", "content": "bytes"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.info", "self._write_file_via_mount", "self._write_file_via_serial", "time.time"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write_file_in_existing_dir(self, path: str, content: bytes) -> None:\n    start_time = time.time()\n\n    if self._read_only_filesystem:\n        self._write_file_via_mount(path, content)\n\n    try:\n        self._write_file_via_serial(path, content)\n    except ReadOnlyFilesystemError:\n        self._read_only_filesystem = True\n        self._write_file_via_mount(path, content)\n\n    logger.info(\"Wrote %s in %.1f seconds\", path, time.time() - start_time)", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\bare_metal.py", "class_name": "SerialPortAdapter", "function_name": "remove_file_if_exists", "parameters": ["self", "path"], "param_types": {"path": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._contains_read_only_error", "self._remove_file_via_mount", "super", "super().remove_file_if_exists"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_file_if_exists(self, path: str) -> None:\n    if self._read_only_filesystem:\n        self._remove_file_via_mount(path)\n        return\n\n    try:\n        super().remove_file_if_exists(path)\n    except ManagementError as e:\n        if self._contains_read_only_error(e.out + e.err):\n            self._read_only_filesystem = True\n            self._remove_file_via_mount(path)\n        else:\n            raise", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\bare_metal.py", "class_name": "SerialPortAdapter", "function_name": "mkdir_in_existing_parent_exists_ok", "parameters": ["self", "path"], "param_types": {"path": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._contains_read_only_error", "self._mkdir_via_mount", "super", "super().mkdir_in_existing_parent_exists_ok"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def mkdir_in_existing_parent_exists_ok(self, path: str) -> None:\n    if self._read_only_filesystem:\n        self._mkdir_via_mount(path)\n        return\n\n    try:\n        super().mkdir_in_existing_parent_exists_ok(path)\n    except ManagementError as e:\n        if self._contains_read_only_error(e.out + e.err):\n            self._read_only_filesystem = True\n            self._mkdir_via_mount(path)\n        else:\n            raise", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\bare_metal.py", "class_name": "SerialPortAdapter", "function_name": "remove_dir_if_empty", "parameters": ["self", "path"], "param_types": {"path": "str"}, "return_type": "bool", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._contains_read_only_error", "self._remove_dir_if_empty_via_mount", "super", "super().remove_dir_if_empty"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def remove_dir_if_empty(self, path: str) -> bool:\n    if self._read_only_filesystem:\n        return self._remove_dir_if_empty_via_mount(path)\n\n    try:\n        return super().remove_dir_if_empty(path)\n    except ManagementError as e:\n        if self._contains_read_only_error(e.out + e.err):\n            self._read_only_filesystem = True\n            return self._remove_dir_if_empty_via_mount(path)\n        else:\n            raise", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\bare_metal.py", "class_name": "WebReplAdapter", "function_name": "write_file_in_existing_dir", "parameters": ["self", "path", "content"], "param_types": {"path": "str", "content": "bytes"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "path.encode", "self._connection.set_text_mode", "self._read_websocket_response", "self._write", "struct.pack"], "control_structures": ["Try", "While"], "behavior_type": ["logic"], "doc_summary": "Adapted from https://github.com/micropython/webrepl/blob/master/webrepl_cli.py", "source_code": "def write_file_in_existing_dir(self, path: str, content: bytes) -> None:\n    \"\"\"\n    Adapted from https://github.com/micropython/webrepl/blob/master/webrepl_cli.py\n    \"\"\"\n    dest_fname = path.encode(\"utf-8\")\n    rec = struct.pack(\n        WEBREPL_REQ_S, b\"WA\", WEBREPL_PUT_FILE, 0, 0, len(content), len(dest_fname), dest_fname\n    )\n    self._connection.set_text_mode(False)\n    try:\n        self._write(rec[:10])\n        self._write(rec[10:])\n        assert self._read_websocket_response() == 0\n\n        to_be_written = content\n        block_size = 1024\n        while to_be_written:\n            block = to_be_written[:block_size]\n            self._write(block)\n            to_be_written = to_be_written[block_size:]\n\n        assert self._read_websocket_response() == 0\n    finally:\n        self._connection.set_text_mode(True)", "loc": 24}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\connection.py", "class_name": "MicroPythonConnection", "function_name": "read", "parameters": ["self", "size", "timeout", "timeout_is_soft"], "param_types": {"size": "int", "timeout": "float", "timeout_is_soft": "bool"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ReadingTimeoutError", "TimeHelper", "len", "logger.error", "self._read_buffer.extend", "self._read_queue.get", "self.check_for_error"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read(self, size: int, timeout: float = 10, timeout_is_soft: bool = False) -> bytes:\n    if timeout == 0:\n        if timeout_is_soft:\n            return b\"\"\n        else:\n            raise ReadingTimeoutError(read_bytes=b\"\")\n\n    timer = TimeHelper(timeout)\n\n    while len(self._read_buffer) < size:\n        self.check_for_error()\n\n        try:\n            self._read_buffer.extend(self._read_queue.get(True, timer.time_left))\n        except queue.Empty as e:\n            if timeout_is_soft:\n                return b\"\"\n            else:\n                logger.error(\n                    \"Could not read expected %s bytes in %s seconds. Bytes read: %r\",\n                    size,\n                    timeout,\n                    self._read_buffer,\n                )\n                raise ReadingTimeoutError(read_bytes=self._read_buffer) from e\n\n    try:\n        data = self._read_buffer[:size]\n        return data\n    finally:\n        del self._read_buffer[:size]", "loc": 31}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\connection.py", "class_name": "MicroPythonConnection", "function_name": "read_until", "parameters": ["self", "terminator", "timeout", "timeout_is_soft"], "param_types": {"terminator": "Union[bytes, re.Pattern]", "timeout": "float", "timeout_is_soft": "bool"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ReadingTimeoutError", "TimeHelper", "isinstance", "len", "match.end", "re.compile", "re.escape", "re.search", "self._read_buffer.extend", "self._read_queue.get", "self.check_for_error"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_until(\n    self,\n    terminator: Union[bytes, re.Pattern],\n    timeout: float = 1000000,\n    timeout_is_soft: bool = False,\n) -> bytes:\n    timer = TimeHelper(timeout)\n\n    if isinstance(terminator, bytes):\n        terminator = re.compile(re.escape(terminator))\n\n    assert isinstance(terminator, re.Pattern)\n\n    while True:\n        self.check_for_error()\n\n        match = re.search(terminator, self._read_buffer)\n        if match:\n            break\n\n        try:\n            data = self._read_queue.get(True, timer.time_left)\n            # print(\"RR\", repr(data), file=sys.stderr)\n            assert len(data) > 0\n            self._read_buffer.extend(data)\n        except queue.Empty:\n            if timeout_is_soft:\n                break\n            else:\n                raise ReadingTimeoutError(read_bytes=self._read_buffer)\n\n    if match:\n        size = match.end()\n    else:\n        assert timeout_is_soft\n        size = len(self._read_buffer)\n\n    data = self._read_buffer[:size]\n    del self._read_buffer[:size]\n    return data", "loc": 40}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\connection.py", "class_name": "MicroPythonConnection", "function_name": "read_all", "parameters": ["self", "check_error"], "param_types": {"check_error": "bool"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytearray", "len", "self._fetch_to_buffer", "self.check_for_error"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_all(self, check_error: bool = True) -> bytes:\n    self._fetch_to_buffer()\n\n    if len(self._read_buffer) == 0 and check_error:\n        self.check_for_error()\n\n    try:\n        return self._read_buffer\n    finally:\n        self._read_buffer = bytearray()", "loc": 10}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\connection.py", "class_name": "MicroPythonConnection", "function_name": "read_all_expected", "parameters": ["self", "expected", "timeout"], "param_types": {"expected": "bytes", "timeout": "float"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self.read", "self.read_all"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read_all_expected(self, expected: bytes, timeout: float = None) -> bytes:\n    actual = self.read(len(expected), timeout=timeout)\n    actual += self.read_all()\n    assert expected == actual, \"Expected %r, got %r\" % (expected, actual)\n    return actual", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\connection.py", "class_name": "MicroPythonConnection", "function_name": "check_for_error", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ConnectionError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def check_for_error(self) -> None:\n    if self._error is None:\n        return\n\n    raise ConnectionError(self._error)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\connection.py", "class_name": "MicroPythonConnection", "function_name": "unread", "parameters": ["self", "data"], "param_types": {"data": "bytes"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytearray", "data.encode", "isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def unread(self, data: bytes) -> None:\n    if not data:\n        return\n\n    if isinstance(data, str):\n        data = data.encode(self.encoding)\n    elif isinstance(data, bytes):\n        data = bytearray(data)\n\n    self._read_buffer = data + self._read_buffer", "loc": 10}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\proxy.py", "class_name": null, "function_name": "start_proxy", "parameters": ["no_mp_org", "index_url", "extra_index_urls"], "param_types": {"no_mp_org": "bool", "index_url": "Optional[str]", "extra_index_urls": "List[str]"}, "return_type": "PipkinProxy", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PipkinProxy", "logger.warning", "server_thread.start", "threading.Thread"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def start_proxy(\n    no_mp_org: bool,\n    index_url: Optional[str],\n    extra_index_urls: List[str],\n) -> PipkinProxy:\n    port = PREFERRED_PORT\n    if no_mp_org:\n        # Use different port for different set of source indexes, otherwise\n        # pip may use wrong cached wheel.\n        port += 7\n    try:\n        proxy = PipkinProxy(no_mp_org, index_url, extra_index_urls, port)\n    except OSError as e:\n        if e.errno == errno.EADDRINUSE:\n            logger.warning(\"Port %s was in use. Letting OS choose.\", port)\n            proxy = PipkinProxy(no_mp_org, index_url, extra_index_urls, 0)\n        else:\n            raise e\n\n    server_thread = threading.Thread(target=proxy.serve_forever)\n    server_thread.start()\n\n    return proxy", "loc": 23}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\proxy.py", "class_name": "SimpleUrlsParser", "function_name": "handle_data", "parameters": ["self", "data"], "param_types": {"data": "str"}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def handle_data(self, data: str) -> None:\n    if self._current_tag == \"a\":\n        for att, val in self._current_attrs:\n            if att == \"href\":\n                self.file_urls[data] = val", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\proxy.py", "class_name": "RegularIndexDownloader", "function_name": "get_dist_file_names", "parameters": ["self", "dist_name"], "param_types": {"dist_name": "str"}, "return_type": "Optional[List[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["list", "self._get_dist_urls", "urls.keys"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_dist_file_names(self, dist_name: str) -> Optional[List[str]]:\n    urls = self._get_dist_urls(dist_name)\n    if urls is None:\n        return None\n    return list(urls.keys())", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\proxy.py", "class_name": "RegularIndexDownloader", "function_name": "get_file_content", "parameters": ["self", "dist_name", "file_name"], "param_types": {"dist_name": "str", "file_name": "str"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["create_dummy_dist", "self._download_file", "self._should_return_dummy", "self._tweak_file"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_file_content(self, dist_name: str, file_name: str) -> bytes:\n    if self._should_return_dummy(dist_name):\n        return create_dummy_dist(dist_name, file_name)\n    else:\n        original_bytes = self._download_file(dist_name, file_name)\n        return self._tweak_file(dist_name, file_name, original_bytes)", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\proxy.py", "class_name": "MpOrgV2IndexDownloader", "function_name": "get_dist_file_names", "parameters": ["self", "dist_name"], "param_types": {"dist_name": "str"}, "return_type": "Optional[List[str]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["create_dist_info_version_name", "result.append", "self._get_dist_metadata"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_dist_file_names(self, dist_name: str) -> Optional[List[str]]:\n    # there is no per-package, all-versions metadata resource. Need to use the global index\n    meta = self._get_dist_metadata(dist_name)\n    if meta is None:\n        return None\n\n    # Collect relationship between version and constructed file names so that I won't need to parse file name later.\n    meta[\"original_versions_per_file_name\"] = {}\n\n    result = []\n    for version in meta[\"versions\"][\"py\"]:\n        file_name = create_dist_info_version_name(dist_name, version) + \"-py3-none-any.whl\"\n        meta[\"original_versions_per_file_name\"][file_name] = version\n        result.append(file_name)\n\n    return result", "loc": 16}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\proxy.py", "class_name": "MpOrgV2IndexDownloader", "function_name": "get_file_content", "parameters": ["self", "dist_name", "file_name"], "param_types": {"dist_name": "str", "file_name": "str"}, "return_type": "bytes", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dist_meta.get", "isinstance", "json.load", "original_versions.get", "self._construct_wheel_content", "self._get_dist_metadata", "urlopen"], "control_structures": [], "behavior_type": ["file_io", "serialization"], "doc_summary": "", "source_code": "def get_file_content(self, dist_name: str, file_name: str) -> bytes:\n    dist_meta = self._get_dist_metadata(dist_name)\n    original_name = dist_meta[\"name\"]\n\n    original_versions = dist_meta.get(\"original_versions_per_file_name\", None)\n    assert isinstance(original_versions, dict)\n    original_version = original_versions.get(file_name, None)\n    assert isinstance(original_version, str)\n\n    version_meta_url = f\"{self._index_url}/package/py/{original_name}/{original_version}.json\"\n    with urlopen(version_meta_url) as fp:\n        version_meta = json.load(fp)\n\n    return self._construct_wheel_content(dist_meta, version_meta)", "loc": 14}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\proxy.py", "class_name": "PipkinProxy", "function_name": "get_downloader_for_dist", "parameters": ["self", "dist_name"], "param_types": {"dist_name": "str"}, "return_type": "Optional[BaseIndexDownloader]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["downloader.get_dist_file_names", "len", "logger.debug"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_downloader_for_dist(self, dist_name: str) -> Optional[BaseIndexDownloader]:\n    if dist_name not in self._downloaders_by_dist_name:\n        for downloader in self._downloaders:\n            logger.debug(\"Checking if %s has %r\", downloader, dist_name)\n            file_names = downloader.get_dist_file_names(dist_name)\n            if file_names is not None:\n                logger.debug(\"Got %r file names\", len(file_names))\n                self._downloaders_by_dist_name[dist_name] = downloader\n                break\n            else:\n                logger.debug(\"Got None. Trying next downloader\")\n        else:\n            self._downloaders_by_dist_name[dist_name] = None\n\n    return self._downloaders_by_dist_name[dist_name]", "loc": 15}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\proxy.py", "class_name": "PipkinProxyHandler", "function_name": "do_GET", "parameters": ["self"], "param_types": {}, "return_type": "None", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.debug", "path.count", "path.split", "self._serve_distribution_page", "self._serve_file", "self.path.strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def do_GET(self) -> None:\n    path = self.path.strip(\"/\")\n    logger.debug(\"do_GET for %s\", path)\n    if \"/\" in path:\n        assert path.count(\"/\") == 1\n        self._serve_file(*path.split(\"/\"))\n    else:\n        self._serve_distribution_page(path)", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\serial_connection.py", "class_name": "SerialConnection", "function_name": "write", "parameters": ["self", "data"], "param_types": {"data": "bytes"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["len", "self._serial.write"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write(self, data: bytes) -> int:\n    size = self._serial.write(data)\n    # print(data.decode(), end=\"\")\n    assert size == len(data)\n    return len(data)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\serial_connection.py", "class_name": "SerialConnection", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["logger.exception", "self._reading_thread.join", "self._serial.cancel_read", "self._serial.close"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self):\n    if self._serial is not None:\n        try:\n            self._serial.cancel_read()\n            if self._reading_thread:\n                self._reading_thread.join()\n        finally:\n            try:\n                self._serial.close()\n                self._serial = None\n            except Exception:\n                logger.exception(\"Couldn't close serial\")", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\session.py", "class_name": "Session", "function_name": "list", "parameters": ["self", "outdated", "uptodate", "not_required", "pre", "paths", "user", "format", "no_mp_org", "index_url", "extra_index_urls", "no_index", "find_links", "excludes"], "param_types": {"outdated": "bool", "uptodate": "bool", "not_required": "bool", "pre": "bool", "paths": "Optional[List[str]]", "user": "bool", "format": "str", "no_mp_org": "Optional[bool]", "index_url": "Optional[str]", "extra_index_urls": "Optional[List[str]]", "no_index": "bool", "find_links": "Optional[str]", "excludes": "Optional[List[str]]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["args.append", "self._format_exclusion_args", "self._invoke_pip_with_index_args", "self._populate_venv"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def list(\n    self,\n    outdated: bool = False,\n    uptodate: bool = False,\n    not_required: bool = False,\n    pre: bool = False,\n    paths: Optional[List[str]] = None,\n    user: bool = False,\n    format: str = \"columns\",\n    no_mp_org: Optional[bool] = False,\n    index_url: Optional[str] = None,\n    extra_index_urls: Optional[List[str]] = None,\n    no_index: bool = False,\n    find_links: Optional[str] = None,\n    excludes: Optional[List[str]] = None,\n    **_,\n):\n    args = [\"list\"]\n\n    if outdated:\n        args.append(\"--outdated\")\n    if uptodate:\n        args.append(\"--uptodate\")\n    if not_required:\n        args.append(\"--not-required\")\n    if pre:\n        args.append(\"--pre\")\n    if format:\n        args += [\"--format\", format]\n\n    args += self._format_exclusion_args(excludes)\n\n    self._populate_venv(paths=paths, user=user)\n\n    self._invoke_pip_with_index_args(\n        args,\n        no_mp_org=no_mp_org,\n        index_url=index_url,\n        extra_index_urls=extra_index_urls,\n        no_index=no_index,\n        find_links=find_links,\n    )", "loc": 42}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\session.py", "class_name": "Session", "function_name": "basic_list", "parameters": ["self"], "param_types": {}, "return_type": "Set[DistInfo]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DistInfo", "parse_meta_dir_name", "result.add", "self._adapter.list_dists", "set"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Allows listing without requiring the venv.", "source_code": "def basic_list(self) -> Set[DistInfo]:\n    \"\"\"\n    Allows listing without requiring the venv.\n    \"\"\"\n    dists_by_name = self._adapter.list_dists()\n    result = set()\n    for name in dists_by_name:\n        meta_dir_name, location = dists_by_name[name]\n        name, version = parse_meta_dir_name(meta_dir_name)\n        result.add(\n            DistInfo(\n                key=name,\n                project_name=name,\n                version=version,\n                location=location,\n                meta_dir_name=meta_dir_name,\n            )\n        )\n\n    return result", "loc": 20}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\session.py", "class_name": "Session", "function_name": "freeze", "parameters": ["self", "paths", "user", "excludes"], "param_types": {"paths": "Optional[List[str]]", "user": "bool", "excludes": "Optional[List[str]]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._format_exclusion_args", "self._invoke_pip", "self._populate_venv"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def freeze(\n    self,\n    paths: Optional[List[str]] = None,\n    user: bool = False,\n    excludes: Optional[List[str]] = None,\n    **_,\n):\n    args = [\"freeze\"]\n\n    args += self._format_exclusion_args(excludes)\n\n    self._populate_venv(paths=paths, user=user)\n    self._invoke_pip(args)", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\session.py", "class_name": "Session", "function_name": "download", "parameters": ["self", "specs", "requirement_files", "constraint_files", "pre", "no_deps", "no_mp_org", "index_url", "extra_index_urls", "no_index", "find_links", "dest"], "param_types": {"specs": "Optional[List[str]]", "requirement_files": "Optional[List[str]]", "constraint_files": "Optional[List[str]]", "pre": "bool", "no_deps": "bool", "no_mp_org": "bool", "index_url": "Optional[str]", "extra_index_urls": "Optional[List[str]]", "no_index": "bool", "find_links": "Optional[str]", "dest": "Optional[str]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._format_selection_args", "self._invoke_pip_with_index_args", "self._populate_venv"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def download(\n    self,\n    specs: Optional[List[str]] = None,\n    requirement_files: Optional[List[str]] = None,\n    constraint_files: Optional[List[str]] = None,\n    pre: bool = False,\n    no_deps: bool = False,\n    no_mp_org: bool = False,\n    index_url: Optional[str] = None,\n    extra_index_urls: Optional[List[str]] = None,\n    no_index: bool = False,\n    find_links: Optional[str] = None,\n    dest: Optional[str] = None,\n    **_,\n):\n    args = [\"download\"]\n\n    if dest:\n        args += [\"--dest\", dest]\n\n    args += self._format_selection_args(\n        specs=specs,\n        requirement_files=requirement_files,\n        constraint_files=constraint_files,\n        pre=pre,\n        no_deps=no_deps,\n    )\n\n    self._populate_venv()\n    self._invoke_pip_with_index_args(\n        args,\n        no_mp_org=no_mp_org,\n        index_url=index_url,\n        extra_index_urls=extra_index_urls,\n        no_index=no_index,\n        find_links=find_links,\n    )", "loc": 37}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\session.py", "class_name": "Session", "function_name": "wheel", "parameters": ["self", "specs", "requirement_files", "constraint_files", "pre", "no_deps", "no_mp_org", "index_url", "extra_index_urls", "no_index", "find_links", "wheel_dir"], "param_types": {"specs": "Optional[List[str]]", "requirement_files": "Optional[List[str]]", "constraint_files": "Optional[List[str]]", "pre": "bool", "no_deps": "bool", "no_mp_org": "bool", "index_url": "Optional[str]", "extra_index_urls": "Optional[List[str]]", "no_index": "bool", "find_links": "Optional[str]", "wheel_dir": "Optional[str]"}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._format_selection_args", "self._invoke_pip_with_index_args", "self._populate_venv"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wheel(\n    self,\n    specs: Optional[List[str]] = None,\n    requirement_files: Optional[List[str]] = None,\n    constraint_files: Optional[List[str]] = None,\n    pre: bool = False,\n    no_deps: bool = False,\n    no_mp_org: bool = False,\n    index_url: Optional[str] = None,\n    extra_index_urls: Optional[List[str]] = None,\n    no_index: bool = False,\n    find_links: Optional[str] = None,\n    wheel_dir: Optional[str] = None,\n    **_,\n):\n    args = [\"wheel\"]\n\n    if wheel_dir:\n        args += [\"--wheel-dir\", wheel_dir]\n\n    args += self._format_selection_args(\n        specs=specs,\n        requirement_files=requirement_files,\n        constraint_files=constraint_files,\n        pre=pre,\n        no_deps=no_deps,\n    )\n\n    self._populate_venv()\n    self._invoke_pip_with_index_args(\n        args,\n        no_mp_org=no_mp_org,\n        index_url=index_url,\n        extra_index_urls=extra_index_urls,\n        no_index=no_index,\n        find_links=find_links,\n    )", "loc": 37}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\util.py", "class_name": null, "function_name": "create_dist_info_version_name", "parameters": ["dist_name", "version"], "param_types": {"dist_name": "str", "version": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["safe_name", "safe_name(dist_name).replace", "safe_version"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def create_dist_info_version_name(dist_name: str, version: str) -> str:\n    # https://packaging.python.org/en/latest/specifications/binary-distribution-format/#escaping-and-unicode\n    # https://peps.python.org/pep-0440/\n    name = safe_name(dist_name).replace(\"-\", \"_\")\n    version = safe_version(version)\n    return f\"{name}-{version}\"", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\util.py", "class_name": null, "function_name": "get_windows_folder", "parameters": ["ID"], "param_types": {"ID": "int"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AssertionError", "ctypes.create_unicode_buffer", "ctypes.windll.shell32.SHGetFolderPathW"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_windows_folder(ID: int) -> str:\n    # http://stackoverflow.com/a/3859336/261181\n    # http://www.installmate.com/support/im9/using/symbols/functions/csidls.htm\n    if sys.platform == \"win32\":\n        import ctypes.wintypes\n\n        SHGFP_TYPE_CURRENT = 0\n        buf = ctypes.create_unicode_buffer(ctypes.wintypes.MAX_PATH)\n        ctypes.windll.shell32.SHGetFolderPathW(0, ID, 0, SHGFP_TYPE_CURRENT, buf)\n        assert buf.value\n        return buf.value\n    else:\n        raise AssertionError(\"Meant to be used only on Windows\")", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\util.py", "class_name": null, "function_name": "get_venv_site_packages_path", "parameters": ["venv_path"], "param_types": {"venv_path": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["get_venv_executable", "logger.debug", "result.startswith", "subprocess.check_output", "subprocess.check_output(args, executable=args[0], text=True, stdin=subprocess.DEVNULL).strip"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_venv_site_packages_path(venv_path: str) -> str:\n    logger.debug(\"Querying site packages path for %s\", venv_path)\n    args = [\n        get_venv_executable(venv_path),\n        \"-c\",\n        \"import site; print([p for p in site.getsitepackages() if 'site-packages' in p][0])\",\n    ]\n    result = subprocess.check_output(\n        args,\n        executable=args[0],\n        text=True,\n        stdin=subprocess.DEVNULL,\n    ).strip()\n    assert result.startswith(venv_path) and result != venv_path\n    logger.debug(\"Got site packages path %s\", result)\n    return result", "loc": 16}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\util.py", "class_name": null, "function_name": "parse_dist_file_name", "parameters": ["file_name"], "param_types": {"file_name": "str"}, "return_type": "Tuple[str, str, str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AssertionError", "file_name.count", "file_name.endswith", "file_name.lower", "file_name.split", "len", "parse_wheel_filename", "re.sub", "tweaked_file_name.rsplit"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_dist_file_name(file_name: str) -> Tuple[str, str, str]:\n    file_name = file_name.lower()\n\n    if file_name.endswith(\".whl\"):\n        pwf = parse_wheel_filename(file_name)\n        return pwf.project, pwf.version, \".whl\"\n\n    for suffix in [\".zip\", \".tar.gz\"]:\n        if file_name.endswith(suffix):\n            file_name = file_name[: -len(suffix)]\n            break\n    else:\n        raise AssertionError(\"Unexpected file name \" + file_name)\n\n    # dist name and version is separated by the dash, but both parts can also contain dashes...\n    if file_name.count(\"-\") == 1:\n        dist_name, version = file_name.split(\"-\")\n    else:\n        # assuming dashes in the version part have digit on their left and letter on their right\n        # let's get rid of these\n        tweaked_file_name = re.sub(r\"(\\d)-([a-zA-Z])\", r\"\\1_\\2\", file_name)\n        # now let's treat the rightmost dash as separator\n        dist_name = tweaked_file_name.rsplit(\"-\", maxsplit=1)[0]\n        version = file_name[len(dist_name) + 1 :]\n\n    return dist_name, version, suffix", "loc": 26}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\util.py", "class_name": null, "function_name": "safe_version", "parameters": ["version"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["packaging.version.Version", "re.sub", "str", "version.replace"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Convert an arbitrary string to a standard version string Copied from pkg_resources", "source_code": "def safe_version(version):\n    \"\"\"\n    Convert an arbitrary string to a standard version string\n    Copied from pkg_resources\n    \"\"\"\n    try:\n        # normalize the version\n        return str(packaging.version.Version(version))\n    except packaging.version.InvalidVersion:\n        version = version.replace(\" \", \".\")\n        return re.sub(\"[^A-Za-z0-9.]+\", \"-\", version)", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\pipkin\\__init__.py", "class_name": null, "function_name": "main", "parameters": ["raw_args"], "param_types": {"raw_args": "Optional[List[str]]"}, "return_type": "int", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DummyAdapter", "Session", "command_handler", "console_handler.setLevel", "create_adapter", "error", "getattr", "logger.addHandler", "logger.error", "logger.setLevel", "logging.StreamHandler", "parser.parse_arguments", "session.close", "str", "traceback.format_exc", "vars"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main(raw_args: Optional[List[str]] = None) -> int:\n    from pipkin import parser\n\n    args = parser.parse_arguments(raw_args)\n\n    if args.verbose:\n        logging_level = logging.DEBUG\n    elif args.quiet:\n        logging_level = logging.ERROR\n    else:\n        logging_level = logging.INFO\n\n    logger.setLevel(logging_level)\n    logger.propagate = True\n    console_handler = logging.StreamHandler(sys.stderr)\n    console_handler.setLevel(logging_level)\n    logger.addHandler(console_handler)\n\n    args_dict = vars(args)\n\n    try:\n        adapter: Adapter\n        if args.command == \"cache\":\n            adapter = DummyAdapter()\n        else:\n            adapter = create_adapter(**args_dict)\n        session = Session(adapter)\n        try:\n            command_handler = getattr(session, args.command)\n            command_handler(**args_dict)\n        finally:\n            session.close()\n    except KeyboardInterrupt:\n        return 1\n    except ManagementError as e:\n        logger.error(traceback.format_exc())\n        logger.error(\"SCRIPT: %r\", e.script)\n        logger.error(\"OUT=%r\", e.out)\n        logger.error(\"ERR=%r\", e.err)\n    except UserError as e:\n        return error(str(e))\n    except subprocess.CalledProcessError:\n        # assuming the subprocess (pip) already printed the error\n        return 1\n\n    return 0", "loc": 46}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "TelnetOption", "function_name": "process_incoming", "parameters": ["self", "command"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'option in illegal state {!r}'.format", "ValueError", "self.activation_callback", "self.connection.telnet_send_option"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "A DO/DONT/WILL/WONT was received for this option, update state and answer when needed.", "source_code": "def process_incoming(self, command):\n    \"\"\"\\\n    A DO/DONT/WILL/WONT was received for this option, update state and\n    answer when needed.\n    \"\"\"\n    if command == self.ack_yes:\n        if self.state is REQUESTED:\n            self.state = ACTIVE\n            self.active = True\n            if self.activation_callback is not None:\n                self.activation_callback()\n        elif self.state is ACTIVE:\n            pass\n        elif self.state is INACTIVE:\n            self.state = ACTIVE\n            self.connection.telnet_send_option(self.send_yes, self.option)\n            self.active = True\n            if self.activation_callback is not None:\n                self.activation_callback()\n        elif self.state is REALLY_INACTIVE:\n            self.connection.telnet_send_option(self.send_no, self.option)\n        else:\n            raise ValueError('option in illegal state {!r}'.format(self))\n    elif command == self.ack_no:\n        if self.state is REQUESTED:\n            self.state = INACTIVE\n            self.active = False\n        elif self.state is ACTIVE:\n            self.state = INACTIVE\n            self.connection.telnet_send_option(self.send_no, self.option)\n            self.active = False\n        elif self.state is INACTIVE:\n            pass\n        elif self.state is REALLY_INACTIVE:\n            pass\n        else:\n            raise ValueError('option in illegal state {!r}'.format(self))", "loc": 37}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "TelnetSubnegotiation", "function_name": "set", "parameters": ["self", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'SB Requesting {} -> {!r}'.format", "self.connection.logger.debug", "self.connection.rfc2217_send_subnegotiation"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Request a change of the value. a request is sent to the server. if the client needs to know if the change is performed he has to check the state of this object.", "source_code": "def set(self, value):\n    \"\"\"\\\n    Request a change of the value. a request is sent to the server. if\n    the client needs to know if the change is performed he has to check the\n    state of this object.\n    \"\"\"\n    self.value = value\n    self.state = REQUESTED\n    self.connection.rfc2217_send_subnegotiation(self.option, self.value)\n    if self.connection.logger:\n        self.connection.logger.debug(\"SB Requesting {} -> {!r}\".format(self.name, self.value))", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "TelnetSubnegotiation", "function_name": "is_ready", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'remote rejected value for option {!r}'.format", "ValueError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Check if answer from server has been received. when server rejects the change, raise a ValueError.", "source_code": "def is_ready(self):\n    \"\"\"\\\n    Check if answer from server has been received. when server rejects\n    the change, raise a ValueError.\n    \"\"\"\n    if self.state == REALLY_INACTIVE:\n        raise ValueError(\"remote rejected value for option {!r}\".format(self.name))\n    return self.state == ACTIVE", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "TelnetSubnegotiation", "function_name": "wait", "parameters": ["self", "timeout"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'timeout while waiting for option {!r}'.format", "SerialException", "Timeout", "self.is_ready", "time.sleep", "timeout_timer.expired"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Wait until the subnegotiation has been acknowledged or timeout. It can also throw a value error when the answer from the server does not match the value sent.", "source_code": "def wait(self, timeout=3):\n    \"\"\"\\\n    Wait until the subnegotiation has been acknowledged or timeout. It\n    can also throw a value error when the answer from the server does not\n    match the value sent.\n    \"\"\"\n    timeout_timer = Timeout(timeout)\n    while not timeout_timer.expired():\n        time.sleep(0.05)    # prevent 100% CPU load\n        if self.is_ready():\n            break\n    else:\n        raise SerialException(\"timeout while waiting for option {!r}\".format(self.name))", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "TelnetSubnegotiation", "function_name": "check_answer", "parameters": ["self", "suboption"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'SB Answer {} -> {!r} -> {}'.format", "len", "self.connection.logger.debug"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Check an incoming subnegotiation block. The parameter already has cut off the header like sub option number and com port option value.", "source_code": "def check_answer(self, suboption):\n    \"\"\"\\\n    Check an incoming subnegotiation block. The parameter already has\n    cut off the header like sub option number and com port option value.\n    \"\"\"\n    if self.value == suboption[:len(self.value)]:\n        self.state = ACTIVE\n    else:\n        # error propagation done in is_ready\n        self.state = REALLY_INACTIVE\n    if self.connection.logger:\n        self.connection.logger.debug(\"SB Answer {} -> {!r} -> {}\".format(self.name, suboption, self.state))", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._socket.close", "self._socket.shutdown", "self._thread.join", "time.sleep"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Close port", "source_code": "def close(self):\n    \"\"\"Close port\"\"\"\n    self.is_open = False\n    if self._socket:\n        try:\n            self._socket.shutdown(socket.SHUT_RDWR)\n            self._socket.close()\n        except:\n            # ignore errors.\n            pass\n    if self._thread:\n        self._thread.join(7)  # XXX more than socket timeout\n        self._thread = None\n        # in case of quick reconnects, give the server some time\n        time.sleep(0.3)\n    self._socket = None", "loc": 16}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "from_url", "parameters": ["self", "url"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'expected a string in the form \"rfc2217://<host>:<port>[?option[&option...]]\": not starting with rfc2217:// ({!r})'.format", "'expected a string in the form \"rfc2217://<host>:<port>[?option[&option...]]\": {}'.format", "'unknown option: {!r}'.format", "SerialException", "ValueError", "float", "logging.basicConfig", "logging.getLogger", "self.logger.debug", "self.logger.setLevel", "urlparse.parse_qs", "urlparse.parse_qs(parts.query, True).items", "urlparse.urlsplit"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "extract host and port from an URL string, other settings are extracted an stored in instance", "source_code": "def from_url(self, url):\n    \"\"\"\\\n    extract host and port from an URL string, other settings are extracted\n    an stored in instance\n    \"\"\"\n    parts = urlparse.urlsplit(url)\n    if parts.scheme != \"rfc2217\":\n        raise SerialException(\n            'expected a string in the form '\n            '\"rfc2217://<host>:<port>[?option[&option...]]\": '\n            'not starting with rfc2217:// ({!r})'.format(parts.scheme))\n    try:\n        # process options now, directly altering self\n        for option, values in urlparse.parse_qs(parts.query, True).items():\n            if option == 'logging':\n                logging.basicConfig()   # XXX is that good to call it here?\n                self.logger = logging.getLogger('pySerial.rfc2217')\n                self.logger.setLevel(LOGGER_LEVELS[values[0]])\n                self.logger.debug('enabled logging')\n            elif option == 'ign_set_control':\n                self._ignore_set_control_answer = True\n            elif option == 'poll_modem':\n                self._poll_modem_state = True\n            elif option == 'timeout':\n                self._network_timeout = float(values[0])\n            else:\n                raise ValueError('unknown option: {!r}'.format(option))\n        if not 0 <= parts.port < 65536:\n            raise ValueError(\"port not in range 0...65535\")\n    except ValueError as e:\n        raise SerialException(\n            'expected a string in the form '\n            '\"rfc2217://<host>:<port>[?option[&option...]]\": {}'.format(e))\n    return (parts.hostname, parts.port)", "loc": 34}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "in_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self._read_buffer.qsize"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the number of bytes currently in the input buffer.", "source_code": "def in_waiting(self):\n    \"\"\"Return the number of bytes currently in the input buffer.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    return self._read_buffer.qsize()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "SerialException", "Timeout", "bytearray", "bytes", "len", "self._read_buffer.get", "self._thread.is_alive", "timeout.expired", "timeout.time_left"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Read size bytes from the serial port. If a timeout is set it may return less characters as requested. With no timeout it will block until the requested number of bytes is read.", "source_code": "def read(self, size=1):\n    \"\"\"\\\n    Read size bytes from the serial port. If a timeout is set it may\n    return less characters as requested. With no timeout it will block\n    until the requested number of bytes is read.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    data = bytearray()\n    try:\n        timeout = Timeout(self._timeout)\n        while len(data) < size:\n            if self._thread is None or not self._thread.is_alive():\n                raise SerialException('connection failed (reader thread died)')\n            buf = self._read_buffer.get(True, timeout.time_left())\n            if buf is None:\n                return bytes(data)\n            data += buf\n            if timeout.expired():\n                break\n    except Queue.Empty:  # -> timeout\n        pass\n    return bytes(data)", "loc": 23}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "write", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'connection failed (socket error): {}'.format", "PortNotOpenError", "SerialException", "len", "self._socket.sendall", "to_bytes", "to_bytes(data).replace"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Output the given byte string over the serial port. Can block if the connection is blocked. May raise SerialException if the connection is closed.", "source_code": "def write(self, data):\n    \"\"\"\\\n    Output the given byte string over the serial port. Can block if the\n    connection is blocked. May raise SerialException if the connection is\n    closed.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    with self._write_lock:\n        try:\n            self._socket.sendall(to_bytes(data).replace(IAC, IAC_DOUBLED))\n        except socket.error as e:\n            raise SerialException(\"connection failed (socket error): {}\".format(e))\n    return len(data)", "loc": 14}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "reset_input_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self._read_buffer.get", "self._read_buffer.qsize", "self.rfc2217_send_purge"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Clear input buffer, discarding all that is in the buffer.", "source_code": "def reset_input_buffer(self):\n    \"\"\"Clear input buffer, discarding all that is in the buffer.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    self.rfc2217_send_purge(PURGE_RECEIVE_BUFFER)\n    # empty read buffer\n    while self._read_buffer.qsize():\n        self._read_buffer.get(False)", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "reset_output_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.rfc2217_send_purge"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Clear output buffer, aborting the current output and discarding all that is in the buffer.", "source_code": "def reset_output_buffer(self):\n    \"\"\"\\\n    Clear output buffer, aborting the current output and\n    discarding all that is in the buffer.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    self.rfc2217_send_purge(PURGE_TRANSMIT_BUFFER)", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "cts", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "bool", "self.get_modem_state"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Clear To Send.", "source_code": "def cts(self):\n    \"\"\"Read terminal status line: Clear To Send.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    return bool(self.get_modem_state() & MODEMSTATE_MASK_CTS)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "dsr", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "bool", "self.get_modem_state"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Data Set Ready.", "source_code": "def dsr(self):\n    \"\"\"Read terminal status line: Data Set Ready.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    return bool(self.get_modem_state() & MODEMSTATE_MASK_DSR)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "ri", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "bool", "self.get_modem_state"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Ring Indicator.", "source_code": "def ri(self):\n    \"\"\"Read terminal status line: Ring Indicator.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    return bool(self.get_modem_state() & MODEMSTATE_MASK_RI)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "cd", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "bool", "self.get_modem_state"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Carrier Detect.", "source_code": "def cd(self):\n    \"\"\"Read terminal status line: Carrier Detect.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    return bool(self.get_modem_state() & MODEMSTATE_MASK_CD)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "rfc2217_send_purge", "parameters": ["self", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["item.set", "item.wait"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Send purge request to the remote. (PURGE_RECEIVE_BUFFER / PURGE_TRANSMIT_BUFFER / PURGE_BOTH_BUFFERS)", "source_code": "def rfc2217_send_purge(self, value):\n    \"\"\"\\\n    Send purge request to the remote.\n    (PURGE_RECEIVE_BUFFER / PURGE_TRANSMIT_BUFFER / PURGE_BOTH_BUFFERS)\n    \"\"\"\n    item = self._rfc2217_options['purge']\n    item.set(value)  # transmit desired purge type\n    item.wait(self._network_timeout)  # wait for acknowledge from the server", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "rfc2217_set_control", "parameters": ["self", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["item.set", "item.wait", "time.sleep"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "transmit change of control line to remote", "source_code": "def rfc2217_set_control(self, value):\n    \"\"\"transmit change of control line to remote\"\"\"\n    item = self._rfc2217_options['control']\n    item.set(value)  # transmit desired control type\n    if self._ignore_set_control_answer:\n        # answers are ignored when option is set. compatibility mode for\n        # servers that answer, but not the expected one... (or no answer\n        # at all) i.e. sredird\n        time.sleep(0.1)  # this helps getting the unit tests passed\n    else:\n        item.wait(self._network_timeout)  # wait for acknowledge from the server", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "Serial", "function_name": "get_modem_state", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SerialException", "Timeout", "self._modemstate_timeout.expired", "self.logger.debug", "self.logger.warning", "self.rfc2217_send_subnegotiation", "time.sleep", "timeout.expired"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "get last modem state (cached value. If value is \"old\", request a new one. This cache helps that we don't issue to many requests when e.g. all status lines, one after the other is queried by the user (CTS, DSR", "source_code": "def get_modem_state(self):\n    \"\"\"\\\n    get last modem state (cached value. If value is \"old\", request a new\n    one. This cache helps that we don't issue to many requests when e.g. all\n    status lines, one after the other is queried by the user (CTS, DSR\n    etc.)\n    \"\"\"\n    # active modem state polling enabled? is the value fresh enough?\n    if self._poll_modem_state and self._modemstate_timeout.expired():\n        if self.logger:\n            self.logger.debug('polling modem state')\n        # when it is older, request an update\n        self.rfc2217_send_subnegotiation(NOTIFY_MODEMSTATE)\n        timeout = Timeout(self._network_timeout)\n        while not timeout.expired():\n            time.sleep(0.05)    # prevent 100% CPU load\n            # when expiration time is updated, it means that there is a new\n            # value\n            if not self._modemstate_timeout.expired():\n                break\n        else:\n            if self.logger:\n                self.logger.warning('poll for modem state failed')\n        # even when there is a timeout, do not generate an error just\n        # return the last known value. this way we can support buggy\n        # servers that do not respond to polls, but send automatic\n        # updates.\n    if self._modemstate is not None:\n        if self.logger:\n            self.logger.debug('using cached modem state')\n        return self._modemstate\n    else:\n        # never received a notification from the server\n        raise SerialException(\"remote sends no NOTIFY_MODEMSTATE\")", "loc": 34}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "PortManager", "function_name": "check_modem_lines", "parameters": ["self", "force_notification"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'NOTIFY_MODEMSTATE: {}'.format", "self.logger.info", "self.rfc2217_send_subnegotiation", "to_bytes"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "read control lines from serial port and compare the last value sent to remote. send updates on changes.", "source_code": "def check_modem_lines(self, force_notification=False):\n    \"\"\"\\\n    read control lines from serial port and compare the last value sent to remote.\n    send updates on changes.\n    \"\"\"\n    modemstate = (\n        (self.serial.cts and MODEMSTATE_MASK_CTS) |\n        (self.serial.dsr and MODEMSTATE_MASK_DSR) |\n        (self.serial.ri and MODEMSTATE_MASK_RI) |\n        (self.serial.cd and MODEMSTATE_MASK_CD))\n    # check what has changed\n    deltas = modemstate ^ (self.last_modemstate or 0)  # when last is None -> 0\n    if deltas & MODEMSTATE_MASK_CTS:\n        modemstate |= MODEMSTATE_MASK_CTS_CHANGE\n    if deltas & MODEMSTATE_MASK_DSR:\n        modemstate |= MODEMSTATE_MASK_DSR_CHANGE\n    if deltas & MODEMSTATE_MASK_RI:\n        modemstate |= MODEMSTATE_MASK_RI_CHANGE\n    if deltas & MODEMSTATE_MASK_CD:\n        modemstate |= MODEMSTATE_MASK_CD_CHANGE\n    # if new state is different and the mask allows this change, send\n    # notification. suppress notifications when client is not rfc2217\n    if modemstate != self.last_modemstate or force_notification:\n        if (self._client_is_rfc2217 and (modemstate & self.modemstate_mask)) or force_notification:\n            self.rfc2217_send_subnegotiation(\n                SERVER_NOTIFY_MODEMSTATE,\n                to_bytes([modemstate & self.modemstate_mask]))\n            if self.logger:\n                self.logger.info(\"NOTIFY_MODEMSTATE: {}\".format(modemstate))\n        # save last state, but forget about deltas.\n        # otherwise it would also notify about changing deltas which is\n        # probably not very useful\n        self.last_modemstate = modemstate & 0xf0", "loc": 33}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "PortManager", "function_name": "escape", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["iterbytes"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "This generator function is for the user. All outgoing data has to be properly escaped, so that no IAC character in the data stream messes up the Telnet state machine in the server.", "source_code": "def escape(self, data):\n    \"\"\"\\\n    This generator function is for the user. All outgoing data has to be\n    properly escaped, so that no IAC character in the data stream messes up\n    the Telnet state machine in the server.\n\n    socket.sendall(escape(data))\n    \"\"\"\n    for byte in iterbytes(data):\n        if byte == IAC:\n            yield IAC\n            yield IAC\n        else:\n            yield byte", "loc": 14}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rfc2217.py", "class_name": "PortManager", "function_name": "filter", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytearray", "bytes", "iterbytes", "self._telnet_negotiate_option", "self._telnet_process_command", "self._telnet_process_subnegotiation"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Handle a bunch of incoming bytes. This is a generator. It will yield all characters not of interest for Telnet/RFC 2217. The idea is that the reader thread pushes data from the socket through", "source_code": "def filter(self, data):\n    \"\"\"\\\n    Handle a bunch of incoming bytes. This is a generator. It will yield\n    all characters not of interest for Telnet/RFC 2217.\n\n    The idea is that the reader thread pushes data from the socket through\n    this filter:\n\n    for byte in filter(socket.recv(1024)):\n        # do things like CR/LF conversion/whatever\n        # and write data to the serial port\n        serial.write(byte)\n\n    (socket error handling code left as exercise for the reader)\n    \"\"\"\n    for byte in iterbytes(data):\n        if self.mode == M_NORMAL:\n            # interpret as command or as data\n            if byte == IAC:\n                self.mode = M_IAC_SEEN\n            else:\n                # store data in sub option buffer or pass it to our\n                # consumer depending on state\n                if self.suboption is not None:\n                    self.suboption += byte\n                else:\n                    yield byte\n        elif self.mode == M_IAC_SEEN:\n            if byte == IAC:\n                # interpret as command doubled -> insert character\n                # itself\n                if self.suboption is not None:\n                    self.suboption += byte\n                else:\n                    yield byte\n                self.mode = M_NORMAL\n            elif byte == SB:\n                # sub option start\n                self.suboption = bytearray()\n                self.mode = M_NORMAL\n            elif byte == SE:\n                # sub option end -> process it now\n                self._telnet_process_subnegotiation(bytes(self.suboption))\n                self.suboption = None\n                self.mode = M_NORMAL\n            elif byte in (DO, DONT, WILL, WONT):\n                # negotiation\n                self.telnet_command = byte\n                self.mode = M_NEGOTIATE\n            else:\n                # other telnet commands\n                self._telnet_process_command(byte)\n                self.mode = M_NORMAL\n        elif self.mode == M_NEGOTIATE:  # DO, DONT, WILL, WONT was received, option now following\n            self._telnet_negotiate_option(self.telnet_command, byte)\n            self.mode = M_NORMAL", "loc": 56}
{"file": "thonny\\thonny\\vendored_libs\\serial\\rs485.py", "class_name": "RS485", "function_name": "write", "parameters": ["self", "b"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.setRTS", "super", "super(RS485, self).flush", "super(RS485, self).write", "time.sleep"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Write to port, controlling RTS before and after transmitting.", "source_code": "def write(self, b):\n    \"\"\"Write to port, controlling RTS before and after transmitting.\"\"\"\n    if self._alternate_rs485_settings is not None:\n        # apply level for TX and optional delay\n        self.setRTS(self._alternate_rs485_settings.rts_level_for_tx)\n        if self._alternate_rs485_settings.delay_before_tx is not None:\n            time.sleep(self._alternate_rs485_settings.delay_before_tx)\n        # write and wait for data to be written\n        super(RS485, self).write(b)\n        super(RS485, self).flush()\n        # optional delay and apply level for RX\n        if self._alternate_rs485_settings.delay_before_rx is not None:\n            time.sleep(self._alternate_rs485_settings.delay_before_rx)\n        self.setRTS(self._alternate_rs485_settings.rts_level_for_rx)\n    else:\n        super(RS485, self).write(b)", "loc": 16}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "open", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SerialException", "System.IO.Ports.SerialPort", "self._port_handle.Open", "self._reconfigure_port", "self._update_dtr_state", "self._update_rts_state", "self.reset_input_buffer"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Open port with current settings. This may throw a SerialException if the port cannot be opened.", "source_code": "def open(self):\n    \"\"\"\\\n    Open port with current settings. This may throw a SerialException\n    if the port cannot be opened.\n    \"\"\"\n    if self._port is None:\n        raise SerialException(\"Port must be configured before it can be used.\")\n    if self.is_open:\n        raise SerialException(\"Port is already open.\")\n    try:\n        self._port_handle = System.IO.Ports.SerialPort(self.portstr)\n    except Exception as msg:\n        self._port_handle = None\n        raise SerialException(\"could not open port %s: %s\" % (self.portstr, msg))\n\n    # if RTS and/or DTR are not set before open, they default to True\n    if self._rts_state is None:\n        self._rts_state = True\n    if self._dtr_state is None:\n        self._dtr_state = True\n\n    self._reconfigure_port()\n    self._port_handle.Open()\n    self.is_open = True\n    if not self._dsrdtr:\n        self._update_dtr_state()\n    if not self._rtscts:\n        self._update_rts_state()\n    self.reset_input_buffer()", "loc": 29}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._port_handle.Close"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Close port", "source_code": "def close(self):\n    \"\"\"Close port\"\"\"\n    if self.is_open:\n        if self._port_handle:\n            try:\n                self._port_handle.Close()\n            except System.IO.Ports.InvalidOperationException:\n                # ignore errors. can happen for unplugged USB serial devices\n                pass\n            self._port_handle = None\n        self.is_open = False", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "in_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the number of characters currently in the input buffer.", "source_code": "def in_waiting(self):\n    \"\"\"Return the number of characters currently in the input buffer.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    return self._port_handle.BytesToRead", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "bytearray", "bytes", "data.append", "self._port_handle.ReadByte"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Read size bytes from the serial port. If a timeout is set it may return less characters as requested. With no timeout it will block until the requested number of bytes is read.", "source_code": "def read(self, size=1):\n    \"\"\"\\\n    Read size bytes from the serial port. If a timeout is set it may\n    return less characters as requested. With no timeout it will block\n    until the requested number of bytes is read.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    # must use single byte reads as this is the only way to read\n    # without applying encodings\n    data = bytearray()\n    while size:\n        try:\n            data.append(self._port_handle.ReadByte())\n        except System.TimeoutException:\n            break\n        else:\n            size -= 1\n    return bytes(data)", "loc": 19}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "write", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "SerialTimeoutException", "as_byte_array", "len", "self._port_handle.Write"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Output the given string over the serial port.", "source_code": "def write(self, data):\n    \"\"\"Output the given string over the serial port.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    #~ if not isinstance(data, (bytes, bytearray)):\n        #~ raise TypeError('expected %s or bytearray, got %s' % (bytes, type(data)))\n    try:\n        # must call overloaded method with byte array argument\n        # as this is the only one not applying encodings\n        self._port_handle.Write(as_byte_array(data), 0, len(data))\n    except System.TimeoutException:\n        raise SerialTimeoutException('Write timeout')\n    return len(data)", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "reset_input_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self._port_handle.DiscardInBuffer"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Clear input buffer, discarding all that is in the buffer.", "source_code": "def reset_input_buffer(self):\n    \"\"\"Clear input buffer, discarding all that is in the buffer.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    self._port_handle.DiscardInBuffer()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "reset_output_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self._port_handle.DiscardOutBuffer"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Clear output buffer, aborting the current output and discarding all that is in the buffer.", "source_code": "def reset_output_buffer(self):\n    \"\"\"\\\n    Clear output buffer, aborting the current output and\n    discarding all that is in the buffer.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    self._port_handle.DiscardOutBuffer()", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "cts", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Clear To Send", "source_code": "def cts(self):\n    \"\"\"Read terminal status line: Clear To Send\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    return self._port_handle.CtsHolding", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "dsr", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Data Set Ready", "source_code": "def dsr(self):\n    \"\"\"Read terminal status line: Data Set Ready\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    return self._port_handle.DsrHolding", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "ri", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Ring Indicator", "source_code": "def ri(self):\n    \"\"\"Read terminal status line: Ring Indicator\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    #~ return self._port_handle.XXX\n    return False  # XXX an error would be better", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialcli.py", "class_name": "Serial", "function_name": "cd", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Carrier Detect", "source_code": "def cd(self):\n    \"\"\"Read terminal status line: Carrier Detect\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    return self._port_handle.CDHolding", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": null, "function_name": "my_import", "parameters": ["name"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["__import__", "getattr", "name.split"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def my_import(name):\n    mod = __import__(name)\n    components = name.split('.')\n    for comp in components[1:]:\n        mod = getattr(mod, comp)\n    return mod", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": null, "function_name": "detect_java_comm", "parameters": ["names"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ImportError", "my_import"], "control_structures": ["For", "Try"], "behavior_type": ["logic"], "doc_summary": "try given list of modules and return that imports", "source_code": "def detect_java_comm(names):\n    \"\"\"try given list of modules and return that imports\"\"\"\n    for name in names:\n        try:\n            mod = my_import(name)\n            mod.SerialPort\n            return mod\n        except (ImportError, AttributeError):\n            pass\n    raise ImportError(\"No Java Communications API implementation found\")", "loc": 10}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": null, "function_name": "device", "parameters": ["portnumber"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["comm.CommPortIdentifier.getPortIdentifiers", "el.getPortType", "enum.hasMoreElements", "enum.nextElement", "ports.append", "ports[portnumber].getName"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Turn a port number into a device name", "source_code": "def device(portnumber):\n    \"\"\"Turn a port number into a device name\"\"\"\n    enum = comm.CommPortIdentifier.getPortIdentifiers()\n    ports = []\n    while enum.hasMoreElements():\n        el = enum.nextElement()\n        if el.getPortType() == comm.CommPortIdentifier.PORT_SERIAL:\n            ports.append(el)\n    return ports[portnumber].getName()", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._instream.close", "self._outstream.close", "self.sPort.close"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Close port", "source_code": "def close(self):\n    \"\"\"Close port\"\"\"\n    if self.is_open:\n        if self.sPort:\n            self._instream.close()\n            self._outstream.close()\n            self.sPort.close()\n            self.sPort = None\n        self.is_open = False", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "in_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self._instream.available"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the number of characters currently in the input buffer.", "source_code": "def in_waiting(self):\n    \"\"\"Return the number of characters currently in the input buffer.\"\"\"\n    if not self.sPort:\n        raise PortNotOpenError()\n    return self._instream.available()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "bytearray", "bytes", "len", "read.append", "self._instream.read"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Read size bytes from the serial port. If a timeout is set it may return less characters as requested. With no timeout it will block until the requested number of bytes is read.", "source_code": "def read(self, size=1):\n    \"\"\"\\\n    Read size bytes from the serial port. If a timeout is set it may\n    return less characters as requested. With no timeout it will block\n    until the requested number of bytes is read.\n    \"\"\"\n    if not self.sPort:\n        raise PortNotOpenError()\n    read = bytearray()\n    if size > 0:\n        while len(read) < size:\n            x = self._instream.read()\n            if x == -1:\n                if self.timeout >= 0:\n                    break\n            else:\n                read.append(x)\n    return bytes(read)", "loc": 18}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "write", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "TypeError", "isinstance", "len", "self._outstream.write", "type"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Output the given string over the serial port.", "source_code": "def write(self, data):\n    \"\"\"Output the given string over the serial port.\"\"\"\n    if not self.sPort:\n        raise PortNotOpenError()\n    if not isinstance(data, (bytes, bytearray)):\n        raise TypeError('expected %s or bytearray, got %s' % (bytes, type(data)))\n    self._outstream.write(data)\n    return len(data)", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "reset_input_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self._instream.available", "self._instream.skip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Clear input buffer, discarding all that is in the buffer.", "source_code": "def reset_input_buffer(self):\n    \"\"\"Clear input buffer, discarding all that is in the buffer.\"\"\"\n    if not self.sPort:\n        raise PortNotOpenError()\n    self._instream.skip(self._instream.available())", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "reset_output_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self._outstream.flush"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Clear output buffer, aborting the current output and discarding all that is in the buffer.", "source_code": "def reset_output_buffer(self):\n    \"\"\"\\\n    Clear output buffer, aborting the current output and\n    discarding all that is in the buffer.\n    \"\"\"\n    if not self.sPort:\n        raise PortNotOpenError()\n    self._outstream.flush()", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "send_break", "parameters": ["self", "duration"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.sPort.sendBreak"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Send break condition. Timed, returns to idle state after given duration.", "source_code": "def send_break(self, duration=0.25):\n    \"\"\"Send break condition. Timed, returns to idle state after given duration.\"\"\"\n    if not self.sPort:\n        raise PortNotOpenError()\n    self.sPort.sendBreak(duration*1000.0)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "cts", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.sPort.isCTS"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Clear To Send", "source_code": "def cts(self):\n    \"\"\"Read terminal status line: Clear To Send\"\"\"\n    if not self.sPort:\n        raise PortNotOpenError()\n    self.sPort.isCTS()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "dsr", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.sPort.isDSR"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Data Set Ready", "source_code": "def dsr(self):\n    \"\"\"Read terminal status line: Data Set Ready\"\"\"\n    if not self.sPort:\n        raise PortNotOpenError()\n    self.sPort.isDSR()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "ri", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.sPort.isRI"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Ring Indicator", "source_code": "def ri(self):\n    \"\"\"Read terminal status line: Ring Indicator\"\"\"\n    if not self.sPort:\n        raise PortNotOpenError()\n    self.sPort.isRI()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialjava.py", "class_name": "Serial", "function_name": "cd", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.sPort.isCD"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Carrier Detect", "source_code": "def cd(self):\n    \"\"\"Read terminal status line: Carrier Detect\"\"\"\n    if not self.sPort:\n        raise PortNotOpenError()\n    self.sPort.isCD()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["os.close"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Close port", "source_code": "def close(self):\n    \"\"\"Close port\"\"\"\n    if self.is_open:\n        if self.fd is not None:\n            os.close(self.fd)\n            self.fd = None\n            os.close(self.pipe_abort_read_w)\n            os.close(self.pipe_abort_read_r)\n            os.close(self.pipe_abort_write_w)\n            os.close(self.pipe_abort_write_r)\n            self.pipe_abort_read_r, self.pipe_abort_read_w = None, None\n            self.pipe_abort_write_r, self.pipe_abort_write_w = None, None\n        self.is_open = False", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "in_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fcntl.ioctl", "struct.unpack"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Return the number of bytes currently in the input buffer.", "source_code": "def in_waiting(self):\n    \"\"\"Return the number of bytes currently in the input buffer.\"\"\"\n    #~ s = fcntl.ioctl(self.fd, termios.FIONREAD, TIOCM_zero_str)\n    s = fcntl.ioctl(self.fd, TIOCINQ, TIOCM_zero_str)\n    return struct.unpack('I', s)[0]", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'read failed: {}'.format", "PortNotOpenError", "SerialException", "Timeout", "bytearray", "bytes", "len", "os.read", "read.extend", "select.select", "timeout.expired", "timeout.time_left"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Read size bytes from the serial port. If a timeout is set it may return less characters as requested. With no timeout it will block until the requested number of bytes is read.", "source_code": "def read(self, size=1):\n    \"\"\"\\\n    Read size bytes from the serial port. If a timeout is set it may\n    return less characters as requested. With no timeout it will block\n    until the requested number of bytes is read.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    read = bytearray()\n    timeout = Timeout(self._timeout)\n    while len(read) < size:\n        try:\n            ready, _, _ = select.select([self.fd, self.pipe_abort_read_r], [], [], timeout.time_left())\n            if self.pipe_abort_read_r in ready:\n                os.read(self.pipe_abort_read_r, 1000)\n                break\n            # If select was used with a timeout, and the timeout occurs, it\n            # returns with empty lists -> thus abort read operation.\n            # For timeout == 0 (non-blocking operation) also abort when\n            # there is nothing to read.\n            if not ready:\n                break   # timeout\n            buf = os.read(self.fd, size - len(read))\n        except OSError as e:\n            # this is for Python 3.x where select.error is a subclass of\n            # OSError ignore BlockingIOErrors and EINTR. other errors are shown\n            # https://www.python.org/dev/peps/pep-0475.\n            if e.errno not in (errno.EAGAIN, errno.EALREADY, errno.EWOULDBLOCK, errno.EINPROGRESS, errno.EINTR):\n                raise SerialException('read failed: {}'.format(e))\n        except select.error as e:\n            # this is for Python 2.x\n            # ignore BlockingIOErrors and EINTR. all errors are shown\n            # see also http://www.python.org/dev/peps/pep-3151/#select\n            if e[0] not in (errno.EAGAIN, errno.EALREADY, errno.EWOULDBLOCK, errno.EINPROGRESS, errno.EINTR):\n                raise SerialException('read failed: {}'.format(e))\n        else:\n            # read should always return some data as select reported it was\n            # ready to read when we get to this point.\n            if not buf:\n                # Disconnected devices, at least on Linux, show the\n                # behavior that they are always ready to read immediately\n                # but reading returns nothing.\n                raise SerialException(\n                    'device reports readiness to read but returned no data '\n                    '(device disconnected or multiple access on port?)')\n            read.extend(buf)\n\n        if timeout.expired():\n            break\n    return bytes(read)", "loc": 50}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "write", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'write failed: {}'.format", "PortNotOpenError", "SerialException", "SerialTimeoutException", "Timeout", "len", "os.read", "os.write", "select.select", "timeout.expired", "timeout.time_left", "to_bytes"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Output the given byte string over the serial port.", "source_code": "def write(self, data):\n    \"\"\"Output the given byte string over the serial port.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    d = to_bytes(data)\n    tx_len = length = len(d)\n    timeout = Timeout(self._write_timeout)\n    while tx_len > 0:\n        try:\n            n = os.write(self.fd, d)\n            if timeout.is_non_blocking:\n                # Zero timeout indicates non-blocking - simply return the\n                # number of bytes of data actually written\n                return n\n            elif not timeout.is_infinite:\n                # when timeout is set, use select to wait for being ready\n                # with the time left as timeout\n                if timeout.expired():\n                    raise SerialTimeoutException('Write timeout')\n                abort, ready, _ = select.select([self.pipe_abort_write_r], [self.fd], [], timeout.time_left())\n                if abort:\n                    os.read(self.pipe_abort_write_r, 1000)\n                    break\n                if not ready:\n                    raise SerialTimeoutException('Write timeout')\n            else:\n                assert timeout.time_left() is None\n                # wait for write operation\n                abort, ready, _ = select.select([self.pipe_abort_write_r], [self.fd], [], None)\n                if abort:\n                    os.read(self.pipe_abort_write_r, 1)\n                    break\n                if not ready:\n                    raise SerialException('write failed (select)')\n            d = d[n:]\n            tx_len -= n\n        except SerialException:\n            raise\n        except OSError as e:\n            # this is for Python 3.x where select.error is a subclass of\n            # OSError ignore BlockingIOErrors and EINTR. other errors are shown\n            # https://www.python.org/dev/peps/pep-0475.\n            if e.errno not in (errno.EAGAIN, errno.EALREADY, errno.EWOULDBLOCK, errno.EINPROGRESS, errno.EINTR):\n                raise SerialException('write failed: {}'.format(e))\n        except select.error as e:\n            # this is for Python 2.x\n            # ignore BlockingIOErrors and EINTR. all errors are shown\n            # see also http://www.python.org/dev/peps/pep-3151/#select\n            if e[0] not in (errno.EAGAIN, errno.EALREADY, errno.EWOULDBLOCK, errno.EINPROGRESS, errno.EINTR):\n                raise SerialException('write failed: {}'.format(e))\n        if not timeout.is_non_blocking and timeout.expired():\n            raise SerialTimeoutException('Write timeout')\n    return length - len(d)", "loc": 53}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "flush", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "termios.tcdrain"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Flush of file like objects. In this case, wait until all data is written.", "source_code": "def flush(self):\n    \"\"\"\\\n    Flush of file like objects. In this case, wait until all data\n    is written.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    termios.tcdrain(self.fd)", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "reset_input_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self._reset_input_buffer"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Clear input buffer, discarding all that is in the buffer.", "source_code": "def reset_input_buffer(self):\n    \"\"\"Clear input buffer, discarding all that is in the buffer.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    self._reset_input_buffer()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "reset_output_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "termios.tcflush"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Clear output buffer, aborting the current output and discarding all that is in the buffer.", "source_code": "def reset_output_buffer(self):\n    \"\"\"\\\n    Clear output buffer, aborting the current output and discarding all\n    that is in the buffer.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    termios.tcflush(self.fd, termios.TCOFLUSH)", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "send_break", "parameters": ["self", "duration"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "int", "termios.tcsendbreak"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Send break condition. Timed, returns to idle state after given duration.", "source_code": "def send_break(self, duration=0.25):\n    \"\"\"\\\n    Send break condition. Timed, returns to idle state after given\n    duration.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    termios.tcsendbreak(self.fd, int(duration / 0.25))", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "cts", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "fcntl.ioctl", "struct.unpack"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Clear To Send", "source_code": "def cts(self):\n    \"\"\"Read terminal status line: Clear To Send\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    s = fcntl.ioctl(self.fd, TIOCMGET, TIOCM_zero_str)\n    return struct.unpack('I', s)[0] & TIOCM_CTS != 0", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "dsr", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "fcntl.ioctl", "struct.unpack"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Data Set Ready", "source_code": "def dsr(self):\n    \"\"\"Read terminal status line: Data Set Ready\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    s = fcntl.ioctl(self.fd, TIOCMGET, TIOCM_zero_str)\n    return struct.unpack('I', s)[0] & TIOCM_DSR != 0", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "ri", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "fcntl.ioctl", "struct.unpack"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Ring Indicator", "source_code": "def ri(self):\n    \"\"\"Read terminal status line: Ring Indicator\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    s = fcntl.ioctl(self.fd, TIOCMGET, TIOCM_zero_str)\n    return struct.unpack('I', s)[0] & TIOCM_RI != 0", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "cd", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "fcntl.ioctl", "struct.unpack"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Carrier Detect", "source_code": "def cd(self):\n    \"\"\"Read terminal status line: Carrier Detect\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    s = fcntl.ioctl(self.fd, TIOCMGET, TIOCM_zero_str)\n    return struct.unpack('I', s)[0] & TIOCM_CD != 0", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "out_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["fcntl.ioctl", "struct.unpack"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Return the number of bytes currently in the output buffer.", "source_code": "def out_waiting(self):\n    \"\"\"Return the number of bytes currently in the output buffer.\"\"\"\n    #~ s = fcntl.ioctl(self.fd, termios.FIONREAD, TIOCM_zero_str)\n    s = fcntl.ioctl(self.fd, TIOCOUTQ, TIOCM_zero_str)\n    return struct.unpack('I', s)[0]", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "fileno", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "For easier use of the serial port instance with select. WARNING: this function is not portable to different platforms!", "source_code": "def fileno(self):\n    \"\"\"\\\n    For easier use of the serial port instance with select.\n    WARNING: this function is not portable to different platforms!\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    return self.fd", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "set_input_flow_control", "parameters": ["self", "enable"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "termios.tcflow"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Manually control flow - when software flow control is enabled. This will send XON (true) or XOFF (false) to the other device. WARNING: this function is not portable to different platforms!", "source_code": "def set_input_flow_control(self, enable=True):\n    \"\"\"\\\n    Manually control flow - when software flow control is enabled.\n    This will send XON (true) or XOFF (false) to the other device.\n    WARNING: this function is not portable to different platforms!\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if enable:\n        termios.tcflow(self.fd, termios.TCION)\n    else:\n        termios.tcflow(self.fd, termios.TCIOFF)", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "Serial", "function_name": "set_output_flow_control", "parameters": ["self", "enable"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "termios.tcflow"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Manually control flow of outgoing data - when hardware or software flow control is enabled. WARNING: this function is not portable to different platforms!", "source_code": "def set_output_flow_control(self, enable=True):\n    \"\"\"\\\n    Manually control flow of outgoing data - when hardware or software flow\n    control is enabled.\n    WARNING: this function is not portable to different platforms!\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if enable:\n        termios.tcflow(self.fd, termios.TCOON)\n    else:\n        termios.tcflow(self.fd, termios.TCOOFF)", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "PosixPollSerial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "SerialException", "Timeout", "bytearray", "bytes", "len", "os.read", "poll.poll", "poll.register", "read.extend", "select.poll", "timeout.expired", "timeout.time_left"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "Read size bytes from the serial port. If a timeout is set it may return less characters as requested. With no timeout it will block until the requested number of bytes is read.", "source_code": "def read(self, size=1):\n    \"\"\"\\\n    Read size bytes from the serial port. If a timeout is set it may\n    return less characters as requested. With no timeout it will block\n    until the requested number of bytes is read.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    read = bytearray()\n    timeout = Timeout(self._timeout)\n    poll = select.poll()\n    poll.register(self.fd, select.POLLIN | select.POLLERR | select.POLLHUP | select.POLLNVAL)\n    poll.register(self.pipe_abort_read_r, select.POLLIN | select.POLLERR | select.POLLHUP | select.POLLNVAL)\n    if size > 0:\n        while len(read) < size:\n            # print \"\\tread(): size\",size, \"have\", len(read)    #debug\n            # wait until device becomes ready to read (or something fails)\n            for fd, event in poll.poll(None if timeout.is_infinite else (timeout.time_left() * 1000)):\n                if fd == self.pipe_abort_read_r:\n                    break\n                if event & (select.POLLERR | select.POLLHUP | select.POLLNVAL):\n                    raise SerialException('device reports error (poll)')\n                #  we don't care if it is select.POLLIN or timeout, that's\n                #  handled below\n            if fd == self.pipe_abort_read_r:\n                os.read(self.pipe_abort_read_r, 1000)\n                break\n            buf = os.read(self.fd, size - len(read))\n            read.extend(buf)\n            if timeout.expired() \\\n                    or (self._inter_byte_timeout is not None and self._inter_byte_timeout > 0) and not buf:\n                break   # early abort on timeout\n    return bytes(read)", "loc": 33}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "VTIMESerial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "bytearray", "bytes", "len", "os.read", "read.extend"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Read size bytes from the serial port. If a timeout is set it may return less characters as requested. With no timeout it will block until the requested number of bytes is read.", "source_code": "def read(self, size=1):\n    \"\"\"\\\n    Read size bytes from the serial port. If a timeout is set it may\n    return less characters as requested. With no timeout it will block\n    until the requested number of bytes is read.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    read = bytearray()\n    while len(read) < size:\n        buf = os.read(self.fd, size - len(read))\n        if not buf:\n            break\n        read.extend(buf)\n    return bytes(read)", "loc": 15}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialposix.py", "class_name": "PlatformSpecific", "function_name": "set_low_latency_mode", "parameters": ["self", "low_latency_settings"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Failed to update ASYNC_LOW_LATENCY flag to {}: {}'.format", "ValueError", "array.array", "fcntl.ioctl"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def set_low_latency_mode(self, low_latency_settings):\n    buf = array.array('i', [0] * 32)\n\n    try:\n        # get serial_struct\n        fcntl.ioctl(self.fd, termios.TIOCGSERIAL, buf)\n\n        # set or unset ASYNC_LOW_LATENCY flag\n        if low_latency_settings:\n            buf[4] |= 0x2000\n        else:\n            buf[4] &= ~0x2000\n\n        # set serial_struct\n        fcntl.ioctl(self.fd, termios.TIOCSSERIAL, buf)\n    except IOError as e:\n        raise ValueError('Failed to update ASYNC_LOW_LATENCY flag to {}: {}'.format(low_latency_settings, e))", "loc": 17}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": null, "function_name": "iterbytes", "parameters": ["b"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["b.tobytes", "isinstance"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Iterate over bytes, returning bytes instead of ints (python3)", "source_code": "def iterbytes(b):\n    \"\"\"Iterate over bytes, returning bytes instead of ints (python3)\"\"\"\n    if isinstance(b, memoryview):\n        b = b.tobytes()\n    i = 0\n    while True:\n        a = b[i:i + 1]\n        i += 1\n        if a:\n            yield a\n        else:\n            break", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": null, "function_name": "to_bytes", "parameters": ["seq"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'unicode strings are not supported, please encode to bytes: {!r}'.format", "TypeError", "bytearray", "bytes", "isinstance", "seq.tobytes"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "convert a sequence to a bytes type", "source_code": "def to_bytes(seq):\n    \"\"\"convert a sequence to a bytes type\"\"\"\n    if isinstance(seq, bytes):\n        return seq\n    elif isinstance(seq, bytearray):\n        return bytes(seq)\n    elif isinstance(seq, memoryview):\n        return seq.tobytes()\n    elif isinstance(seq, unicode):\n        raise TypeError('unicode strings are not supported, please encode to bytes: {!r}'.format(seq))\n    else:\n        # handle list of integers and bytes (one or more items) for Python 2 and 3\n        return bytes(bytearray(seq))", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "Timeout", "function_name": "time_left", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["max", "self.TIME"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return how many seconds are left until the timeout expires", "source_code": "def time_left(self):\n    \"\"\"Return how many seconds are left until the timeout expires\"\"\"\n    if self.is_non_blocking:\n        return 0\n    elif self.is_infinite:\n        return None\n    else:\n        delta = self.target_time - self.TIME()\n        if delta > self.duration:\n            # clock jumped, recalculate\n            self.target_time = self.TIME() + self.duration\n            return self.duration\n        else:\n            return max(0, delta)", "loc": 14}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "baudrate", "parameters": ["self", "baudrate"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Not a valid baudrate: {!r}'.format", "ValueError", "int", "self._reconfigure_port"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Change baud rate. It raises a ValueError if the port is open and the baud rate is not possible. If the port is closed, then the value is accepted and the exception is raised when the port is opened.", "source_code": "def baudrate(self, baudrate):\n    \"\"\"\\\n    Change baud rate. It raises a ValueError if the port is open and the\n    baud rate is not possible. If the port is closed, then the value is\n    accepted and the exception is raised when the port is opened.\n    \"\"\"\n    try:\n        b = int(baudrate)\n    except TypeError:\n        raise ValueError(\"Not a valid baudrate: {!r}\".format(baudrate))\n    else:\n        if b < 0:\n            raise ValueError(\"Not a valid baudrate: {!r}\".format(baudrate))\n        self._baudrate = b\n        if self.is_open:\n            self._reconfigure_port()", "loc": 16}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "bytesize", "parameters": ["self", "bytesize"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Not a valid byte size: {!r}'.format", "ValueError", "self._reconfigure_port"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Change byte size.", "source_code": "def bytesize(self, bytesize):\n    \"\"\"Change byte size.\"\"\"\n    if bytesize not in self.BYTESIZES:\n        raise ValueError(\"Not a valid byte size: {!r}\".format(bytesize))\n    self._bytesize = bytesize\n    if self.is_open:\n        self._reconfigure_port()", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "exclusive", "parameters": ["self", "exclusive"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._reconfigure_port"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Change the exclusive access setting.", "source_code": "def exclusive(self, exclusive):\n    \"\"\"Change the exclusive access setting.\"\"\"\n    self._exclusive = exclusive\n    if self.is_open:\n        self._reconfigure_port()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "parity", "parameters": ["self", "parity"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Not a valid parity: {!r}'.format", "ValueError", "self._reconfigure_port"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Change parity setting.", "source_code": "def parity(self, parity):\n    \"\"\"Change parity setting.\"\"\"\n    if parity not in self.PARITIES:\n        raise ValueError(\"Not a valid parity: {!r}\".format(parity))\n    self._parity = parity\n    if self.is_open:\n        self._reconfigure_port()", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "stopbits", "parameters": ["self", "stopbits"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Not a valid stop bit size: {!r}'.format", "ValueError", "self._reconfigure_port"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Change stop bits size.", "source_code": "def stopbits(self, stopbits):\n    \"\"\"Change stop bits size.\"\"\"\n    if stopbits not in self.STOPBITS:\n        raise ValueError(\"Not a valid stop bit size: {!r}\".format(stopbits))\n    self._stopbits = stopbits\n    if self.is_open:\n        self._reconfigure_port()", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "timeout", "parameters": ["self", "timeout"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Not a valid timeout: {!r}'.format", "ValueError", "self._reconfigure_port"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Change timeout setting.", "source_code": "def timeout(self, timeout):\n    \"\"\"Change timeout setting.\"\"\"\n    if timeout is not None:\n        try:\n            timeout + 1     # test if it's a number, will throw a TypeError if not...\n        except TypeError:\n            raise ValueError(\"Not a valid timeout: {!r}\".format(timeout))\n        if timeout < 0:\n            raise ValueError(\"Not a valid timeout: {!r}\".format(timeout))\n    self._timeout = timeout\n    if self.is_open:\n        self._reconfigure_port()", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "write_timeout", "parameters": ["self", "timeout"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Not a valid timeout: {!r}'.format", "ValueError", "self._reconfigure_port"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Change timeout setting.", "source_code": "def write_timeout(self, timeout):\n    \"\"\"Change timeout setting.\"\"\"\n    if timeout is not None:\n        if timeout < 0:\n            raise ValueError(\"Not a valid timeout: {!r}\".format(timeout))\n        try:\n            timeout + 1     # test if it's a number, will throw a TypeError if not...\n        except TypeError:\n            raise ValueError(\"Not a valid timeout: {!r}\".format(timeout))\n\n    self._write_timeout = timeout\n    if self.is_open:\n        self._reconfigure_port()", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "inter_byte_timeout", "parameters": ["self", "ic_timeout"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Not a valid timeout: {!r}'.format", "ValueError", "self._reconfigure_port"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Change inter-byte timeout setting.", "source_code": "def inter_byte_timeout(self, ic_timeout):\n    \"\"\"Change inter-byte timeout setting.\"\"\"\n    if ic_timeout is not None:\n        if ic_timeout < 0:\n            raise ValueError(\"Not a valid timeout: {!r}\".format(ic_timeout))\n        try:\n            ic_timeout + 1     # test if it's a number, will throw a TypeError if not...\n        except TypeError:\n            raise ValueError(\"Not a valid timeout: {!r}\".format(ic_timeout))\n\n    self._inter_byte_timeout = ic_timeout\n    if self.is_open:\n        self._reconfigure_port()", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "xonxoff", "parameters": ["self", "xonxoff"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._reconfigure_port"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Change XON/XOFF setting.", "source_code": "def xonxoff(self, xonxoff):\n    \"\"\"Change XON/XOFF setting.\"\"\"\n    self._xonxoff = xonxoff\n    if self.is_open:\n        self._reconfigure_port()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "rtscts", "parameters": ["self", "rtscts"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._reconfigure_port"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Change RTS/CTS flow control setting.", "source_code": "def rtscts(self, rtscts):\n    \"\"\"Change RTS/CTS flow control setting.\"\"\"\n    self._rtscts = rtscts\n    if self.is_open:\n        self._reconfigure_port()", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "dsrdtr", "parameters": ["self", "dsrdtr"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._reconfigure_port"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Change DsrDtr flow control setting.", "source_code": "def dsrdtr(self, dsrdtr=None):\n    \"\"\"Change DsrDtr flow control setting.\"\"\"\n    if dsrdtr is None:\n        # if not set, keep backwards compatibility and follow rtscts setting\n        self._dsrdtr = self._rtscts\n    else:\n        # if defined independently, follow its value\n        self._dsrdtr = dsrdtr\n    if self.is_open:\n        self._reconfigure_port()", "loc": 10}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "get_settings", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["dict", "getattr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Get current port settings as a dictionary. For use with apply_settings().", "source_code": "def get_settings(self):\n    \"\"\"\\\n    Get current port settings as a dictionary. For use with\n    apply_settings().\n    \"\"\"\n    return dict([(key, getattr(self, '_' + key)) for key in self._SAVED_SETTINGS])", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "apply_settings", "parameters": ["self", "d"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "setattr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Apply stored settings from a dictionary returned from get_settings(). It's allowed to delete keys from the dictionary. These values will simply left unchanged.", "source_code": "def apply_settings(self, d):\n    \"\"\"\\\n    Apply stored settings from a dictionary returned from\n    get_settings(). It's allowed to delete keys from the dictionary. These\n    values will simply left unchanged.\n    \"\"\"\n    for key in self._SAVED_SETTINGS:\n        if key in d and d[key] != getattr(self, '_' + key):   # check against internal \"_\" value\n            setattr(self, key, d[key])          # set non \"_\" value to use properties write function", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "readinto", "parameters": ["self", "b"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["array.array", "isinstance", "len", "self.read"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def readinto(self, b):\n    data = self.read(len(b))\n    n = len(data)\n    try:\n        b[:n] = data\n    except TypeError as err:\n        import array\n        if not isinstance(b, array.array):\n            raise err\n        b[:n] = array.array('b', data)\n    return n", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "send_break", "parameters": ["self", "duration"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "time.sleep"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Send break condition. Timed, returns to idle state after given duration.", "source_code": "def send_break(self, duration=0.25):\n    \"\"\"\\\n    Send break condition. Timed, returns to idle state after given\n    duration.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    self.break_condition = True\n    time.sleep(duration)\n    self.break_condition = False", "loc": 10}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "read_until", "parameters": ["self", "expected", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Timeout", "bytearray", "bytes", "len", "self.read", "timeout.expired"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Read until an expected sequence is found (line feed by default), the size is exceeded or until timeout occurs.", "source_code": "def read_until(self, expected=LF, size=None):\n    \"\"\"\\\n    Read until an expected sequence is found (line feed by default), the size\n    is exceeded or until timeout occurs.\n    \"\"\"\n    lenterm = len(expected)\n    line = bytearray()\n    timeout = Timeout(self._timeout)\n    while True:\n        c = self.read(1)\n        if c:\n            line += c\n            if line[-lenterm:] == expected:\n                break\n            if size is not None and len(line) >= size:\n                break\n        else:\n            break\n        if timeout.expired():\n            break\n    return bytes(line)", "loc": 21}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialutil.py", "class_name": "SerialBase", "function_name": "iread_until", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.read_until"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Read lines, implemented as generator. It will raise StopIteration on timeout (empty read).", "source_code": "def iread_until(self, *args, **kwargs):\n    \"\"\"\\\n    Read lines, implemented as generator. It will raise StopIteration on\n    timeout (empty read).\n    \"\"\"\n    while True:\n        line = self.read_until(*args, **kwargs)\n        if not line:\n            break\n        yield line", "loc": 10}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._close"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Close port", "source_code": "def close(self):\n    \"\"\"Close port\"\"\"\n    if self.is_open:\n        self._close()\n        self.is_open = False", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "in_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'ClearCommError failed ({!r})'.format", "SerialException", "ctypes.WinError", "ctypes.byref", "win32.COMSTAT", "win32.ClearCommError", "win32.DWORD"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the number of bytes currently in the input buffer.", "source_code": "def in_waiting(self):\n    \"\"\"Return the number of bytes currently in the input buffer.\"\"\"\n    flags = win32.DWORD()\n    comstat = win32.COMSTAT()\n    if not win32.ClearCommError(self._port_handle, ctypes.byref(flags), ctypes.byref(comstat)):\n        raise SerialException(\"ClearCommError failed ({!r})\".format(ctypes.WinError()))\n    return comstat.cbInQue", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'ClearCommError failed ({!r})'.format", "'GetOverlappedResult failed ({!r})'.format", "'ReadFile failed ({!r})'.format", "PortNotOpenError", "SerialException", "bytes", "ctypes.WinError", "ctypes.byref", "ctypes.create_string_buffer", "min", "win32.COMSTAT", "win32.ClearCommError", "win32.DWORD", "win32.GetLastError", "win32.GetOverlappedResult", "win32.ReadFile", "win32.ResetEvent"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read size bytes from the serial port. If a timeout is set it may return less characters as requested. With no timeout it will block until the requested number of bytes is read.", "source_code": "def read(self, size=1):\n    \"\"\"\\\n    Read size bytes from the serial port. If a timeout is set it may\n    return less characters as requested. With no timeout it will block\n    until the requested number of bytes is read.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if size > 0:\n        win32.ResetEvent(self._overlapped_read.hEvent)\n        flags = win32.DWORD()\n        comstat = win32.COMSTAT()\n        if not win32.ClearCommError(self._port_handle, ctypes.byref(flags), ctypes.byref(comstat)):\n            raise SerialException(\"ClearCommError failed ({!r})\".format(ctypes.WinError()))\n        n = min(comstat.cbInQue, size) if self.timeout == 0 else size\n        if n > 0:\n            buf = ctypes.create_string_buffer(n)\n            rc = win32.DWORD()\n            read_ok = win32.ReadFile(\n                self._port_handle,\n                buf,\n                n,\n                ctypes.byref(rc),\n                ctypes.byref(self._overlapped_read))\n            if not read_ok and win32.GetLastError() not in (win32.ERROR_SUCCESS, win32.ERROR_IO_PENDING):\n                raise SerialException(\"ReadFile failed ({!r})\".format(ctypes.WinError()))\n            result_ok = win32.GetOverlappedResult(\n                self._port_handle,\n                ctypes.byref(self._overlapped_read),\n                ctypes.byref(rc),\n                True)\n            if not result_ok:\n                if win32.GetLastError() != win32.ERROR_OPERATION_ABORTED:\n                    raise SerialException(\"GetOverlappedResult failed ({!r})\".format(ctypes.WinError()))\n            read = buf.raw[:rc.value]\n        else:\n            read = bytes()\n    else:\n        read = bytes()\n    return bytes(read)", "loc": 40}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "write", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'WriteFile failed ({!r})'.format", "PortNotOpenError", "SerialException", "SerialTimeoutException", "ctypes.WinError", "ctypes.byref", "len", "to_bytes", "win32.DWORD", "win32.GetLastError", "win32.GetOverlappedResult", "win32.WriteFile"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Output the given byte string over the serial port.", "source_code": "def write(self, data):\n    \"\"\"Output the given byte string over the serial port.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    #~ if not isinstance(data, (bytes, bytearray)):\n        #~ raise TypeError('expected %s or bytearray, got %s' % (bytes, type(data)))\n    # convert data (needed in case of memoryview instance: Py 3.1 io lib), ctypes doesn't like memoryview\n    data = to_bytes(data)\n    if data:\n        #~ win32event.ResetEvent(self._overlapped_write.hEvent)\n        n = win32.DWORD()\n        success = win32.WriteFile(self._port_handle, data, len(data), ctypes.byref(n), self._overlapped_write)\n        if self._write_timeout != 0:  # if blocking (None) or w/ write timeout (>0)\n            if not success and win32.GetLastError() not in (win32.ERROR_SUCCESS, win32.ERROR_IO_PENDING):\n                raise SerialException(\"WriteFile failed ({!r})\".format(ctypes.WinError()))\n\n            # Wait for the write to complete.\n            #~ win32.WaitForSingleObject(self._overlapped_write.hEvent, win32.INFINITE)\n            win32.GetOverlappedResult(self._port_handle, self._overlapped_write, ctypes.byref(n), True)\n            if win32.GetLastError() == win32.ERROR_OPERATION_ABORTED:\n                return n.value  # canceled IO is no error\n            if n.value != len(data):\n                raise SerialTimeoutException('Write timeout')\n            return n.value\n        else:\n            errorcode = win32.ERROR_SUCCESS if success else win32.GetLastError()\n            if errorcode in (win32.ERROR_INVALID_USER_BUFFER, win32.ERROR_NOT_ENOUGH_MEMORY,\n                             win32.ERROR_OPERATION_ABORTED):\n                return 0\n            elif errorcode in (win32.ERROR_SUCCESS, win32.ERROR_IO_PENDING):\n                # no info on true length provided by OS function in async mode\n                return len(data)\n            else:\n                raise SerialException(\"WriteFile failed ({!r})\".format(ctypes.WinError()))\n    else:\n        return 0", "loc": 36}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "flush", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["time.sleep"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "Flush of file like objects. In this case, wait until all data is written.", "source_code": "def flush(self):\n    \"\"\"\\\n    Flush of file like objects. In this case, wait until all data\n    is written.\n    \"\"\"\n    while self.out_waiting:\n        time.sleep(0.05)", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "reset_input_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "win32.PurgeComm"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Clear input buffer, discarding all that is in the buffer.", "source_code": "def reset_input_buffer(self):\n    \"\"\"Clear input buffer, discarding all that is in the buffer.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    win32.PurgeComm(self._port_handle, win32.PURGE_RXCLEAR | win32.PURGE_RXABORT)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "reset_output_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "win32.PurgeComm"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Clear output buffer, aborting the current output and discarding all that is in the buffer.", "source_code": "def reset_output_buffer(self):\n    \"\"\"\\\n    Clear output buffer, aborting the current output and discarding all\n    that is in the buffer.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    win32.PurgeComm(self._port_handle, win32.PURGE_TXCLEAR | win32.PURGE_TXABORT)", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "set_buffer_size", "parameters": ["self", "rx_size", "tx_size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["win32.SetupComm"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Recommend a buffer size to the driver (device driver can ignore this value). Must be called after the port is opened.", "source_code": "def set_buffer_size(self, rx_size=4096, tx_size=None):\n    \"\"\"\\\n    Recommend a buffer size to the driver (device driver can ignore this\n    value). Must be called after the port is opened.\n    \"\"\"\n    if tx_size is None:\n        tx_size = rx_size\n    win32.SetupComm(self._port_handle, rx_size, tx_size)", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "set_output_flow_control", "parameters": ["self", "enable"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "win32.EscapeCommFunction"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Manually control flow - when software flow control is enabled. This will do the same as if XON (true) or XOFF (false) are received from the other device and control the transmission accordingly.", "source_code": "def set_output_flow_control(self, enable=True):\n    \"\"\"\\\n    Manually control flow - when software flow control is enabled.\n    This will do the same as if XON (true) or XOFF (false) are received\n    from the other device and control the transmission accordingly.\n    WARNING: this function is not portable to different platforms!\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if enable:\n        win32.EscapeCommFunction(self._port_handle, win32.SETXON)\n    else:\n        win32.EscapeCommFunction(self._port_handle, win32.SETXOFF)", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "out_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'ClearCommError failed ({!r})'.format", "SerialException", "ctypes.WinError", "ctypes.byref", "win32.COMSTAT", "win32.ClearCommError", "win32.DWORD"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return how many bytes the in the outgoing buffer", "source_code": "def out_waiting(self):\n    \"\"\"Return how many bytes the in the outgoing buffer\"\"\"\n    flags = win32.DWORD()\n    comstat = win32.COMSTAT()\n    if not win32.ClearCommError(self._port_handle, ctypes.byref(flags), ctypes.byref(comstat)):\n        raise SerialException(\"ClearCommError failed ({!r})\".format(ctypes.WinError()))\n    return comstat.cbOutQue", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\serialwin32.py", "class_name": "Serial", "function_name": "exclusive", "parameters": ["self", "exclusive"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'win32 only supports exclusive access (not: {})'.format", "ValueError", "serial.SerialBase.exclusive.__set__"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Change the exclusive access setting.", "source_code": "def exclusive(self, exclusive):\n    \"\"\"Change the exclusive access setting.\"\"\"\n    if exclusive is not None and not exclusive:\n        raise ValueError('win32 only supports exclusive access (not: {})'.format(exclusive))\n    else:\n        serial.SerialBase.exclusive.__set__(self, exclusive)", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\threaded\\__init__.py", "class_name": "Protocol", "function_name": "connection_lost", "parameters": ["self", "exc"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Called when the serial port is closed or the reader loop terminated otherwise.", "source_code": "def connection_lost(self, exc):\n    \"\"\"\\\n    Called when the serial port is closed or the reader loop terminated\n    otherwise.\n    \"\"\"\n    if isinstance(exc, Exception):\n        raise exc", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\threaded\\__init__.py", "class_name": "Packetizer", "function_name": "data_received", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.buffer.extend", "self.buffer.split", "self.handle_packet"], "control_structures": ["While"], "behavior_type": ["logic"], "doc_summary": "Buffer received data, find TERMINATOR, call handle_packet", "source_code": "def data_received(self, data):\n    \"\"\"Buffer received data, find TERMINATOR, call handle_packet\"\"\"\n    self.buffer.extend(data)\n    while self.TERMINATOR in self.buffer:\n        packet, self.buffer = self.buffer.split(self.TERMINATOR, 1)\n        self.handle_packet(packet)", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\threaded\\__init__.py", "class_name": "FramedPacket", "function_name": "connection_lost", "parameters": ["self", "exc"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["super", "super(FramedPacket, self).connection_lost"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Forget transport", "source_code": "def connection_lost(self, exc):\n    \"\"\"Forget transport\"\"\"\n    self.transport = None\n    self.in_packet = False\n    del self.packet[:]\n    super(FramedPacket, self).connection_lost(exc)", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\threaded\\__init__.py", "class_name": "FramedPacket", "function_name": "data_received", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["bytes", "self.handle_out_of_packet_data", "self.handle_packet", "self.packet.extend", "serial.iterbytes"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Find data enclosed in START/STOP, call handle_packet", "source_code": "def data_received(self, data):\n    \"\"\"Find data enclosed in START/STOP, call handle_packet\"\"\"\n    for byte in serial.iterbytes(data):\n        if byte == self.START:\n            self.in_packet = True\n        elif byte == self.STOP:\n            self.in_packet = False\n            self.handle_packet(bytes(self.packet)) # make read-only copy\n            del self.packet[:]\n        elif self.in_packet:\n            self.packet.extend(byte)\n        else:\n            self.handle_out_of_packet_data(byte)", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\serial\\threaded\\__init__.py", "class_name": "LineReader", "function_name": "write_line", "parameters": ["self", "text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.transport.write", "text.encode"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Write text to the transport. ``text`` is a Unicode string and the encoding is applied before sending and also the newline is append.", "source_code": "def write_line(self, text):\n    \"\"\"\n    Write text to the transport. ``text`` is a Unicode string and the encoding\n    is applied before sending and also the newline is append.\n    \"\"\"\n    # + is not the best choice but bytes does not support % or .format in py3 and we want a single write call\n    self.transport.write(text.encode(self.ENCODING, self.UNICODE_HANDLING) + self.TERMINATOR)", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\threaded\\__init__.py", "class_name": "ReaderThread", "function_name": "stop", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "self.join", "self.serial.cancel_read"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Stop the reader thread", "source_code": "def stop(self):\n    \"\"\"Stop the reader thread\"\"\"\n    self.alive = False\n    if hasattr(self.serial, 'cancel_read'):\n        self.serial.cancel_read()\n    self.join(2)", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\threaded\\__init__.py", "class_name": "ReaderThread", "function_name": "run", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "self._connection_made.set", "self.protocol.connection_lost", "self.protocol.connection_made", "self.protocol.data_received", "self.protocol_factory", "self.serial.read"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Reader loop", "source_code": "def run(self):\n    \"\"\"Reader loop\"\"\"\n    if not hasattr(self.serial, 'cancel_read'):\n        self.serial.timeout = 1\n    self.protocol = self.protocol_factory()\n    try:\n        self.protocol.connection_made(self)\n    except Exception as e:\n        self.alive = False\n        self.protocol.connection_lost(e)\n        self._connection_made.set()\n        return\n    error = None\n    self._connection_made.set()\n    while self.alive and self.serial.is_open:\n        try:\n            # read all that is there or wait for one byte (blocking)\n            data = self.serial.read(self.serial.in_waiting or 1)\n        except serial.SerialException as e:\n            # probably some I/O problem such as disconnected USB serial\n            # adapters -> exit\n            error = e\n            break\n        else:\n            if data:\n                # make a separated try-except for called user code\n                try:\n                    self.protocol.data_received(data)\n                except Exception as e:\n                    error = e\n                    break\n    self.alive = False\n    self.protocol.connection_lost(error)\n    self.protocol = None", "loc": 34}
{"file": "thonny\\thonny\\vendored_libs\\serial\\threaded\\__init__.py", "class_name": "ReaderThread", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.serial.close", "self.stop"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Close the serial port and exit reader thread (uses lock)", "source_code": "def close(self):\n    \"\"\"Close the serial port and exit reader thread (uses lock)\"\"\"\n    # use the lock to let other threads finish writing\n    with self._lock:\n        # first stop reading, so that closing can be done on idle port\n        self.stop()\n        self.serial.close()", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\threaded\\__init__.py", "class_name": "ReaderThread", "function_name": "connect", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["RuntimeError", "self._connection_made.wait"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Wait until connection is set up and return the transport and protocol instances.", "source_code": "def connect(self):\n    \"\"\"\n    Wait until connection is set up and return the transport and protocol\n    instances.\n    \"\"\"\n    if self.alive:\n        self._connection_made.wait()\n        if not self.alive:\n            raise RuntimeError('connection_lost already called')\n        return (self, self.protocol)\n    else:\n        raise RuntimeError('already stopped')", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\hexlify_codec.py", "class_name": "IncrementalEncoder", "function_name": "encode", "parameters": ["self", "data", "final"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'non-hex digit found: {!r}'.format", "HEXDIGITS.index", "UnicodeError", "data.upper", "encoded.append", "serial.to_bytes"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Incremental encode, keep track of digits and emit a byte when a pair of hex digits is found. The space is optional unless the error handling is defined to be 'strict'.", "source_code": "def encode(self, data, final=False):\n    \"\"\"\\\n    Incremental encode, keep track of digits and emit a byte when a pair\n    of hex digits is found. The space is optional unless the error\n    handling is defined to be 'strict'.\n    \"\"\"\n    state = self.state\n    encoded = []\n    for c in data.upper():\n        if c in HEXDIGITS:\n            z = HEXDIGITS.index(c)\n            if state:\n                encoded.append(z + (state & 0xf0))\n                state = 0\n            else:\n                state = 0x100 + (z << 4)\n        elif c == ' ':      # allow spaces to separate values\n            if state and self.errors == 'strict':\n                raise UnicodeError('odd number of hex digits')\n            state = 0\n        else:\n            if self.errors == 'strict':\n                raise UnicodeError('non-hex digit found: {!r}'.format(c))\n    self.state = state\n    return serial.to_bytes(encoded)", "loc": 25}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports.py", "class_name": null, "function_name": "grep", "parameters": ["regexp", "include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["comports", "r.search", "re.compile"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "Search for ports using a regular expression. Port name, description and hardware ID are searched. The function returns an iterable that returns the same tuples as comport() would do.", "source_code": "def grep(regexp, include_links=False):\n    \"\"\"\\\n    Search for ports using a regular expression. Port name, description and\n    hardware ID are searched. The function returns an iterable that returns the\n    same tuples as comport() would do.\n    \"\"\"\n    r = re.compile(regexp, re.I)\n    for info in comports(include_links):\n        port, desc, hwid = info\n        if r.search(port) or r.search(desc) or r.search(hwid):\n            yield info", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports.py", "class_name": null, "function_name": "main", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'    desc: {}\\n'.format", "'    hwid: {}\\n'.format", "'Filtered list with regexp: {!r}\\n'.format", "'{:20}\\n'.format", "'{} ports found\\n'.format", "argparse.ArgumentParser", "comports", "enumerate", "grep", "parser.add_argument", "parser.parse_args", "sorted", "sys.stderr.write", "sys.stdout.write"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def main():\n    import argparse\n\n    parser = argparse.ArgumentParser(description='Serial port enumeration')\n\n    parser.add_argument(\n        'regexp',\n        nargs='?',\n        help='only show ports that match this regex')\n\n    parser.add_argument(\n        '-v', '--verbose',\n        action='store_true',\n        help='show more messages')\n\n    parser.add_argument(\n        '-q', '--quiet',\n        action='store_true',\n        help='suppress all messages')\n\n    parser.add_argument(\n        '-n',\n        type=int,\n        help='only output the N-th entry')\n\n    parser.add_argument(\n        '-s', '--include-links',\n        action='store_true',\n        help='include entries that are symlinks to real devices')\n\n    args = parser.parse_args()\n\n    hits = 0\n    # get iteraror w/ or w/o filter\n    if args.regexp:\n        if not args.quiet:\n            sys.stderr.write(\"Filtered list with regexp: {!r}\\n\".format(args.regexp))\n        iterator = sorted(grep(args.regexp, include_links=args.include_links))\n    else:\n        iterator = sorted(comports(include_links=args.include_links))\n    # list them\n    for n, (port, desc, hwid) in enumerate(iterator, 1):\n        if args.n is None or args.n == n:\n            sys.stdout.write(\"{:20}\\n\".format(port))\n            if args.verbose:\n                sys.stdout.write(\"    desc: {}\\n\".format(desc))\n                sys.stdout.write(\"    hwid: {}\\n\".format(hwid))\n        hits += 1\n    if not args.quiet:\n        if hits:\n            sys.stderr.write(\"{} ports found\\n\".format(hits))\n        else:\n            sys.stderr.write(\"no ports found\\n\")", "loc": 53}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_common.py", "class_name": null, "function_name": "numsplit", "parameters": ["text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["int", "re.split", "result.append"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "Convert string into a list of texts and numbers in order to support a natural sorting.", "source_code": "def numsplit(text):\n    \"\"\"\\\n    Convert string into a list of texts and numbers in order to support a\n    natural sorting.\n    \"\"\"\n    result = []\n    for group in re.split(r'(\\d+)', text):\n        if group:\n            try:\n                group = int(group)\n            except ValueError:\n                pass\n            result.append(group)\n    return result", "loc": 14}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_common.py", "class_name": "ListPortInfo", "function_name": "usb_description", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'{} - {}'.format"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "return a short string to name the port based on USB info", "source_code": "def usb_description(self):\n    \"\"\"return a short string to name the port based on USB info\"\"\"\n    if self.interface is not None:\n        return '{} - {}'.format(self.product, self.interface)\n    elif self.product is not None:\n        return self.product\n    else:\n        return self.name", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_common.py", "class_name": "ListPortInfo", "function_name": "usb_info", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' LOCATION={}'.format", "' SER={}'.format", "'USB VID:PID={:04X}:{:04X}{}{}'.format"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "return a string with USB related information about device", "source_code": "def usb_info(self):\n    \"\"\"return a string with USB related information about device\"\"\"\n    return 'USB VID:PID={:04X}:{:04X}{}{}'.format(\n        self.vid or 0,\n        self.pid or 0,\n        ' SER={}'.format(self.serial_number) if self.serial_number is not None else '',\n        ' LOCATION={}'.format(self.location) if self.location is not None else '')", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_linux.py", "class_name": null, "function_name": "comports", "parameters": ["include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SysFS", "devices.update", "glob.glob", "list_ports_common.list_links", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def comports(include_links=False):\n    devices = set()\n    devices.update(glob.glob('/dev/ttyS*'))     # built-in serial ports\n    devices.update(glob.glob('/dev/ttyUSB*'))   # usb-serial with own driver\n    devices.update(glob.glob('/dev/ttyXRUSB*')) # xr-usb-serial port exar (DELL Edge 3001)\n    devices.update(glob.glob('/dev/ttyACM*'))   # usb-serial with CDC-ACM profile\n    devices.update(glob.glob('/dev/ttyAMA*'))   # ARM internal port (raspi)\n    devices.update(glob.glob('/dev/rfcomm*'))   # BT serial devices\n    devices.update(glob.glob('/dev/ttyAP*'))    # Advantech multi-port serial controllers\n    devices.update(glob.glob('/dev/ttyGS*'))    # https://www.kernel.org/doc/Documentation/usb/gadget_serial.txt\n\n    if include_links:\n        devices.update(list_ports_common.list_links(devices))\n    return [info\n            for info in [SysFS(d) for d in devices]\n            if info.subsystem != \"platform\"]    # hide non-present internal serial ports", "loc": 16}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_osx.py", "class_name": null, "function_name": "get_string_property", "parameters": ["device_type", "property"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["buffer.value.decode", "cf.CFRelease", "cf.CFStringCreateWithCString", "cf.CFStringGetCString", "cf.CFStringGetCStringPtr", "ctypes.byref", "ctypes.create_string_buffer", "iokit.IORegistryEntryCreateCFProperty", "output.decode", "property.encode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Search the given device for the specified string property @param device_type Type of Device @param property String to search for", "source_code": "def get_string_property(device_type, property):\n    \"\"\"\n    Search the given device for the specified string property\n\n    @param device_type Type of Device\n    @param property String to search for\n    @return Python string containing the value, or None if not found.\n    \"\"\"\n    key = cf.CFStringCreateWithCString(\n            kCFAllocatorDefault,\n            property.encode(\"utf-8\"),\n            kCFStringEncodingUTF8)\n\n    CFContainer = iokit.IORegistryEntryCreateCFProperty(\n            device_type,\n            key,\n            kCFAllocatorDefault,\n            0)\n    output = None\n\n    if CFContainer:\n        output = cf.CFStringGetCStringPtr(CFContainer, 0)\n        if output is not None:\n            output = output.decode('utf-8')\n        else:\n            buffer = ctypes.create_string_buffer(io_name_size);\n            success = cf.CFStringGetCString(CFContainer, ctypes.byref(buffer), io_name_size, kCFStringEncodingUTF8)\n            if success:\n                output = buffer.value.decode('utf-8')\n        cf.CFRelease(CFContainer)\n    return output", "loc": 31}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_osx.py", "class_name": null, "function_name": "get_int_property", "parameters": ["device_type", "property", "cf_number_type"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["cf.CFNumberGetValue", "cf.CFRelease", "cf.CFStringCreateWithCString", "ctypes.byref", "ctypes.c_uint16", "ctypes.c_uint32", "iokit.IORegistryEntryCreateCFProperty", "property.encode"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Search the given device for the specified string property @param device_type Device to search @param property String to search for", "source_code": "def get_int_property(device_type, property, cf_number_type):\n    \"\"\"\n    Search the given device for the specified string property\n\n    @param device_type Device to search\n    @param property String to search for\n    @param cf_number_type CFType number\n\n    @return Python string containing the value, or None if not found.\n    \"\"\"\n    key = cf.CFStringCreateWithCString(\n            kCFAllocatorDefault,\n            property.encode(\"utf-8\"),\n            kCFStringEncodingUTF8)\n\n    CFContainer = iokit.IORegistryEntryCreateCFProperty(\n            device_type,\n            key,\n            kCFAllocatorDefault,\n            0)\n\n    if CFContainer:\n        if (cf_number_type == kCFNumberSInt32Type):\n            number = ctypes.c_uint32()\n        elif (cf_number_type == kCFNumberSInt16Type):\n            number = ctypes.c_uint16()\n        cf.CFNumberGetValue(CFContainer, cf_number_type, ctypes.byref(number))\n        cf.CFRelease(CFContainer)\n        return number.value\n    return None", "loc": 30}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_osx.py", "class_name": null, "function_name": "IORegistryEntryGetName", "parameters": ["device"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ctypes.byref", "ctypes.create_string_buffer", "devicename.value.decode", "iokit.IORegistryEntryGetName"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def IORegistryEntryGetName(device):\n    devicename = ctypes.create_string_buffer(io_name_size);\n    res = iokit.IORegistryEntryGetName(device, ctypes.byref(devicename))\n    if res != KERN_SUCCESS:\n        return None\n    # this works in python2 but may not be valid. Also I don't know if\n    # this encoding is guaranteed. It may be dependent on system locale.\n    return devicename.value.decode('utf-8')", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_osx.py", "class_name": null, "function_name": "GetParentDeviceByType", "parameters": ["device", "parent_type"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'IOService'.encode", "IOObjectGetClass", "ctypes.byref", "ctypes.c_void_p", "iokit.IORegistryEntryGetParentEntry", "parent_type.encode"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "Find the first parent of a device that implements the parent_type @param IOService Service to inspect @return Pointer to the parent type, or None if it was not found.", "source_code": "def GetParentDeviceByType(device, parent_type):\n    \"\"\" Find the first parent of a device that implements the parent_type\n        @param IOService Service to inspect\n        @return Pointer to the parent type, or None if it was not found.\n    \"\"\"\n    # First, try to walk up the IOService tree to find a parent of this device that is a IOUSBDevice.\n    parent_type = parent_type.encode('utf-8')\n    while IOObjectGetClass(device) != parent_type:\n        parent = ctypes.c_void_p()\n        response = iokit.IORegistryEntryGetParentEntry(\n                device,\n                \"IOService\".encode(\"utf-8\"),\n                ctypes.byref(parent))\n        # If we weren't able to find a parent for the device, we're done.\n        if response != KERN_SUCCESS:\n            return None\n        device = parent\n    return device", "loc": 18}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_osx.py", "class_name": null, "function_name": "GetIOServicesByType", "parameters": ["service_type"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ctypes.byref", "ctypes.c_void_p", "iokit.IOIteratorIsValid", "iokit.IOIteratorNext", "iokit.IOObjectRelease", "iokit.IOServiceGetMatchingServices", "iokit.IOServiceMatching", "service_type.encode", "services.append"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "returns iterator over specified service_type", "source_code": "def GetIOServicesByType(service_type):\n    \"\"\"\n    returns iterator over specified service_type\n    \"\"\"\n    serial_port_iterator = ctypes.c_void_p()\n\n    iokit.IOServiceGetMatchingServices(\n            kIOMasterPortDefault,\n            iokit.IOServiceMatching(service_type.encode('utf-8')),\n            ctypes.byref(serial_port_iterator))\n\n    services = []\n    while iokit.IOIteratorIsValid(serial_port_iterator):\n        service = iokit.IOIteratorNext(serial_port_iterator)\n        if not service:\n            break\n        services.append(service)\n    iokit.IOObjectRelease(serial_port_iterator)\n    return services", "loc": 19}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_osx.py", "class_name": null, "function_name": "location_to_string", "parameters": ["locationID"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "'{}'.format", "'{}-'.format", "len", "loc.append"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "helper to calculate port and bus number from locationID", "source_code": "def location_to_string(locationID):\n    \"\"\"\n    helper to calculate port and bus number from locationID\n    \"\"\"\n    loc = ['{}-'.format(locationID >> 24)]\n    while locationID & 0xf00000:\n        if len(loc) > 1:\n            loc.append('.')\n        loc.append('{}'.format((locationID >> 20) & 0xf))\n        locationID <<= 4\n    return ''.join(loc)", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_osx.py", "class_name": null, "function_name": "scan_interfaces", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["GetIOServicesByType", "SuitableSerialInterface", "get_int_property", "get_string_property", "interfaces.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "helper function to scan USB interfaces returns a list of SuitableSerialInterface objects with name and id attributes", "source_code": "def scan_interfaces():\n    \"\"\"\n    helper function to scan USB interfaces\n    returns a list of SuitableSerialInterface objects with name and id attributes\n    \"\"\"\n    interfaces = []\n    # this is for [High] Sierra compatibility (AppleUSBInterface ?)\n    for interface in GetIOServicesByType('IOUSBInterface'):\n        name = get_string_property(interface, \"USB Interface Name\")\n        if name is None: continue\n        locationID = get_int_property(interface, \"locationID\", kCFNumberSInt32Type)\n        bInterfaceNumber = get_int_property(interface, \"bInterfaceNumber\", kCFNumberSInt32Type)\n        i = SuitableSerialInterface()\n        i.id = (locationID, bInterfaceNumber)\n        i.name = name\n        interfaces.append(i)\n    return interfaces", "loc": 17}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_osx.py", "class_name": null, "function_name": "search_in_interfaces", "parameters": ["serial_interfaces", "identifier"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def search_in_interfaces(serial_interfaces, identifier):\n    for interface in serial_interfaces:\n        if (interface.id == identifier):\n            return interface.name\n    return None", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_osx.py", "class_name": null, "function_name": "comports", "parameters": ["include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["GetIOServicesByType", "GetParentDeviceByType", "IORegistryEntryGetName", "get_int_property", "get_string_property", "info.apply_usb_info", "list_ports_common.ListPortInfo", "location_to_string", "ports.append", "scan_interfaces", "search_in_interfaces"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def comports(include_links=False):\n    # XXX include_links is currently ignored. are links in /dev even supported here?\n    # Scan for all iokit serial ports\n    services = GetIOServicesByType('IOSerialBSDClient')\n    ports = []\n    serial_interfaces = None\n    for service in services:\n        # First, add the callout device file.\n        device = get_string_property(service, \"IOCalloutDevice\")\n        if device:\n            info = list_ports_common.ListPortInfo(device)\n            # find the serial interface associated with this device\n            # like below, IOUSBInterface is IOUSBHostInterface on Apple Silicon\n            serial_interface = GetParentDeviceByType(service, \"IOUSBHostInterface\")\n            if serial_interface is None:\n                serial_interface = GetParentDeviceByType(service, \"IOUSBInterface\")\n            # If the serial port is implemented by IOUSBDevice\n            # NOTE IOUSBDevice was deprecated as of 10.11 and finally on Apple Silicon\n            # devices has been completely removed.  Thanks to @oskay for this patch.\n            usb_device = GetParentDeviceByType(service, \"IOUSBHostDevice\")\n            if not usb_device:\n                usb_device = GetParentDeviceByType(service, \"IOUSBDevice\")\n            if usb_device:\n                # fetch some useful information from properties\n                info.vid = get_int_property(usb_device, \"idVendor\", kCFNumberSInt16Type)\n                info.pid = get_int_property(usb_device, \"idProduct\", kCFNumberSInt16Type)\n                info.serial_number = get_string_property(usb_device, kUSBSerialNumberString)\n                # We know this is a usb device, so the\n                # IORegistryEntryName should always be aliased to the\n                # usb product name string descriptor.\n                info.product = IORegistryEntryGetName(usb_device) or 'n/a'\n                info.manufacturer = get_string_property(usb_device, kUSBVendorString)\n                locationID = get_int_property(usb_device, \"locationID\", kCFNumberSInt32Type)\n                info.location = location_to_string(locationID)\n                info.interface = get_string_property(serial_interface, \"kUSBString\")\n                # \"kUSBString\" might not be available on older macOS ? who knows ?\n                if info.interface is None:\n                    info.interface = get_string_property(serial_interface, \"USB Interface Name\")\n                if info.interface is None:\n                    # macOS 10.13 or earlier, the interface name is not in the hierarchy\n                    # of the serial port, use the scan to find it out there\n                    if serial_interfaces is None:\n                        serial_interfaces = scan_interfaces()\n                    bInterfaceNumber = get_int_property(serial_interface, \"bInterfaceNumber\", kCFNumberSInt32Type)\n                    info.interface = search_in_interfaces(serial_interfaces, (locationID, bInterfaceNumber))\n                info.apply_usb_info()\n            ports.append(info)\n    return ports", "loc": 48}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_posix.py", "class_name": null, "function_name": "comports", "parameters": ["include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["devices.update", "glob.glob", "list_ports_common.ListPortInfo", "list_ports_common.list_links", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def comports(include_links=False):\n    devices = set(glob.glob('/dev/ttyS*'))\n    if include_links:\n        devices.update(list_ports_common.list_links(devices))\n    return [list_ports_common.ListPortInfo(d) for d in devices]", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_posix.py", "class_name": null, "function_name": "comports", "parameters": ["include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["devices.update", "glob.glob", "list_ports_common.ListPortInfo", "list_ports_common.list_links", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def comports(include_links=False):\n    devices = set(glob.glob('/dev/cua*'))\n    if include_links:\n        devices.update(list_ports_common.list_links(devices))\n    return [list_ports_common.ListPortInfo(d) for d in devices]", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_posix.py", "class_name": null, "function_name": "comports", "parameters": ["include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["devices.update", "glob.glob", "list_ports_common.ListPortInfo", "list_ports_common.list_links", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def comports(include_links=False):\n    devices = set(glob.glob('/dev/cua*[!.init][!.lock]'))\n    if include_links:\n        devices.update(list_ports_common.list_links(devices))\n    return [list_ports_common.ListPortInfo(d) for d in devices]", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_posix.py", "class_name": null, "function_name": "comports", "parameters": ["include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["devices.update", "glob.glob", "list_ports_common.ListPortInfo", "list_ports_common.list_links", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "scan for available ports. return a list of device names.", "source_code": "def comports(include_links=False):\n    \"\"\"scan for available ports. return a list of device names.\"\"\"\n    devices = set(glob.glob('/dev/dty*'))\n    if include_links:\n        devices.update(list_ports_common.list_links(devices))\n    return [list_ports_common.ListPortInfo(d) for d in devices]", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_posix.py", "class_name": null, "function_name": "comports", "parameters": ["include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["devices.update", "glob.glob", "list_ports_common.ListPortInfo", "list_ports_common.list_links", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "scan for available ports. return a list of device names.", "source_code": "def comports(include_links=False):\n    \"\"\"scan for available ports. return a list of device names.\"\"\"\n    devices = set(glob.glob('/dev/ttyf*'))\n    if include_links:\n        devices.update(list_ports_common.list_links(devices))\n    return [list_ports_common.ListPortInfo(d) for d in devices]", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_posix.py", "class_name": null, "function_name": "comports", "parameters": ["include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["devices.update", "glob.glob", "list_ports_common.ListPortInfo", "list_ports_common.list_links", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "scan for available ports. return a list of device names.", "source_code": "def comports(include_links=False):\n    \"\"\"scan for available ports. return a list of device names.\"\"\"\n    devices = set(glob.glob('/dev/tty*p0'))\n    if include_links:\n        devices.update(list_ports_common.list_links(devices))\n    return [list_ports_common.ListPortInfo(d) for d in devices]", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_posix.py", "class_name": null, "function_name": "comports", "parameters": ["include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["devices.update", "glob.glob", "list_ports_common.ListPortInfo", "list_ports_common.list_links", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "scan for available ports. return a list of device names.", "source_code": "def comports(include_links=False):\n    \"\"\"scan for available ports. return a list of device names.\"\"\"\n    devices = set(glob.glob('/dev/tty*c'))\n    if include_links:\n        devices.update(list_ports_common.list_links(devices))\n    return [list_ports_common.ListPortInfo(d) for d in devices]", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_posix.py", "class_name": null, "function_name": "comports", "parameters": ["include_links"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["devices.update", "glob.glob", "list_ports_common.ListPortInfo", "list_ports_common.list_links", "set"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "scan for available ports. return a list of device names.", "source_code": "def comports(include_links=False):\n    \"\"\"scan for available ports. return a list of device names.\"\"\"\n    devices = set(glob.glob('/dev/tty*'))\n    if include_links:\n        devices.update(list_ports_common.list_links(devices))\n    return [list_ports_common.ListPortInfo(d) for d in devices]", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": null, "function_name": "parse_device_property", "parameters": ["buffer", "buffer_size", "property_type"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'DEVPROPTYPE {} is not implemented!'.format", "NotImplementedError", "ctypes.POINTER", "ctypes.cast", "ctypes.wstring_at", "ctypes.wstring_at(buffer, buffer_size.value // 2).rstrip", "ctypes.wstring_at(buffer, buffer_size.value // 2).rstrip('\\x00').split"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parse_device_property(buffer, buffer_size, property_type):\n    if property_type.value == DEVPROP_TYPE_STRING:\n        return ctypes.wstring_at(buffer, buffer_size.value // 2 - 1)\n    if property_type.value == DEVPROP_TYPE_UINT32:\n        return ctypes.cast(buffer, ctypes.POINTER(ctypes.c_uint32)).contents.value\n    if property_type.value == DEVPROP_TYPE_STRING_LIST:\n        return ctypes.wstring_at(buffer, buffer_size.value // 2).rstrip('\\0').split('\\0')\n    if property_type.value == DEVPROP_TYPE_BINARY:\n        return buffer\n    raise NotImplementedError('DEVPROPTYPE {} is not implemented!'.format(property_type.value))", "loc": 10}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": null, "function_name": "iterate_comports", "parameters": ["cache_usb_info"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DeviceRegistry", "ListPortInfo", "PortDevice.enumerate_device", "device_registry.get_usb_info", "info.apply_usb_info", "port_device.port_name.startswith", "yielded_devices.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def iterate_comports(cache_usb_info=True):\n    # Enumerate and store all connected usb hubs.\n    device_registry = DeviceRegistry(cache_usb_info)\n\n    # Generate non-repeating serial devices.\n    yielded_devices = []\n\n    # Iterate through each serial device.\n    for port_device in PortDevice.enumerate_device():\n        if port_device in yielded_devices:\n            # Skip repeated serial device.\n            continue\n        yielded_devices.append(port_device)\n\n        # Skip parallel ports.\n        if port_device.port_name.startswith('LPT'):\n            continue\n\n        # Request usb information.\n        usb_info = device_registry.get_usb_info(port_device)\n\n        # Generate pyserial ListPortInfo\n        info = ListPortInfo(port_device.port_name, skip_link_detection=True)\n        if usb_info is None:\n            # usb_info may be None because some serial ports are not usb interfaces (e.g. virtual serial ports).\n            info.name = port_device.name\n            info.hwid = port_device.instance_identifier\n            info.manufacturer = port_device.manufacturer\n            info.description = port_device.description\n            info.interface = port_device.bus_reported_device_description\n        else:\n            info.name = port_device.name\n            info.pid = usb_info.pid\n            info.vid = usb_info.vid\n            info.product = usb_info.product\n            info.manufacturer = usb_info.manufacturer\n            info.serial_number = usb_info.serial_number\n            info.location = usb_info.location\n            info.interface = usb_info.interface\n            info.apply_usb_info()\n        yield info", "loc": 41}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceNode", "function_name": "status", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CM_Get_DevNode_Status", "ctypes.byref", "ctypes.c_uint32"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def status(self):\n    node_status = ctypes.c_uint32()\n    problem_number = ctypes.c_uint32()\n    cr = CM_Get_DevNode_Status(ctypes.byref(node_status), ctypes.byref(problem_number), self.__instance_handle, 0)\n    if cr != CR_SUCCESS:\n        return None\n    return node_status, problem_number", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceNode", "function_name": "parent", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CM_Get_Parent", "DeviceNode", "ctypes.byref", "ctypes.c_uint32"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def parent(self):\n    parent_instance_handle = ctypes.c_uint32()\n    cr = CM_Get_Parent(ctypes.byref(parent_instance_handle), self.__instance_handle, 0)\n    if cr != CR_SUCCESS:\n        return None\n    return DeviceNode(parent_instance_handle.value)", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceNode", "function_name": "power_data", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CM_POWER_DATA.from_buffer_copy", "self.get_property"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def power_data(self):\n    buffer = self.get_property(DEVPKEY_Device_PowerData)\n    if buffer is None:\n        return None\n    return CM_POWER_DATA.from_buffer_copy(buffer)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceNode", "function_name": "port_name", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CM_Open_DevNode_Key", "RegCloseKey", "RegQueryValueExW", "ctypes.byref", "ctypes.c_uint32", "ctypes.c_void_p", "ctypes.create_unicode_buffer"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def port_name(self):\n    hkey = ctypes.c_void_p()\n    cr = CM_Open_DevNode_Key(\n        self.__instance_handle,\n        KEY_READ,\n        0,\n        RegDisposition_OpenExisting,\n        ctypes.byref(hkey),\n        CM_REGISTRY_HARDWARE\n    )\n    if cr != CR_SUCCESS:\n        return None\n    buffer_size = ctypes.c_uint32()\n    status = RegQueryValueExW(\n        hkey,\n        \"PortName\",\n        None,\n        None,\n        None,\n        ctypes.byref(buffer_size)\n    )\n    if (status != ERROR_SUCCESS) and (status != ERROR_MORE_DATA):\n        return None\n    buffer = ctypes.create_unicode_buffer(buffer_size.value // 2)\n    status = RegQueryValueExW(\n        hkey,\n        \"PortName\",\n        None,\n        None,\n        buffer,\n        ctypes.byref(buffer_size)\n    )\n    if status != ERROR_SUCCESS:\n        return None\n    RegCloseKey(hkey)\n    return buffer.value", "loc": 36}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceNode", "function_name": "get_property", "parameters": ["self", "property_key"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CM_Get_DevNode_PropertyW", "ctypes.byref", "ctypes.c_uint32", "ctypes.create_string_buffer", "parse_device_property"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_property(self, property_key):\n    buffer_size = ctypes.c_uint32()\n    property_type = ctypes.c_uint32()\n    cr = CM_Get_DevNode_PropertyW(\n        self.__instance_handle,\n        ctypes.byref(property_key),\n        ctypes.byref(property_type),\n        None,\n        ctypes.byref(buffer_size),\n        0\n    )\n    if cr != CR_BUFFER_SMALL and cr != CR_SUCCESS:\n        return None\n    buffer = ctypes.create_string_buffer(buffer_size.value)\n    cr = CM_Get_DevNode_PropertyW(\n            self.__instance_handle,\n            ctypes.byref(property_key),\n            ctypes.byref(property_type),\n            buffer,\n            ctypes.byref(buffer_size),\n            0\n    )\n    if cr != CR_SUCCESS:\n        return None\n    return parse_device_property(buffer, buffer_size, property_type)", "loc": 25}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceInterface", "function_name": "enumerate_device", "parameters": ["cls"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CM_Get_Device_Interface_ListW", "CM_Get_Device_Interface_List_SizeW", "CM_MapCrToWin32Err", "cls", "ctypes.WinError", "ctypes.byref", "ctypes.c_uint32", "ctypes.create_unicode_buffer", "ctypes.sizeof", "ctypes.wstring_at", "null_terminated_list.rstrip", "null_terminated_list.rstrip('\\x00').split"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def enumerate_device(cls):\n    # Repeat for all possible GUIDs.\n    for guid in cls.guid_list:\n        device_interface_list_size = ctypes.c_uint32()\n        cr = CM_Get_Device_Interface_List_SizeW(\n            ctypes.byref(device_interface_list_size),\n            ctypes.byref(guid),\n            None,\n            CM_GET_DEVICE_INTERFACE_LIST_PRESENT\n        )\n        if cr != CR_SUCCESS:\n            raise ctypes.WinError(CM_MapCrToWin32Err(cr, 0))\n        if device_interface_list_size.value > 1:\n            device_interface_list = ctypes.create_unicode_buffer(device_interface_list_size.value)\n            cr = CM_Get_Device_Interface_ListW(\n                ctypes.byref(guid),\n                None,\n                device_interface_list,\n                ctypes.sizeof(device_interface_list),\n                CM_GET_DEVICE_INTERFACE_LIST_PRESENT\n            )\n            if cr != CR_SUCCESS:\n                raise ctypes.WinError(CM_MapCrToWin32Err(cr, 0))\n            null_terminated_list = ctypes.wstring_at(device_interface_list, device_interface_list_size.value)\n            for interface in null_terminated_list.rstrip('\\0').split('\\0'):\n                yield cls(interface)", "loc": 26}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceInterface", "function_name": "instance_handle", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CM_Locate_DevNodeW", "ctypes.byref", "ctypes.c_uint32"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def instance_handle(self):\n    instance_handle = ctypes.c_uint32()\n    cr = CM_Locate_DevNodeW(\n        ctypes.byref(instance_handle),\n        self.instance_identifier,\n        CM_LOCATE_DEVNODE_NORMAL\n    )\n    if cr != CR_SUCCESS:\n        return None\n    return instance_handle.value", "loc": 10}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceInterface", "function_name": "get_interface_property", "parameters": ["self", "property_key"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CM_Get_Device_Interface_PropertyW", "ctypes.byref", "ctypes.c_uint32", "ctypes.create_string_buffer", "parse_device_property"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_interface_property(self, property_key):\n    buffer_size = ctypes.c_uint32()\n    property_type = ctypes.c_uint32()\n    cr = CM_Get_Device_Interface_PropertyW(\n        self.__interface,\n        ctypes.byref(property_key),\n        ctypes.byref(property_type),\n        None,\n        ctypes.byref(buffer_size),\n        0\n    )\n    if cr != CR_BUFFER_SMALL and cr != CR_SUCCESS:\n        return None\n    buffer = ctypes.create_string_buffer(buffer_size.value)\n    cr = CM_Get_Device_Interface_PropertyW(\n            self.__interface,\n            ctypes.byref(property_key),\n            ctypes.byref(property_type),\n            buffer,\n            ctypes.byref(buffer_size),\n            0\n    )\n    if cr != CR_SUCCESS:\n        return None\n    return parse_device_property(buffer, buffer_size, property_type)", "loc": 25}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "PortDevice", "function_name": "wake_up_device", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CloseHandle", "CreateFileW"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def wake_up_device(self):\n    # Trigger the port to wake up the usb device.\n    port_handle = CreateFileW(\n        self.interface,\n        GENERIC_READ | GENERIC_WRITE,\n        0,\n        None,\n        OPEN_EXISTING,\n        FILE_ATTRIBUTE_NORMAL,\n        0\n    )\n    CloseHandle(port_handle)", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceRegistry", "function_name": "get_cache_key", "parameters": ["port_device", "usb_device"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["port_device.instance_identifier.casefold", "usb_device.location_paths[0].casefold"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_cache_key(port_device, usb_device):\n    # The cache key includes the device instance identifier and its location\n    cache_key = port_device.instance_identifier.casefold()\n    if usb_device.location_paths:\n        cache_key += usb_device.location_paths[0].casefold()\n    return cache_key", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceRegistry", "function_name": "get_location_string", "parameters": ["self", "usb_device", "usb_host_controller", "bConfigurationValue", "bInterfaceNumber"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "':{}.{}'.format", "g.group", "len", "location.append", "re.finditer", "self.get_bus_number", "str"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_location_string(self, usb_device, usb_host_controller, bConfigurationValue=None, bInterfaceNumber=None):\n    # <bus>-<port[.port[.port]]>:<config>.<interface>\n    location_paths = usb_device.location_paths\n    if not location_paths:\n        return None\n    if (bConfigurationValue is None) and (bInterfaceNumber is not None):\n        bConfigurationValue = 'x'\n    location = [str(self.get_bus_number(usb_host_controller))]\n    for g in re.finditer(r'#USB\\((\\w+)\\)', location_paths[0]):\n        if len(location) > 1:\n            location.append('.')\n        else:\n            location.append('-')\n        location.append(g.group(1))\n    if bInterfaceNumber is not None:\n        location.append(':{}.{}'.format(\n            bConfigurationValue,\n            bInterfaceNumber\n        ))\n    return ''.join(location)", "loc": 20}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "DeviceRegistry", "function_name": "get_bus_number", "parameters": ["self", "usb_host_controller"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.all_usb_host_controllers.index"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_bus_number(self, usb_host_controller):\n    try:\n        bus_number = self.all_usb_host_controllers.index(usb_host_controller) + 1\n    except ValueError:\n        bus_number = 0\n    return bus_number", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "USBHubDeviceIOControl", "function_name": "request_supported_languages", "parameters": ["self", "usb_hub_port"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DeviceIoControl", "ctypes.POINTER", "ctypes.byref", "ctypes.c_uint16.from_buffer", "ctypes.c_uint32", "ctypes.cast", "ctypes.create_string_buffer", "ctypes.sizeof", "languages.append", "range"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_supported_languages(self, usb_hub_port):\n    # Filling setup package.\n    description_request_buffer = ctypes.create_string_buffer(\n        ctypes.sizeof(USB_DESCRIPTOR_REQUEST) + ctypes.sizeof(USB_STRING_DESCRIPTOR)\n    )\n    description_request = ctypes.cast(description_request_buffer, ctypes.POINTER(USB_DESCRIPTOR_REQUEST))\n    description_request.contents.ConnectionIndex = usb_hub_port\n    description_request.contents.SetupPacket.wValue = USB_STRING_DESCRIPTOR_TYPE << 8\n    description_request.contents.SetupPacket.wIndex = 0\n    description_request.contents.SetupPacket.wLength = \\\n        ctypes.sizeof(description_request_buffer) - ctypes.sizeof(USB_DESCRIPTOR_REQUEST)\n\n    # Send string description request.\n    returned_size = ctypes.c_uint32()\n    if not DeviceIoControl(\n            self.device_handle,\n            IOCTL_USB_GET_DESCRIPTOR_FROM_NODE_CONNECTION,\n            description_request_buffer,\n            ctypes.sizeof(description_request_buffer),\n            description_request_buffer,\n            ctypes.sizeof(description_request_buffer),\n            ctypes.byref(returned_size),\n            None\n    ):\n        return None\n\n    # Parse string description from wstring buffer.\n    description = ctypes.cast(\n        ctypes.byref(description_request_buffer, ctypes.sizeof(USB_DESCRIPTOR_REQUEST)),\n        ctypes.POINTER(USB_STRING_DESCRIPTOR)\n    )\n\n    # Check size again\n    string_descriptor_size = returned_size.value - ctypes.sizeof(USB_DESCRIPTOR_REQUEST)\n    if string_descriptor_size != description.contents.bLength:\n        return None\n\n    # Parse available language id\n    available_language_id_count = (string_descriptor_size - 2) // 2\n    languages = []\n    for i in range(available_language_id_count):\n        languages.append(ctypes.c_uint16.from_buffer(\n            description_request_buffer,\n            ctypes.sizeof(USB_DESCRIPTOR_REQUEST) + i * 2 + 2\n        ).value)\n    return languages", "loc": 46}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "USBHubDeviceIOControl", "function_name": "suggest_language_id", "parameters": ["self", "usb_hub_port"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["GetUserDefaultLangID", "self.request_supported_languages"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def suggest_language_id(self, usb_hub_port):\n    available_languages = self.request_supported_languages(usb_hub_port)\n    if not available_languages:\n        return 0x0409\n    default_language = GetUserDefaultLangID()\n    if default_language in available_languages:\n        return default_language\n    else:\n        return available_languages[0]", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "USBHubDeviceIOControl", "function_name": "request_usb_string_description", "parameters": ["self", "usb_hub_port", "string_index", "langid"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DeviceIoControl", "ctypes.POINTER", "ctypes.byref", "ctypes.c_uint32", "ctypes.cast", "ctypes.create_string_buffer", "ctypes.sizeof", "ctypes.wstring_at", "ctypes.wstring_at(description.contents.bString, description.contents.bLength // 2 - 1).rstrip", "self.suggest_language_id"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_usb_string_description(self, usb_hub_port, string_index, langid=None):\n    if string_index == 0:\n        # There is no string description at this index.\n        return None\n\n    # Get a list of supported languages from index 0, and match langid to system default language.\n    if langid is None:\n        langid = self.suggest_language_id(usb_hub_port)\n\n    # Filling setup package.\n    description_request_buffer = \\\n        ctypes.create_string_buffer(ctypes.sizeof(USB_DESCRIPTOR_REQUEST) + ctypes.sizeof(USB_STRING_DESCRIPTOR))\n    description_request = ctypes.cast(description_request_buffer, ctypes.POINTER(USB_DESCRIPTOR_REQUEST))\n    description_request.contents.ConnectionIndex = usb_hub_port\n    description_request.contents.SetupPacket.wValue = (USB_STRING_DESCRIPTOR_TYPE << 8) | string_index\n    description_request.contents.SetupPacket.wIndex = langid\n    description_request.contents.SetupPacket.wLength = \\\n        ctypes.sizeof(description_request_buffer) - ctypes.sizeof(USB_DESCRIPTOR_REQUEST)\n\n    # Send string description request.\n    returned_size = ctypes.c_uint32()\n    if not DeviceIoControl(\n            self.device_handle,\n            IOCTL_USB_GET_DESCRIPTOR_FROM_NODE_CONNECTION,\n            description_request_buffer,\n            ctypes.sizeof(description_request_buffer),\n            description_request_buffer,\n            ctypes.sizeof(description_request_buffer),\n            ctypes.byref(returned_size),\n            None\n    ):\n        return None\n\n    # Parse string description from wstring buffer.\n    description = ctypes.cast(\n        ctypes.byref(description_request_buffer, ctypes.sizeof(USB_DESCRIPTOR_REQUEST)),\n        ctypes.POINTER(USB_STRING_DESCRIPTOR)\n    )\n\n    # Convert wstring to python str.\n    # Very few devices will have an extra null at the end of string, strip it.\n    return ctypes.wstring_at(description.contents.bString, description.contents.bLength // 2 - 1).rstrip('\\0')", "loc": 42}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "USBHubDeviceIOControl", "function_name": "request_usb_device_description", "parameters": ["self", "usb_hub_port"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DeviceIoControl", "USB_DEVICE_DESCRIPTOR.from_buffer_copy", "ctypes.POINTER", "ctypes.byref", "ctypes.c_uint32", "ctypes.cast", "ctypes.create_string_buffer", "ctypes.sizeof"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_usb_device_description(self, usb_hub_port):\n    # Filling setup package for requesting device description.\n    device_description_request_buffer = ctypes.create_string_buffer(\n        ctypes.sizeof(USB_DESCRIPTOR_REQUEST) + ctypes.sizeof(USB_DEVICE_DESCRIPTOR)\n    )\n    device_description_request = ctypes.cast(\n        device_description_request_buffer,\n        ctypes.POINTER(USB_DESCRIPTOR_REQUEST)\n    )\n    device_description_request.contents.ConnectionIndex = usb_hub_port\n    device_description_request.contents.SetupPacket.bmRequest = 0x80\n    device_description_request.contents.SetupPacket.bRequest = USB_REQUEST_GET_DESCRIPTOR\n    device_description_request.contents.SetupPacket.wValue = USB_DEVICE_DESCRIPTOR_TYPE << 8\n    device_description_request.contents.SetupPacket.wLength = ctypes.sizeof(USB_DEVICE_DESCRIPTOR)\n\n    # Send usb device description request.\n    returned_size = ctypes.c_uint32()\n    if not DeviceIoControl(\n            self.device_handle,\n            IOCTL_USB_GET_DESCRIPTOR_FROM_NODE_CONNECTION,\n            device_description_request_buffer,\n            ctypes.sizeof(device_description_request_buffer),\n            device_description_request_buffer,\n            ctypes.sizeof(device_description_request_buffer),\n            ctypes.byref(returned_size),\n            None\n    ):\n        return None\n\n    # Get device description.\n    return USB_DEVICE_DESCRIPTOR.from_buffer_copy(\n        device_description_request_buffer,\n        ctypes.sizeof(USB_DESCRIPTOR_REQUEST)\n    )", "loc": 34}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "USBHubDeviceIOControl", "function_name": "request_usb_configuration_description", "parameters": ["self", "usb_hub_port", "bConfigurationValue"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DeviceIoControl", "USB_CONFIGURATION_DESCRIPTOR.from_buffer_copy", "ctypes.POINTER", "ctypes.byref", "ctypes.c_uint32", "ctypes.cast", "ctypes.create_string_buffer", "ctypes.sizeof"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_usb_configuration_description(self, usb_hub_port, bConfigurationValue):\n    # Filling setup package for requesting configuration description.\n    configuration_description_request_buffer = ctypes.create_string_buffer(\n        ctypes.sizeof(USB_DESCRIPTOR_REQUEST) + ctypes.sizeof(USB_CONFIGURATION_DESCRIPTOR)\n    )\n    configuration_description_request = ctypes.cast(\n        configuration_description_request_buffer,\n        ctypes.POINTER(USB_DESCRIPTOR_REQUEST)\n    )\n    configuration_description_request.contents.ConnectionIndex = usb_hub_port\n    configuration_description_request.contents.SetupPacket.bmRequest = 0x80\n    configuration_description_request.contents.SetupPacket.bRequest = USB_REQUEST_GET_DESCRIPTOR\n    configuration_description_request.contents.SetupPacket.wValue = \\\n        (USB_CONFIGURATION_DESCRIPTOR_TYPE << 8) | (bConfigurationValue - 1)\n    configuration_description_request.contents.SetupPacket.wLength = ctypes.sizeof(USB_CONFIGURATION_DESCRIPTOR)\n\n    # Send usb configuration description request.\n    returned_size = ctypes.c_uint32()\n    if not DeviceIoControl(\n            self.device_handle,\n            IOCTL_USB_GET_DESCRIPTOR_FROM_NODE_CONNECTION,\n            configuration_description_request_buffer,\n            ctypes.sizeof(configuration_description_request_buffer),\n            configuration_description_request_buffer,\n            ctypes.sizeof(configuration_description_request_buffer),\n            ctypes.byref(returned_size),\n            None\n    ):\n        return None\n\n    # Get configuration description.\n    return USB_CONFIGURATION_DESCRIPTOR.from_buffer_copy(\n        configuration_description_request_buffer,\n        ctypes.sizeof(USB_DESCRIPTOR_REQUEST)\n    )", "loc": 35}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\list_ports_windows.py", "class_name": "USBHubDeviceIOControl", "function_name": "request_usb_connection_info", "parameters": ["self", "usb_hub_port"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DeviceIoControl", "USB_NODE_CONNECTION_INFORMATION_EX", "ctypes.byref", "ctypes.c_uint32", "ctypes.sizeof"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def request_usb_connection_info(self, usb_hub_port):\n    connection_info = USB_NODE_CONNECTION_INFORMATION_EX()\n    connection_info.ConnectionIndex = usb_hub_port\n    returned_size = ctypes.c_uint32()\n    if not DeviceIoControl(\n            self.device_handle,\n            IOCTL_USB_GET_NODE_CONNECTION_INFORMATION_EX,\n            ctypes.byref(connection_info),\n            ctypes.sizeof(USB_NODE_CONNECTION_INFORMATION_EX),\n            ctypes.byref(connection_info),\n            ctypes.sizeof(USB_NODE_CONNECTION_INFORMATION_EX),\n            ctypes.byref(returned_size),\n            None\n    ):\n        return None\n    return connection_info", "loc": 16}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": null, "function_name": "key_description", "parameters": ["character"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'Ctrl+{:c}'.format", "ord", "repr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "generate a readable description for a key", "source_code": "def key_description(character):\n    \"\"\"generate a readable description for a key\"\"\"\n    ascii_code = ord(character)\n    if ascii_code < 32:\n        return 'Ctrl+{:c}'.format(ord('@') + ascii_code)\n    else:\n        return repr(character)", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": null, "function_name": "ask_for_port", "parameters": [], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'--- {:2}: {:20} {!r}\\n'.format", "comports", "enumerate", "int", "len", "ports.append", "raw_input", "sorted", "sys.stderr.write"], "control_structures": ["For", "If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Show a list of ports and ask the user for a choice. To make selection easier on systems with long device names, also allow the input of an index.", "source_code": "def ask_for_port():\n    \"\"\"\\\n    Show a list of ports and ask the user for a choice. To make selection\n    easier on systems with long device names, also allow the input of an\n    index.\n    \"\"\"\n    sys.stderr.write('\\n--- Available ports:\\n')\n    ports = []\n    for n, (port, desc, hwid) in enumerate(sorted(comports()), 1):\n        sys.stderr.write('--- {:2}: {:20} {!r}\\n'.format(n, port, desc))\n        ports.append(port)\n    while True:\n        sys.stderr.write('--- Enter port index or full name: ')\n        port = raw_input('')\n        try:\n            index = int(port) - 1\n            if not 0 <= index < len(ports):\n                sys.stderr.write('--- Invalid index!\\n')\n                continue\n        except ValueError:\n            pass\n        else:\n            port = ports[index]\n        return port", "loc": 24}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Printable", "function_name": "rx", "parameters": ["self", "text"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "'{:d}'.format", "ord", "r.append", "r.extend", "unichr"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def rx(self, text):\n    r = []\n    for c in text:\n        if ' ' <= c < '\\x7f' or c in '\\r\\n\\b\\t':\n            r.append(c)\n        elif c < ' ':\n            r.append(unichr(0x2400 + ord(c)))\n        else:\n            r.extend(unichr(0x2080 + ord(d) - 48) for d in '{:d}'.format(ord(c)))\n            r.append(' ')\n    return ''.join(r)", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "start", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._start_reader", "self.console.setup", "self.transmitter_thread.start", "threading.Thread"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "start worker threads", "source_code": "def start(self):\n    \"\"\"start worker threads\"\"\"\n    self.alive = True\n    self._start_reader()\n    # enter console->serial loop\n    self.transmitter_thread = threading.Thread(target=self.writer, name='tx')\n    self.transmitter_thread.daemon = True\n    self.transmitter_thread.start()\n    self.console.setup()", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "join", "parameters": ["self", "transmit_only"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["hasattr", "self.receiver_thread.join", "self.serial.cancel_read", "self.transmitter_thread.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "wait for worker threads to terminate", "source_code": "def join(self, transmit_only=False):\n    \"\"\"wait for worker threads to terminate\"\"\"\n    self.transmitter_thread.join()\n    if not transmit_only:\n        if hasattr(self.serial, 'cancel_read'):\n            self.serial.cancel_read()\n        self.receiver_thread.join()", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "update_transformations", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["list", "reversed", "t"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "take list of transformation classes and instantiate them for rx and tx", "source_code": "def update_transformations(self):\n    \"\"\"take list of transformation classes and instantiate them for rx and tx\"\"\"\n    transformations = [EOL_TRANSFORMATIONS[self.eol]] + [TRANSFORMATIONS[f]\n                                                         for f in self.filters]\n    self.tx_transformations = [t() for t in transformations]\n    self.rx_transformations = list(reversed(self.tx_transformations))", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "dump_port_settings", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "'--- CTS: {:8}  DSR: {:8}  RI: {:8}  CD: {:8}\\n'.format", "'--- EOL: {}\\n'.format", "'--- RTS: {:8}  DTR: {:8}  BREAK: {:8}\\n'.format", "'--- filters: {}\\n'.format", "'--- hardware flow control: {}\\n'.format", "'--- serial input encoding: {}\\n'.format", "'--- serial output encoding: {}\\n'.format", "'--- software flow control: {}\\n'.format", "'\\n--- Settings: {p.name}  {p.baudrate},{p.bytesize},{p.parity},{p.stopbits}\\n'.format", "self.eol.upper", "sys.stderr.write"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "Write current settings to sys.stderr", "source_code": "def dump_port_settings(self):\n    \"\"\"Write current settings to sys.stderr\"\"\"\n    sys.stderr.write(\"\\n--- Settings: {p.name}  {p.baudrate},{p.bytesize},{p.parity},{p.stopbits}\\n\".format(\n        p=self.serial))\n    sys.stderr.write('--- RTS: {:8}  DTR: {:8}  BREAK: {:8}\\n'.format(\n        ('active' if self.serial.rts else 'inactive'),\n        ('active' if self.serial.dtr else 'inactive'),\n        ('active' if self.serial.break_condition else 'inactive')))\n    try:\n        sys.stderr.write('--- CTS: {:8}  DSR: {:8}  RI: {:8}  CD: {:8}\\n'.format(\n            ('active' if self.serial.cts else 'inactive'),\n            ('active' if self.serial.dsr else 'inactive'),\n            ('active' if self.serial.ri else 'inactive'),\n            ('active' if self.serial.cd else 'inactive')))\n    except serial.SerialException:\n        # on RFC 2217 ports, it can happen if no modem state notification was\n        # yet received. ignore this error.\n        pass\n    sys.stderr.write('--- software flow control: {}\\n'.format('active' if self.serial.xonxoff else 'inactive'))\n    sys.stderr.write('--- hardware flow control: {}\\n'.format('active' if self.serial.rtscts else 'inactive'))\n    sys.stderr.write('--- serial input encoding: {}\\n'.format(self.input_encoding))\n    sys.stderr.write('--- serial output encoding: {}\\n'.format(self.output_encoding))\n    sys.stderr.write('--- EOL: {}\\n'.format(self.eol.upper()))\n    sys.stderr.write('--- filters: {}\\n'.format(' '.join(self.filters)))", "loc": 24}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "reader", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.console.cancel", "self.console.write", "self.console.write_bytes", "self.rx_decoder.decode", "self.serial.read", "transformation.rx"], "control_structures": ["For", "If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "loop and copy serial->console", "source_code": "def reader(self):\n    \"\"\"loop and copy serial->console\"\"\"\n    try:\n        while self.alive and self._reader_alive:\n            # read all that is there or wait for one byte\n            data = self.serial.read(self.serial.in_waiting or 1)\n            if data:\n                if self.raw:\n                    self.console.write_bytes(data)\n                else:\n                    text = self.rx_decoder.decode(data)\n                    for transformation in self.rx_transformations:\n                        text = transformation.rx(text)\n                    self.console.write(text)\n    except serial.SerialException:\n        self.alive = False\n        self.console.cancel()\n        raise       # XXX handle instead of re-raise?", "loc": 18}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "writer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.console.getkey", "self.console.write", "self.handle_menu_key", "self.serial.write", "self.stop", "self.tx_encoder.encode", "transformation.echo", "transformation.tx"], "control_structures": ["For", "If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Loop and copy console->serial until self.exit_character character is found. When self.menu_character is found, interpret the next key locally.", "source_code": "def writer(self):\n    \"\"\"\\\n    Loop and copy console->serial until self.exit_character character is\n    found. When self.menu_character is found, interpret the next key\n    locally.\n    \"\"\"\n    menu_active = False\n    try:\n        while self.alive:\n            try:\n                c = self.console.getkey()\n            except KeyboardInterrupt:\n                c = '\\x03'\n            if not self.alive:\n                break\n            if menu_active:\n                self.handle_menu_key(c)\n                menu_active = False\n            elif c == self.menu_character:\n                menu_active = True      # next char will be for menu\n            elif c == self.exit_character:\n                self.stop()             # exit app\n                break\n            else:\n                #~ if self.raw:\n                text = c\n                for transformation in self.tx_transformations:\n                    text = transformation.tx(text)\n                self.serial.write(self.tx_encoder.encode(text))\n                if self.echo:\n                    echo_text = c\n                    for transformation in self.tx_transformations:\n                        echo_text = transformation.echo(echo_text)\n                    self.console.write(echo_text)\n    except:\n        self.alive = False\n        raise", "loc": 37}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "handle_menu_key", "parameters": ["self", "c"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'--- BREAK {} ---\\n'.format", "'--- DTR {} ---\\n'.format", "'--- EOL: {} ---\\n'.format", "'--- RTS {} ---\\n'.format", "'--- local echo {} ---\\n'.format", "'--- unknown menu character {} --\\n'.format", "key_description", "len", "list", "modes.index", "self.change_baudrate", "self.change_encoding", "self.change_filter", "self.change_port", "self.console.write", "self.dump_port_settings", "self.eol.upper", "self.get_help_text", "self.serial.write", "self.stop", "self.suspend_port", "self.tx_encoder.encode", "self.update_transformations", "self.upload_file", "sys.stderr.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Implement a simple menu / settings", "source_code": "def handle_menu_key(self, c):\n    \"\"\"Implement a simple menu / settings\"\"\"\n    if c == self.menu_character or c == self.exit_character:\n        # Menu/exit character again -> send itself\n        self.serial.write(self.tx_encoder.encode(c))\n        if self.echo:\n            self.console.write(c)\n    elif c == '\\x15':                       # CTRL+U -> upload file\n        self.upload_file()\n    elif c in '\\x08hH?':                    # CTRL+H, h, H, ? -> Show help\n        sys.stderr.write(self.get_help_text())\n    elif c == '\\x12':                       # CTRL+R -> Toggle RTS\n        self.serial.rts = not self.serial.rts\n        sys.stderr.write('--- RTS {} ---\\n'.format('active' if self.serial.rts else 'inactive'))\n    elif c == '\\x04':                       # CTRL+D -> Toggle DTR\n        self.serial.dtr = not self.serial.dtr\n        sys.stderr.write('--- DTR {} ---\\n'.format('active' if self.serial.dtr else 'inactive'))\n    elif c == '\\x02':                       # CTRL+B -> toggle BREAK condition\n        self.serial.break_condition = not self.serial.break_condition\n        sys.stderr.write('--- BREAK {} ---\\n'.format('active' if self.serial.break_condition else 'inactive'))\n    elif c == '\\x05':                       # CTRL+E -> toggle local echo\n        self.echo = not self.echo\n        sys.stderr.write('--- local echo {} ---\\n'.format('active' if self.echo else 'inactive'))\n    elif c == '\\x06':                       # CTRL+F -> edit filters\n        self.change_filter()\n    elif c == '\\x0c':                       # CTRL+L -> EOL mode\n        modes = list(EOL_TRANSFORMATIONS)   # keys\n        eol = modes.index(self.eol) + 1\n        if eol >= len(modes):\n            eol = 0\n        self.eol = modes[eol]\n        sys.stderr.write('--- EOL: {} ---\\n'.format(self.eol.upper()))\n        self.update_transformations()\n    elif c == '\\x01':                       # CTRL+A -> set encoding\n        self.change_encoding()\n    elif c == '\\x09':                       # CTRL+I -> info\n        self.dump_port_settings()\n    #~ elif c == '\\x01':                       # CTRL+A -> cycle escape mode\n    #~ elif c == '\\x0c':                       # CTRL+L -> cycle linefeed mode\n    elif c in 'pP':                         # P -> change port\n        self.change_port()\n    elif c in 'zZ':                         # S -> suspend / open port temporarily\n        self.suspend_port()\n    elif c in 'bB':                         # B -> change baudrate\n        self.change_baudrate()\n    elif c == '8':                          # 8 -> change to 8 bits\n        self.serial.bytesize = serial.EIGHTBITS\n        self.dump_port_settings()\n    elif c == '7':                          # 7 -> change to 8 bits\n        self.serial.bytesize = serial.SEVENBITS\n        self.dump_port_settings()\n    elif c in 'eE':                         # E -> change to even parity\n        self.serial.parity = serial.PARITY_EVEN\n        self.dump_port_settings()\n    elif c in 'oO':                         # O -> change to odd parity\n        self.serial.parity = serial.PARITY_ODD\n        self.dump_port_settings()\n    elif c in 'mM':                         # M -> change to mark parity\n        self.serial.parity = serial.PARITY_MARK\n        self.dump_port_settings()\n    elif c in 'sS':                         # S -> change to space parity\n        self.serial.parity = serial.PARITY_SPACE\n        self.dump_port_settings()\n    elif c in 'nN':                         # N -> change to no parity\n        self.serial.parity = serial.PARITY_NONE\n        self.dump_port_settings()\n    elif c == '1':                          # 1 -> change to 1 stop bits\n        self.serial.stopbits = serial.STOPBITS_ONE\n        self.dump_port_settings()\n    elif c == '2':                          # 2 -> change to 2 stop bits\n        self.serial.stopbits = serial.STOPBITS_TWO\n        self.dump_port_settings()\n    elif c == '3':                          # 3 -> change to 1.5 stop bits\n        self.serial.stopbits = serial.STOPBITS_ONE_POINT_FIVE\n        self.dump_port_settings()\n    elif c in 'xX':                         # X -> change software flow control\n        self.serial.xonxoff = (c == 'X')\n        self.dump_port_settings()\n    elif c in 'rR':                         # R -> change hardware flow control\n        self.serial.rtscts = (c == 'R')\n        self.dump_port_settings()\n    elif c in 'qQ':\n        self.stop()                         # Q -> exit app\n    else:\n        sys.stderr.write('--- unknown menu character {} --\\n'.format(key_description(c)))", "loc": 85}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "change_filter", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "'---   {:<10} = {.__doc__}'.format", "'--- filters: {}\\n'.format", "'--- unknown filter: {!r}\\n'.format", "'\\n'.join", "'\\n--- Enter new filter name(s) [{}]: '.format", "TRANSFORMATIONS.items", "self.update_transformations", "sorted", "sys.stderr.write", "sys.stdin.readline", "sys.stdin.readline().lower", "sys.stdin.readline().lower().split"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "change the i/o transformations", "source_code": "def change_filter(self):\n    \"\"\"change the i/o transformations\"\"\"\n    sys.stderr.write('\\n--- Available Filters:\\n')\n    sys.stderr.write('\\n'.join(\n        '---   {:<10} = {.__doc__}'.format(k, v)\n        for k, v in sorted(TRANSFORMATIONS.items())))\n    sys.stderr.write('\\n--- Enter new filter name(s) [{}]: '.format(' '.join(self.filters)))\n    with self.console:\n        new_filters = sys.stdin.readline().lower().split()\n    if new_filters:\n        for f in new_filters:\n            if f not in TRANSFORMATIONS:\n                sys.stderr.write('--- unknown filter: {!r}\\n'.format(f))\n                break\n        else:\n            self.filters = new_filters\n            self.update_transformations()\n    sys.stderr.write('--- filters: {}\\n'.format(' '.join(self.filters)))", "loc": 18}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "change_encoding", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'--- invalid encoding name: {}\\n'.format", "'--- serial input encoding: {}\\n'.format", "'--- serial output encoding: {}\\n'.format", "'\\n--- Enter new encoding name [{}]: '.format", "codecs.lookup", "self.set_rx_encoding", "self.set_tx_encoding", "sys.stderr.write", "sys.stdin.readline", "sys.stdin.readline().strip"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "change encoding on the serial port", "source_code": "def change_encoding(self):\n    \"\"\"change encoding on the serial port\"\"\"\n    sys.stderr.write('\\n--- Enter new encoding name [{}]: '.format(self.input_encoding))\n    with self.console:\n        new_encoding = sys.stdin.readline().strip()\n    if new_encoding:\n        try:\n            codecs.lookup(new_encoding)\n        except LookupError:\n            sys.stderr.write('--- invalid encoding name: {}\\n'.format(new_encoding))\n        else:\n            self.set_rx_encoding(new_encoding)\n            self.set_tx_encoding(new_encoding)\n    sys.stderr.write('--- serial input encoding: {}\\n'.format(self.input_encoding))\n    sys.stderr.write('--- serial output encoding: {}\\n'.format(self.output_encoding))", "loc": 15}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "change_baudrate", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'--- ERROR setting baudrate: {} ---\\n'.format", "int", "self.dump_port_settings", "sys.stderr.flush", "sys.stderr.write", "sys.stdin.readline", "sys.stdin.readline().strip"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "change the baudrate", "source_code": "def change_baudrate(self):\n    \"\"\"change the baudrate\"\"\"\n    sys.stderr.write('\\n--- Baudrate: ')\n    sys.stderr.flush()\n    with self.console:\n        backup = self.serial.baudrate\n        try:\n            self.serial.baudrate = int(sys.stdin.readline().strip())\n        except ValueError as e:\n            sys.stderr.write('--- ERROR setting baudrate: {} ---\\n'.format(e))\n            self.serial.baudrate = backup\n        else:\n            self.dump_port_settings()", "loc": 13}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Miniterm", "function_name": "get_help_text", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'\\n--- pySerial ({version}) - miniterm - help\\n---\\n--- {exit:8} Exit program (alias {menu} Q)\\n--- {menu:8} Menu escape key, followed by:\\n--- Menu keys:\\n---    {menu:7} Send the menu character itself to remote\\n---    {exit:7} Send the exit character itself to remote\\n---    {info:7} Show info\\n---    {upload:7} Upload file (prompt will be shown)\\n---    {repr:7} encoding\\n---    {filter:7} edit filters\\n--- Toggles:\\n---    {rts:7} RTS   {dtr:7} DTR   {brk:7} BREAK\\n---    {echo:7} echo  {eol:7} EOL\\n---\\n--- Port settings ({menu} followed by the following):\\n---    p          change port\\n---    7 8        set data bits\\n---    N E O S M  change parity (None, Even, Odd, Space, Mark)\\n---    1 2 3      set stop bits (1, 2, 1.5)\\n---    b          change baud rate\\n---    x X        disable/enable software flow control\\n---    r R        disable/enable hardware flow control\\n'.format", "getattr", "key_description"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "return the help text", "source_code": "    def get_help_text(self):\n        \"\"\"return the help text\"\"\"\n        # help text, starts with blank line!\n        return \"\"\"\n--- pySerial ({version}) - miniterm - help\n---\n--- {exit:8} Exit program (alias {menu} Q)\n--- {menu:8} Menu escape key, followed by:\n--- Menu keys:\n---    {menu:7} Send the menu character itself to remote\n---    {exit:7} Send the exit character itself to remote\n---    {info:7} Show info\n---    {upload:7} Upload file (prompt will be shown)\n---    {repr:7} encoding\n---    {filter:7} edit filters\n--- Toggles:\n---    {rts:7} RTS   {dtr:7} DTR   {brk:7} BREAK\n---    {echo:7} echo  {eol:7} EOL\n---\n--- Port settings ({menu} followed by the following):\n---    p          change port\n---    7 8        set data bits\n---    N E O S M  change parity (None, Even, Odd, Space, Mark)\n---    1 2 3      set stop bits (1, 2, 1.5)\n---    b          change baud rate\n---    x X        disable/enable software flow control\n---    r R        disable/enable hardware flow control\n\"\"\".format(version=getattr(serial, 'VERSION', 'unknown version'),\n           exit=key_description(self.exit_character),\n           menu=key_description(self.menu_character),\n           rts=key_description('\\x12'),\n           dtr=key_description('\\x04'),\n           brk=key_description('\\x02'),\n           echo=key_description('\\x05'),\n           info=key_description('\\x09'),\n           upload=key_description('\\x15'),\n           repr=key_description('\\x01'),\n           filter=key_description('\\x06'),\n           eol=key_description('\\x0c'))", "loc": 39}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Console", "function_name": "getkey", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["msvcrt.getwch", "unichr"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def getkey(self):\n    while True:\n        z = msvcrt.getwch()\n        if z == unichr(13):\n            return unichr(10)\n        elif z is unichr(0) or z is unichr(0xe0):\n            try:\n                code = msvcrt.getwch()\n                if z is unichr(0):\n                    return self.fncodes[code]\n                else:\n                    return self.navcodes[code]\n            except KeyError:\n                pass\n        else:\n            return z", "loc": 16}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Console", "function_name": "cancel", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ctypes.windll.kernel32.GetConsoleWindow", "ctypes.windll.user32.PostMessageA"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def cancel(self):\n    # CancelIo, CancelSynchronousIo do not seem to work when using\n    # getwch, so instead, send a key to the window with the console\n    hwnd = ctypes.windll.kernel32.GetConsoleWindow()\n    ctypes.windll.user32.PostMessageA(hwnd, 0x100, 0x0d, 0)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Console", "function_name": "setup", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["termios.tcgetattr", "termios.tcsetattr"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def setup(self):\n    new = termios.tcgetattr(self.fd)\n    new[3] = new[3] & ~termios.ICANON & ~termios.ECHO & ~termios.ISIG\n    new[6][termios.VMIN] = 1\n    new[6][termios.VTIME] = 0\n    termios.tcsetattr(self.fd, termios.TCSANOW, new)", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\tools\\miniterm.py", "class_name": "Console", "function_name": "getkey", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.enc_stdin.read", "unichr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def getkey(self):\n    c = self.enc_stdin.read(1)\n    if c == unichr(0x7f):\n        c = unichr(8)    # map the BS key (which yields DEL) to backspace\n    return c", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_alt.py", "class_name": null, "function_name": "serial_class_for_url", "parameters": ["url"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["''.join", "'class {!r} is not an instance of Serial'.format", "'expected a string in the form \"alt://port[?option[=value][&option[=value]]]\": not starting with alt:// ({!r})'.format", "'expected a string in the form \"alt://port[?option[=value][&option[=value]]]\": {!r}'.format", "'unknown class: {!r}'.format", "'unknown option: {!r}'.format", "ValueError", "getattr", "hasattr", "issubclass", "serial.SerialException", "urlparse.parse_qs", "urlparse.parse_qs(parts.query, True).items", "urlparse.urlsplit"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "extract host and port from an URL string", "source_code": "def serial_class_for_url(url):\n    \"\"\"extract host and port from an URL string\"\"\"\n    parts = urlparse.urlsplit(url)\n    if parts.scheme != 'alt':\n        raise serial.SerialException(\n            'expected a string in the form \"alt://port[?option[=value][&option[=value]]]\": '\n            'not starting with alt:// ({!r})'.format(parts.scheme))\n    class_name = 'Serial'\n    try:\n        for option, values in urlparse.parse_qs(parts.query, True).items():\n            if option == 'class':\n                class_name = values[0]\n            else:\n                raise ValueError('unknown option: {!r}'.format(option))\n    except ValueError as e:\n        raise serial.SerialException(\n            'expected a string in the form '\n            '\"alt://port[?option[=value][&option[=value]]]\": {!r}'.format(e))\n    if not hasattr(serial, class_name):\n        raise ValueError('unknown class: {!r}'.format(class_name))\n    cls = getattr(serial, class_name)\n    if not issubclass(cls, serial.Serial):\n        raise ValueError('class {!r} is not an instance of Serial'.format(class_name))\n    return (''.join([parts.netloc, parts.path]), cls)", "loc": 24}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_cp2110.py", "class_name": "Serial", "function_name": "from_url", "parameters": ["self", "url"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'expected a string in the forms \"cp2110:///dev/hidraw9\" or \"cp2110://0001:0023:00\": not starting with cp2110:// {{!r}}'.format", "SerialException", "parts.netloc.encode", "parts.path.encode", "urlparse.urlsplit"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def from_url(self, url):\n    parts = urlparse.urlsplit(url)\n    if parts.scheme != \"cp2110\":\n        raise SerialException(\n            'expected a string in the forms '\n            '\"cp2110:///dev/hidraw9\" or \"cp2110://0001:0023:00\": '\n            'not starting with cp2110:// {{!r}}'.format(parts.scheme))\n    if parts.netloc:  # cp2100://BUS:DEVICE:ENDPOINT, for libusb\n        return parts.netloc.encode('utf-8')\n    return parts.path.encode('utf-8')", "loc": 10}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_cp2110.py", "class_name": "Serial", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._hid_handle.close", "self._thread.join"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self):\n    self.is_open = False\n    if self._thread:\n        self._thread.join(1)  # read timeout is 0.1\n        self._thread = None\n    self._hid_handle.close()\n    self._hid_handle = None", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_cp2110.py", "class_name": "Serial", "function_name": "reset_input_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "bytes", "self._hid_handle.send_feature_report", "self._read_buffer.get", "self._read_buffer.qsize"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def reset_input_buffer(self):\n    if not self.is_open:\n        raise PortNotOpenError()\n    self._hid_handle.send_feature_report(\n        bytes((_REPORT_SET_PURGE_FIFOS, _PURGE_RX_FIFO)))\n    # empty read buffer\n    while self._read_buffer.qsize():\n        self._read_buffer.get(False)", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_cp2110.py", "class_name": "Serial", "function_name": "reset_output_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "bytes", "self._hid_handle.send_feature_report"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def reset_output_buffer(self):\n    if not self.is_open:\n        raise PortNotOpenError()\n    self._hid_handle.send_feature_report(\n        bytes((_REPORT_SET_PURGE_FIFOS, _PURGE_TX_FIFO)))", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_cp2110.py", "class_name": "Serial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "SerialException", "Timeout", "bytearray", "bytes", "len", "self._read_buffer.get", "timeout.expired", "timeout.time_left"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read(self, size=1):\n    if not self.is_open:\n        raise PortNotOpenError()\n\n    data = bytearray()\n    try:\n        timeout = Timeout(self._timeout)\n        while len(data) < size:\n            if self._thread is None:\n                raise SerialException('connection failed (reader thread died)')\n            buf = self._read_buffer.get(True, timeout.time_left())\n            if buf is None:\n                return bytes(data)\n            data += buf\n            if timeout.expired():\n                break\n    except Queue.Empty:  # -> timeout\n        pass\n    return bytes(data)", "loc": 19}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_cp2110.py", "class_name": "Serial", "function_name": "write", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "len", "min", "self._hid_handle.write", "to_bytes"], "control_structures": ["If", "While"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def write(self, data):\n    if not self.is_open:\n        raise PortNotOpenError()\n    data = to_bytes(data)\n    tx_len = len(data)\n    while tx_len > 0:\n        to_be_sent = min(tx_len, 0x3F)\n        report = to_bytes([to_be_sent]) + data[:to_be_sent]\n        self._hid_handle.write(report)\n\n        data = data[to_be_sent:]\n        tx_len = len(data)", "loc": 12}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_hwgrep.py", "class_name": "Serial", "function_name": "port", "parameters": ["self", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self.from_url", "serial.Serial.port.__set__", "value.startswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "translate port name before storing it", "source_code": "def port(self, value):\n    \"\"\"translate port name before storing it\"\"\"\n    if isinstance(value, basestring) and value.startswith('hwgrep://'):\n        serial.Serial.port.__set__(self, self.from_url(value))\n    else:\n        serial.Serial.port.__set__(self, value)", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_hwgrep.py", "class_name": "Serial", "function_name": "from_url", "parameters": ["self", "url"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'no ports found matching regexp {!r}'.format", "'option \"n\" expects a positive integer larger than 1: {!r}'.format", "'unknown option: {!r}'.format", "ValueError", "arg.split", "args.pop", "int", "s.close", "serial.Serial", "serial.SerialException", "serial.tools.list_ports.grep", "sorted", "url.lower", "url.lower().startswith", "url.split"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "extract host and port from an URL string", "source_code": "def from_url(self, url):\n    \"\"\"extract host and port from an URL string\"\"\"\n    if url.lower().startswith(\"hwgrep://\"):\n        url = url[9:]\n    n = 0\n    test_open = False\n    args = url.split('&')\n    regexp = args.pop(0)\n    for arg in args:\n        if '=' in arg:\n            option, value = arg.split('=', 1)\n        else:\n            option = arg\n            value = None\n        if option == 'n':\n            # pick n'th element\n            n = int(value) - 1\n            if n < 1:\n                raise ValueError('option \"n\" expects a positive integer larger than 1: {!r}'.format(value))\n        elif option == 'skip_busy':\n            # open to test if port is available. not the nicest way..\n            test_open = True\n        else:\n            raise ValueError('unknown option: {!r}'.format(option))\n    # use a for loop to get the 1st element from the generator\n    for port, desc, hwid in sorted(serial.tools.list_ports.grep(regexp)):\n        if test_open:\n            try:\n                s = serial.Serial(port)\n            except serial.SerialException:\n                # it has some error, skip this one\n                continue\n            else:\n                s.close()\n        if n:\n            n -= 1\n            continue\n        return port\n    else:\n        raise serial.SerialException('no ports found matching regexp {!r}'.format(url))", "loc": 40}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "open", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["SerialException", "queue.Queue", "self._reconfigure_port", "self._update_dtr_state", "self._update_rts_state", "self.from_url", "self.reset_input_buffer", "self.reset_output_buffer"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Open port with current settings. This may throw a SerialException if the port cannot be opened.", "source_code": "def open(self):\n    \"\"\"\\\n    Open port with current settings. This may throw a SerialException\n    if the port cannot be opened.\n    \"\"\"\n    if self.is_open:\n        raise SerialException(\"Port is already open.\")\n    self.logger = None\n    self.queue = queue.Queue(self.buffer_size)\n\n    if self._port is None:\n        raise SerialException(\"Port must be configured before it can be used.\")\n    # not that there is anything to open, but the function applies the\n    # options found in the URL\n    self.from_url(self.port)\n\n    # not that there anything to configure...\n    self._reconfigure_port()\n    # all things set up get, now a clean start\n    self.is_open = True\n    if not self._dsrdtr:\n        self._update_dtr_state()\n    if not self._rtscts:\n        self._update_rts_state()\n    self.reset_input_buffer()\n    self.reset_output_buffer()", "loc": 26}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.queue.put_nowait", "super", "super(Serial, self).close"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def close(self):\n    if self.is_open:\n        self.is_open = False\n        try:\n            self.queue.put_nowait(None)\n        except queue.Full:\n            pass\n    super(Serial, self).close()", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "from_url", "parameters": ["self", "url"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'expected a string in the form \"loop://[?logging={debug|info|warning|error}]\": not starting with loop:// ({!r})'.format", "'expected a string in the form \"loop://[?logging={debug|info|warning|error}]\": {}'.format", "'unknown option: {!r}'.format", "SerialException", "ValueError", "logging.basicConfig", "logging.getLogger", "self.logger.debug", "self.logger.setLevel", "urlparse.parse_qs", "urlparse.parse_qs(parts.query, True).items", "urlparse.urlsplit"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "extract host and port from an URL string", "source_code": "def from_url(self, url):\n    \"\"\"extract host and port from an URL string\"\"\"\n    parts = urlparse.urlsplit(url)\n    if parts.scheme != \"loop\":\n        raise SerialException(\n            'expected a string in the form '\n            '\"loop://[?logging={debug|info|warning|error}]\": not starting '\n            'with loop:// ({!r})'.format(parts.scheme))\n    try:\n        # process options now, directly altering self\n        for option, values in urlparse.parse_qs(parts.query, True).items():\n            if option == 'logging':\n                logging.basicConfig()   # XXX is that good to call it here?\n                self.logger = logging.getLogger('pySerial.loop')\n                self.logger.setLevel(LOGGER_LEVELS[values[0]])\n                self.logger.debug('enabled logging')\n            else:\n                raise ValueError('unknown option: {!r}'.format(option))\n    except ValueError as e:\n        raise SerialException(\n            'expected a string in the form '\n            '\"loop://[?logging={debug|info|warning|error}]\": {}'.format(e))", "loc": 22}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "in_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'in_waiting -> {:d}'.format", "PortNotOpenError", "self.logger.debug", "self.queue.qsize"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the number of bytes currently in the input buffer.", "source_code": "def in_waiting(self):\n    \"\"\"Return the number of bytes currently in the input buffer.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        # attention the logged value can differ from return value in\n        # threaded environments...\n        self.logger.debug('in_waiting -> {:d}'.format(self.queue.qsize()))\n    return self.queue.qsize()", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "bytearray", "bytes", "self.logger.info", "self.queue.get", "time.time"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Read size bytes from the serial port. If a timeout is set it may return less characters as requested. With no timeout it will block until the requested number of bytes is read.", "source_code": "def read(self, size=1):\n    \"\"\"\\\n    Read size bytes from the serial port. If a timeout is set it may\n    return less characters as requested. With no timeout it will block\n    until the requested number of bytes is read.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self._timeout is not None and self._timeout != 0:\n        timeout = time.time() + self._timeout\n    else:\n        timeout = None\n    data = bytearray()\n    while size > 0 and self.is_open:\n        try:\n            b = self.queue.get(timeout=self._timeout)  # XXX inter char timeout\n        except queue.Empty:\n            if self._timeout == 0:\n                break\n        else:\n            if b is not None:\n                data += b\n                size -= 1\n            else:\n                break\n        # check for timeout now, after data has been read.\n        # useful for timeout = 0 (non blocking) read\n        if timeout and time.time() > timeout:\n            if self.logger:\n                self.logger.info('read timeout')\n            break\n    return bytes(data)", "loc": 32}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "write", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "SerialTimeoutException", "iterbytes", "len", "min", "self.queue.put", "time.sleep", "to_bytes"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "Output the given byte string over the serial port. Can block if the connection is blocked. May raise SerialException if the connection is closed.", "source_code": "def write(self, data):\n    \"\"\"\\\n    Output the given byte string over the serial port. Can block if the\n    connection is blocked. May raise SerialException if the connection is\n    closed.\n    \"\"\"\n    self._cancel_write = False\n    if not self.is_open:\n        raise PortNotOpenError()\n    data = to_bytes(data)\n    # calculate aprox time that would be used to send the data\n    time_used_to_send = 10.0 * len(data) / self._baudrate\n    # when a write timeout is configured check if we would be successful\n    # (not sending anything, not even the part that would have time)\n    if self._write_timeout is not None and time_used_to_send > self._write_timeout:\n        # must wait so that unit test succeeds\n        time_left = self._write_timeout\n        while time_left > 0 and not self._cancel_write:\n            time.sleep(min(time_left, 0.5))\n            time_left -= 0.5\n        if self._cancel_write:\n            return 0  # XXX\n        raise SerialTimeoutException('Write timeout')\n    for byte in iterbytes(data):\n        self.queue.put(byte, timeout=self._write_timeout)\n    return len(data)", "loc": 26}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "reset_input_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.logger.info", "self.queue.get_nowait", "self.queue.qsize"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Clear input buffer, discarding all that is in the buffer.", "source_code": "def reset_input_buffer(self):\n    \"\"\"Clear input buffer, discarding all that is in the buffer.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('reset_input_buffer()')\n    try:\n        while self.queue.qsize():\n            self.queue.get_nowait()\n    except queue.Empty:\n        pass", "loc": 11}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "reset_output_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.logger.info", "self.queue.get_nowait", "self.queue.qsize"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Clear output buffer, aborting the current output and discarding all that is in the buffer.", "source_code": "def reset_output_buffer(self):\n    \"\"\"\\\n    Clear output buffer, aborting the current output and\n    discarding all that is in the buffer.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('reset_output_buffer()')\n    try:\n        while self.queue.qsize():\n            self.queue.get_nowait()\n    except queue.Empty:\n        pass", "loc": 14}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "out_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'out_waiting -> {:d}'.format", "PortNotOpenError", "self.logger.debug", "self.queue.qsize"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return how many bytes the in the outgoing buffer", "source_code": "def out_waiting(self):\n    \"\"\"Return how many bytes the in the outgoing buffer\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        # attention the logged value can differ from return value in\n        # threaded environments...\n        self.logger.debug('out_waiting -> {:d}'.format(self.queue.qsize()))\n    return self.queue.qsize()", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "cts", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'CTS -> state of RTS ({!r})'.format", "PortNotOpenError", "self.logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Clear To Send", "source_code": "def cts(self):\n    \"\"\"Read terminal status line: Clear To Send\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('CTS -> state of RTS ({!r})'.format(self._rts_state))\n    return self._rts_state", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "dsr", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'DSR -> state of DTR ({!r})'.format", "self.logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Data Set Ready", "source_code": "def dsr(self):\n    \"\"\"Read terminal status line: Data Set Ready\"\"\"\n    if self.logger:\n        self.logger.info('DSR -> state of DTR ({!r})'.format(self._dtr_state))\n    return self._dtr_state", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "ri", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Ring Indicator", "source_code": "def ri(self):\n    \"\"\"Read terminal status line: Ring Indicator\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('returning dummy for RI')\n    return False", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_loop.py", "class_name": "Serial", "function_name": "cd", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Carrier Detect", "source_code": "def cd(self):\n    \"\"\"Read terminal status line: Carrier Detect\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('returning dummy for CD')\n    return True", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "close", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self._socket.close", "self._socket.shutdown", "time.sleep"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "Close port", "source_code": "def close(self):\n    \"\"\"Close port\"\"\"\n    if self.is_open:\n        if self._socket:\n            try:\n                self._socket.shutdown(socket.SHUT_RDWR)\n                self._socket.close()\n            except:\n                # ignore errors.\n                pass\n            self._socket = None\n        self.is_open = False\n        # in case of quick reconnects, give the server some time\n        time.sleep(0.3)", "loc": 14}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "from_url", "parameters": ["self", "url"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'expected a string in the form \"socket://<host>:<port>[?logging={debug|info|warning|error}]\": not starting with socket:// ({!r})'.format", "'expected a string in the form \"socket://<host>:<port>[?logging={debug|info|warning|error}]\": {}'.format", "'unknown option: {!r}'.format", "SerialException", "ValueError", "logging.basicConfig", "logging.getLogger", "self.logger.debug", "self.logger.setLevel", "urlparse.parse_qs", "urlparse.parse_qs(parts.query, True).items", "urlparse.urlsplit"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "extract host and port from an URL string", "source_code": "def from_url(self, url):\n    \"\"\"extract host and port from an URL string\"\"\"\n    parts = urlparse.urlsplit(url)\n    if parts.scheme != \"socket\":\n        raise SerialException(\n            'expected a string in the form '\n            '\"socket://<host>:<port>[?logging={debug|info|warning|error}]\": '\n            'not starting with socket:// ({!r})'.format(parts.scheme))\n    try:\n        # process options now, directly altering self\n        for option, values in urlparse.parse_qs(parts.query, True).items():\n            if option == 'logging':\n                logging.basicConfig()   # XXX is that good to call it here?\n                self.logger = logging.getLogger('pySerial.socket')\n                self.logger.setLevel(LOGGER_LEVELS[values[0]])\n                self.logger.debug('enabled logging')\n            else:\n                raise ValueError('unknown option: {!r}'.format(option))\n        if not 0 <= parts.port < 65536:\n            raise ValueError(\"port not in range 0...65535\")\n    except ValueError as e:\n        raise SerialException(\n            'expected a string in the form '\n            '\"socket://<host>:<port>[?logging={debug|info|warning|error}]\": {}'.format(e))\n\n    return (parts.hostname, parts.port)", "loc": 26}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "in_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "len", "select.select"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return the number of bytes currently in the input buffer.", "source_code": "def in_waiting(self):\n    \"\"\"Return the number of bytes currently in the input buffer.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    # Poll the socket to see if it is ready for reading.\n    # If ready, at least one byte will be to read.\n    lr, lw, lx = select.select([self._socket], [], [], 0)\n    return len(lr)", "loc": 8}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'read failed: {}'.format", "PortNotOpenError", "SerialException", "Timeout", "bytearray", "bytes", "len", "read.extend", "select.select", "self._socket.recv", "timeout.expired", "timeout.time_left"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Read size bytes from the serial port. If a timeout is set it may return less characters as requested. With no timeout it will block until the requested number of bytes is read.", "source_code": "def read(self, size=1):\n    \"\"\"\\\n    Read size bytes from the serial port. If a timeout is set it may\n    return less characters as requested. With no timeout it will block\n    until the requested number of bytes is read.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    read = bytearray()\n    timeout = Timeout(self._timeout)\n    while len(read) < size:\n        try:\n            ready, _, _ = select.select([self._socket], [], [], timeout.time_left())\n            # If select was used with a timeout, and the timeout occurs, it\n            # returns with empty lists -> thus abort read operation.\n            # For timeout == 0 (non-blocking operation) also abort when\n            # there is nothing to read.\n            if not ready:\n                break   # timeout\n            buf = self._socket.recv(size - len(read))\n            # read should always return some data as select reported it was\n            # ready to read when we get to this point, unless it is EOF\n            if not buf:\n                raise SerialException('socket disconnected')\n            read.extend(buf)\n        except OSError as e:\n            # this is for Python 3.x where select.error is a subclass of\n            # OSError ignore BlockingIOErrors and EINTR. other errors are shown\n            # https://www.python.org/dev/peps/pep-0475.\n            if e.errno not in (errno.EAGAIN, errno.EALREADY, errno.EWOULDBLOCK, errno.EINPROGRESS, errno.EINTR):\n                raise SerialException('read failed: {}'.format(e))\n        except (select.error, socket.error) as e:\n            # this is for Python 2.x\n            # ignore BlockingIOErrors and EINTR. all errors are shown\n            # see also http://www.python.org/dev/peps/pep-3151/#select\n            if e[0] not in (errno.EAGAIN, errno.EALREADY, errno.EWOULDBLOCK, errno.EINPROGRESS, errno.EINTR):\n                raise SerialException('read failed: {}'.format(e))\n        if timeout.expired():\n            break\n    return bytes(read)", "loc": 40}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "write", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'write failed: {}'.format", "PortNotOpenError", "SerialException", "SerialTimeoutException", "Timeout", "len", "select.select", "self._socket.send", "timeout.expired", "timeout.time_left", "to_bytes"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Output the given byte string over the serial port. Can block if the connection is blocked. May raise SerialException if the connection is closed.", "source_code": "def write(self, data):\n    \"\"\"\\\n    Output the given byte string over the serial port. Can block if the\n    connection is blocked. May raise SerialException if the connection is\n    closed.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n\n    d = to_bytes(data)\n    tx_len = length = len(d)\n    timeout = Timeout(self._write_timeout)\n    while tx_len > 0:\n        try:\n            n = self._socket.send(d)\n            if timeout.is_non_blocking:\n                # Zero timeout indicates non-blocking - simply return the\n                # number of bytes of data actually written\n                return n\n            elif not timeout.is_infinite:\n                # when timeout is set, use select to wait for being ready\n                # with the time left as timeout\n                if timeout.expired():\n                    raise SerialTimeoutException('Write timeout')\n                _, ready, _ = select.select([], [self._socket], [], timeout.time_left())\n                if not ready:\n                    raise SerialTimeoutException('Write timeout')\n            else:\n                assert timeout.time_left() is None\n                # wait for write operation\n                _, ready, _ = select.select([], [self._socket], [], None)\n                if not ready:\n                    raise SerialException('write failed (select)')\n            d = d[n:]\n            tx_len -= n\n        except SerialException:\n            raise\n        except OSError as e:\n            # this is for Python 3.x where select.error is a subclass of\n            # OSError ignore BlockingIOErrors and EINTR. other errors are shown\n            # https://www.python.org/dev/peps/pep-0475.\n            if e.errno not in (errno.EAGAIN, errno.EALREADY, errno.EWOULDBLOCK, errno.EINPROGRESS, errno.EINTR):\n                raise SerialException('write failed: {}'.format(e))\n        except select.error as e:\n            # this is for Python 2.x\n            # ignore BlockingIOErrors and EINTR. all errors are shown\n            # see also http://www.python.org/dev/peps/pep-3151/#select\n            if e[0] not in (errno.EAGAIN, errno.EALREADY, errno.EWOULDBLOCK, errno.EINPROGRESS, errno.EINTR):\n                raise SerialException('write failed: {}'.format(e))\n        if not timeout.is_non_blocking and timeout.expired():\n            raise SerialTimeoutException('Write timeout')\n    return length - len(d)", "loc": 52}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "reset_input_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'read failed: {}'.format", "PortNotOpenError", "SerialException", "select.select", "self._socket.recv"], "control_structures": ["If", "Try", "While"], "behavior_type": ["logic"], "doc_summary": "Clear input buffer, discarding all that is in the buffer.", "source_code": "def reset_input_buffer(self):\n    \"\"\"Clear input buffer, discarding all that is in the buffer.\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n\n    # just use recv to remove input, while there is some\n    ready = True\n    while ready:\n        ready, _, _ = select.select([self._socket], [], [], 0)\n        try:\n            if ready:\n                ready = self._socket.recv(4096)\n        except OSError as e:\n            # this is for Python 3.x where select.error is a subclass of\n            # OSError ignore BlockingIOErrors and EINTR. other errors are shown\n            # https://www.python.org/dev/peps/pep-0475.\n            if e.errno not in (errno.EAGAIN, errno.EALREADY, errno.EWOULDBLOCK, errno.EINPROGRESS, errno.EINTR):\n                raise SerialException('read failed: {}'.format(e))\n        except (select.error, socket.error) as e:\n            # this is for Python 2.x\n            # ignore BlockingIOErrors and EINTR. all errors are shown\n            # see also http://www.python.org/dev/peps/pep-3151/#select\n            if e[0] not in (errno.EAGAIN, errno.EALREADY, errno.EWOULDBLOCK, errno.EINPROGRESS, errno.EINTR):\n                raise SerialException('read failed: {}'.format(e))", "loc": 24}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "reset_output_buffer", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Clear output buffer, aborting the current output and discarding all that is in the buffer.", "source_code": "def reset_output_buffer(self):\n    \"\"\"\\\n    Clear output buffer, aborting the current output and\n    discarding all that is in the buffer.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('ignored reset_output_buffer')", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "send_break", "parameters": ["self", "duration"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'ignored send_break({!r})'.format", "PortNotOpenError", "self.logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Send break condition. Timed, returns to idle state after given duration.", "source_code": "def send_break(self, duration=0.25):\n    \"\"\"\\\n    Send break condition. Timed, returns to idle state after given\n    duration.\n    \"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('ignored send_break({!r})'.format(duration))", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "cts", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Clear To Send", "source_code": "def cts(self):\n    \"\"\"Read terminal status line: Clear To Send\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('returning dummy for cts')\n    return True", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "dsr", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Data Set Ready", "source_code": "def dsr(self):\n    \"\"\"Read terminal status line: Data Set Ready\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('returning dummy for dsr')\n    return True", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "ri", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Ring Indicator", "source_code": "def ri(self):\n    \"\"\"Read terminal status line: Ring Indicator\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('returning dummy for ri')\n    return False", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_socket.py", "class_name": "Serial", "function_name": "cd", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["PortNotOpenError", "self.logger.info"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Read terminal status line: Carrier Detect", "source_code": "def cd(self):\n    \"\"\"Read terminal status line: Carrier Detect\"\"\"\n    if not self.is_open:\n        raise PortNotOpenError()\n    if self.logger:\n        self.logger.info('returning dummy for cd)')\n    return True", "loc": 7}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_spy.py", "class_name": null, "function_name": "sixteen", "parameters": ["data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'{:02X} '.format", "b.decode", "ord", "serial.iterbytes"], "control_structures": ["For", "If", "While"], "behavior_type": ["logic"], "doc_summary": "yield tuples of hex and ASCII display in multiples of 16. Includes a space after 8 bytes and (None, None) after 16 bytes and at the end.", "source_code": "def sixteen(data):\n    \"\"\"\\\n    yield tuples of hex and ASCII display in multiples of 16. Includes a\n    space after 8 bytes and (None, None) after 16 bytes and at the end.\n    \"\"\"\n    n = 0\n    for b in serial.iterbytes(data):\n        yield ('{:02X} '.format(ord(b)), b.decode('ascii') if b' ' <= b < b'\\x7f' else '.')\n        n += 1\n        if n == 8:\n            yield (' ', '')\n        elif n >= 16:\n            yield (None, None)\n            n = 0\n    if n > 0:\n        while n < 16:\n            n += 1\n            if n == 8:\n                yield (' ', '')\n            yield ('   ', ' ')\n        yield (None, None)", "loc": 21}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_spy.py", "class_name": null, "function_name": "hexdump", "parameters": ["data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["' '.join", "''.join", "ascii.append", "sixteen", "values.append"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "yield lines with hexdump of data", "source_code": "def hexdump(data):\n    \"\"\"yield lines with hexdump of data\"\"\"\n    values = []\n    ascii = []\n    offset = 0\n    for h, a in sixteen(data):\n        if h is None:\n            yield (offset, ' '.join([''.join(values), ''.join(ascii)]))\n            del values[:]\n            del ascii[:]\n            offset += 0x10\n        else:\n            values.append(h)\n            ascii.append(a)", "loc": 14}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_spy.py", "class_name": "FormatRaw", "function_name": "rx", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.output.flush", "self.output.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "show received data", "source_code": "def rx(self, data):\n    \"\"\"show received data\"\"\"\n    if self.color:\n        self.output.write(self.rx_color)\n    self.output.write(data)\n    self.output.flush()", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_spy.py", "class_name": "FormatRaw", "function_name": "tx", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.output.flush", "self.output.write"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "show transmitted data", "source_code": "def tx(self, data):\n    \"\"\"show transmitted data\"\"\"\n    if self.color:\n        self.output.write(self.tx_color)\n    self.output.write(data)\n    self.output.flush()", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_spy.py", "class_name": "FormatHexdump", "function_name": "rx", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'{:04X}  '.format", "hexdump", "self.output.write", "self.write_line", "time.time"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "show received data as hex dump", "source_code": "def rx(self, data):\n    \"\"\"show received data as hex dump\"\"\"\n    if self.color:\n        self.output.write(self.rx_color)\n    if data:\n        for offset, row in hexdump(data):\n            self.write_line(time.time() - self.start_time, 'RX', '{:04X}  '.format(offset), row)\n    else:\n        self.write_line(time.time() - self.start_time, 'RX', '<empty>')", "loc": 9}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_spy.py", "class_name": "FormatHexdump", "function_name": "tx", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'{:04X}  '.format", "hexdump", "self.output.write", "self.write_line", "time.time"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "show transmitted data as hex dump", "source_code": "def tx(self, data):\n    \"\"\"show transmitted data as hex dump\"\"\"\n    if self.color:\n        self.output.write(self.tx_color)\n    for offset, row in hexdump(data):\n        self.write_line(time.time() - self.start_time, 'TX', '{:04X}  '.format(offset), row)", "loc": 6}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_spy.py", "class_name": "FormatHexdump", "function_name": "control", "parameters": ["self", "name", "value"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.output.write", "self.write_line", "time.time"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "show control calls", "source_code": "def control(self, name, value):\n    \"\"\"show control calls\"\"\"\n    if self.color:\n        self.output.write(self.control_color)\n    self.write_line(time.time() - self.start_time, name, value)", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_spy.py", "class_name": "FormatLogHex", "function_name": "rx", "parameters": ["self", "data"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'RX {}{}'.format", "'{:04X}  '.format", "hexdump", "self.log.info"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "show received data", "source_code": "def rx(self, data):\n    \"\"\"show received data\"\"\"\n    if data:\n        for offset, row in hexdump(data):\n            self.log.info('RX {}{}'.format('{:04X}  '.format(offset), row))", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_spy.py", "class_name": "Serial", "function_name": "read", "parameters": ["self", "size"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.formatter.rx", "super", "super(Serial, self).read"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def read(self, size=1):\n    rx = super(Serial, self).read(size)\n    if rx or self.show_all:\n        self.formatter.rx(rx)\n    return rx", "loc": 5}
{"file": "thonny\\thonny\\vendored_libs\\serial\\urlhandler\\protocol_spy.py", "class_name": "Serial", "function_name": "in_waiting", "parameters": ["self"], "param_types": {}, "return_type": null, "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["'in_waiting -> {}'.format", "self.formatter.control", "super"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def in_waiting(self):\n    n = super(Serial, self).in_waiting\n    if self.show_all:\n        self.formatter.control('Q-RX', 'in_waiting -> {}'.format(n))\n    return n", "loc": 5}
{"file": "typesystem\\typesystem\\base.py", "class_name": "BaseError", "function_name": "messages", "parameters": ["self"], "param_types": {}, "return_type": "typing.List[Message]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Message", "list"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Return a list of all the messages. add_prefix - An optional key to add to the index of all returned messages. Useful in nested objects when validation needs to accumulate", "source_code": "def messages(\n    self, *, add_prefix: typing.Union[str, int] = None\n) -> typing.List[Message]:\n    \"\"\"\n    Return a list of all the messages.\n\n    add_prefix - An optional key to add to the index of all returned messages.\n                 Useful in nested objects when validation needs to accumulate\n                 all the child messages for each item in the parent object.\n    \"\"\"\n    if add_prefix is not None:\n        return [\n            Message(\n                text=message.text,\n                code=message.code,\n                index=[add_prefix] + message.index,\n            )\n            for message in self._messages\n        ]\n    return list(self._messages)", "loc": 20}
{"file": "typesystem\\typesystem\\composites.py", "class_name": "OneOf", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["child.validate_or_error", "self.validation_error"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    candidate = None\n    match_count = 0\n    for child in self.one_of:\n        validated, error = child.validate_or_error(value)\n        if error is None:\n            match_count += 1\n            candidate = validated\n\n    if match_count == 1:\n        return candidate\n    elif match_count > 1:\n        raise self.validation_error(\"multiple_matches\")\n    raise self.validation_error(\"no_match\")", "loc": 14}
{"file": "typesystem\\typesystem\\composites.py", "class_name": "Not", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.negated.validate_or_error", "self.validation_error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    _, error = self.negated.validate_or_error(value)\n    if error:\n        return value\n    raise self.validation_error(\"negated\")", "loc": 5}
{"file": "typesystem\\typesystem\\composites.py", "class_name": "IfThenElse", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.else_clause.validate", "self.if_clause.validate_or_error", "self.then_clause.validate"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    _, error = self.if_clause.validate_or_error(value)\n    if error is None:\n        return self.then_clause.validate(value)\n    else:\n        return self.else_clause.validate(value)", "loc": 6}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "Field", "function_name": "validate_or_error", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "ValidationResult", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ValidationResult", "self.validate"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate_or_error(self, value: typing.Any) -> ValidationResult:\n    try:\n        value = self.validate(value)\n    except ValidationError as error:\n        return ValidationResult(value=None, error=error)\n    return ValidationResult(value=value, error=None)", "loc": 6}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "Field", "function_name": "get_default_value", "parameters": ["self"], "param_types": {}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["callable", "default", "getattr"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_default_value(self) -> typing.Any:\n    default = getattr(self, \"default\", None)\n    if callable(default):\n        return default()\n    return default", "loc": 5}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "String", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["FORMATS[self.format].is_native_type", "FORMATS[self.format].validate", "isinstance", "len", "self.pattern_regex.search", "self.validation_error", "value.replace", "value.strip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    if value is None and self.allow_null:\n        return None\n    elif value is None and self.allow_blank and self.coerce_types:\n        # Leniently cast nulls to empty strings if allow_blank.\n        return \"\"\n    elif value is None:\n        raise self.validation_error(\"null\")\n    elif self.format in FORMATS and FORMATS[self.format].is_native_type(value):\n        return value\n    elif not isinstance(value, str):\n        raise self.validation_error(\"type\")\n\n    # The null character is always invalid.\n    value = value.replace(\"\\0\", \"\")\n\n    # Strip leading/trailing whitespace by default.\n    if self.trim_whitespace:\n        value = value.strip()\n\n    if not self.allow_blank and not value:\n        if self.allow_null and self.coerce_types:\n            # Leniently cast empty strings (after trimming) to null if allow_null.\n            return None\n        raise self.validation_error(\"blank\")\n\n    if self.min_length is not None:\n        if len(value) < self.min_length:\n            raise self.validation_error(\"min_length\")\n\n    if self.max_length is not None:\n        if len(value) > self.max_length:\n            raise self.validation_error(\"max_length\")\n\n    if self.pattern_regex is not None:\n        if not self.pattern_regex.search(value):\n            raise self.validation_error(\"pattern\")\n\n    if self.format in FORMATS:\n        return FORMATS[self.format].validate(value)\n\n    return value", "loc": 42}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "Number", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["decimal.Decimal", "decimal_val.quantize", "isfinite", "isinstance", "numeric_type", "self.numeric_type", "self.validation_error", "type", "value * (1 / self.multiple_of).is_integer", "value.is_integer"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    if value is None and self.allow_null:\n        return None\n    elif value == \"\" and self.allow_null and self.coerce_types:\n        return None\n    elif value is None:\n        raise self.validation_error(\"null\")\n    elif isinstance(value, bool):\n        raise self.validation_error(\"type\")\n    elif (\n        self.numeric_type is int\n        and isinstance(value, float)\n        and not value.is_integer()\n    ):\n        raise self.validation_error(\"integer\")\n    elif not isinstance(value, (int, float)) and not self.coerce_types:\n        raise self.validation_error(\"type\")\n\n    try:\n        if isinstance(value, str):\n            # Casting to a decimal first gives more lenient parsing.\n            value = decimal.Decimal(value)\n        if self.numeric_type is not None:\n            value = self.numeric_type(value)\n    except (TypeError, ValueError, decimal.InvalidOperation):\n        raise self.validation_error(\"type\")\n\n    if not isfinite(value):\n        # inf, -inf, nan, are all invalid.\n        raise self.validation_error(\"finite\")\n\n    if self.precision is not None:\n        numeric_type = self.numeric_type or type(value)\n        quantize_val = decimal.Decimal(self.precision)\n        decimal_val = decimal.Decimal(value)\n        decimal_val = decimal_val.quantize(\n            quantize_val, rounding=decimal.ROUND_HALF_UP\n        )\n        value = numeric_type(decimal_val)\n\n    if self.minimum is not None and value < self.minimum:\n        raise self.validation_error(\"minimum\")\n\n    if self.exclusive_minimum is not None and value <= self.exclusive_minimum:\n        raise self.validation_error(\"exclusive_minimum\")\n\n    if self.maximum is not None and value > self.maximum:\n        raise self.validation_error(\"maximum\")\n\n    if self.exclusive_maximum is not None and value >= self.exclusive_maximum:\n        raise self.validation_error(\"exclusive_maximum\")\n\n    if self.multiple_of is not None:\n        if isinstance(self.multiple_of, int):\n            if value % self.multiple_of:\n                raise self.validation_error(\"multiple_of\")\n        else:\n            if not (value * (1 / self.multiple_of)).is_integer():\n                raise self.validation_error(\"multiple_of\")\n\n    return value", "loc": 61}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "Boolean", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self.validation_error", "value.lower"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    if value is None and self.allow_null:\n        return None\n\n    elif value is None:\n        raise self.validation_error(\"null\")\n\n    elif not isinstance(value, bool):\n        if not self.coerce_types:\n            raise self.validation_error(\"type\")\n\n        if isinstance(value, str):\n            value = value.lower()\n\n        if self.allow_null and value in self.coerce_null_values:\n            return None\n\n        try:\n            value = self.coerce_values[value]\n        except (KeyError, TypeError):\n            raise self.validation_error(\"type\")\n\n    return value", "loc": 23}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "Choice", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Uniqueness", "self.validation_error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    if value is None and self.allow_null:\n        return None\n    elif value is None:\n        raise self.validation_error(\"null\")\n    elif value not in Uniqueness([key for key, value in self.choices]):\n        if value == \"\":\n            if self.allow_null and self.coerce_types:\n                return None\n            raise self.validation_error(\"required\")\n        raise self.validation_error(\"choice\")\n    return value", "loc": 12}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "Object", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Message", "ValidationError", "child_schema.get_default_value", "child_schema.has_default", "child_schema.validate_or_error", "error.messages", "error_messages.append", "isinstance", "len", "list", "re.search", "self.get_error_text", "self.pattern_properties.items", "self.properties.items", "self.property_names.validate_or_error", "self.validation_error", "set", "validated.keys", "value.keys"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    if value is None and self.allow_null:\n        return None\n    elif value is None:\n        raise self.validation_error(\"null\")\n    elif not isinstance(value, (dict, typing.Mapping)):\n        raise self.validation_error(\"type\")\n\n    validated = {}\n    error_messages = []\n\n    # Ensure all property keys are strings.\n    for key in value.keys():\n        if not isinstance(key, str):\n            text = self.get_error_text(\"invalid_key\")\n            message = Message(text=text, code=\"invalid_key\", index=[key])\n            error_messages.append(message)\n        elif self.property_names is not None:\n            _, error = self.property_names.validate_or_error(key)\n            if error is not None:\n                text = self.get_error_text(\"invalid_property\")\n                message = Message(text=text, code=\"invalid_property\", index=[key])\n                error_messages.append(message)\n\n    # Min/Max properties\n    if self.min_properties is not None:\n        if len(value) < self.min_properties:\n            if self.min_properties == 1:\n                raise self.validation_error(\"empty\")\n            else:\n                raise self.validation_error(\"min_properties\")\n    if self.max_properties is not None:\n        if len(value) > self.max_properties:\n            raise self.validation_error(\"max_properties\")\n\n    # Required properties\n    for key in self.required:\n        if key not in value:\n            text = self.get_error_text(\"required\")\n            message = Message(text=text, code=\"required\", index=[key])\n            error_messages.append(message)\n\n    # Properties\n    for key, child_schema in self.properties.items():\n        if key not in value:\n            if child_schema.has_default():\n                validated[key] = child_schema.get_default_value()\n            continue\n        item = value[key]\n        child_value, error = child_schema.validate_or_error(item)\n        if not error:\n            validated[key] = child_value\n        else:\n            error_messages += error.messages(add_prefix=key)\n\n    # Pattern properties\n    if self.pattern_properties:\n        for key in list(value.keys()):\n            for pattern, child_schema in self.pattern_properties.items():\n                if isinstance(key, str) and re.search(pattern, key):\n                    item = value[key]\n                    child_value, error = child_schema.validate_or_error(item)\n                    if not error:\n                        validated[key] = child_value\n                    else:\n                        error_messages += error.messages(add_prefix=key)\n\n    # Additional properties\n    validated_keys = set(validated.keys())\n    error_keys = set(\n        [message.index[0] for message in error_messages if message.index]\n    )\n\n    remaining = [\n        key for key in value.keys() if key not in validated_keys | error_keys\n    ]\n\n    if self.additional_properties is True:\n        for key in remaining:\n            validated[key] = value[key]\n    elif self.additional_properties is False:\n        for key in remaining:\n            text = self.get_error_text(\"invalid_property\")\n            message = Message(text=text, code=\"invalid_property\", key=key)\n            error_messages.append(message)\n    elif self.additional_properties is not None:\n        assert isinstance(self.additional_properties, Field)\n        child_schema = self.additional_properties\n        for key in remaining:\n            item = value[key]\n            child_value, error = child_schema.validate_or_error(item)\n            if not error:\n                validated[key] = child_value\n            else:\n                error_messages += error.messages(add_prefix=key)\n\n    if error_messages:\n        raise ValidationError(messages=error_messages)\n\n    return validated", "loc": 100}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "Array", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Message", "Uniqueness", "ValidationError", "enumerate", "error.messages", "error_messages.append", "isinstance", "len", "seen_items.add", "self.get_error_text", "self.validation_error", "validated.append", "validator.validate_or_error"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    if value is None and self.allow_null:\n        return None\n    elif value is None:\n        raise self.validation_error(\"null\")\n    elif not isinstance(value, list):\n        raise self.validation_error(\"type\")\n\n    if (\n        self.min_items is not None\n        and self.min_items == self.max_items\n        and len(value) != self.min_items\n    ):\n        raise self.validation_error(\"exact_items\")\n    if self.min_items is not None and len(value) < self.min_items:\n        if self.min_items == 1:\n            raise self.validation_error(\"empty\")\n        raise self.validation_error(\"min_items\")\n    elif self.max_items is not None and len(value) > self.max_items:\n        raise self.validation_error(\"max_items\")\n\n    # Ensure all items are of the right type.\n    validated = []\n    error_messages: typing.List[Message] = []\n    if self.unique_items:\n        seen_items = Uniqueness()\n\n    for pos, item in enumerate(value):\n        validator = None\n        if isinstance(self.items, list):\n            if pos < len(self.items):\n                validator = self.items[pos]\n            elif isinstance(self.additional_items, Field):\n                validator = self.additional_items\n        elif self.items is not None:\n            validator = self.items\n\n        if validator is None:\n            validated.append(item)\n        else:\n            item, error = validator.validate_or_error(item)\n            if error:\n                error_messages += error.messages(add_prefix=pos)\n            else:\n                validated.append(item)\n\n        if self.unique_items:\n            if item in seen_items:\n                text = self.get_error_text(\"unique_items\")\n                message = Message(text=text, code=\"unique_items\", key=pos)\n                error_messages.append(message)\n            else:\n                seen_items.add(item)\n\n    if error_messages:\n        raise ValidationError(messages=error_messages)\n\n    return validated", "loc": 58}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "Array", "function_name": "serialize", "parameters": ["self", "obj"], "param_types": {"obj": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "self.items.serialize", "serializer.serialize", "zip"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize(self, obj: typing.Any) -> typing.Any:\n    if obj is None:\n        return None\n\n    if isinstance(self.items, list):\n        return [\n            serializer.serialize(value)\n            for serializer, value in zip(self.items, obj)\n        ]\n\n    if self.items is None:\n        return obj\n\n    return [self.items.serialize(value) for value in obj]", "loc": 14}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "Union", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["candidate_errors.append", "child.validate_or_error", "error.messages", "len", "self.validation_error"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    if value is None and self.allow_null:\n        return None\n    elif value is None:\n        raise self.validation_error(\"null\")\n\n    candidate_errors = []\n    for child in self.any_of:\n        validated, error = child.validate_or_error(value)\n        if error is None:\n            return validated\n        else:\n            # If a child returned anything other than a type error, then\n            # it is a candidate for returning as the primary error.\n            messages = error.messages()\n            if (\n                len(messages) != 1\n                or messages[0].code != \"type\"\n                or messages[0].index\n            ):\n                candidate_errors.append(error)\n\n    if len(candidate_errors) == 1:\n        # If exactly one child was of the correct type, then we can use\n        # the error from the child.\n        raise candidate_errors[0]\n    raise self.validation_error(\"union\")", "loc": 27}
{"file": "typesystem\\typesystem\\fields.py", "class_name": "Const", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.validation_error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    if value != self.const:\n        if self.const is None:\n            raise self.validation_error(\"only_null\")\n        raise self.validation_error(\"const\")\n    return value", "loc": 6}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "DateFormat", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "datetime.date", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DATE_REGEX.match", "datetime.date", "int", "match.groupdict", "match.groupdict().items", "self.validation_error"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> datetime.date:\n    match = DATE_REGEX.match(value)\n    if not match:\n        raise self.validation_error(\"format\")\n\n    kwargs = {k: int(v) for k, v in match.groupdict().items()}\n    try:\n        return datetime.date(**kwargs)\n    except ValueError:\n        raise self.validation_error(\"invalid\")", "loc": 10}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "DateFormat", "function_name": "serialize", "parameters": ["self", "obj"], "param_types": {"obj": "typing.Optional[datetime.date]"}, "return_type": "typing.Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "obj.isoformat"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize(self, obj: typing.Optional[datetime.date]) -> typing.Optional[str]:\n    if obj is None:\n        return None\n\n    assert isinstance(obj, datetime.date)\n\n    return obj.isoformat()", "loc": 7}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "TimeFormat", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "datetime.time", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["TIME_REGEX.match", "datetime.time", "groups.items", "groups['microsecond'].ljust", "int", "match.groupdict", "self.validation_error"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> datetime.time:\n    match = TIME_REGEX.match(value)\n    if not match:\n        raise self.validation_error(\"format\")\n\n    groups = match.groupdict()\n    if groups[\"microsecond\"]:\n        groups[\"microsecond\"] = groups[\"microsecond\"].ljust(6, \"0\")\n\n    kwargs = {k: int(v) for k, v in groups.items() if v is not None}\n    try:\n        return datetime.time(tzinfo=None, **kwargs)\n    except ValueError:\n        raise self.validation_error(\"invalid\")", "loc": 14}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "TimeFormat", "function_name": "serialize", "parameters": ["self", "obj"], "param_types": {"obj": "typing.Optional[datetime.time]"}, "return_type": "typing.Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "obj.isoformat"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize(self, obj: typing.Optional[datetime.time]) -> typing.Optional[str]:\n    if obj is None:\n        return None\n\n    assert isinstance(obj, datetime.time)\n\n    return obj.isoformat()", "loc": 7}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "DateTimeFormat", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "datetime.datetime", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DATETIME_REGEX.match", "datetime.datetime", "datetime.timedelta", "datetime.timezone", "groups.items", "groups.pop", "groups['microsecond'].ljust", "int", "len", "match.groupdict", "self.validation_error"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> datetime.datetime:\n    match = DATETIME_REGEX.match(value)\n    if not match:\n        raise self.validation_error(\"format\")\n\n    groups = match.groupdict()\n    if groups[\"microsecond\"] is not None:\n        groups[\"microsecond\"] = groups[\"microsecond\"].ljust(6, \"0\")\n\n    tzinfo_str = groups.pop(\"tzinfo\")\n    if tzinfo_str == \"Z\":\n        tzinfo = datetime.timezone.utc\n    elif tzinfo_str is not None:\n        offset_mins = int(tzinfo_str[-2:]) if len(tzinfo_str) > 3 else 0\n        offset_hours = int(tzinfo_str[1:3])\n        delta = datetime.timedelta(hours=offset_hours, minutes=offset_mins)\n        if tzinfo_str[0] == \"-\":\n            delta = -delta\n        tzinfo = datetime.timezone(delta)\n    else:\n        tzinfo = None\n\n    kwargs = {k: int(v) for k, v in groups.items() if v is not None}\n    try:\n        return datetime.datetime(**kwargs, tzinfo=tzinfo)  # type: ignore\n    except ValueError:\n        raise self.validation_error(\"invalid\")", "loc": 27}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "DateTimeFormat", "function_name": "serialize", "parameters": ["self", "obj"], "param_types": {"obj": "typing.Optional[datetime.datetime]"}, "return_type": "typing.Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "obj.isoformat", "value.endswith"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize(\n    self, obj: typing.Optional[datetime.datetime]\n) -> typing.Optional[str]:\n    if obj is None:\n        return None\n\n    assert isinstance(obj, datetime.datetime)\n\n    value = obj.isoformat()\n\n    if value.endswith(\"+00:00\"):\n        value = value[:-6] + \"Z\"\n\n    return value", "loc": 14}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "UUIDFormat", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "uuid.UUID", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["UUID_REGEX.match", "self.validation_error", "uuid.UUID"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> uuid.UUID:\n    match = UUID_REGEX.match(value)\n    if not match:\n        raise self.validation_error(\"format\")\n\n    return uuid.UUID(value)", "loc": 6}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "UUIDFormat", "function_name": "serialize", "parameters": ["self", "obj"], "param_types": {"obj": "typing.Optional[uuid.UUID]"}, "return_type": "typing.Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize(self, obj: typing.Optional[uuid.UUID]) -> typing.Optional[str]:\n    if obj is None:\n        return None\n\n    assert isinstance(obj, uuid.UUID)\n\n    return str(obj)", "loc": 7}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "EmailFormat", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "str"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["EMAIL_REGEX.match", "self.validation_error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: str) -> str:\n    match = EMAIL_REGEX.match(value)\n    if not match:\n        raise self.validation_error(\"format\")\n\n    return value", "loc": 6}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "EmailFormat", "function_name": "serialize", "parameters": ["self", "obj"], "param_types": {"obj": "typing.Optional[str]"}, "return_type": "typing.Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize(self, obj: typing.Optional[str]) -> typing.Optional[str]:\n    if obj is None:\n        return None\n\n    return obj", "loc": 5}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "IPAddressFormat", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Union[ipaddress.IPv4Address, ipaddress.IPv6Address]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["IPV4_REGEX.match", "IPV6_REGEX.match", "ipaddress.ip_address", "self.validation_error"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(\n    self, value: typing.Any\n) -> typing.Union[ipaddress.IPv4Address, ipaddress.IPv6Address]:\n    match_ipv4 = IPV4_REGEX.match(value)\n    match_ipv6 = IPV6_REGEX.match(value)\n    if not match_ipv4 and not match_ipv6:\n        raise self.validation_error(\"format\")\n\n    try:\n        return ipaddress.ip_address(value)\n    except ValueError:\n        raise self.validation_error(\"invalid\")", "loc": 12}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "IPAddressFormat", "function_name": "serialize", "parameters": ["self", "obj"], "param_types": {"obj": "typing.Union[ipaddress.IPv4Address, ipaddress.IPv6Address, None]"}, "return_type": "typing.Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance", "str"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize(\n    self, obj: typing.Union[ipaddress.IPv4Address, ipaddress.IPv6Address, None]\n) -> typing.Optional[str]:\n    if obj is None:\n        return None\n\n    assert isinstance(obj, (ipaddress.IPv4Address, ipaddress.IPv6Address))\n\n    return str(obj)", "loc": 9}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "URLFormat", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["all", "self.validation_error", "str", "urlparse"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> str:\n    url = urlparse(value)\n    if not all([url.scheme, url.netloc]):\n        raise self.validation_error(\"invalid\")\n\n    return str(value)", "loc": 6}
{"file": "typesystem\\typesystem\\formats.py", "class_name": "URLFormat", "function_name": "serialize", "parameters": ["self", "obj"], "param_types": {"obj": "typing.Optional[str]"}, "return_type": "typing.Optional[str]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": [], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize(self, obj: typing.Optional[str]) -> typing.Optional[str]:\n    if obj is None:\n        return None\n\n    return obj", "loc": 5}
{"file": "typesystem\\typesystem\\forms.py", "class_name": "Form", "function_name": "render_fields", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["errors.get", "self.render_field", "self.schema.fields.items", "values.get"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def render_fields(self) -> str:\n    values = self.data if self.errors else self.values\n    errors = self.errors\n\n    html = \"\"\n    for field_name, field in self.schema.fields.items():\n        if field.read_only:\n            continue\n        value = None if values is None else values.get(field_name)\n        error = None if errors is None else errors.get(field_name)\n        html += self.render_field(\n            field_name=field_name, field=field, value=value, error=error\n        )\n    return html", "loc": 14}
{"file": "typesystem\\typesystem\\forms.py", "class_name": "Form", "function_name": "render_field", "parameters": ["self"], "param_types": {}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["field.has_default", "field_name.replace", "getattr", "self.env.get_template", "self.input_type_for_field", "self.template_for_field", "template.render"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def render_field(\n    self,\n    *,\n    field_name: str,\n    field: Field,\n    value: typing.Any = None,\n    error: str = None,\n) -> str:\n    field_id = field_name.replace(\"_\", \"-\")\n    label = field.title or field_name\n    allow_empty = field.allow_null or getattr(field, \"allow_blank\", False)\n    required = not field.has_default() and not allow_empty\n    input_type = self.input_type_for_field(field)\n    template_name = self.template_for_field(field)\n    template = self.env.get_template(template_name)\n    value = \"\" if input_type == \"password\" else value\n    return template.render(\n        {\n            \"field_id\": field_id,\n            \"field_name\": field_name,\n            \"field\": field,\n            \"label\": label,\n            \"required\": required,\n            \"input_type\": input_type,\n            \"value\": value,\n            \"error\": error,\n        }\n    )", "loc": 28}
{"file": "typesystem\\typesystem\\forms.py", "class_name": "Form", "function_name": "template_for_field", "parameters": ["self", "field"], "param_types": {"field": "Field"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["isinstance"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def template_for_field(self, field: Field) -> str:\n    assert not isinstance(\n        field, Object\n    ), \"Forms do not support rendering Object fields\"\n\n    if isinstance(field, Choice):\n        return \"forms/select.html\"\n    elif isinstance(field, Boolean):\n        return \"forms/checkbox.html\"\n    if isinstance(field, String) and field.format == \"text\":\n        return \"forms/textarea.html\"\n    return \"forms/input.html\"", "loc": 12}
{"file": "typesystem\\typesystem\\forms.py", "class_name": "Form", "function_name": "input_type_for_field", "parameters": ["self", "field"], "param_types": {"field": "Field"}, "return_type": "str", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["getattr", "self.FORMAT_TO_INPUTTYPE.get"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def input_type_for_field(self, field: Field) -> str:\n    format = getattr(field, \"format\", None)\n    if not format:\n        return \"text\"\n    return self.FORMAT_TO_INPUTTYPE.get(format, \"text\")", "loc": 5}
{"file": "typesystem\\typesystem\\json_schema.py", "class_name": null, "function_name": "from_json_schema", "parameters": ["data", "definitions"], "param_types": {"data": "typing.Union[bool, dict]", "definitions": "Definitions"}, "return_type": "Field", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["AllOf", "Any", "Definitions", "NeverMatch", "all_of_from_json_schema", "any", "any_of_from_json_schema", "const_from_json_schema", "constraints.append", "data.get", "data.get('components', {}).get", "data.get('components', {}).get('schemas', {}).items", "enum_from_json_schema", "from_json_schema", "if_then_else_from_json_schema", "isinstance", "len", "not_from_json_schema", "one_of_from_json_schema", "ref_from_json_schema", "type_from_json_schema"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def from_json_schema(\n    data: typing.Union[bool, dict], definitions: Definitions = None\n) -> Field:\n    if isinstance(data, bool):\n        return {True: Any(), False: NeverMatch()}[data]\n\n    if definitions is None:\n        definitions = Definitions()\n        for key, value in data.get(\"components\", {}).get(\"schemas\", {}).items():\n            ref = f\"#/components/schemas/{key}\"\n            definitions[ref] = from_json_schema(value, definitions=definitions)\n\n    if \"$ref\" in data:\n        return ref_from_json_schema(data, definitions=definitions)\n\n    constraints = []  # typing.List[Field]\n    if any([property_name in data for property_name in TYPE_CONSTRAINTS]):\n        constraints.append(type_from_json_schema(data, definitions=definitions))\n    if \"enum\" in data:\n        constraints.append(enum_from_json_schema(data, definitions=definitions))\n    if \"const\" in data:\n        constraints.append(const_from_json_schema(data, definitions=definitions))\n    if \"allOf\" in data:\n        constraints.append(all_of_from_json_schema(data, definitions=definitions))\n    if \"anyOf\" in data:\n        constraints.append(any_of_from_json_schema(data, definitions=definitions))\n    if \"oneOf\" in data:\n        constraints.append(one_of_from_json_schema(data, definitions=definitions))\n    if \"not\" in data:\n        constraints.append(not_from_json_schema(data, definitions=definitions))\n    if \"if\" in data:\n        constraints.append(if_then_else_from_json_schema(data, definitions=definitions))\n\n    if len(constraints) == 1:\n        return constraints[0]\n    elif len(constraints) > 1:\n        return AllOf(constraints)\n    return Any()", "loc": 38}
{"file": "typesystem\\typesystem\\json_schema.py", "class_name": null, "function_name": "type_from_json_schema", "parameters": ["data", "definitions"], "param_types": {"data": "dict", "definitions": "Definitions"}, "return_type": "Field", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Const", "NeverMatch", "Union", "from_json_schema_type", "get_valid_types", "len", "type_strings.pop"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Build a typed field or union of typed fields from a JSON schema object.", "source_code": "def type_from_json_schema(data: dict, definitions: Definitions) -> Field:\n    \"\"\"\n    Build a typed field or union of typed fields from a JSON schema object.\n    \"\"\"\n    type_strings, allow_null = get_valid_types(data)\n\n    if len(type_strings) > 1:\n        items = [\n            from_json_schema_type(\n                data, type_string=type_string, allow_null=False, definitions=definitions\n            )\n            for type_string in type_strings\n        ]\n        return Union(any_of=items, allow_null=allow_null)\n\n    if len(type_strings) == 0:\n        return {True: Const(None), False: NeverMatch()}[allow_null]\n\n    type_string = type_strings.pop()\n    return from_json_schema_type(\n        data, type_string=type_string, allow_null=allow_null, definitions=definitions\n    )", "loc": 22}
{"file": "typesystem\\typesystem\\json_schema.py", "class_name": null, "function_name": "get_valid_types", "parameters": ["data"], "param_types": {"data": "dict"}, "return_type": "typing.Tuple[typing.Set[str], bool]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["data.get", "isinstance", "set", "type_strings.discard", "type_strings.remove"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_valid_types(data: dict) -> typing.Tuple[typing.Set[str], bool]:\n    \"\"\"\n    Returns a two-tuple of `(type_strings, allow_null)`.\n    \"\"\"\n\n    type_strings = data.get(\"type\", [])\n    if isinstance(type_strings, str):\n        type_strings = {type_strings}\n    else:\n        type_strings = set(type_strings)\n\n    if not type_strings:\n        type_strings = {\"null\", \"boolean\", \"object\", \"array\", \"number\", \"string\"}\n\n    if \"number\" in type_strings:\n        type_strings.discard(\"integer\")\n\n    allow_null = False\n    if \"null\" in type_strings:\n        allow_null = True\n        type_strings.remove(\"null\")\n\n    return (type_strings, allow_null)", "loc": 23}
{"file": "typesystem\\typesystem\\json_schema.py", "class_name": null, "function_name": "if_then_else_from_json_schema", "parameters": ["data", "definitions"], "param_types": {"data": "dict", "definitions": "Definitions"}, "return_type": "Field", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["IfThenElse", "data.get", "from_json_schema"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def if_then_else_from_json_schema(data: dict, definitions: Definitions) -> Field:\n    if_clause = from_json_schema(data[\"if\"], definitions=definitions)\n    then_clause = (\n        from_json_schema(data[\"then\"], definitions=definitions)\n        if \"then\" in data\n        else None\n    )\n    else_clause = (\n        from_json_schema(data[\"else\"], definitions=definitions)\n        if \"else\" in data\n        else None\n    )\n    kwargs = {\n        \"if_clause\": if_clause,\n        \"then_clause\": then_clause,\n        \"else_clause\": else_clause,\n        \"default\": data.get(\"default\", NO_DEFAULT),\n    }\n    return IfThenElse(**kwargs)  # type: ignore", "loc": 19}
{"file": "typesystem\\typesystem\\json_schema.py", "class_name": null, "function_name": "get_standard_properties", "parameters": ["field"], "param_types": {"field": "Field"}, "return_type": "dict", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["field.has_default"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def get_standard_properties(field: Field) -> dict:\n    data = {}\n    if field.has_default():\n        data[\"default\"] = field.default\n    return data", "loc": 5}
{"file": "typesystem\\typesystem\\schemas.py", "class_name": "Schema", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Message", "ValidationError", "child_schema.get_default_value", "child_schema.has_default", "child_schema.validate_or_error", "error.messages", "error_messages.append", "isinstance", "self.fields.items", "self.get_error_text", "self.validation_error", "value.keys"], "control_structures": ["For", "If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    if value is None and self.allow_null:\n        return None\n    elif value is None:\n        raise self.validation_error(\"null\")\n    elif not isinstance(value, (dict, typing.Mapping)):\n        raise self.validation_error(\"type\")\n\n    validated = {}\n    error_messages = []\n\n    # Ensure all property keys are strings.\n    for key in value.keys():\n        if not isinstance(key, str):\n            text = self.get_error_text(\"invalid_key\")\n            message = Message(text=text, code=\"invalid_key\", index=[key])\n            error_messages.append(message)\n\n    # Required properties\n    for key in self.required:\n        if key not in value:\n            text = self.get_error_text(\"required\")\n            message = Message(text=text, code=\"required\", index=[key])\n            error_messages.append(message)\n\n    # Properties\n    for key, child_schema in self.fields.items():\n        if child_schema.read_only:\n            continue\n\n        if key not in value:\n            if child_schema.has_default():\n                validated[key] = child_schema.get_default_value()\n            continue\n        item = value[key]\n        child_value, error = child_schema.validate_or_error(item)\n        if not error:\n            validated[key] = child_value\n        else:\n            error_messages += error.messages(add_prefix=key)\n\n    if error_messages:\n        raise ValidationError(messages=error_messages)\n\n    return validated", "loc": 45}
{"file": "typesystem\\typesystem\\schemas.py", "class_name": "Schema", "function_name": "serialize", "parameters": ["self", "obj"], "param_types": {"obj": "typing.Any"}, "return_type": "typing.Optional[typing.Dict[str, typing.Any]]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["field.serialize", "getattr", "isinstance", "self.fields.items"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def serialize(\n    self, obj: typing.Any\n) -> typing.Optional[typing.Dict[str, typing.Any]]:\n    if obj is None:\n        return None\n\n    is_mapping = isinstance(obj, dict)\n\n    ret = {}\n    for key, field in self.fields.items():\n        try:\n            value = obj[key] if is_mapping else getattr(obj, key)\n        except (KeyError, AttributeError):\n            continue\n        ret[key] = field.serialize(value)\n    return ret", "loc": 16}
{"file": "typesystem\\typesystem\\schemas.py", "class_name": "Reference", "function_name": "validate", "parameters": ["self", "value"], "param_types": {"value": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.target.validate", "self.validation_error"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate(self, value: typing.Any) -> typing.Any:\n    if value is None and self.allow_null:\n        return None\n    elif value is None:\n        raise self.validation_error(\"null\")\n\n    return self.target.validate(value)", "loc": 7}
{"file": "typesystem\\typesystem\\unique.py", "class_name": "Uniqueness", "function_name": "make_hashable", "parameters": ["self", "element"], "param_types": {"element": "typing.Any"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["element.items", "isinstance", "self.make_hashable", "tuple"], "control_structures": ["If"], "behavior_type": ["logic"], "doc_summary": "Coerce a primitive into a uniquely hashable type, for uniqueness checks.", "source_code": "def make_hashable(self, element: typing.Any) -> typing.Any:\n    \"\"\"\n    Coerce a primitive into a uniquely hashable type, for uniqueness checks.\n    \"\"\"\n\n    # Only primitive types can be handled.\n    assert (element is None) or isinstance(\n        element, (bool, int, float, str, list, dict)\n    )\n\n    if element is True:\n        # Need to make `True` distinct from `1`.\n        return self.TRUE\n    elif element is False:\n        # Need to make `False` distinct from `0`.\n        return self.FALSE\n    elif isinstance(element, list):\n        # Represent lists using a two-tuple of ('list', (item, item, ...))\n        return (\"list\", tuple([self.make_hashable(item) for item in element]))\n    elif isinstance(element, dict):\n        # Represent dicts\n        # using a two-tuple of('dict', ((key, val), (key, val), ...))\n        return (\n            \"dict\",\n            tuple(\n                [\n                    (self.make_hashable(key), self.make_hashable(value))\n                    for key, value in element.items()\n                ]\n            ),\n        )\n\n    return element", "loc": 33}
{"file": "typesystem\\typesystem\\tokenize\\positional_validation.py", "class_name": null, "function_name": "validate_with_positions", "parameters": [], "param_types": {}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["Message", "ValidationError", "error.messages", "messages.append", "sorted", "token.lookup", "validator.validate"], "control_structures": ["For", "If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def validate_with_positions(\n    *, token: Token, validator: typing.Union[Field, Schema]\n) -> typing.Any:\n    try:\n        return validator.validate(token.value)\n    except ValidationError as error:\n        messages = []\n        for message in error.messages():\n            if message.code == \"required\":\n                field = message.index[-1]\n                token = token.lookup(message.index[:-1])\n                text = f\"The field {field!r} is required.\"\n            else:\n                token = token.lookup(message.index)\n                text = message.text\n\n            positional_message = Message(\n                text=text,\n                code=message.code,\n                index=message.index,\n                start_position=token.start,\n                end_position=token.end,\n            )\n            messages.append(positional_message)\n        messages = sorted(\n            messages, key=lambda m: m.start_position.char_index  # type: ignore\n        )\n        raise ValidationError(messages=messages)", "loc": 28}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_json.py", "class_name": null, "function_name": "tokenize_json", "parameters": ["content"], "param_types": {"content": "typing.Union[str, bytes]"}, "return_type": "Token", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ParseError", "Position", "_TokenizingDecoder", "content.decode", "content.strip", "decoder.decode", "isinstance"], "control_structures": ["If", "Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def tokenize_json(content: typing.Union[str, bytes]) -> Token:\n    if isinstance(content, bytes):\n        content = content.decode(\"utf-8\", \"ignore\")\n\n    if not content.strip():\n        # Handle the empty string case explicitly for clear error messaging.\n        position = Position(column_no=1, line_no=1, char_index=0)\n        raise ParseError(text=\"No content.\", code=\"no_content\", position=position)\n\n    decoder = _TokenizingDecoder(content=content)\n    try:\n        return decoder.decode(content)\n    except JSONDecodeError as exc:\n        # Handle cases that result in a JSON parse error.\n        position = Position(column_no=exc.colno, line_no=exc.lineno, char_index=exc.pos)\n        raise ParseError(text=exc.msg + \".\", code=\"parse_error\", position=position)", "loc": 16}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_json.py", "class_name": null, "function_name": "validate_json", "parameters": ["content", "validator"], "param_types": {"content": "typing.Union[str, bytes]", "validator": "typing.Union[Field, Schema]"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["tokenize_json", "validate_with_positions"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Parse and validate a JSON string, returning positionally marked error messages on parse or validation failures. content - A JSON string or bytestring. validator - A Field instance or Schema class to validate against.", "source_code": "def validate_json(\n    content: typing.Union[str, bytes],\n    validator: typing.Union[Field, Schema],\n) -> typing.Any:\n    \"\"\"\n    Parse and validate a JSON string, returning positionally marked error\n    messages on parse or validation failures.\n\n    content - A JSON string or bytestring.\n    validator - A Field instance or Schema class to validate against.\n\n    Returns a two-tuple of (value, error_messages)\n    \"\"\"\n    token = tokenize_json(content)\n    return validate_with_positions(token=token, validator=validator)", "loc": 15}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_json.py", "class_name": null, "function_name": "scan_once", "parameters": ["string", "idx"], "param_types": {"string": "str", "idx": "int"}, "return_type": "typing.Tuple[Token, int]", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["_scan_once", "memo.clear"], "control_structures": ["Try"], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def scan_once(string: str, idx: int) -> typing.Tuple[Token, int]:\n    try:\n        return _scan_once(string, idx)\n    finally:\n        memo.clear()", "loc": 5}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_yaml.py", "class_name": null, "function_name": "tokenize_yaml", "parameters": ["content"], "param_types": {"content": "typing.Union[str, bytes]"}, "return_type": "Token", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["CustomSafeLoader.add_constructor", "DictToken", "ListToken", "ParseError", "Position", "ScalarToken", "_get_position", "content.decode", "isinstance", "loader.construct_mapping", "loader.construct_scalar", "loader.construct_sequence", "loader.construct_yaml_bool", "loader.construct_yaml_float", "loader.construct_yaml_int", "loader.construct_yaml_null", "str_content.strip", "yaml.load"], "control_structures": ["If", "Try"], "behavior_type": ["serialization"], "doc_summary": "", "source_code": "def tokenize_yaml(content: typing.Union[str, bytes]) -> Token:\n    assert yaml is not None, \"'pyyaml' must be installed.\"\n\n    if isinstance(content, bytes):\n        str_content = content.decode(\"utf-8\", \"ignore\")\n    else:\n        str_content = content\n\n    if not str_content.strip():\n        # Handle the empty string case explicitly for clear error messaging.\n        position = Position(column_no=1, line_no=1, char_index=0)\n        raise ParseError(text=\"No content.\", code=\"no_content\", position=position)\n\n    class CustomSafeLoader(SafeLoader):\n        pass\n\n    def construct_mapping(loader: \"yaml.Loader\", node: \"yaml.Node\") -> DictToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        mapping = loader.construct_mapping(node)\n        return DictToken(mapping, start, end - 1, content=str_content)\n\n    def construct_sequence(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ListToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_sequence(node)\n        return ListToken(value, start, end - 1, content=str_content)\n\n    def construct_scalar(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_scalar(node)  # type: ignore\n        return ScalarToken(value, start, end - 1, content=str_content)\n\n    def construct_int(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_int(node)\n        return ScalarToken(value, start, end - 1, content=str_content)\n\n    def construct_float(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_float(node)\n        return ScalarToken(value, start, end - 1, content=str_content)\n\n    def construct_bool(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_bool(node)\n        return ScalarToken(value, start, end - 1, content=str_content)\n\n    def construct_null(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n        start = node.start_mark.index\n        end = node.end_mark.index\n        value = loader.construct_yaml_null(node)\n        return ScalarToken(value, start, end - 1, content=str_content)\n\n    CustomSafeLoader.add_constructor(\n        yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG, construct_mapping\n    )\n\n    CustomSafeLoader.add_constructor(\n        yaml.resolver.BaseResolver.DEFAULT_SEQUENCE_TAG, construct_sequence\n    )\n\n    CustomSafeLoader.add_constructor(\n        yaml.resolver.BaseResolver.DEFAULT_SCALAR_TAG, construct_scalar\n    )\n\n    CustomSafeLoader.add_constructor(\"tag:yaml.org,2002:int\", construct_int)\n\n    CustomSafeLoader.add_constructor(\"tag:yaml.org,2002:float\", construct_float)\n\n    CustomSafeLoader.add_constructor(\"tag:yaml.org,2002:bool\", construct_bool)\n\n    CustomSafeLoader.add_constructor(\"tag:yaml.org,2002:null\", construct_null)\n\n    try:\n        return yaml.load(str_content, CustomSafeLoader)\n    except (yaml.scanner.ScannerError, yaml.parser.ParserError) as exc:  # type: ignore\n        # Handle cases that result in a YAML parse error.\n        assert exc.problem is not None\n        assert exc.problem_mark is not None\n        text = exc.problem + \".\"\n        position = _get_position(str_content, index=exc.problem_mark.index)\n        raise ParseError(text=text, code=\"parse_error\", position=position)", "loc": 87}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_yaml.py", "class_name": null, "function_name": "validate_yaml", "parameters": ["content", "validator"], "param_types": {"content": "typing.Union[str, bytes]", "validator": "typing.Union[Field, Schema]"}, "return_type": "typing.Any", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["tokenize_yaml", "validate_with_positions"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Parse and validate a YAML string, returning positionally marked error messages on parse or validation failures. content - A YAML string or bytestring. validator - A Field instance or Schema class to validate against.", "source_code": "def validate_yaml(\n    content: typing.Union[str, bytes],\n    validator: typing.Union[Field, Schema],\n) -> typing.Any:\n    \"\"\"\n    Parse and validate a YAML string, returning positionally marked error\n    messages on parse or validation failures.\n\n    content - A YAML string or bytestring.\n    validator - A Field instance or Schema class to validate against.\n\n    Returns a two-tuple of (value, error_messages)\n    \"\"\"\n    assert yaml is not None, \"'pyyaml' must be installed.\"\n\n    token = tokenize_yaml(content)\n    return validate_with_positions(token=token, validator=validator)", "loc": 17}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_yaml.py", "class_name": null, "function_name": "construct_mapping", "parameters": ["loader", "node"], "param_types": {"loader": "'yaml.Loader'", "node": "'yaml.Node'"}, "return_type": "DictToken", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["DictToken", "loader.construct_mapping"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def construct_mapping(loader: \"yaml.Loader\", node: \"yaml.Node\") -> DictToken:\n    start = node.start_mark.index\n    end = node.end_mark.index\n    mapping = loader.construct_mapping(node)\n    return DictToken(mapping, start, end - 1, content=str_content)", "loc": 5}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_yaml.py", "class_name": null, "function_name": "construct_sequence", "parameters": ["loader", "node"], "param_types": {"loader": "'yaml.Loader'", "node": "'yaml.Node'"}, "return_type": "ListToken", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ListToken", "loader.construct_sequence"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def construct_sequence(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ListToken:\n    start = node.start_mark.index\n    end = node.end_mark.index\n    value = loader.construct_sequence(node)\n    return ListToken(value, start, end - 1, content=str_content)", "loc": 5}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_yaml.py", "class_name": null, "function_name": "construct_scalar", "parameters": ["loader", "node"], "param_types": {"loader": "'yaml.Loader'", "node": "'yaml.Node'"}, "return_type": "ScalarToken", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ScalarToken", "loader.construct_scalar"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def construct_scalar(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n    start = node.start_mark.index\n    end = node.end_mark.index\n    value = loader.construct_scalar(node)  # type: ignore\n    return ScalarToken(value, start, end - 1, content=str_content)", "loc": 5}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_yaml.py", "class_name": null, "function_name": "construct_int", "parameters": ["loader", "node"], "param_types": {"loader": "'yaml.Loader'", "node": "'yaml.Node'"}, "return_type": "ScalarToken", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ScalarToken", "loader.construct_yaml_int"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def construct_int(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n    start = node.start_mark.index\n    end = node.end_mark.index\n    value = loader.construct_yaml_int(node)\n    return ScalarToken(value, start, end - 1, content=str_content)", "loc": 5}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_yaml.py", "class_name": null, "function_name": "construct_float", "parameters": ["loader", "node"], "param_types": {"loader": "'yaml.Loader'", "node": "'yaml.Node'"}, "return_type": "ScalarToken", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ScalarToken", "loader.construct_yaml_float"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def construct_float(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n    start = node.start_mark.index\n    end = node.end_mark.index\n    value = loader.construct_yaml_float(node)\n    return ScalarToken(value, start, end - 1, content=str_content)", "loc": 5}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_yaml.py", "class_name": null, "function_name": "construct_bool", "parameters": ["loader", "node"], "param_types": {"loader": "'yaml.Loader'", "node": "'yaml.Node'"}, "return_type": "ScalarToken", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ScalarToken", "loader.construct_yaml_bool"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def construct_bool(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n    start = node.start_mark.index\n    end = node.end_mark.index\n    value = loader.construct_yaml_bool(node)\n    return ScalarToken(value, start, end - 1, content=str_content)", "loc": 5}
{"file": "typesystem\\typesystem\\tokenize\\tokenize_yaml.py", "class_name": null, "function_name": "construct_null", "parameters": ["loader", "node"], "param_types": {"loader": "'yaml.Loader'", "node": "'yaml.Node'"}, "return_type": "ScalarToken", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["ScalarToken", "loader.construct_yaml_null"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "", "source_code": "def construct_null(loader: \"yaml.Loader\", node: \"yaml.Node\") -> ScalarToken:\n    start = node.start_mark.index\n    end = node.end_mark.index\n    value = loader.construct_yaml_null(node)\n    return ScalarToken(value, start, end - 1, content=str_content)", "loc": 5}
{"file": "typesystem\\typesystem\\tokenize\\tokens.py", "class_name": "Token", "function_name": "lookup", "parameters": ["self", "index"], "param_types": {"index": "list"}, "return_type": "'Token'", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["token._get_child_token"], "control_structures": ["For"], "behavior_type": ["logic"], "doc_summary": "Given an index, lookup a child token within this structure.", "source_code": "def lookup(self, index: list) -> \"Token\":\n    \"\"\"\n    Given an index, lookup a child token within this structure.\n    \"\"\"\n    token = self\n    for key in index:\n        token = token._get_child_token(key)\n    return token", "loc": 8}
{"file": "typesystem\\typesystem\\tokenize\\tokens.py", "class_name": "Token", "function_name": "lookup_key", "parameters": ["self", "index"], "param_types": {"index": "list"}, "return_type": "'Token'", "param_doc": {}, "return_doc": "", "raises_doc": [], "called_functions": ["self.lookup", "token._get_key_token"], "control_structures": [], "behavior_type": ["logic"], "doc_summary": "Given an index, lookup a token for a dictionary key within this structure.", "source_code": "def lookup_key(self, index: list) -> \"Token\":\n    \"\"\"\n    Given an index, lookup a token for a dictionary key within this structure.\n    \"\"\"\n    token = self.lookup(index[:-1])\n    return token._get_key_token(index[-1])", "loc": 6}
